<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: Using Azure AI Foundry to manage all your Large Language Models</title>
    <meta name="description" content="One model, extra large, please!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/Peter%20De%20Tender_llm.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Using Azure AI Foundry to manage all your Large Language Models | Conf42"/>
    <meta property="og:description" content="Microsoft embraced OpenAI for their Copilot and Azure AI solutions early 2024. But did you know, now more than a year later, you can deploy several other LLMs from different vendors, using your trusted Azure environment? Thanks to Azure AI Foundry."/>
    <meta property="og:url" content="https://conf42.com/Large_Language_Models_LLMs_2025_Peter_De_Tender_azure_models_management"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/LLM2025_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Large Language Models (LLMs) 2025
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2025-03-20
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/llms2025" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2025">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2025">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2025">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2025">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2025">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2025">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2025">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2025">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2025">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2025">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2025">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/robotics2025">
                            Robotics
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2025">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2025">
                            Internet of Things (IoT)
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="https://conf42.circle.so/">
                            <b>Community platform login</b>
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Join the community!
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #CCB87B;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Large Language Models (LLMs) 2025 - Online
            </h1>

            <h2 class="text-white">
              
              Content unlocked! Welcome to the community!
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- One model, extra large, please!
 -->
              <script>
                const event_date = new Date("2025-03-20T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2025-03-20T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "39HKmrC3AHI"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://www.youtube.com/playlist?list=PLIuxSyKxlQrCnqe_gWc_lIVyDmyIx8BQG" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hey everyone.", "timestamp": "00:00:00,330", "timestamp_s": 0.0}, {"text": "Welcome to com 42 on large language models.", "timestamp": "00:00:01,350", "timestamp_s": 1.0}, {"text": "My name is Peter Deten, technical trainer at Microsoft Live,", "timestamp": "00:00:05,970", "timestamp_s": 5.0}, {"text": "presenting from Redmond, Washington.", "timestamp": "00:00:09,570", "timestamp_s": 9.0}, {"text": "My session today covers using Azure AI Foundry to manage all", "timestamp": "00:00:11,730", "timestamp_s": 11.0}, {"text": "your large language models.", "timestamp": "00:00:16,560", "timestamp_s": 16.0}, {"text": "With that, I would say welcome and let\u0027s go.", "timestamp": "00:00:18,870", "timestamp_s": 18.0}, {"text": "Over the next 45 minutes to an hour, I will cover the following topics, starting", "timestamp": "00:00:21,740", "timestamp_s": 21.0}, {"text": "with a quick overview of the future of work with ai, followed by domain", "timestamp": "00:00:26,630", "timestamp_s": 26.0}, {"text": "section, how Azure AI Foundry is used by Microsoft itself to run AI solutions and", "timestamp": "00:00:32,030", "timestamp_s": 32.0}, {"text": "obviously how you can leverage the same.", "timestamp": "00:00:38,300", "timestamp_s": 38.0}, {"text": "And then last, how to bring in a rag architecture, meaning using all the beauty", "timestamp": "00:00:41,480", "timestamp_s": 41.0}, {"text": "from Azure AI together with AI Foundry.", "timestamp": "00:00:46,849", "timestamp_s": 46.0}, {"text": "Generative AI using large language models, but then also integrating your own data.", "timestamp": "00:00:50,060", "timestamp_s": 50.0}, {"text": "And then for each of these topics, you can expect quite some live", "timestamp": "00:00:56,000", "timestamp_s": 56.0}, {"text": "demos during the session as well.", "timestamp": "00:00:59,510", "timestamp_s": 59.0}, {"text": "So again, my name is Peter d Tander originally.", "timestamp": "00:01:02,890", "timestamp_s": 62.0}, {"text": "Originally from Belgium, but ated to Redmond, Washington to continue my", "timestamp": "00:01:06,450", "timestamp_s": 66.0}, {"text": "job as a Microsoft technical trainer.", "timestamp": "00:01:10,619", "timestamp_s": 70.0}, {"text": "I\u0027ve been a Microsoft trainer for about six years now.", "timestamp": "00:01:13,200", "timestamp_s": 73.0}, {"text": "before I joined Microsoft in a full-time employee position, I was already working", "timestamp": "00:01:16,150", "timestamp_s": 76.0}, {"text": "for them as a partner and vendor out of my own company for about seven years.", "timestamp": "00:01:20,860", "timestamp_s": 80.0}, {"text": "My Azure background has always been on the infra and in architecture side, but", "timestamp": "00:01:25,590", "timestamp_s": 85.0}, {"text": "gradually I shifted more into DevOps developing Azure solutions, and nowadays,", "timestamp": "00:01:30,360", "timestamp_s": 90.0}, {"text": "obviously a lot about AI and copilot.", "timestamp": "00:01:35,220", "timestamp_s": 95.0}, {"text": "Feel free to reach out if you should have any questions using", "timestamp": "00:01:38,820", "timestamp_s": 98.0}, {"text": "any of the listed methods.", "timestamp": "00:01:42,420", "timestamp_s": 102.0}, {"text": "Good.", "timestamp": "00:01:45,100", "timestamp_s": 105.0}, {"text": "So with that all out of the way, let\u0027s jump in.", "timestamp": "00:01:45,350", "timestamp_s": 105.0}, {"text": "Now.", "timestamp": "00:01:48,530", "timestamp_s": 108.0}, {"text": "When I talk about AI in any of the Azure and AI workshops I\u0027m", "timestamp": "00:01:48,680", "timestamp_s": 108.0}, {"text": "teaching, I always like to start with a quote from our CEO Satya.", "timestamp": "00:01:53,150", "timestamp_s": 113.0}, {"text": "He explained it as follows.", "timestamp": "00:01:58,130", "timestamp_s": 118.0}, {"text": "Organizations are asking not only how, but also how fast they can actually", "timestamp": "00:02:00,110", "timestamp_s": 120.0}, {"text": "apply this next generation of AI to address the biggest opportunities", "timestamp": "00:02:06,230", "timestamp_s": 126.0}, {"text": "and challenges they are facing.", "timestamp": "00:02:11,120", "timestamp_s": 131.0}, {"text": "Good with that all out of the way, let\u0027s jump in.", "timestamp": "00:02:13,269", "timestamp_s": 133.0}, {"text": "Now when I talk about AI in our workshops here at Microsoft, I always", "timestamp": "00:02:17,105", "timestamp_s": 137.0}, {"text": "like to start with a quote from our CEO.", "timestamp": "00:02:20,855", "timestamp_s": 140.0}, {"text": "Satya.", "timestamp": "00:02:22,924", "timestamp_s": 142.0}, {"text": "Organizations are asking not only how, but also how fast they can apply this", "timestamp": "00:02:24,454", "timestamp_s": 144.0}, {"text": "next generation of AI to address the biggest challenges, but also opportunities", "timestamp": "00:02:29,734", "timestamp_s": 149.0}, {"text": "they face safely and responsibly.", "timestamp": "00:02:35,015", "timestamp_s": 155.0}, {"text": "Now the core of the quote will become more clear by the end of my", "timestamp": "00:02:38,454", "timestamp_s": 158.0}, {"text": "session, so that, let\u0027s start with the foundation, understanding what", "timestamp": "00:02:41,815", "timestamp_s": 161.0}, {"text": "the future of work with AI looks like.", "timestamp": "00:02:46,225", "timestamp_s": 166.0}, {"text": "For the last two years, give or take, organizations have primarily been", "timestamp": "00:02:48,975", "timestamp_s": 168.0}, {"text": "experimenting with different models.", "timestamp": "00:02:53,265", "timestamp_s": 173.0}, {"text": "I think it is safe to say that OpenAI with Jet GPD revolutionized the world", "timestamp": "00:02:56,115", "timestamp_s": 176.0}, {"text": "with Jet GPD again, end of 2023.", "timestamp": "00:03:01,275", "timestamp_s": 181.0}, {"text": "But from there, several other players came into the market like Gemini,", "timestamp": "00:03:05,115", "timestamp_s": 185.0}, {"text": "from Google, and Tropic with Claude.", "timestamp": "00:03:09,455", "timestamp_s": 189.0}, {"text": "deep seek from China, Microsoft having the five, models, menstrual,", "timestamp": "00:03:12,285", "timestamp_s": 192.0}, {"text": "hugging, face, and so many other.", "timestamp": "00:03:17,125", "timestamp_s": 197.0}, {"text": "Now what this slide represents is how many different models are actually", "timestamp": "00:03:19,435", "timestamp_s": 199.0}, {"text": "being used by an organization.", "timestamp": "00:03:23,605", "timestamp_s": 203.0}, {"text": "The average, you could say here is, 3, 2, 5, so probably four as", "timestamp": "00:03:26,095", "timestamp_s": 206.0}, {"text": "the average where no one on the interviewed organizations was just", "timestamp": "00:03:30,335", "timestamp_s": 210.0}, {"text": "relying on a single large language model for any of their AI solutions.", "timestamp": "00:03:34,295", "timestamp_s": 214.0}, {"text": "Now also important to highlight is that about 80% of early AI projects", "timestamp": "00:03:39,145", "timestamp_s": 219.0}, {"text": "actually fail because not meeting expectations and not meeting them", "timestamp": "00:03:44,065", "timestamp_s": 224.0}, {"text": "because they\u0027re too complex now.", "timestamp": "00:03:48,295", "timestamp_s": 228.0}, {"text": "Complexity and the fact that especially generative AI is", "timestamp": "00:03:50,395", "timestamp_s": 230.0}, {"text": "still rather new technology.", "timestamp": "00:03:54,055", "timestamp_s": 234.0}, {"text": "And also providing a breadth of large language models to", "timestamp": "00:03:55,755", "timestamp_s": 235.0}, {"text": "choose from, but then also.", "timestamp": "00:03:58,965", "timestamp_s": 238.0}, {"text": "The fact that applications are changing, moving from single models", "timestamp": "00:04:02,175", "timestamp_s": 242.0}, {"text": "into orchestrated systems, allowing to learn and adapt continuously.", "timestamp": "00:04:07,245", "timestamp_s": 247.0}, {"text": "Customers and users are expecting AI influenced, or you could", "timestamp": "00:04:12,825", "timestamp_s": 252.0}, {"text": "say AI inspired capabilities.", "timestamp": "00:04:16,845", "timestamp_s": 256.0}, {"text": "In almost any kind of application today across different industries", "timestamp": "00:04:19,455", "timestamp_s": 259.0}, {"text": "and across different use cases.", "timestamp": "00:04:23,835", "timestamp_s": 263.0}, {"text": "Now, even amidst these challenges, it\u0027s clear that generative AI is what makes", "timestamp": "00:04:25,985", "timestamp_s": 265.0}, {"text": "applications through the intelligent, but that\u0027s also a paradigm shift.", "timestamp": "00:04:30,455", "timestamp_s": 270.0}, {"text": "AI is moving from this, I don\u0027t know, autopilot phase, which was all", "timestamp": "00:04:35,365", "timestamp_s": 275.0}, {"text": "about narrowing purpose-built tools that use machine learning models.", "timestamp": "00:04:39,490", "timestamp_s": 279.0}, {"text": "To now come up with predictions recommendations.", "timestamp": "00:04:43,875", "timestamp_s": 283.0}, {"text": "also just automating to now having this co-pilot era where there\u0027s tremendous", "timestamp": "00:04:46,935", "timestamp_s": 286.0}, {"text": "opportunity to really revolutionize how just about everything can start", "timestamp": "00:04:53,235", "timestamp_s": 293.0}, {"text": "using those intelligent applications.", "timestamp": "00:04:58,745", "timestamp_s": 298.0}, {"text": "You can now enable natural language interaction, constantly improving user", "timestamp": "00:05:00,875", "timestamp_s": 300.0}, {"text": "experience and quickly delivering new features and capabilities to the market.", "timestamp": "00:05:05,375", "timestamp_s": 305.0}, {"text": "So with that, let\u0027s shift gears a little bit and talk about", "timestamp": "00:05:10,675", "timestamp_s": 310.0}, {"text": "Azure AI Foundry specifically.", "timestamp": "00:05:13,735", "timestamp_s": 313.0}, {"text": "By the way, one of the reasons Microsoft has moved such fast pace over the last", "timestamp": "00:05:16,525", "timestamp_s": 316.0}, {"text": "few months is because our Microsoft AI solutions within Microsoft are", "timestamp": "00:05:20,995", "timestamp_s": 320.0}, {"text": "all running using Azure AI Foundry.", "timestamp": "00:05:25,945", "timestamp_s": 325.0}, {"text": "Now we\u0027ve built our Microsoft copilot reaching in meantime,", "timestamp": "00:05:28,755", "timestamp_s": 328.0}, {"text": "millions of users across the globe.", "timestamp": "00:05:32,925", "timestamp_s": 332.0}, {"text": "Informing them across different platforms using, for example, just copilot on", "timestamp": "00:05:35,775", "timestamp_s": 335.0}, {"text": "the mobile device in the browser, using copilot web, using copilot", "timestamp": "00:05:40,245", "timestamp_s": 340.0}, {"text": "within Microsoft 3 6 5 applications, security copilot dynamics copilot,", "timestamp": "00:05:44,595", "timestamp_s": 344.0}, {"text": "Azure co-pilot, and GitHub copilot.", "timestamp": "00:05:50,145", "timestamp_s": 350.0}, {"text": "All of these co-pilot are a hundred percent begged by Azure AI Foundry.", "timestamp": "00:05:53,175", "timestamp_s": 353.0}, {"text": "Which now also becomes available to you.", "timestamp": "00:05:58,535", "timestamp_s": 358.0}, {"text": "So you might have heard about Azure AI Studio before, where it\u0027s still the same", "timestamp": "00:06:02,045", "timestamp_s": 362.0}, {"text": "foundation, I would say being the one-stop shop, like a management portal for", "timestamp": "00:06:06,455", "timestamp_s": 366.0}, {"text": "developers IT sales admins, cloud admins.", "timestamp": "00:06:11,345", "timestamp_s": 371.0}, {"text": "If you want to create your own custom copilots leveraging ai, Azure AI services.", "timestamp": "00:06:14,105", "timestamp_s": 374.0}, {"text": "So insured Azure AI Foundry is a trusted, integrated platform designed for", "timestamp": "00:06:21,665", "timestamp_s": 381.0}, {"text": "developers, IT admins, cloud architects, allowing them to design, customize, and", "timestamp": "00:06:26,975", "timestamp_s": 386.0}, {"text": "manage AI applications as well as agents.", "timestamp": "00:06:32,645", "timestamp_s": 392.0}, {"text": "Nowadays, it offers a rich set of AI capabilities and tools, and yes, I\u0027ll", "timestamp": "00:06:35,675", "timestamp_s": 395.0}, {"text": "walk you through a few of these in a demo using an easy to use, easy to navigate.", "timestamp": "00:06:40,675", "timestamp_s": 400.0}, {"text": "Portal, but there\u0027s also a unified SDK providing you APIs to really accelerate", "timestamp": "00:06:46,165", "timestamp_s": 406.0}, {"text": "the path from developing to production.", "timestamp": "00:06:52,225", "timestamp_s": 412.0}, {"text": "Now, what sets Azure AI Foundry apart is the accessibility through the world\u0027s", "timestamp": "00:06:54,915", "timestamp_s": 414.0}, {"text": "most loved developer tools, meaning GitHub Visual Studio and co-pilot studio.", "timestamp": "00:06:59,595", "timestamp_s": 419.0}, {"text": "This really integrates with a lot of other scenarios.", "timestamp": "00:07:05,770", "timestamp_s": 425.0}, {"text": "So what we see here is continuously building up on Azure AI Foundry being this", "timestamp": "00:07:09,640", "timestamp_s": 429.0}, {"text": "open, flexible, modular platform, sorry, with a lot of the tools a developer needs", "timestamp": "00:07:15,010", "timestamp_s": 435.0}, {"text": "in a single platform to build multi-agent solutions, integrating third party tools.", "timestamp": "00:07:20,760", "timestamp_s": 440.0}, {"text": "Just like we\u0027ve done with our own models.", "timestamp": "00:07:26,465", "timestamp_s": 446.0}, {"text": "This also means that developers now get access to Quick Start AI application", "timestamp": "00:07:28,885", "timestamp_s": 448.0}, {"text": "templates to support their development cycle and really shortening that", "timestamp": "00:07:33,085", "timestamp_s": 453.0}, {"text": "complexity that I talked about before.", "timestamp": "00:07:37,525", "timestamp_s": 457.0}, {"text": "Any of these templates can be customized using a wide area of already existing", "timestamp": "00:07:40,395", "timestamp_s": 460.0}, {"text": "models and tools, making your applications future-proof development investments.", "timestamp": "00:07:45,345", "timestamp_s": 465.0}, {"text": "Another part I wanna talk about is it governance.", "timestamp": "00:07:51,425", "timestamp_s": 471.0}, {"text": "So IT governance at scale, like what we call here, enterprise", "timestamp": "00:07:54,425", "timestamp_s": 474.0}, {"text": "setup is baked in AI foundry.", "timestamp": "00:07:57,905", "timestamp_s": 477.0}, {"text": "It allows you to provide a comprehensive approach providing self-service", "timestamp": "00:08:01,295", "timestamp_s": 481.0}, {"text": "experiences, customizable configurations, and overall enhancing agility, security,", "timestamp": "00:08:05,375", "timestamp_s": 485.0}, {"text": "but also keeping compliance in mind.", "timestamp": "00:08:11,795", "timestamp_s": 491.0}, {"text": "So to give you an idea, there\u0027s obviously prebuilt baked in.", "timestamp": "00:08:14,495", "timestamp_s": 494.0}, {"text": "Azure and Azure AI Foundry, role-based access control, including like owner", "timestamp": "00:08:18,670", "timestamp_s": 498.0}, {"text": "having you, giving you all permissions, including changing security permissions.", "timestamp": "00:08:23,890", "timestamp_s": 503.0}, {"text": "They\u0027re a little bit lower permission contributor, but there\u0027s", "timestamp": "00:08:28,955", "timestamp_s": 508.0}, {"text": "also reader ai, developer and AI inference deployment operator roles.", "timestamp": "00:08:32,135", "timestamp_s": 512.0}, {"text": "Little bit complex there.", "timestamp": "00:08:38,015", "timestamp_s": 518.0}, {"text": "but what it means is like for any kind of responsibility as", "timestamp": "00:08:39,505", "timestamp_s": 519.0}, {"text": "part of your development cycle.", "timestamp": "00:08:43,465", "timestamp_s": 523.0}, {"text": "You can have, a corresponding role-based access control.", "timestamp": "00:08:45,390", "timestamp_s": 525.0}, {"text": "Next to that, all these roles, are accessible from within the same AI", "timestamp": "00:08:49,680", "timestamp_s": 529.0}, {"text": "foundry where we now use a topology called the hub and projects out of the hub.", "timestamp": "00:08:53,460", "timestamp_s": 533.0}, {"text": "It\u0027s like the highest level in the topology.", "timestamp": "00:08:59,100", "timestamp_s": 539.0}, {"text": "You\u0027re gonna allocate one or more projects, and within a", "timestamp": "00:09:01,920", "timestamp_s": 541.0}, {"text": "project you\u0027re gonna define.", "timestamp": "00:09:04,980", "timestamp_s": 544.0}, {"text": "The different, permissions On top of that, you can think about other", "timestamp": "00:09:06,680", "timestamp_s": 546.0}, {"text": "features, mentioned here on the diagram.", "timestamp": "00:09:11,440", "timestamp_s": 551.0}, {"text": "Identity, access management, network security, data protection,", "timestamp": "00:09:14,315", "timestamp_s": 554.0}, {"text": "encryption, compute, storage, quota, access to the models.", "timestamp": "00:09:18,525", "timestamp_s": 558.0}, {"text": "All that is now becoming available within a project and within a hub.", "timestamp": "00:09:22,935", "timestamp_s": 562.0}, {"text": "Mainly avoiding that each and every developer when they\u0027re working", "timestamp": "00:09:28,725", "timestamp_s": 568.0}, {"text": "on an AI inspired application that they have to deploy, like", "timestamp": "00:09:32,265", "timestamp_s": 572.0}, {"text": "the full architecture themselves.", "timestamp": "00:09:36,035", "timestamp_s": 576.0}, {"text": "So you would almost say that your cloud team is now building the hub and project.", "timestamp": "00:09:38,165", "timestamp_s": 578.0}, {"text": "And developers are consuming the services, the building blocks within", "timestamp": "00:09:43,355", "timestamp_s": 583.0}, {"text": "a project, and then on the outside.", "timestamp": "00:09:47,705", "timestamp_s": 587.0}, {"text": "And then on the outside we have our business it.", "timestamp": "00:09:50,595", "timestamp_s": 590.0}, {"text": "And from there we could also expand with IT security because in the", "timestamp": "00:09:53,535", "timestamp_s": 593.0}, {"text": "end, it\u0027s still part of the broader Azure world, which means that", "timestamp": "00:09:58,605", "timestamp_s": 598.0}, {"text": "everything you might already know.", "timestamp": "00:10:01,755", "timestamp_s": 601.0}, {"text": "From Azure Tenants, Azure subscriptions management groups, like the whole", "timestamp": "00:10:03,840", "timestamp_s": 603.0}, {"text": "governance layer around it is now also still valid once you start", "timestamp": "00:10:07,770", "timestamp_s": 607.0}, {"text": "deploying your AI foundry and corresponding Azure Resources.", "timestamp": "00:10:11,970", "timestamp_s": 611.0}, {"text": "Apart from the core AI services dependencies extended with other", "timestamp": "00:10:16,550", "timestamp_s": 616.0}, {"text": "Azure resources like E Vault, private networking, and the like.", "timestamp": "00:10:20,480", "timestamp_s": 620.0}, {"text": "You can now also easily, I would say, provide access to those external", "timestamp": "00:10:24,350", "timestamp_s": 624.0}, {"text": "resources from within AI Foundry using a feature called Connections.", "timestamp": "00:10:28,340", "timestamp_s": 628.0}, {"text": "So again, it means that instead of needing to provide access to your development", "timestamp": "00:10:34,040", "timestamp_s": 634.0}, {"text": "team, your IT Cloud admins to all those resources, it\u0027s now becoming just another", "timestamp": "00:10:38,240", "timestamp_s": 638.0}, {"text": "aspect of your AI Foundry landscape.", "timestamp": "00:10:43,790", "timestamp_s": 643.0}, {"text": "And these connections are typically already linked to", "timestamp": "00:10:46,880", "timestamp_s": 646.0}, {"text": "multiple projects within a hub.", "timestamp": "00:10:49,550", "timestamp_s": 649.0}, {"text": "And with that, let\u0027s shift to a first demo here where I\u0027ll walk you through the", "timestamp": "00:10:51,820", "timestamp_s": 651.0}, {"text": "base deployment of Azure AI services, as well as a first look at Azure AI Foundry,", "timestamp": "00:10:55,540", "timestamp_s": 655.0}, {"text": "showing you the hope and project, as well as how to add and manage your connections.", "timestamp": "00:11:01,840", "timestamp_s": 661.0}, {"text": "So my starting point here is my Azure subscription, and I got everything inside", "timestamp": "00:11:06,960", "timestamp_s": 666.0}, {"text": "my, sample com 42 Foundry resource group.", "timestamp": "00:11:13,680", "timestamp_s": 673.0}, {"text": "I already deployed most of the resources that I need, but my", "timestamp": "00:11:18,160", "timestamp_s": 678.0}, {"text": "assumption is that you already know how to deploy some resource in Azure.", "timestamp": "00:11:23,090", "timestamp_s": 683.0}, {"text": "So not all that important.", "timestamp": "00:11:27,710", "timestamp_s": 687.0}, {"text": "for now.", "timestamp": "00:11:29,280", "timestamp_s": 689.0}, {"text": "One of the building blocks I have is an Azure AI hub.", "timestamp": "00:11:29,990", "timestamp_s": 689.0}, {"text": "I\u0027ll talk about that a little bit again later on.", "timestamp": "00:11:34,100", "timestamp_s": 694.0}, {"text": "Within, we got a project, the core that I\u0027m using here is Azure AI Services,", "timestamp": "00:11:37,070", "timestamp_s": 697.0}, {"text": "and I got a few site services over here, like a container registry and Azure Key", "timestamp": "00:11:43,010", "timestamp_s": 703.0}, {"text": "Vault log analytics for my monitoring.", "timestamp": "00:11:48,380", "timestamp_s": 708.0}, {"text": "So the starting point will most probably be your AI service, which means that", "timestamp": "00:11:51,170", "timestamp_s": 711.0}, {"text": "you would go into the Azure portal.", "timestamp": "00:11:57,050", "timestamp_s": 717.0}, {"text": "From there, you would deploy a new service called Azure AI", "timestamp": "00:11:59,470", "timestamp_s": 719.0}, {"text": "Service, and that\u0027s pretty much it.", "timestamp": "00:12:02,920", "timestamp_s": 722.0}, {"text": "Now, from a development perspective, there are a few things that you need to keep in", "timestamp": "00:12:05,830", "timestamp_s": 725.0}, {"text": "mind for connecting to your AI service.", "timestamp": "00:12:09,940", "timestamp_s": 729.0}, {"text": "Primarily, I would say here, endpoints and your keys.", "timestamp": "00:12:14,280", "timestamp_s": 734.0}, {"text": "So when we move to endpoints, what we have is obviously depending", "timestamp": "00:12:18,060", "timestamp_s": 738.0}, {"text": "on the different AI use cases.", "timestamp": "00:12:22,230", "timestamp_s": 742.0}, {"text": "In my example here, I\u0027m using OpenAI to really have that generative AI", "timestamp": "00:12:24,660", "timestamp_s": 744.0}, {"text": "capability available as an endpoint allowing me to integrate later on", "timestamp": "00:12:29,490", "timestamp_s": 749.0}, {"text": "my large language models and so much more out of my foundry interface.", "timestamp": "00:12:35,790", "timestamp_s": 755.0}, {"text": "I. If I wanna interact with other AI services like the", "timestamp": "00:12:40,200", "timestamp_s": 760.0}, {"text": "more traditional ones, right?", "timestamp": "00:12:44,090", "timestamp_s": 764.0}, {"text": "Compute, vision, content, safety, language, translator, I can again", "timestamp": "00:12:45,650", "timestamp_s": 765.0}, {"text": "find all that information up here.", "timestamp": "00:12:49,730", "timestamp_s": 769.0}, {"text": "Now, the reason why, we have our AI Foundry as a portal is because in", "timestamp": "00:12:52,450", "timestamp_s": 772.0}, {"text": "the end from here, what I\u0027m doing is just managing the Azure resources.", "timestamp": "00:12:57,500", "timestamp_s": 777.0}, {"text": "So you could almost say that this should be a part.", "timestamp": "00:13:02,780", "timestamp_s": 782.0}, {"text": "That maybe your developer is not really seeing anymore.", "timestamp": "00:13:05,535", "timestamp_s": 785.0}, {"text": "Why not?", "timestamp": "00:13:09,105", "timestamp_s": 789.0}, {"text": "Because for them, everything that is related to management", "timestamp": "00:13:09,555", "timestamp_s": 789.0}, {"text": "is now moved into AI Foundry.", "timestamp": "00:13:13,575", "timestamp_s": 793.0}, {"text": "By the way, if you navigate back to the starting point AI service,", "timestamp": "00:13:16,695", "timestamp_s": 796.0}, {"text": "you can see down here there is the Azure AI Foundry portal link.", "timestamp": "00:13:21,125", "timestamp_s": 801.0}, {"text": "So let me move over to that one, and that\u0027s where we are now,", "timestamp": "00:13:26,465", "timestamp_s": 806.0}, {"text": "landing in our Foundry portal.", "timestamp": "00:13:29,785", "timestamp_s": 809.0}, {"text": "Now, there\u0027s a few different ways you can.", "timestamp": "00:13:32,515", "timestamp_s": 812.0}, {"text": "You\u0027d end up here.", "timestamp": "00:13:34,285", "timestamp_s": 814.0}, {"text": "So I talked about the hub and project, right?", "timestamp": "00:13:35,305", "timestamp_s": 815.0}, {"text": "But when within my setup here, you won\u0027t really see that.", "timestamp": "00:13:39,175", "timestamp_s": 819.0}, {"text": "So depending a bit how you get there, you\u0027re gonna see that.", "timestamp": "00:13:43,875", "timestamp_s": 823.0}, {"text": "Right now here I\u0027m in my Azure open AI service because for", "timestamp": "00:13:46,935", "timestamp_s": 826.0}, {"text": "this scenario, I started from deploying an open ai Azure service.", "timestamp": "00:13:51,375", "timestamp_s": 831.0}, {"text": "now if I navigate to my other scenario, I\u0027m now in my Azure AI foundry, homepage", "timestamp": "00:13:57,455", "timestamp_s": 837.0}, {"text": "you could say, which by the way, you can navigate to from ai.azure.com.", "timestamp": "00:14:04,575", "timestamp_s": 844.0}, {"text": "And within.", "timestamp": "00:14:10,855", "timestamp_s": 850.0}, {"text": "As you can see here, I do have my hub and my project.", "timestamp": "00:14:12,385", "timestamp_s": 852.0}, {"text": "When I navigate to my hub, you\u0027re gonna see some highlights", "timestamp": "00:14:16,525", "timestamp_s": 856.0}, {"text": "from my Azure subscription.", "timestamp": "00:14:20,545", "timestamp_s": 860.0}, {"text": "So down here I can still see my Azure subscription.", "timestamp": "00:14:22,735", "timestamp_s": 862.0}, {"text": "I could switch back to manage it in my Azure portal, but now I can also,", "timestamp": "00:14:26,065", "timestamp_s": 866.0}, {"text": "as a developer, picking up the AI endpoints and keys that I need from here.", "timestamp": "00:14:30,805", "timestamp_s": 870.0}, {"text": "So instead of now just having my open AI service, it\u0027s not.", "timestamp": "00:14:36,225", "timestamp_s": 876.0}, {"text": "Now switched, you could say, to Azure AI Foundry Management Center.", "timestamp": "00:14:40,095", "timestamp_s": 880.0}, {"text": "Within the management center, we have obviously the overview", "timestamp": "00:14:46,925", "timestamp_s": 886.0}, {"text": "of our hubs and projects.", "timestamp": "00:14:50,825", "timestamp_s": 890.0}, {"text": "And again, the logic is that you would create one or more hubs as", "timestamp": "00:14:52,535", "timestamp_s": 892.0}, {"text": "the higher level in the topology and underneath you would create", "timestamp": "00:14:56,525", "timestamp_s": 896.0}, {"text": "one or more projects within a hub.", "timestamp": "00:15:00,395", "timestamp_s": 900.0}, {"text": "So that\u0027s the relationship you can see from here.", "timestamp": "00:15:03,335", "timestamp_s": 903.0}, {"text": "I got my AI project as part of my.", "timestamp": "00:15:07,145", "timestamp_s": 907.0}, {"text": "AI hub.", "timestamp": "00:15:09,875", "timestamp_s": 909.0}, {"text": "That\u0027s the logic behind it.", "timestamp": "00:15:10,595", "timestamp_s": 910.0}, {"text": "Staying within the hub level for a minute.", "timestamp": "00:15:12,715", "timestamp_s": 912.0}, {"text": "I talked about RAC, role-based access control, where now you can see I got", "timestamp": "00:15:17,365", "timestamp_s": 917.0}, {"text": "my AI admin and a little bit lower.", "timestamp": "00:15:21,595", "timestamp_s": 921.0}, {"text": "I got my Azure ML data scientists replicating that you have someone", "timestamp": "00:15:25,255", "timestamp_s": 925.0}, {"text": "managing the AI service and you might have some data scientist on the other side", "timestamp": "00:15:29,845", "timestamp_s": 929.0}, {"text": "interacting with the storage, providing, the data endpoints most probably.", "timestamp": "00:15:34,975", "timestamp_s": 934.0}, {"text": "And then from there, allowing my developers to start interacting.", "timestamp": "00:15:39,845", "timestamp_s": 939.0}, {"text": "You can manage your quota.", "timestamp": "00:15:44,005", "timestamp_s": 944.0}, {"text": "So if I switch back up here, one of the, I would say.", "timestamp": "00:15:46,495", "timestamp_s": 946.0}, {"text": "Configuration options you have within Azure.", "timestamp": "00:15:51,395", "timestamp_s": 951.0}, {"text": "Later on when we start deploying our models is that you need to", "timestamp": "00:15:53,885", "timestamp_s": 953.0}, {"text": "know a bit about the models.", "timestamp": "00:15:58,115", "timestamp_s": 958.0}, {"text": "First of all, you need to know how much tokens, like the virtual AI currency,", "timestamp": "00:15:59,645", "timestamp_s": 959.0}, {"text": "I would call it, your application would need, but also knowing that each", "timestamp": "00:16:05,165", "timestamp_s": 965.0}, {"text": "and every Azure region together with the models, also provide you a quota.", "timestamp": "00:16:09,965", "timestamp_s": 969.0}, {"text": "So in my setup here, I already have a few scenarios like models", "timestamp": "00:16:14,655", "timestamp_s": 974.0}, {"text": "deployed and I\u0027ll show you in there.", "timestamp": "00:16:19,205", "timestamp_s": 979.0}, {"text": "Next demo how to actually do this.", "timestamp": "00:16:20,555", "timestamp_s": 980.0}, {"text": "But what you can see here is that I deployed GPT-4 oh.", "timestamp": "00:16:23,135", "timestamp_s": 983.0}, {"text": "This is the version I\u0027m using most, probably the latest one, and I\u0027m", "timestamp": "00:16:28,235", "timestamp_s": 988.0}, {"text": "allocating 8,000 tokens per minute.", "timestamp": "00:16:32,555", "timestamp_s": 992.0}, {"text": "We\u0027re now, for the total of my Azure region, there\u0027s 450,000 available.", "timestamp": "00:16:36,125", "timestamp_s": 996.0}, {"text": "So depending on the needs of your application, you\u0027re gonna", "timestamp": "00:16:43,160", "timestamp_s": 1003.0}, {"text": "allow less or more numbers of tokens or thousands of tokens.", "timestamp": "00:16:46,175", "timestamp_s": 1006.0}, {"text": "Because they heavily influence, the richness, I would say, of the prompts", "timestamp": "00:16:51,195", "timestamp_s": 1011.0}, {"text": "your users can run, but also, how complete the actual, prompt response can be.", "timestamp": "00:16:55,385", "timestamp_s": 1015.0}, {"text": "Where at some point you might actually run out of tokens, and that\u0027s where", "timestamp": "00:17:02,345", "timestamp_s": 1022.0}, {"text": "now in the quota you need to validate what your Azure region, provides.", "timestamp": "00:17:06,305", "timestamp_s": 1026.0}, {"text": "So that\u0027s the first, I would say high level scenario on how to", "timestamp": "00:17:11,565", "timestamp_s": 1031.0}, {"text": "actually navigate across your.", "timestamp": "00:17:15,545", "timestamp_s": 1035.0}, {"text": "AI foundry starting from the Azure portal, deploying an Azure AI service,", "timestamp": "00:17:18,695", "timestamp_s": 1038.0}, {"text": "and within navigating to Foundry.", "timestamp": "00:17:24,245", "timestamp_s": 1044.0}, {"text": "Where next you have the option to use the hub and, project topology allocating REC.", "timestamp": "00:17:26,855", "timestamp_s": 1046.0}, {"text": "And then in the next step, we\u0027re gonna allocate our actual, language models.", "timestamp": "00:17:34,245", "timestamp_s": 1054.0}, {"text": "But for now, back to the presentation.", "timestamp": "00:17:39,845", "timestamp_s": 1059.0}, {"text": "While most of my demos will happen from the AI Foundry portal, I understand", "timestamp": "00:17:42,355", "timestamp_s": 1062.0}, {"text": "that most developers will probably like to interact from a, I don\u0027t know,", "timestamp": "00:17:46,735", "timestamp_s": 1066.0}, {"text": "development interface, and that\u0027s where an SDK comes into the picture.", "timestamp": "00:17:51,535", "timestamp_s": 1071.0}, {"text": "So the good news is that there is an Azure ai, SDK specifically available.", "timestamp": "00:17:56,335", "timestamp_s": 1076.0}, {"text": "To equip developers streamlining AI integration and really enriching", "timestamp": "00:18:01,215", "timestamp_s": 1081.0}, {"text": "that user experience and building in functionalities into their applications.", "timestamp": "00:18:06,135", "timestamp_s": 1086.0}, {"text": "This toolkit supports multiple programming languages, Python, c sharp.net,", "timestamp": "00:18:11,535", "timestamp_s": 1091.0}, {"text": "Java, you think of it, you name it, and it is supported, really enabling", "timestamp": "00:18:16,065", "timestamp_s": 1096.0}, {"text": "developers to select the language of choice and making them more productive.", "timestamp": "00:18:20,325", "timestamp_s": 1100.0}, {"text": "While developing, generative AI inspired applications.", "timestamp": "00:18:25,115", "timestamp_s": 1105.0}, {"text": "So from there, developers can efficiently build, evaluate,", "timestamp": "00:18:29,385", "timestamp_s": 1109.0}, {"text": "deploy those AI components.", "timestamp": "00:18:32,805", "timestamp_s": 1112.0}, {"text": "The SEK integration is obviously part of the already trusted", "timestamp": "00:18:35,475", "timestamp_s": 1115.0}, {"text": "development environments, mentioned before, GitHub Visual Studio vs.", "timestamp": "00:18:39,435", "timestamp_s": 1119.0}, {"text": "Code, and you\u0027re gonna interact with your AI Foundry not from", "timestamp": "00:18:43,105", "timestamp_s": 1123.0}, {"text": "within the portal, like I\u0027ll show you in the demo, but obviously from", "timestamp": "00:18:47,785", "timestamp_s": 1127.0}, {"text": "within the SDK integration directly.", "timestamp": "00:18:51,415", "timestamp_s": 1131.0}, {"text": "With the base Azure Services and AI Foundry up and running.", "timestamp": "00:18:54,315", "timestamp_s": 1134.0}, {"text": "Let\u0027s talk a bit about the large language models, which by the way is the topic", "timestamp": "00:18:58,365", "timestamp_s": 1138.0}, {"text": "of the conference overall, right?", "timestamp": "00:19:02,445", "timestamp_s": 1142.0}, {"text": "With Azure AI Foundry, you get access to an extensive", "timestamp": "00:19:04,665", "timestamp_s": 1144.0}, {"text": "list of large language models.", "timestamp": "00:19:07,935", "timestamp_s": 1147.0}, {"text": "Really allowing you as the developer or obviously your customers,", "timestamp": "00:19:10,065", "timestamp_s": 1150.0}, {"text": "to choose the models that make most sense for your solution.", "timestamp": "00:19:14,025", "timestamp_s": 1154.0}, {"text": "Now, while this list here on screen might not feel extensive.", "timestamp": "00:19:18,405", "timestamp_s": 1158.0}, {"text": "Know that there are more than a thousand different models.", "timestamp": "00:19:22,230", "timestamp_s": 1162.0}, {"text": "Yes, more than a thousand to choose from available today, which can all", "timestamp": "00:19:24,900", "timestamp_s": 1164.0}, {"text": "be deployed within your AI foundry.", "timestamp": "00:19:30,300", "timestamp_s": 1170.0}, {"text": "Even I would say deep seek.", "timestamp": "00:19:32,730", "timestamp_s": 1172.0}, {"text": "One of the more recent, large language models integrated", "timestamp": "00:19:34,230", "timestamp_s": 1174.0}, {"text": "only a couple of weeks ago.", "timestamp": "00:19:37,850", "timestamp_s": 1177.0}, {"text": "It\u0027s already available, and we got more on the list coming out in the near future.", "timestamp": "00:19:39,380", "timestamp_s": 1179.0}, {"text": "So for that, let me jump back to my demo environment and show you how", "timestamp": "00:19:44,380", "timestamp_s": 1184.0}, {"text": "easy it can be to search for models, deploy the models, and also covering", "timestamp": "00:19:48,580", "timestamp_s": 1188.0}, {"text": "a few other, I would say, baseline tasks once you start using models", "timestamp": "00:19:52,930", "timestamp_s": 1192.0}, {"text": "and all from within AI Foundry.", "timestamp": "00:19:57,550", "timestamp_s": 1197.0}, {"text": "All right.", "timestamp": "00:20:00,030", "timestamp_s": 1200.0}, {"text": "So with that, let\u0027s have a look at, the actual large language models can be", "timestamp": "00:20:00,420", "timestamp_s": 1200.0}, {"text": "deployed again from within our AI foundry.", "timestamp": "00:20:04,710", "timestamp_s": 1204.0}, {"text": "So I\u0027m still at the screen where, I finished my previous demo.", "timestamp": "00:20:08,490", "timestamp_s": 1208.0}, {"text": "There was actually one part I forgot to show you.", "timestamp": "00:20:12,120", "timestamp_s": 1212.0}, {"text": "And that\u0027s, the connectors or connected resources.", "timestamp": "00:20:14,730", "timestamp_s": 1214.0}, {"text": "Now, if you think about how a developer interacts with.", "timestamp": "00:20:18,540", "timestamp_s": 1218.0}, {"text": "The AI service, as I showed you, there\u0027s the endpoint, but there\u0027s also the keys.", "timestamp": "00:20:22,455", "timestamp_s": 1222.0}, {"text": "And later on we\u0027ll talk about rag architecture, which means you\u0027re", "timestamp": "00:20:27,405", "timestamp_s": 1227.0}, {"text": "probably gonna integrate, like AI search.", "timestamp": "00:20:30,735", "timestamp_s": 1230.0}, {"text": "And then in the last part there\u0027s a little bit, I\u0027ll talk about content", "timestamp": "00:20:33,775", "timestamp_s": 1233.0}, {"text": "safety, making sure that your application is following our Microsoft", "timestamp": "00:20:37,195", "timestamp_s": 1237.0}, {"text": "responsible AI framework guidelines.", "timestamp": "00:20:41,815", "timestamp_s": 1241.0}, {"text": "So all of these are standalone services, standalone resources", "timestamp": "00:20:45,175", "timestamp_s": 1245.0}, {"text": "in the Azure platform.", "timestamp": "00:20:49,225", "timestamp_s": 1249.0}, {"text": "We\u0027re now again, in that mindset that your developer will probably", "timestamp": "00:20:50,975", "timestamp_s": 1250.0}, {"text": "need access to all those resources.", "timestamp": "00:20:54,635", "timestamp_s": 1254.0}, {"text": "Instead of giving them access from an Azure perspective, you could now", "timestamp": "00:20:57,155", "timestamp_s": 1257.0}, {"text": "allocate them as an available resource for the hub or an individual project.", "timestamp": "00:21:01,535", "timestamp_s": 1261.0}, {"text": "And that\u0027s mainly what you could manage from here.", "timestamp": "00:21:07,840", "timestamp_s": 1267.0}, {"text": "So just to clarify the interface, if you\u0027ve never really seen, AI Foundry", "timestamp": "00:21:10,390", "timestamp_s": 1270.0}, {"text": "in action, the highest level AI foundry is available from ai.azure.com and", "timestamp": "00:21:14,570", "timestamp_s": 1274.0}, {"text": "underneath you\u0027re gonna create a hub.", "timestamp": "00:21:22,040", "timestamp_s": 1282.0}, {"text": "Within the hub.", "timestamp": "00:21:24,920", "timestamp_s": 1284.0}, {"text": "You later on gonna create a project that we already talked about,", "timestamp": "00:21:26,090", "timestamp_s": 1286.0}, {"text": "and then from there we interact with our connected resources.", "timestamp": "00:21:29,810", "timestamp_s": 1289.0}, {"text": "So from here I could interact with new.", "timestamp": "00:21:34,250", "timestamp_s": 1294.0}, {"text": "I talked about Key Vault.", "timestamp": "00:21:37,610", "timestamp_s": 1297.0}, {"text": "I didn\u0027t really, deploy it yet, but you could interact with OpenAI, with your", "timestamp": "00:21:39,350", "timestamp_s": 1299.0}, {"text": "speech and other, some other services.", "timestamp": "00:21:43,960", "timestamp_s": 1303.0}, {"text": "And if you want, you could actually directly connect to other service", "timestamp": "00:21:46,770", "timestamp_s": 1306.0}, {"text": "building blocks in Azure or even outside of Azure as well.", "timestamp": "00:21:50,520", "timestamp_s": 1310.0}, {"text": "Now, from here, we can shift to our models.", "timestamp": "00:21:54,470", "timestamp_s": 1314.0}, {"text": "Now, there\u0027s a few different ways, I would say within the portal to do this,", "timestamp": "00:21:57,380", "timestamp_s": 1317.0}, {"text": "depending if you are active on a project, active on a. Are active in the open AI", "timestamp": "00:22:01,100", "timestamp_s": 1321.0}, {"text": "services that I showed you at the start.", "timestamp": "00:22:06,950", "timestamp_s": 1326.0}, {"text": "From here, I navigated inside the hub and I\u0027m now inside this specific project", "timestamp": "00:22:09,430", "timestamp_s": 1329.0}, {"text": "where you can see, as you already know from my previous demo, I already", "timestamp": "00:22:16,320", "timestamp_s": 1336.0}, {"text": "have some of my connections available.", "timestamp": "00:22:19,710", "timestamp_s": 1339.0}, {"text": "So what this means is that, for example, my cloud admin pre deploy the connections", "timestamp": "00:22:22,680", "timestamp_s": 1342.0}, {"text": "and they\u0027re now becoming available.", "timestamp": "00:22:27,570", "timestamp_s": 1347.0}, {"text": "But imagine that I also wanna deploy my own specific.", "timestamp": "00:22:29,670", "timestamp_s": 1349.0}, {"text": "That I only want to use within this specific project.", "timestamp": "00:22:33,330", "timestamp_s": 1353.0}, {"text": "So I could do this again from here since I\u0027m already in the project, right?", "timestamp": "00:22:36,960", "timestamp_s": 1356.0}, {"text": "I could manage it all from here, or why not?", "timestamp": "00:22:41,460", "timestamp_s": 1361.0}, {"text": "I could open up my project in a separate blade.", "timestamp": "00:22:44,730", "timestamp_s": 1364.0}, {"text": "And then from here I get again, my models and endpoints.", "timestamp": "00:22:48,860", "timestamp_s": 1368.0}, {"text": "So it looks about the same.", "timestamp": "00:22:53,000", "timestamp_s": 1373.0}, {"text": "It just depends on how you\u0027re gonna navigate to it.", "timestamp": "00:22:54,110", "timestamp_s": 1374.0}, {"text": "So let\u0027s show you how we can add a new model, and this is now", "timestamp": "00:22:57,455", "timestamp_s": 1377.0}, {"text": "giving me access to all possible models within our environment.", "timestamp": "00:23:02,135", "timestamp_s": 1382.0}, {"text": "So you can see I talked about, a bit more than a thousand, and we actually", "timestamp": "00:23:07,115", "timestamp_s": 1387.0}, {"text": "have almost 2000 available in there.", "timestamp": "00:23:11,495", "timestamp_s": 1391.0}, {"text": "So you can start with pre-built collections.", "timestamp": "00:23:14,675", "timestamp_s": 1394.0}, {"text": "So if you want, you could filter based on only the ones from OpenAI.", "timestamp": "00:23:17,435", "timestamp_s": 1397.0}, {"text": "Like an easy example and then the list will only obviously present those ones.", "timestamp": "00:23:22,110", "timestamp_s": 1402.0}, {"text": "Or if you wanna filter based on what I can do with them and then maybe", "timestamp": "00:23:27,330", "timestamp_s": 1407.0}, {"text": "some specific features, like I only wanna have the ones supporting chat", "timestamp": "00:23:32,850", "timestamp_s": 1412.0}, {"text": "completions and overall completions.", "timestamp": "00:23:37,710", "timestamp_s": 1417.0}, {"text": "Then you can see that there are, open AI ones.", "timestamp": "00:23:40,650", "timestamp_s": 1420.0}, {"text": "The Microsoft five one, there\u0027s minus one, there\u0027s Lama from Meta, and again,", "timestamp": "00:23:43,720", "timestamp_s": 1423.0}, {"text": "all the other ones showing up here.", "timestamp": "00:23:48,700", "timestamp_s": 1428.0}, {"text": "So the next step now is selecting your model.", "timestamp": "00:23:50,850", "timestamp_s": 1430.0}, {"text": "It always provides you a pretty detailed description, what that model actually", "timestamp": "00:23:55,200", "timestamp_s": 1435.0}, {"text": "represents, and then you could also define some of its, capabilities.", "timestamp": "00:23:59,850", "timestamp_s": 1439.0}, {"text": "From there, you would confirm, now, since I already deployed this, it\u0027s not gonna", "timestamp": "00:24:05,710", "timestamp_s": 1445.0}, {"text": "allow me to deploy this anymore, so let\u0027s.", "timestamp": "00:24:09,670", "timestamp_s": 1449.0}, {"text": "Try and select another one here, GPT-4 oh.", "timestamp": "00:24:12,890", "timestamp_s": 1452.0}, {"text": "Still one of the more recent ones.", "timestamp": "00:24:16,370", "timestamp_s": 1456.0}, {"text": "Again, explanation, sharing information about the latest, version you could", "timestamp": "00:24:18,770", "timestamp_s": 1458.0}, {"text": "say, and then some description what it actually allows you to do.", "timestamp": "00:24:23,370", "timestamp_s": 1463.0}, {"text": "So I\u0027m gonna confirm, and the next step is now defining the specifics", "timestamp": "00:24:27,180", "timestamp_s": 1467.0}, {"text": "for my project so I can choose the deployment type global standard.", "timestamp": "00:24:32,090", "timestamp_s": 1472.0}, {"text": "It means that you\u0027re gonna pay per API call.", "timestamp": "00:24:36,830", "timestamp_s": 1476.0}, {"text": "And if you want, if the model supports it, there\u0027s a few other ones as well.", "timestamp": "00:24:40,475", "timestamp_s": 1480.0}, {"text": "I would say if you wanna know more details, then please consult our,", "timestamp": "00:24:44,735", "timestamp_s": 1484.0}, {"text": "Microsoft documentation, because I don\u0027t have the time in this", "timestamp": "00:24:48,135", "timestamp_s": 1488.0}, {"text": "demo to expand on all of these.", "timestamp": "00:24:51,075", "timestamp_s": 1491.0}, {"text": "But it has a lot to do with.", "timestamp": "00:24:53,145", "timestamp_s": 1493.0}, {"text": "The high variability aspects of the Azure architecture in the backend.", "timestamp": "00:24:55,410", "timestamp_s": 1495.0}, {"text": "Next, in our deployment details, we can fine tune, customize this a little bit, so", "timestamp": "00:25:00,330", "timestamp_s": 1500.0}, {"text": "you\u0027ve got the different model versions.", "timestamp": "00:25:05,430", "timestamp_s": 1505.0}, {"text": "some versions up and down.", "timestamp": "00:25:07,250", "timestamp_s": 1507.0}, {"text": "You could say typically, my guidance is to use the most up-to-date version,", "timestamp": "00:25:08,570", "timestamp_s": 1508.0}, {"text": "but there might be specific use cases where maybe you don\u0027t have", "timestamp": "00:25:13,790", "timestamp_s": 1513.0}, {"text": "to or you don\u0027t want to do that.", "timestamp": "00:25:17,120", "timestamp_s": 1517.0}, {"text": "If you wanna integrate it with one of your previously discussed", "timestamp": "00:25:19,495", "timestamp_s": 1519.0}, {"text": "connections, you could do that as well.", "timestamp": "00:25:22,555", "timestamp_s": 1522.0}, {"text": "And then defining the tokens per minute rate limit.", "timestamp": "00:25:24,595", "timestamp_s": 1524.0}, {"text": "And again, this influences the use cases of your application if you", "timestamp": "00:25:27,775", "timestamp_s": 1527.0}, {"text": "wanna integrate content filtering.", "timestamp": "00:25:32,785", "timestamp_s": 1532.0}, {"text": "So again, the content safety, right?", "timestamp": "00:25:34,465", "timestamp_s": 1534.0}, {"text": "That\u0027s where, you could at least for now, pick the default, because I\u0027ll talk about", "timestamp": "00:25:36,770", "timestamp_s": 1536.0}, {"text": "this, a little bit more towards the end.", "timestamp": "00:25:40,930", "timestamp_s": 1540.0}, {"text": "So you pick your model, use, confirm some of the settings,", "timestamp": "00:25:43,790", "timestamp_s": 1543.0}, {"text": "and from there you\u0027re gonna.", "timestamp": "00:25:47,480", "timestamp_s": 1547.0}, {"text": "To run the deployment.", "timestamp": "00:25:48,740", "timestamp_s": 1548.0}, {"text": "So pretty easy.", "timestamp": "00:25:50,090", "timestamp_s": 1550.0}, {"text": "I would say pretty straightforward.", "timestamp": "00:25:51,260", "timestamp_s": 1551.0}, {"text": "Once we have a model deployed, like in this case, we typically", "timestamp": "00:25:53,410", "timestamp_s": 1553.0}, {"text": "provide you some starting points.", "timestamp": "00:25:57,750", "timestamp_s": 1557.0}, {"text": "And again, we\u0027re targeting developers, right?", "timestamp": "00:25:59,580", "timestamp_s": 1559.0}, {"text": "So what do you need here is.", "timestamp": "00:26:02,100", "timestamp_s": 1562.0}, {"text": "Azure credentials.", "timestamp": "00:26:04,745", "timestamp_s": 1564.0}, {"text": "Installing like Python example in this case, and how to actually", "timestamp": "00:26:05,915", "timestamp_s": 1565.0}, {"text": "start testing, validating, and it\u0027s almost literally copy pasting.", "timestamp": "00:26:09,905", "timestamp_s": 1569.0}, {"text": "If Python is your, language of choice.", "timestamp": "00:26:14,855", "timestamp_s": 1574.0}, {"text": "If you go oh, actually I want to use another language, I\u0027m gonna do C sharp,", "timestamp": "00:26:17,905", "timestamp_s": 1577.0}, {"text": "bam, within just a split second, it\u0027s gonna give you the different steps,", "timestamp": "00:26:21,855", "timestamp_s": 1581.0}, {"text": "how to import the necessary packages.", "timestamp": "00:26:25,965", "timestamp_s": 1585.0}, {"text": "To install Azure AI and then obviously the identity, and then from there, creating", "timestamp": "00:26:31,255", "timestamp_s": 1591.0}, {"text": "a point to your AI service endpoint.", "timestamp": "00:26:38,095", "timestamp_s": 1598.0}, {"text": "What\u0027s important here is the name of your endpoint together with the deployment", "timestamp": "00:26:40,975", "timestamp_s": 1600.0}, {"text": "and the name of your deployment.", "timestamp": "00:26:46,045", "timestamp_s": 1606.0}, {"text": "And then you\u0027re gonna tune your chat conversations.", "timestamp": "00:26:48,455", "timestamp_s": 1608.0}, {"text": "I\u0027ll talk about this a little bit later on.", "timestamp": "00:26:50,915", "timestamp_s": 1610.0}, {"text": "And then if you want some additional samples, how to interact with,", "timestamp": "00:26:53,345", "timestamp_s": 1613.0}, {"text": "conversational context, how to keep the history and so on.", "timestamp": "00:26:58,165", "timestamp_s": 1618.0}, {"text": "Another angle to validate some model information is now I", "timestamp": "00:27:02,005", "timestamp_s": 1622.0}, {"text": "moved from project into the hub.", "timestamp": "00:27:07,585", "timestamp_s": 1627.0}, {"text": "The way to deploy is obviously, a hundred percent the same.", "timestamp": "00:27:10,345", "timestamp_s": 1630.0}, {"text": "So if I wanna search for LAMA instead of using any of the", "timestamp": "00:27:13,625", "timestamp_s": 1633.0}, {"text": "pre-built categories and filters.", "timestamp": "00:27:18,325", "timestamp_s": 1638.0}, {"text": "You could now interact with, any of these models.", "timestamp": "00:27:20,620", "timestamp_s": 1640.0}, {"text": "So the baseline is the same on the hub level, on the project level,", "timestamp": "00:27:23,780", "timestamp_s": 1643.0}, {"text": "so nothing really different.", "timestamp": "00:27:27,500", "timestamp_s": 1647.0}, {"text": "Another scenario that I would like to highlight here, this is the playground,", "timestamp": "00:27:29,560", "timestamp_s": 1649.0}, {"text": "but I\u0027ll talk about the playground, a little bit later on, is inside.", "timestamp": "00:27:34,990", "timestamp_s": 1654.0}, {"text": "Our model catalog.", "timestamp": "00:27:39,575", "timestamp_s": 1659.0}, {"text": "From here, it\u0027s basically giving you the exact same view.", "timestamp": "00:27:40,865", "timestamp_s": 1660.0}, {"text": "Now, where it is slightly different is that again, here I\u0027m inside the", "timestamp": "00:27:44,885", "timestamp_s": 1664.0}, {"text": "open AI service specific option.", "timestamp": "00:27:49,745", "timestamp_s": 1669.0}, {"text": "And again, I like to highlight that it\u0027s all based on AI Foundry, but", "timestamp": "00:27:52,895", "timestamp_s": 1672.0}, {"text": "every now and then, depending on the model you deploy, it might show", "timestamp": "00:27:56,705", "timestamp_s": 1676.0}, {"text": "you more or less, integrations.", "timestamp": "00:28:00,335", "timestamp_s": 1680.0}, {"text": "If I now move to another open model here.", "timestamp": "00:28:03,435", "timestamp_s": 1683.0}, {"text": "You can see that it also allows me to deploy it.", "timestamp": "00:28:07,895", "timestamp_s": 1687.0}, {"text": "It still provides all those details, but now I could also look into why", "timestamp": "00:28:11,195", "timestamp_s": 1691.0}, {"text": "should I maybe deploy this if one of my colleagues already deployed this scenario?", "timestamp": "00:28:15,515", "timestamp_s": 1695.0}, {"text": "So giving you, again, quite some, some options.", "timestamp": "00:28:21,305", "timestamp_s": 1701.0}, {"text": "Another question that we sometimes get about the model", "timestamp": "00:28:24,835", "timestamp_s": 1704.0}, {"text": "is getting access to metrics.", "timestamp": "00:28:28,015", "timestamp_s": 1708.0}, {"text": "Now this is not showing you, like specific details I would say about", "timestamp": "00:28:31,135", "timestamp_s": 1711.0}, {"text": "the model, but more about how your applications, how your developers", "timestamp": "00:28:35,225", "timestamp_s": 1715.0}, {"text": "are using, targeting this model.", "timestamp": "00:28:40,265", "timestamp_s": 1720.0}, {"text": "I just deployed this without actually having a sample app in the front", "timestamp": "00:28:42,995", "timestamp_s": 1722.0}, {"text": "of it, so that\u0027s why my metrics are not really impressive, right?", "timestamp": "00:28:46,955", "timestamp_s": 1726.0}, {"text": "But it should give.", "timestamp": "00:28:50,885", "timestamp_s": 1730.0}, {"text": "You some idea that auditing monitoring is also baked in.", "timestamp": "00:28:51,605", "timestamp_s": 1731.0}, {"text": "And then a bit on our Microsoft security framework or the responsible AI framework.", "timestamp": "00:28:56,345", "timestamp_s": 1736.0}, {"text": "We have, since I deployed my model using a default filter, it\u0027s already", "timestamp": "00:29:02,470", "timestamp_s": 1742.0}, {"text": "having, some content safety as part of my language model baked in.", "timestamp": "00:29:08,020", "timestamp_s": 1748.0}, {"text": "And obviously for now, because I didn\u0027t use it, there\u0027s no violations,", "timestamp": "00:29:14,740", "timestamp_s": 1754.0}, {"text": "there\u0027s no abusive use and so on.", "timestamp": "00:29:18,040", "timestamp_s": 1758.0}, {"text": "But again, giving you a pretty nice idea about, what you could use it for.", "timestamp": "00:29:20,280", "timestamp_s": 1760.0}, {"text": "Another example I can show you is using the model catalog.", "timestamp": "00:29:25,260", "timestamp_s": 1765.0}, {"text": "And again, this is the same catalog, what I showed you before, it just giving", "timestamp": "00:29:29,490", "timestamp_s": 1769.0}, {"text": "you the full list and a different view.", "timestamp": "00:29:33,720", "timestamp_s": 1773.0}, {"text": "Why did I switch yet to another view?", "timestamp": "00:29:36,180", "timestamp_s": 1776.0}, {"text": "Because there\u0027s another question that we can answer from here", "timestamp": "00:29:38,820", "timestamp_s": 1778.0}, {"text": "and that\u0027s what is, the model?", "timestamp": "00:29:42,270", "timestamp_s": 1782.0}, {"text": "Supposed to help me with, or also answering the question,", "timestamp": "00:29:44,450", "timestamp_s": 1784.0}, {"text": "what model is better for a specific purpose than another?", "timestamp": "00:29:48,530", "timestamp_s": 1788.0}, {"text": "Since I got deep seek up here, I\u0027m gonna check out that model.", "timestamp": "00:29:52,850", "timestamp_s": 1792.0}, {"text": "And same as before, providing a description, but now it also", "timestamp": "00:29:56,570", "timestamp_s": 1796.0}, {"text": "gives me a link to benchmarks.", "timestamp": "00:30:01,280", "timestamp_s": 1801.0}, {"text": "So by design, what it\u0027s gonna do is looking at, I would say its", "timestamp": "00:30:04,190", "timestamp_s": 1804.0}, {"text": "own, core competition, right?", "timestamp": "00:30:07,730", "timestamp_s": 1807.0}, {"text": "\u0027cause as a developer.", "timestamp": "00:30:10,540", "timestamp_s": 1810.0}, {"text": "You need to think about all these different language models, and I\u0027m", "timestamp": "00:30:12,580", "timestamp_s": 1812.0}, {"text": "pretty sure that the conference sessions will help you with a lot of this.", "timestamp": "00:30:15,520", "timestamp_s": 1815.0}, {"text": "But then within our AI Foundry, knowing that you get access to", "timestamp": "00:30:19,600", "timestamp_s": 1819.0}, {"text": "more than, 1800, now, how do you decide across those language models?", "timestamp": "00:30:22,990", "timestamp_s": 1822.0}, {"text": "So that\u0027s where now you can easily select any of the models and", "timestamp": "00:30:28,970", "timestamp_s": 1828.0}, {"text": "there will always be benchmarking.", "timestamp": "00:30:32,270", "timestamp_s": 1832.0}, {"text": "In this case, it\u0027s comparing the deep seek feed three that I selected with", "timestamp": "00:30:34,910", "timestamp_s": 1834.0}, {"text": "some of the other popular counterparts.", "timestamp": "00:30:39,530", "timestamp_s": 1839.0}, {"text": "Parts, but nothing blocks you from also integrating a comparison", "timestamp": "00:30:41,870", "timestamp_s": 1841.0}, {"text": "that you can manage, that you can tune with some other models.", "timestamp": "00:30:46,850", "timestamp_s": 1846.0}, {"text": "I think with that, you should have a pretty good idea about, using", "timestamp": "00:30:51,310", "timestamp_s": 1851.0}, {"text": "different parts of the AI Foundry portal, how to deploy the different", "timestamp": "00:30:54,870", "timestamp_s": 1854.0}, {"text": "models using open AI service, using other services within the hub and", "timestamp": "00:30:59,490", "timestamp_s": 1859.0}, {"text": "project, and then also talked about.", "timestamp": "00:31:05,700", "timestamp_s": 1865.0}, {"text": "The higher level model, catalog, and the benchmarking, so that, let\u0027s", "timestamp": "00:31:08,085", "timestamp_s": 1868.0}, {"text": "switch back to the presentation.", "timestamp": "00:31:13,425", "timestamp_s": 1873.0}, {"text": "Nice.", "timestamp": "00:31:15,215", "timestamp_s": 1875.0}, {"text": "So we\u0027re now at the point where we have our large language models deployed.", "timestamp": "00:31:15,875", "timestamp_s": 1875.0}, {"text": "We did some benchmark testing and I briefly talked about some", "timestamp": "00:31:20,105", "timestamp_s": 1880.0}, {"text": "other capabilities, like the fine tuning I briefly touched on.", "timestamp": "00:31:23,675", "timestamp_s": 1883.0}, {"text": "So I can hear your next question already.", "timestamp": "00:31:27,675", "timestamp_s": 1887.0}, {"text": "coming up.", "timestamp": "00:31:30,445", "timestamp_s": 1890.0}, {"text": "okay.", "timestamp": "00:31:31,425", "timestamp_s": 1891.0}, {"text": "AI Foundry is the go-to portal I use for generative AI with large language models.", "timestamp": "00:31:32,055", "timestamp_s": 1892.0}, {"text": "But what about all the other more traditional AI services that we had", "timestamp": "00:31:37,695", "timestamp_s": 1897.0}, {"text": "in the Azure portal in the past?", "timestamp": "00:31:41,865", "timestamp_s": 1901.0}, {"text": "I would say that\u0027s actually a great question.", "timestamp": "00:31:44,145", "timestamp_s": 1904.0}, {"text": "Now remember in the introduction section we talked about the paradigm", "timestamp": "00:31:46,545", "timestamp_s": 1906.0}, {"text": "shift in application development where customers and users somewhat", "timestamp": "00:31:50,595", "timestamp_s": 1910.0}, {"text": "expect to have AI capabilities.", "timestamp": "00:31:55,125", "timestamp_s": 1915.0}, {"text": "In basically any kind of application they\u0027re building or using.", "timestamp": "00:31:57,570", "timestamp_s": 1917.0}, {"text": "While generative f AI seems to provide a lot of those capabilities, all other", "timestamp": "00:32:02,130", "timestamp_s": 1922.0}, {"text": "AI services you might know from the past existing in Azure already are now", "timestamp": "00:32:06,840", "timestamp_s": 1926.0}, {"text": "also gradually moving into AI Foundry as that management, AI services portal.", "timestamp": "00:32:12,180", "timestamp_s": 1932.0}, {"text": "For example, AI search for architecture, although I\u0027ll talk about that later on,", "timestamp": "00:32:18,750", "timestamp_s": 1938.0}, {"text": "but also talking about AI speech, AI Vision, document intelligence, language", "timestamp": "00:32:23,370", "timestamp_s": 1943.0}, {"text": "translator, all those services have been around in Azure for close to 10 years", "timestamp": "00:32:28,820", "timestamp_s": 1948.0}, {"text": "and can now gradually be integrated and managed from within AI Foundry as well.", "timestamp": "00:32:34,100", "timestamp_s": 1954.0}, {"text": "Now the magic behind the scenes to manage all this is Foundry playground.", "timestamp": "00:32:39,850", "timestamp_s": 1959.0}, {"text": "I already showed you a little bit of this from within our AI Foundry", "timestamp": "00:32:45,780", "timestamp_s": 1965.0}, {"text": "portal, especially around a large language model deployment, but there\u0027s", "timestamp": "00:32:50,820", "timestamp_s": 1970.0}, {"text": "actually a lot more you can do with it.", "timestamp": "00:32:55,110", "timestamp_s": 1975.0}, {"text": "I would say let\u0027s have another look.", "timestamp": "00:32:57,540", "timestamp_s": 1977.0}, {"text": "In this next demo, I\u0027m gonna walk you through AI Foundry, showing you some", "timestamp": "00:32:59,795", "timestamp_s": 1979.0}, {"text": "of the capabilities around playground, allowing you to test and validate", "timestamp": "00:33:03,695", "timestamp_s": 1983.0}, {"text": "your models, and also switching to some more traditional AI capabilities.", "timestamp": "00:33:08,135", "timestamp_s": 1988.0}, {"text": "Good.", "timestamp": "00:33:13,375", "timestamp_s": 1993.0}, {"text": "So we have our models deployed in the previous part of the presentation,", "timestamp": "00:33:13,825", "timestamp_s": 1993.0}, {"text": "which now means that we\u0027re ready to actually test and validate.", "timestamp": "00:33:18,595", "timestamp_s": 1998.0}, {"text": "So the way to do this is from within once more AI Foundry,", "timestamp": "00:33:22,435", "timestamp_s": 2002.0}, {"text": "we\u0027re now selecting playgrounds.", "timestamp": "00:33:26,955", "timestamp_s": 2006.0}, {"text": "You could do this directly navigating to ai.azure.com/playgrounds, and", "timestamp": "00:33:29,115", "timestamp_s": 2009.0}, {"text": "then it\u0027s gonna pull up your project.", "timestamp": "00:33:35,895", "timestamp_s": 2015.0}, {"text": "And allowing you to actually build out your playgrounds.", "timestamp": "00:33:37,995", "timestamp_s": 2017.0}, {"text": "Remember, we\u0027re primarily focusing on generative AI using chat co", "timestamp": "00:33:41,895", "timestamp_s": 2021.0}, {"text": "conversations, but remember that we do have other AI services as well.", "timestamp": "00:33:47,325", "timestamp_s": 2027.0}, {"text": "So if you wanna integrate with like speech or the newer agents based, like auto gen", "timestamp": "00:33:53,415", "timestamp_s": 2033.0}, {"text": "alike syns, or you wanna integrate with like images using, for example, Dali or", "timestamp": "00:33:58,195", "timestamp_s": 2038.0}, {"text": "some other large language model using.", "timestamp": "00:34:03,955", "timestamp_s": 2043.0}, {"text": "Language playground.", "timestamp": "00:34:07,015", "timestamp_s": 2047.0}, {"text": "And again, there\u0027s so many different ways to start testing interacting.", "timestamp": "00:34:08,095", "timestamp_s": 2048.0}, {"text": "The most obvious one is using the chat playground.", "timestamp": "00:34:12,535", "timestamp_s": 2052.0}, {"text": "So in the previous part of the demo, we deployed our GPT model", "timestamp": "00:34:16,615", "timestamp_s": 2056.0}, {"text": "as part of our hub and project.", "timestamp": "00:34:21,475", "timestamp_s": 2061.0}, {"text": "I got two of them linked to different connectors.", "timestamp": "00:34:23,275", "timestamp_s": 2063.0}, {"text": "So again, emphasizing that all those building blocks from the", "timestamp": "00:34:26,425", "timestamp_s": 2066.0}, {"text": "start are still nicely coming back here, I could start easy.", "timestamp": "00:34:29,155", "timestamp_s": 2069.0}, {"text": "I got an AI assistant pretty.", "timestamp": "00:34:34,155", "timestamp_s": 2074.0}, {"text": "Generic message here, and I\u0027m gonna ask something like, what is the", "timestamp": "00:34:36,165", "timestamp_s": 2076.0}, {"text": "typical weather in Seattle mid-March?", "timestamp": "00:34:40,215", "timestamp_s": 2080.0}, {"text": "now it\u0027s nicely responding in mid-March and so on.", "timestamp": "00:34:45,625", "timestamp_s": 2085.0}, {"text": "Obviously it\u0027s not about, the details, although in a real life scenario, I", "timestamp": "00:34:48,565", "timestamp_s": 2088.0}, {"text": "would obviously encourage you to really validate and verify the actual response.", "timestamp": "00:34:52,505", "timestamp_s": 2092.0}, {"text": "Now, again, based on your model, what do we get as a confirmation here?", "timestamp": "00:34:58,235", "timestamp_s": 2098.0}, {"text": "Is that the model is working, it is responding well.", "timestamp": "00:35:02,105", "timestamp_s": 2102.0}, {"text": "Now, if I would ask something like,", "timestamp": "00:35:05,885", "timestamp_s": 2105.0}, {"text": "can you provide Belgian food recipe?", "timestamp": "00:35:08,185", "timestamp_s": 2108.0}, {"text": "Remember my Belgian roots, it\u0027s gonna come up with some ingredients, and again,", "timestamp": "00:35:11,095", "timestamp_s": 2111.0}, {"text": "it\u0027s still doing a pretty good job.", "timestamp": "00:35:16,735", "timestamp_s": 2116.0}, {"text": "Let\u0027s see.", "timestamp": "00:35:19,135", "timestamp_s": 2119.0}, {"text": "It came up with a, so mussels and fries.", "timestamp": "00:35:19,795", "timestamp_s": 2119.0}, {"text": "Perfect.", "timestamp": "00:35:22,585", "timestamp_s": 2122.0}, {"text": "Like a typical Belgian dish.", "timestamp": "00:35:23,095", "timestamp_s": 2123.0}, {"text": "It provides me the ingredients, and next to that, it also provides.", "timestamp": "00:35:25,285", "timestamp_s": 2125.0}, {"text": "The instructions and I\u0027m actually getting a little bit hungry now out", "timestamp": "00:35:28,795", "timestamp_s": 2128.0}, {"text": "of that, but not there yet because I need to show you a few other things.", "timestamp": "00:35:32,485", "timestamp_s": 2132.0}, {"text": "Now, back to our starting point.", "timestamp": "00:35:37,405", "timestamp_s": 2137.0}, {"text": "I got another project here, so quickly switching where this time I", "timestamp": "00:35:40,645", "timestamp_s": 2140.0}, {"text": "got two different language models.", "timestamp": "00:35:44,965", "timestamp_s": 2144.0}, {"text": "Now remember, the language model is trained on public data", "timestamp": "00:35:47,455", "timestamp_s": 2147.0}, {"text": "up to a certain point in time.", "timestamp": "00:35:52,525", "timestamp_s": 2152.0}, {"text": "Easy set.", "timestamp": "00:35:54,925", "timestamp_s": 2154.0}, {"text": "GPT-3 five is.", "timestamp": "00:35:55,615", "timestamp_s": 2155.0}, {"text": "Less up to date than GPT-4.", "timestamp": "00:35:57,885", "timestamp_s": 2157.0}, {"text": "An easy example I can use to show you how this works is who", "timestamp": "00:36:00,945", "timestamp_s": 2160.0}, {"text": "is the Prime Minister of the uk?", "timestamp": "00:36:06,705", "timestamp_s": 2166.0}, {"text": "now it\u0027s gonna tell me based on a date.", "timestamp": "00:36:10,555", "timestamp_s": 2170.0}, {"text": "October 21.", "timestamp": "00:36:12,775", "timestamp_s": 2172.0}, {"text": "The Prime Minister is Boris Johnson.", "timestamp": "00:36:14,275", "timestamp_s": 2174.0}, {"text": "Pretty cool.", "timestamp": "00:36:16,910", "timestamp_s": 2176.0}, {"text": "I got my answer.", "timestamp": "00:36:17,480", "timestamp_s": 2177.0}, {"text": "Where now if I switch to my GPT-4 model and I\u0027m gonna run the same prompt,", "timestamp": "00:36:19,370", "timestamp_s": 2179.0}, {"text": "I\u0027m just gonna copy it from here.", "timestamp": "00:36:26,510", "timestamp_s": 2186.0}, {"text": "You can see that now the answer is different and not", "timestamp": "00:36:28,900", "timestamp_s": 2188.0}, {"text": "only different in context.", "timestamp": "00:36:32,140", "timestamp_s": 2192.0}, {"text": "Like the actual answer I would say is.", "timestamp": "00:36:34,120", "timestamp_s": 2194.0}, {"text": "More up to date, but also just by switching the model, you can", "timestamp": "00:36:36,895", "timestamp_s": 2196.0}, {"text": "see that now I get access to more tokens, a short answer, a", "timestamp": "00:36:41,125", "timestamp_s": 2201.0}, {"text": "pretty, little bit longer answer.", "timestamp": "00:36:45,055", "timestamp_s": 2205.0}, {"text": "And if you wanna tune all this a little bit more, that\u0027s where you can go back", "timestamp": "00:36:47,335", "timestamp_s": 2207.0}, {"text": "to, the previous part of the demo.", "timestamp": "00:36:50,965", "timestamp_s": 2210.0}, {"text": "Another thing that\u0027s pretty cool is interacting with what", "timestamp": "00:36:53,125", "timestamp_s": 2213.0}, {"text": "your chat actually can do.", "timestamp": "00:36:57,055", "timestamp_s": 2217.0}, {"text": "So right now I used an easy example.", "timestamp": "00:36:59,755", "timestamp_s": 2219.0}, {"text": "This could be used for I dunno, writing an essay on UK politics or something.", "timestamp": "00:37:02,275", "timestamp_s": 2222.0}, {"text": "I don\u0027t know where.", "timestamp": "00:37:06,955", "timestamp_s": 2226.0}, {"text": "Now we could tune this a little bit more, where I could do", "timestamp": "00:37:08,215", "timestamp_s": 2228.0}, {"text": "something like, you are, Microsoft.", "timestamp": "00:37:12,145", "timestamp_s": 2232.0}, {"text": "Technical trainer with expertise in Azure and Azure ai.", "timestamp": "00:37:15,875", "timestamp_s": 2235.0}, {"text": "You can answer questions as long as you keep it polite and professional.", "timestamp": "00:37:23,465", "timestamp_s": 2243.0}, {"text": "There we go.", "timestamp": "00:37:30,115", "timestamp_s": 2250.0}, {"text": "You cannot answer questions about Amazon AWS or Google Cloud platform", "timestamp": "00:37:30,825", "timestamp_s": 2250.0}, {"text": "to apologize in those scenarios.", "timestamp": "00:37:40,825", "timestamp_s": 2260.0}, {"text": "Offer a Belgian beer flavor to try out instead.", "timestamp": "00:37:44,805", "timestamp_s": 2264.0}, {"text": "So now what I\u0027m doing here is tweaking, fine tuning if you want.", "timestamp": "00:37:50,765", "timestamp_s": 2270.0}, {"text": "I use case where this could almost be like a virtual Microsoft technical trainer.", "timestamp": "00:37:54,755", "timestamp_s": 2274.0}, {"text": "I\u0027m gonna run a new chat conversation and from here I could do, can you explain", "timestamp": "00:38:01,045", "timestamp_s": 2281.0}, {"text": "a bit about Azure Kubernetes service?", "timestamp": "00:38:07,095", "timestamp_s": 2287.0}, {"text": "So it comes back as expected with a nice detailed prompt.", "timestamp": "00:38:11,845", "timestamp_s": 2291.0}, {"text": "I\u0027m using GPT-4 oh latest version, quite some tokens available in my", "timestamp": "00:38:15,955", "timestamp_s": 2295.0}, {"text": "subscription when Now from here I could ask, what is the use case for AWS Beans", "timestamp": "00:38:20,485", "timestamp_s": 2300.0}, {"text": "stock, like an existing AWS service.", "timestamp": "00:38:30,075", "timestamp_s": 2310.0}, {"text": "When now it tells me like, oh, I\u0027m sorry.", "timestamp": "00:38:33,935", "timestamp_s": 2313.0}, {"text": "So I asked it to be professional and polite.", "timestamp": "00:38:36,005", "timestamp_s": 2316.0}, {"text": "I think that\u0027s, pretty well covered here.", "timestamp": "00:38:38,675", "timestamp_s": 2318.0}, {"text": "Unable to answer questions about AWS or any other AWS service and then however.", "timestamp": "00:38:41,735", "timestamp_s": 2321.0}, {"text": "To make up for it.", "timestamp": "00:38:48,430", "timestamp_s": 2328.0}, {"text": "Again, being nice and professional, I could recommend a Belgium beer.", "timestamp": "00:38:49,660", "timestamp_s": 2329.0}, {"text": "How cool is that?", "timestamp": "00:38:54,580", "timestamp_s": 2334.0}, {"text": "You can actually tune your environment, your chat conversations, using by the", "timestamp": "00:38:55,660", "timestamp_s": 2335.0}, {"text": "way, what we call the system message.", "timestamp": "00:39:01,600", "timestamp_s": 2341.0}, {"text": "And then as a developer you would integrate that, obviously", "timestamp": "00:39:04,930", "timestamp_s": 2344.0}, {"text": "as part of your code as well.", "timestamp": "00:39:08,840", "timestamp_s": 2348.0}, {"text": "And then allowing the chat conversations, going back and forth.", "timestamp": "00:39:10,760", "timestamp_s": 2350.0}, {"text": "So that\u0027s pretty much it.", "timestamp": "00:39:14,960", "timestamp_s": 2354.0}, {"text": "Out of this demo showed you.", "timestamp": "00:39:16,160", "timestamp_s": 2356.0}, {"text": "How to interact with the playground, specifically this one for chat or", "timestamp": "00:39:17,930", "timestamp_s": 2357.0}, {"text": "going back to the previous part of the demo where you can choose across", "timestamp": "00:39:22,790", "timestamp_s": 2362.0}, {"text": "different playgrounds depending on use cases for images, integrating audio,", "timestamp": "00:39:26,600", "timestamp_s": 2366.0}, {"text": "integrating other, assistant alike scenarios back to the presentation.", "timestamp": "00:39:31,880", "timestamp_s": 2371.0}, {"text": "Sweet.", "timestamp": "00:39:37,230", "timestamp_s": 2377.0}, {"text": "This brings me to the last topic in today\u0027s session covering rag architecture", "timestamp": "00:39:37,920", "timestamp_s": 2377.0}, {"text": "or retrieval augmented generation.", "timestamp": "00:39:42,510", "timestamp_s": 2382.0}, {"text": "Now, we heavily discussed large language models and how they", "timestamp": "00:39:45,500", "timestamp_s": 2385.0}, {"text": "enrich your applications with generative AI capabilities.", "timestamp": "00:39:48,560", "timestamp_s": 2388.0}, {"text": "For example, conversational context, natural language,", "timestamp": "00:39:52,145", "timestamp_s": 2392.0}, {"text": "and primarily chat driven.", "timestamp": "00:39:56,285", "timestamp_s": 2396.0}, {"text": "One main characteristic for most LMS is that they\u0027re trained using public", "timestamp": "00:39:58,985", "timestamp_s": 2398.0}, {"text": "internet data, which obviously is totally fine, but what if your app", "timestamp": "00:40:03,755", "timestamp_s": 2403.0}, {"text": "needs to know about your organizational data specifically, or your customer?", "timestamp": "00:40:08,405", "timestamp_s": 2408.0}, {"text": "Your user can only use internal company specific information, not", "timestamp": "00:40:13,745", "timestamp_s": 2413.0}, {"text": "using the context from public models.", "timestamp": "00:40:18,455", "timestamp_s": 2418.0}, {"text": "That\u0027s exactly what RAG or retrieval augmented Generation is about.", "timestamp": "00:40:21,450", "timestamp_s": 2421.0}, {"text": "Starting from a large language model approach, you are now augmenting", "timestamp": "00:40:26,850", "timestamp_s": 2426.0}, {"text": "enriching if you want the dataset your AI application is using within your own data.", "timestamp": "00:40:30,990", "timestamp_s": 2430.0}, {"text": "Which can be images, documents, knowledge bases, and they can be", "timestamp": "00:40:38,405", "timestamp_s": 2438.0}, {"text": "stored within the Azure backend.", "timestamp": "00:40:43,145", "timestamp_s": 2443.0}, {"text": "And that\u0027s really the next step, right?", "timestamp": "00:40:45,445", "timestamp_s": 2445.0}, {"text": "So if you are wondering like where does this data come from,", "timestamp": "00:40:47,305", "timestamp_s": 2447.0}, {"text": "like how do I integrate it?", "timestamp": "00:40:50,485", "timestamp_s": 2450.0}, {"text": "There\u0027s a lot of different options.", "timestamp": "00:40:52,885", "timestamp_s": 2452.0}, {"text": "So the easiest one I would say is using Azure blob storage.", "timestamp": "00:40:54,655", "timestamp_s": 2454.0}, {"text": "But nothing blocks you from integrating with, for example,", "timestamp": "00:40:58,650", "timestamp_s": 2458.0}, {"text": "Amazon S3 buckets as well.", "timestamp": "00:41:01,260", "timestamp_s": 2461.0}, {"text": "And yes, I can show you also how to upload files manually in the", "timestamp": "00:41:03,990", "timestamp_s": 2463.0}, {"text": "Azure portal, although I don\u0027t think it\u0027s like an enterprise", "timestamp": "00:41:08,010", "timestamp_s": 2468.0}, {"text": "recommended approach to do that.", "timestamp": "00:41:10,860", "timestamp_s": 2470.0}, {"text": "The backend interaction happens out of Azure AI search, building up", "timestamp": "00:41:12,950", "timestamp_s": 2472.0}, {"text": "what we call vector information for each and every of your data sets.", "timestamp": "00:41:17,810", "timestamp_s": 2477.0}, {"text": "And then once the indexing is done, your AI application will be able to respond to", "timestamp": "00:41:22,250", "timestamp_s": 2482.0}, {"text": "prompts in the same way you expect from your large language model, but now using", "timestamp": "00:41:27,650", "timestamp_s": 2487.0}, {"text": "knowledge coming in from your own data.", "timestamp": "00:41:32,420", "timestamp_s": 2492.0}, {"text": "And you can expect it also brings me to the last demo here, showing you", "timestamp": "00:41:35,320", "timestamp_s": 2495.0}, {"text": "what this rag architecture looks like and how to use it from within ai.", "timestamp": "00:41:39,580", "timestamp_s": 2499.0}, {"text": "So regarding the, rag architecture, the main idea we wanna do from", "timestamp": "00:41:45,030", "timestamp_s": 2505.0}, {"text": "here, and again, I\u0027m just using the playground again, is importing", "timestamp": "00:41:49,070", "timestamp_s": 2509.0}, {"text": "or linking it to our custom data.", "timestamp": "00:41:53,120", "timestamp_s": 2513.0}, {"text": "So I\u0027m, inside my project and I\u0027m gonna.", "timestamp": "00:41:56,360", "timestamp_s": 2516.0}, {"text": "Select here a new section where I could define other system messages, but", "timestamp": "00:42:00,520", "timestamp_s": 2520.0}, {"text": "that\u0027s not specifically to re anymore.", "timestamp": "00:42:05,970", "timestamp_s": 2525.0}, {"text": "So we\u0027re shifting down to the next section, and that\u0027s using your own data.", "timestamp": "00:42:08,490", "timestamp_s": 2528.0}, {"text": "We can add new data sources and for now, I\u0027ll make it a little bit bigger.", "timestamp": "00:42:13,130", "timestamp_s": 2533.0}, {"text": "You can choose from any of these using Azure AI search a service that\u0027s been", "timestamp": "00:42:19,070", "timestamp_s": 2539.0}, {"text": "around in the platform for a couple of years already and now nicely integrating.", "timestamp": "00:42:23,780", "timestamp_s": 2543.0}, {"text": "With, the generative AI capabilities of what an AI solution is, offering today", "timestamp": "00:42:29,060", "timestamp_s": 2549.0}, {"text": "Azure blob storage, where obviously the idea is to have your data sets", "timestamp": "00:42:35,870", "timestamp_s": 2555.0}, {"text": "like, PDF documents, images, word files, any other text files, json", "timestamp": "00:42:41,420", "timestamp_s": 2561.0}, {"text": "alike scenarios in Azure blob storage.", "timestamp": "00:42:46,000", "timestamp_s": 2566.0}, {"text": "Remember, you could link this to your hub and project, making sure that not.", "timestamp": "00:42:48,970", "timestamp_s": 2568.0}, {"text": "Everyone needs access to the blob storage.", "timestamp": "00:42:53,800", "timestamp_s": 2573.0}, {"text": "I would also recommend using, role-based access, preferably managed identities", "timestamp": "00:42:56,500", "timestamp_s": 2576.0}, {"text": "to interact with those data endpoints.", "timestamp": "00:43:02,380", "timestamp_s": 2582.0}, {"text": "Azure Cosmos database, our non-relational database here, which could be a", "timestamp": "00:43:04,980", "timestamp_s": 2584.0}, {"text": "perfect, data set or database endpoint interacting with elastic search.", "timestamp": "00:43:09,840", "timestamp_s": 2589.0}, {"text": "If you want, you could straight point to your web address", "timestamp": "00:43:15,100", "timestamp_s": 2595.0}, {"text": "connecting to, a knowledge base.", "timestamp": "00:43:19,120", "timestamp_s": 2599.0}, {"text": "Website, intranet, maybe SharePoint alike scenario, or, why not uploading", "timestamp": "00:43:21,890", "timestamp_s": 2601.0}, {"text": "files and then still allowing you to turn them into an index.", "timestamp": "00:43:27,300", "timestamp_s": 2607.0}, {"text": "So quite some options.", "timestamp": "00:43:32,130", "timestamp_s": 2612.0}, {"text": "So imagine we are gonna go for blob storage.", "timestamp": "00:43:33,450", "timestamp_s": 2613.0}, {"text": "You need to identify your subscription, the storage container,", "timestamp": "00:43:36,720", "timestamp_s": 2616.0}, {"text": "the BLO storage, obviously.", "timestamp": "00:43:42,060", "timestamp_s": 2622.0}, {"text": "And then if you wanna use a specific Azure search, you\u0027re gonna define the index.", "timestamp": "00:43:43,650", "timestamp_s": 2623.0}, {"text": "And then from there.", "timestamp": "00:43:50,310", "timestamp_s": 2630.0}, {"text": "How frequently is my information changing, which influences my index?", "timestamp": "00:43:51,510", "timestamp_s": 2631.0}, {"text": "So from here, pretty straightforward.", "timestamp": "00:43:58,410", "timestamp_s": 2638.0}, {"text": "You point to the data endpoints and that\u0027s pretty much it.", "timestamp": "00:44:00,840", "timestamp_s": 2640.0}, {"text": "If I switch here to uploading files, it\u0027s still gonna ask for storage.", "timestamp": "00:44:04,950", "timestamp_s": 2644.0}, {"text": "So you still need to have that storage background where now it\u0027s gonna enable", "timestamp": "00:44:09,810", "timestamp_s": 2649.0}, {"text": "cross, origin to allow me to interact from my AI service here, my playground into.", "timestamp": "00:44:14,160", "timestamp_s": 2654.0}, {"text": "My, blob storage container, I would still need to identify the index,", "timestamp": "00:44:21,730", "timestamp_s": 2661.0}, {"text": "so this could be the live PDT index,", "timestamp": "00:44:26,800", "timestamp_s": 2666.0}, {"text": "where now I can basically from here start uploading my files like a Word document.", "timestamp": "00:44:30,330", "timestamp_s": 2670.0}, {"text": "Where for some reason it didn\u0027t pick up my REC that I specified like a", "timestamp": "00:44:36,530", "timestamp_s": 2676.0}, {"text": "few minutes before the recording, so I\u0027m gonna save this for now.", "timestamp": "00:44:41,330", "timestamp_s": 2681.0}, {"text": "But you probably get the idea, and again, most probably you\u0027re not gonna do this", "timestamp": "00:44:45,980", "timestamp_s": 2685.0}, {"text": "from here \u0027cause you\u0027re gonna ask your data team, your data admins, your data", "timestamp": "00:44:49,760", "timestamp_s": 2689.0}, {"text": "scientists, maybe to upload the data in the Azure storage or in a Cosmos database.", "timestamp": "00:44:54,950", "timestamp_s": 2694.0}, {"text": "But then the way to interact with it from here would be basically the same.", "timestamp": "00:45:02,305", "timestamp_s": 2702.0}, {"text": "That\u0027s, I would say mainly what I wanted to show you.", "timestamp": "00:45:07,465", "timestamp_s": 2707.0}, {"text": "Different capabilities, different ways to interact your GPT alike", "timestamp": "00:45:10,645", "timestamp_s": 2710.0}, {"text": "scenario, at least in this case, your overall AI inspired scenarios.", "timestamp": "00:45:16,555", "timestamp_s": 2716.0}, {"text": "Instead of just using the large language model, how to interact with", "timestamp": "00:45:21,765", "timestamp_s": 2721.0}, {"text": "your own custom data, where again, you got a multitude of sources.", "timestamp": "00:45:25,880", "timestamp_s": 2725.0}, {"text": "I am close to running out of time, so I guess I\u0027m gonna switch back to the", "timestamp": "00:45:30,990", "timestamp_s": 2730.0}, {"text": "presentation for the last couple of words before closing the session boundary.", "timestamp": "00:45:34,950", "timestamp_s": 2734.0}, {"text": "Now, before we wrap it up here, I wanted to highlight one other actually crucial", "timestamp": "00:45:40,420", "timestamp_s": 2740.0}, {"text": "aspect in developing AI solutions.", "timestamp": "00:45:44,950", "timestamp_s": 2744.0}, {"text": "And that\u0027s our Microsoft responsible AI framework.", "timestamp": "00:45:47,510", "timestamp_s": 2747.0}, {"text": "In short, we keep responsibility high across all levels of our", "timestamp": "00:45:51,050", "timestamp_s": 2751.0}, {"text": "AI development cycle and also in our AI and copilot solutions.", "timestamp": "00:45:55,370", "timestamp_s": 2755.0}, {"text": "Now, for example, we don\u0027t train on your data.", "timestamp": "00:46:00,740", "timestamp_s": 2760.0}, {"text": "We also do not use your prompts to train the models, and eventually", "timestamp": "00:46:04,130", "timestamp_s": 2764.0}, {"text": "your data remains your data.", "timestamp": "00:46:08,450", "timestamp_s": 2768.0}, {"text": "Specifically within AI Foundry, you can manage an integration with our", "timestamp": "00:46:11,020", "timestamp_s": 2771.0}, {"text": "responsible framework out of Azure AI content safety, which is, robust,", "timestamp": "00:46:15,430", "timestamp_s": 2775.0}, {"text": "safe content moderation platform.", "timestamp": "00:46:20,830", "timestamp_s": 2780.0}, {"text": "Leveraging AI to ensure that whatever you are building keeps safety, in mind,", "timestamp": "00:46:23,590", "timestamp_s": 2783.0}, {"text": "and also enhances user experiences.", "timestamp": "00:46:30,560", "timestamp_s": 2790.0}, {"text": "It integrates with a lot of powerful AI models.", "timestamp": "00:46:33,530", "timestamp_s": 2793.0}, {"text": "Allowing you to detect, but also eliminate inappropriate content.", "timestamp": "00:46:36,965", "timestamp_s": 2796.0}, {"text": "For example, hateful, sexual, violent, or self-harm inducing responses.", "timestamp": "00:46:41,285", "timestamp_s": 2801.0}, {"text": "Using filters and safety thresholds, organizations can tailor content safety", "timestamp": "00:46:47,555", "timestamp_s": 2807.0}, {"text": "measures to, again, make sure that once the application goes live, a lot of the", "timestamp": "00:46:53,225", "timestamp_s": 2813.0}, {"text": "safety measures are already in place.", "timestamp": "00:46:57,845", "timestamp_s": 2817.0}, {"text": "This brings me to the end of this session where I would like to highlight several", "timestamp": "00:47:00,715", "timestamp_s": 2820.0}, {"text": "of our top use cases for Azure AI Foundry, starting from deploying your Azure AI", "timestamp": "00:47:05,365", "timestamp_s": 2825.0}, {"text": "services and AI foundry hubs and projects.", "timestamp": "00:47:11,425", "timestamp_s": 2831.0}, {"text": "Starting the development project governance.", "timestamp": "00:47:14,425", "timestamp_s": 2834.0}, {"text": "You would use AI Foundry to deploy, test, validate your", "timestamp": "00:47:17,155", "timestamp_s": 2837.0}, {"text": "large language models of choice.", "timestamp": "00:47:20,785", "timestamp_s": 2840.0}, {"text": "From there, you\u0027re gonna primarily use it, out of the playground that", "timestamp": "00:47:23,185", "timestamp_s": 2843.0}, {"text": "I talked about and showed you.", "timestamp": "00:47:26,595", "timestamp_s": 2846.0}, {"text": "To validate the models, configure system messages, validate your prompt responses,", "timestamp": "00:47:28,285", "timestamp_s": 2848.0}, {"text": "and then last fine tuning the model, and then obviously integrating your", "timestamp": "00:47:33,595", "timestamp_s": 2853.0}, {"text": "safety net, your responsible AI as well.", "timestamp": "00:47:37,975", "timestamp_s": 2857.0}, {"text": "I hope with this session I managed to walk you through a sneak peek of what Azure", "timestamp": "00:47:41,325", "timestamp_s": 2861.0}, {"text": "AI services using AI Foundry can do for your organizations, especially when you", "timestamp": "00:47:45,285", "timestamp_s": 2865.0}, {"text": "are thinking about developing your own custom co-pilots, as we like to call it.", "timestamp": "00:47:51,615", "timestamp_s": 2871.0}, {"text": "I wanna thank you for having joined me in this session.", "timestamp": "00:47:56,405", "timestamp_s": 2876.0}, {"text": "I also would like to thank the com 42 team for having invited me as a", "timestamp": "00:47:59,105", "timestamp_s": 2879.0}, {"text": "speaker to present at this conference.", "timestamp": "00:48:03,065", "timestamp_s": 2883.0}, {"text": "I hope you enjoyed the rest of com 42 large language model conference", "timestamp": "00:48:06,065", "timestamp_s": 2886.0}, {"text": "and hopefully we\u0027ll meet again soon in any of the other com 42", "timestamp": "00:48:10,355", "timestamp_s": 2890.0}, {"text": "conferences in the near future.", "timestamp": "00:48:14,225", "timestamp_s": 2894.0}, {"text": "Take care for now.", "timestamp": "00:48:16,595", "timestamp_s": 2896.0}, {"text": "Have a great day and don\u0027t hesitate reaching out if you", "timestamp": "00:48:17,435", "timestamp_s": 2897.0}, {"text": "should have any more questions.", "timestamp": "00:48:20,375", "timestamp_s": 2900.0}, {"text": "Take care my friends.", "timestamp": "00:48:22,385", "timestamp_s": 2902.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: '39HKmrC3AHI',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              Using Azure AI Foundry to manage all your Large Language Models
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>Microsoft embraced OpenAI for their Copilot and Azure AI solutions early 2024. But did you know, now more than a year later, you can deploy several other LLMs from different vendors, using your trusted Azure environment? Thanks to Azure AI Foundry.</p>
<!-- End Text -->
          </div>

          
          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./srt/llms2025_Peter_De_Tender.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:00,330'); seek(0.0)">
              Hey everyone.
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:01,350'); seek(1.0)">
              Welcome to com 42 on large language models.
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:05,970'); seek(5.0)">
              My name is Peter Deten, technical trainer at Microsoft Live,
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:09,570'); seek(9.0)">
              presenting from Redmond, Washington.
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:11,730'); seek(11.0)">
              My session today covers using Azure AI Foundry to manage all
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:16,560'); seek(16.0)">
              your large language models.
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:18,870'); seek(18.0)">
              With that, I would say welcome and let's go.
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:21,740'); seek(21.0)">
              Over the next 45 minutes to an hour, I will cover the following topics, starting
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:26,630'); seek(26.0)">
              with a quick overview of the future of work with ai, followed by domain
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:32,030'); seek(32.0)">
              section, how Azure AI Foundry is used by Microsoft itself to run AI solutions and
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:00:38,300'); seek(38.0)">
              obviously how you can leverage the same.
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:00:41,480'); seek(41.0)">
              And then last, how to bring in a rag architecture, meaning using all the beauty
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:00:46,849'); seek(46.0)">
              from Azure AI together with AI Foundry.
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:00:50,060'); seek(50.0)">
              Generative AI using large language models, but then also integrating your own data.
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:00:56,000'); seek(56.0)">
              And then for each of these topics, you can expect quite some live
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:00:59,510'); seek(59.0)">
              demos during the session as well.
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:01:02,890'); seek(62.0)">
              So again, my name is Peter d Tander originally.
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:06,450'); seek(66.0)">
              Originally from Belgium, but ated to Redmond, Washington to continue my
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:10,619'); seek(70.0)">
              job as a Microsoft technical trainer.
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:13,200'); seek(73.0)">
              I've been a Microsoft trainer for about six years now.
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:16,150'); seek(76.0)">
              before I joined Microsoft in a full-time employee position, I was already working
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:20,860'); seek(80.0)">
              for them as a partner and vendor out of my own company for about seven years.
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:25,590'); seek(85.0)">
              My Azure background has always been on the infra and in architecture side, but
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:30,360'); seek(90.0)">
              gradually I shifted more into DevOps developing Azure solutions, and nowadays,
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:35,220'); seek(95.0)">
              obviously a lot about AI and copilot.
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:38,820'); seek(98.0)">
              Feel free to reach out if you should have any questions using
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:01:42,420'); seek(102.0)">
              any of the listed methods.
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:01:45,100'); seek(105.0)">
              Good.
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:01:45,350'); seek(105.0)">
              So with that all out of the way, let's jump in.
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:01:48,530'); seek(108.0)">
              Now.
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:01:48,680'); seek(108.0)">
              When I talk about AI in any of the Azure and AI workshops I'm
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:01:53,150'); seek(113.0)">
              teaching, I always like to start with a quote from our CEO Satya.
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:01:58,130'); seek(118.0)">
              He explained it as follows.
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:00,110'); seek(120.0)">
              Organizations are asking not only how, but also how fast they can actually
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:06,230'); seek(126.0)">
              apply this next generation of AI to address the biggest opportunities
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:11,120'); seek(131.0)">
              and challenges they are facing.
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:13,269'); seek(133.0)">
              Good with that all out of the way, let's jump in.
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:17,105'); seek(137.0)">
              Now when I talk about AI in our workshops here at Microsoft, I always
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:20,855'); seek(140.0)">
              like to start with a quote from our CEO.
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:22,924'); seek(142.0)">
              Satya.
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:24,454'); seek(144.0)">
              Organizations are asking not only how, but also how fast they can apply this
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:02:29,734'); seek(149.0)">
              next generation of AI to address the biggest challenges, but also opportunities
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:02:35,015'); seek(155.0)">
              they face safely and responsibly.
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:02:38,454'); seek(158.0)">
              Now the core of the quote will become more clear by the end of my
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:02:41,815'); seek(161.0)">
              session, so that, let's start with the foundation, understanding what
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:02:46,225'); seek(166.0)">
              the future of work with AI looks like.
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:02:48,975'); seek(168.0)">
              For the last two years, give or take, organizations have primarily been
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:02:53,265'); seek(173.0)">
              experimenting with different models.
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:02:56,115'); seek(176.0)">
              I think it is safe to say that OpenAI with Jet GPD revolutionized the world
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:01,275'); seek(181.0)">
              with Jet GPD again, end of 2023.
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:05,115'); seek(185.0)">
              But from there, several other players came into the market like Gemini,
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:09,455'); seek(189.0)">
              from Google, and Tropic with Claude.
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:12,285'); seek(192.0)">
              deep seek from China, Microsoft having the five, models, menstrual,
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:17,125'); seek(197.0)">
              hugging, face, and so many other.
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:19,435'); seek(199.0)">
              Now what this slide represents is how many different models are actually
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:23,605'); seek(203.0)">
              being used by an organization.
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:26,095'); seek(206.0)">
              The average, you could say here is, 3, 2, 5, so probably four as
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:03:30,335'); seek(210.0)">
              the average where no one on the interviewed organizations was just
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:03:34,295'); seek(214.0)">
              relying on a single large language model for any of their AI solutions.
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:03:39,145'); seek(219.0)">
              Now also important to highlight is that about 80% of early AI projects
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:03:44,065'); seek(224.0)">
              actually fail because not meeting expectations and not meeting them
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:03:48,295'); seek(228.0)">
              because they're too complex now.
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:03:50,395'); seek(230.0)">
              Complexity and the fact that especially generative AI is
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:03:54,055'); seek(234.0)">
              still rather new technology.
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:03:55,755'); seek(235.0)">
              And also providing a breadth of large language models to
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:03:58,965'); seek(238.0)">
              choose from, but then also.
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:02,175'); seek(242.0)">
              The fact that applications are changing, moving from single models
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:07,245'); seek(247.0)">
              into orchestrated systems, allowing to learn and adapt continuously.
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:12,825'); seek(252.0)">
              Customers and users are expecting AI influenced, or you could
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:16,845'); seek(256.0)">
              say AI inspired capabilities.
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:19,455'); seek(259.0)">
              In almost any kind of application today across different industries
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:23,835'); seek(263.0)">
              and across different use cases.
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:04:25,985'); seek(265.0)">
              Now, even amidst these challenges, it's clear that generative AI is what makes
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:04:30,455'); seek(270.0)">
              applications through the intelligent, but that's also a paradigm shift.
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:04:35,365'); seek(275.0)">
              AI is moving from this, I don't know, autopilot phase, which was all
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:04:39,490'); seek(279.0)">
              about narrowing purpose-built tools that use machine learning models.
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:04:43,875'); seek(283.0)">
              To now come up with predictions recommendations.
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:04:46,935'); seek(286.0)">
              also just automating to now having this co-pilot era where there's tremendous
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:04:53,235'); seek(293.0)">
              opportunity to really revolutionize how just about everything can start
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:04:58,745'); seek(298.0)">
              using those intelligent applications.
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:00,875'); seek(300.0)">
              You can now enable natural language interaction, constantly improving user
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:05,375'); seek(305.0)">
              experience and quickly delivering new features and capabilities to the market.
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:10,675'); seek(310.0)">
              So with that, let's shift gears a little bit and talk about
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:13,735'); seek(313.0)">
              Azure AI Foundry specifically.
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:16,525'); seek(316.0)">
              By the way, one of the reasons Microsoft has moved such fast pace over the last
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:20,995'); seek(320.0)">
              few months is because our Microsoft AI solutions within Microsoft are
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:25,945'); seek(325.0)">
              all running using Azure AI Foundry.
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:05:28,755'); seek(328.0)">
              Now we've built our Microsoft copilot reaching in meantime,
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:05:32,925'); seek(332.0)">
              millions of users across the globe.
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:05:35,775'); seek(335.0)">
              Informing them across different platforms using, for example, just copilot on
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:05:40,245'); seek(340.0)">
              the mobile device in the browser, using copilot web, using copilot
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:05:44,595'); seek(344.0)">
              within Microsoft 3 6 5 applications, security copilot dynamics copilot,
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:05:50,145'); seek(350.0)">
              Azure co-pilot, and GitHub copilot.
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:05:53,175'); seek(353.0)">
              All of these co-pilot are a hundred percent begged by Azure AI Foundry.
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:05:58,535'); seek(358.0)">
              Which now also becomes available to you.
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:02,045'); seek(362.0)">
              So you might have heard about Azure AI Studio before, where it's still the same
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:06,455'); seek(366.0)">
              foundation, I would say being the one-stop shop, like a management portal for
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:11,345'); seek(371.0)">
              developers IT sales admins, cloud admins.
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:14,105'); seek(374.0)">
              If you want to create your own custom copilots leveraging ai, Azure AI services.
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:21,665'); seek(381.0)">
              So insured Azure AI Foundry is a trusted, integrated platform designed for
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:26,975'); seek(386.0)">
              developers, IT admins, cloud architects, allowing them to design, customize, and
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:06:32,645'); seek(392.0)">
              manage AI applications as well as agents.
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:06:35,675'); seek(395.0)">
              Nowadays, it offers a rich set of AI capabilities and tools, and yes, I'll
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:06:40,675'); seek(400.0)">
              walk you through a few of these in a demo using an easy to use, easy to navigate.
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:06:46,165'); seek(406.0)">
              Portal, but there's also a unified SDK providing you APIs to really accelerate
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:06:52,225'); seek(412.0)">
              the path from developing to production.
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:06:54,915'); seek(414.0)">
              Now, what sets Azure AI Foundry apart is the accessibility through the world's
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:06:59,595'); seek(419.0)">
              most loved developer tools, meaning GitHub Visual Studio and co-pilot studio.
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:07:05,770'); seek(425.0)">
              This really integrates with a lot of other scenarios.
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:07:09,640'); seek(429.0)">
              So what we see here is continuously building up on Azure AI Foundry being this
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:15,010'); seek(435.0)">
              open, flexible, modular platform, sorry, with a lot of the tools a developer needs
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:20,760'); seek(440.0)">
              in a single platform to build multi-agent solutions, integrating third party tools.
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:26,465'); seek(446.0)">
              Just like we've done with our own models.
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:28,885'); seek(448.0)">
              This also means that developers now get access to Quick Start AI application
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:33,085'); seek(453.0)">
              templates to support their development cycle and really shortening that
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:37,525'); seek(457.0)">
              complexity that I talked about before.
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:07:40,395'); seek(460.0)">
              Any of these templates can be customized using a wide area of already existing
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:07:45,345'); seek(465.0)">
              models and tools, making your applications future-proof development investments.
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:07:51,425'); seek(471.0)">
              Another part I wanna talk about is it governance.
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:07:54,425'); seek(474.0)">
              So IT governance at scale, like what we call here, enterprise
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:07:57,905'); seek(477.0)">
              setup is baked in AI foundry.
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:08:01,295'); seek(481.0)">
              It allows you to provide a comprehensive approach providing self-service
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:08:05,375'); seek(485.0)">
              experiences, customizable configurations, and overall enhancing agility, security,
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:08:11,795'); seek(491.0)">
              but also keeping compliance in mind.
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:08:14,495'); seek(494.0)">
              So to give you an idea, there's obviously prebuilt baked in.
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:08:18,670'); seek(498.0)">
              Azure and Azure AI Foundry, role-based access control, including like owner
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:23,890'); seek(503.0)">
              having you, giving you all permissions, including changing security permissions.
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:28,955'); seek(508.0)">
              They're a little bit lower permission contributor, but there's
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:32,135'); seek(512.0)">
              also reader ai, developer and AI inference deployment operator roles.
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:38,015'); seek(518.0)">
              Little bit complex there.
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:39,505'); seek(519.0)">
              but what it means is like for any kind of responsibility as
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:08:43,465'); seek(523.0)">
              part of your development cycle.
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:08:45,390'); seek(525.0)">
              You can have, a corresponding role-based access control.
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:08:49,680'); seek(529.0)">
              Next to that, all these roles, are accessible from within the same AI
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:08:53,460'); seek(533.0)">
              foundry where we now use a topology called the hub and projects out of the hub.
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:08:59,100'); seek(539.0)">
              It's like the highest level in the topology.
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:09:01,920'); seek(541.0)">
              You're gonna allocate one or more projects, and within a
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:09:04,980'); seek(544.0)">
              project you're gonna define.
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:09:06,680'); seek(546.0)">
              The different, permissions On top of that, you can think about other
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:09:11,440'); seek(551.0)">
              features, mentioned here on the diagram.
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:09:14,315'); seek(554.0)">
              Identity, access management, network security, data protection,
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:09:18,525'); seek(558.0)">
              encryption, compute, storage, quota, access to the models.
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:09:22,935'); seek(562.0)">
              All that is now becoming available within a project and within a hub.
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:28,725'); seek(568.0)">
              Mainly avoiding that each and every developer when they're working
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:32,265'); seek(572.0)">
              on an AI inspired application that they have to deploy, like
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:09:36,035'); seek(576.0)">
              the full architecture themselves.
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:09:38,165'); seek(578.0)">
              So you would almost say that your cloud team is now building the hub and project.
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:09:43,355'); seek(583.0)">
              And developers are consuming the services, the building blocks within
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:09:47,705'); seek(587.0)">
              a project, and then on the outside.
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:09:50,595'); seek(590.0)">
              And then on the outside we have our business it.
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:09:53,535'); seek(593.0)">
              And from there we could also expand with IT security because in the
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:09:58,605'); seek(598.0)">
              end, it's still part of the broader Azure world, which means that
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:10:01,755'); seek(601.0)">
              everything you might already know.
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:10:03,840'); seek(603.0)">
              From Azure Tenants, Azure subscriptions management groups, like the whole
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:10:07,770'); seek(607.0)">
              governance layer around it is now also still valid once you start
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:10:11,970'); seek(611.0)">
              deploying your AI foundry and corresponding Azure Resources.
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:10:16,550'); seek(616.0)">
              Apart from the core AI services dependencies extended with other
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:10:20,480'); seek(620.0)">
              Azure resources like E Vault, private networking, and the like.
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:10:24,350'); seek(624.0)">
              You can now also easily, I would say, provide access to those external
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:10:28,340'); seek(628.0)">
              resources from within AI Foundry using a feature called Connections.
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:10:34,040'); seek(634.0)">
              So again, it means that instead of needing to provide access to your development
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:10:38,240'); seek(638.0)">
              team, your IT Cloud admins to all those resources, it's now becoming just another
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:10:43,790'); seek(643.0)">
              aspect of your AI Foundry landscape.
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:10:46,880'); seek(646.0)">
              And these connections are typically already linked to
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:10:49,550'); seek(649.0)">
              multiple projects within a hub.
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:10:51,820'); seek(651.0)">
              And with that, let's shift to a first demo here where I'll walk you through the
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:10:55,540'); seek(655.0)">
              base deployment of Azure AI services, as well as a first look at Azure AI Foundry,
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:11:01,840'); seek(661.0)">
              showing you the hope and project, as well as how to add and manage your connections.
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:11:06,960'); seek(666.0)">
              So my starting point here is my Azure subscription, and I got everything inside
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:11:13,680'); seek(673.0)">
              my, sample com 42 Foundry resource group.
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:11:18,160'); seek(678.0)">
              I already deployed most of the resources that I need, but my
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:11:23,090'); seek(683.0)">
              assumption is that you already know how to deploy some resource in Azure.
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:11:27,710'); seek(687.0)">
              So not all that important.
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:11:29,280'); seek(689.0)">
              for now.
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:11:29,990'); seek(689.0)">
              One of the building blocks I have is an Azure AI hub.
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:11:34,100'); seek(694.0)">
              I'll talk about that a little bit again later on.
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:11:37,070'); seek(697.0)">
              Within, we got a project, the core that I'm using here is Azure AI Services,
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:11:43,010'); seek(703.0)">
              and I got a few site services over here, like a container registry and Azure Key
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:11:48,380'); seek(708.0)">
              Vault log analytics for my monitoring.
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:11:51,170'); seek(711.0)">
              So the starting point will most probably be your AI service, which means that
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:11:57,050'); seek(717.0)">
              you would go into the Azure portal.
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:11:59,470'); seek(719.0)">
              From there, you would deploy a new service called Azure AI
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:12:02,920'); seek(722.0)">
              Service, and that's pretty much it.
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:12:05,830'); seek(725.0)">
              Now, from a development perspective, there are a few things that you need to keep in
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:12:09,940'); seek(729.0)">
              mind for connecting to your AI service.
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:12:14,280'); seek(734.0)">
              Primarily, I would say here, endpoints and your keys.
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:12:18,060'); seek(738.0)">
              So when we move to endpoints, what we have is obviously depending
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:12:22,230'); seek(742.0)">
              on the different AI use cases.
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:12:24,660'); seek(744.0)">
              In my example here, I'm using OpenAI to really have that generative AI
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:12:29,490'); seek(749.0)">
              capability available as an endpoint allowing me to integrate later on
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:12:35,790'); seek(755.0)">
              my large language models and so much more out of my foundry interface.
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:12:40,200'); seek(760.0)">
              I. If I wanna interact with other AI services like the
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:12:44,090'); seek(764.0)">
              more traditional ones, right?
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:12:45,650'); seek(765.0)">
              Compute, vision, content, safety, language, translator, I can again
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:12:49,730'); seek(769.0)">
              find all that information up here.
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:12:52,450'); seek(772.0)">
              Now, the reason why, we have our AI Foundry as a portal is because in
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:12:57,500'); seek(777.0)">
              the end from here, what I'm doing is just managing the Azure resources.
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:13:02,780'); seek(782.0)">
              So you could almost say that this should be a part.
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:13:05,535'); seek(785.0)">
              That maybe your developer is not really seeing anymore.
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:13:09,105'); seek(789.0)">
              Why not?
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:13:09,555'); seek(789.0)">
              Because for them, everything that is related to management
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:13:13,575'); seek(793.0)">
              is now moved into AI Foundry.
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:13:16,695'); seek(796.0)">
              By the way, if you navigate back to the starting point AI service,
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:13:21,125'); seek(801.0)">
              you can see down here there is the Azure AI Foundry portal link.
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:13:26,465'); seek(806.0)">
              So let me move over to that one, and that's where we are now,
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:13:29,785'); seek(809.0)">
              landing in our Foundry portal.
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:13:32,515'); seek(812.0)">
              Now, there's a few different ways you can.
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:13:34,285'); seek(814.0)">
              You'd end up here.
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:13:35,305'); seek(815.0)">
              So I talked about the hub and project, right?
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:13:39,175'); seek(819.0)">
              But when within my setup here, you won't really see that.
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:13:43,875'); seek(823.0)">
              So depending a bit how you get there, you're gonna see that.
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:13:46,935'); seek(826.0)">
              Right now here I'm in my Azure open AI service because for
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:13:51,375'); seek(831.0)">
              this scenario, I started from deploying an open ai Azure service.
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:13:57,455'); seek(837.0)">
              now if I navigate to my other scenario, I'm now in my Azure AI foundry, homepage
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:14:04,575'); seek(844.0)">
              you could say, which by the way, you can navigate to from ai.azure.com.
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:14:10,855'); seek(850.0)">
              And within.
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:14:12,385'); seek(852.0)">
              As you can see here, I do have my hub and my project.
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:14:16,525'); seek(856.0)">
              When I navigate to my hub, you're gonna see some highlights
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:14:20,545'); seek(860.0)">
              from my Azure subscription.
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:14:22,735'); seek(862.0)">
              So down here I can still see my Azure subscription.
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:14:26,065'); seek(866.0)">
              I could switch back to manage it in my Azure portal, but now I can also,
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:14:30,805'); seek(870.0)">
              as a developer, picking up the AI endpoints and keys that I need from here.
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:14:36,225'); seek(876.0)">
              So instead of now just having my open AI service, it's not.
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:14:40,095'); seek(880.0)">
              Now switched, you could say, to Azure AI Foundry Management Center.
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:14:46,925'); seek(886.0)">
              Within the management center, we have obviously the overview
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:14:50,825'); seek(890.0)">
              of our hubs and projects.
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:14:52,535'); seek(892.0)">
              And again, the logic is that you would create one or more hubs as
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:14:56,525'); seek(896.0)">
              the higher level in the topology and underneath you would create
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:15:00,395'); seek(900.0)">
              one or more projects within a hub.
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:15:03,335'); seek(903.0)">
              So that's the relationship you can see from here.
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:15:07,145'); seek(907.0)">
              I got my AI project as part of my.
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:15:09,875'); seek(909.0)">
              AI hub.
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:15:10,595'); seek(910.0)">
              That's the logic behind it.
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:15:12,715'); seek(912.0)">
              Staying within the hub level for a minute.
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:15:17,365'); seek(917.0)">
              I talked about RAC, role-based access control, where now you can see I got
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:15:21,595'); seek(921.0)">
              my AI admin and a little bit lower.
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:15:25,255'); seek(925.0)">
              I got my Azure ML data scientists replicating that you have someone
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:15:29,845'); seek(929.0)">
              managing the AI service and you might have some data scientist on the other side
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:15:34,975'); seek(934.0)">
              interacting with the storage, providing, the data endpoints most probably.
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:15:39,845'); seek(939.0)">
              And then from there, allowing my developers to start interacting.
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:15:44,005'); seek(944.0)">
              You can manage your quota.
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:15:46,495'); seek(946.0)">
              So if I switch back up here, one of the, I would say.
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:15:51,395'); seek(951.0)">
              Configuration options you have within Azure.
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:15:53,885'); seek(953.0)">
              Later on when we start deploying our models is that you need to
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:15:58,115'); seek(958.0)">
              know a bit about the models.
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:15:59,645'); seek(959.0)">
              First of all, you need to know how much tokens, like the virtual AI currency,
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:16:05,165'); seek(965.0)">
              I would call it, your application would need, but also knowing that each
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:16:09,965'); seek(969.0)">
              and every Azure region together with the models, also provide you a quota.
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:16:14,655'); seek(974.0)">
              So in my setup here, I already have a few scenarios like models
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:16:19,205'); seek(979.0)">
              deployed and I'll show you in there.
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:16:20,555'); seek(980.0)">
              Next demo how to actually do this.
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:16:23,135'); seek(983.0)">
              But what you can see here is that I deployed GPT-4 oh.
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:16:28,235'); seek(988.0)">
              This is the version I'm using most, probably the latest one, and I'm
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:16:32,555'); seek(992.0)">
              allocating 8,000 tokens per minute.
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:16:36,125'); seek(996.0)">
              We're now, for the total of my Azure region, there's 450,000 available.
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:16:43,160'); seek(1003.0)">
              So depending on the needs of your application, you're gonna
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:16:46,175'); seek(1006.0)">
              allow less or more numbers of tokens or thousands of tokens.
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:16:51,195'); seek(1011.0)">
              Because they heavily influence, the richness, I would say, of the prompts
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:16:55,385'); seek(1015.0)">
              your users can run, but also, how complete the actual, prompt response can be.
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:17:02,345'); seek(1022.0)">
              Where at some point you might actually run out of tokens, and that's where
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:17:06,305'); seek(1026.0)">
              now in the quota you need to validate what your Azure region, provides.
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:17:11,565'); seek(1031.0)">
              So that's the first, I would say high level scenario on how to
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:17:15,545'); seek(1035.0)">
              actually navigate across your.
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:17:18,695'); seek(1038.0)">
              AI foundry starting from the Azure portal, deploying an Azure AI service,
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:17:24,245'); seek(1044.0)">
              and within navigating to Foundry.
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:17:26,855'); seek(1046.0)">
              Where next you have the option to use the hub and, project topology allocating REC.
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:17:34,245'); seek(1054.0)">
              And then in the next step, we're gonna allocate our actual, language models.
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:17:39,845'); seek(1059.0)">
              But for now, back to the presentation.
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:17:42,355'); seek(1062.0)">
              While most of my demos will happen from the AI Foundry portal, I understand
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:17:46,735'); seek(1066.0)">
              that most developers will probably like to interact from a, I don't know,
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:17:51,535'); seek(1071.0)">
              development interface, and that's where an SDK comes into the picture.
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:17:56,335'); seek(1076.0)">
              So the good news is that there is an Azure ai, SDK specifically available.
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:18:01,215'); seek(1081.0)">
              To equip developers streamlining AI integration and really enriching
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:18:06,135'); seek(1086.0)">
              that user experience and building in functionalities into their applications.
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:18:11,535'); seek(1091.0)">
              This toolkit supports multiple programming languages, Python, c sharp.net,
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:18:16,065'); seek(1096.0)">
              Java, you think of it, you name it, and it is supported, really enabling
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:18:20,325'); seek(1100.0)">
              developers to select the language of choice and making them more productive.
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:18:25,115'); seek(1105.0)">
              While developing, generative AI inspired applications.
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:18:29,385'); seek(1109.0)">
              So from there, developers can efficiently build, evaluate,
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:18:32,805'); seek(1112.0)">
              deploy those AI components.
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:18:35,475'); seek(1115.0)">
              The SEK integration is obviously part of the already trusted
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:18:39,435'); seek(1119.0)">
              development environments, mentioned before, GitHub Visual Studio vs.
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:18:43,105'); seek(1123.0)">
              Code, and you're gonna interact with your AI Foundry not from
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:18:47,785'); seek(1127.0)">
              within the portal, like I'll show you in the demo, but obviously from
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:18:51,415'); seek(1131.0)">
              within the SDK integration directly.
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:18:54,315'); seek(1134.0)">
              With the base Azure Services and AI Foundry up and running.
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:18:58,365'); seek(1138.0)">
              Let's talk a bit about the large language models, which by the way is the topic
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:19:02,445'); seek(1142.0)">
              of the conference overall, right?
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:19:04,665'); seek(1144.0)">
              With Azure AI Foundry, you get access to an extensive
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:19:07,935'); seek(1147.0)">
              list of large language models.
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:19:10,065'); seek(1150.0)">
              Really allowing you as the developer or obviously your customers,
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:19:14,025'); seek(1154.0)">
              to choose the models that make most sense for your solution.
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:19:18,405'); seek(1158.0)">
              Now, while this list here on screen might not feel extensive.
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:19:22,230'); seek(1162.0)">
              Know that there are more than a thousand different models.
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:19:24,900'); seek(1164.0)">
              Yes, more than a thousand to choose from available today, which can all
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:19:30,300'); seek(1170.0)">
              be deployed within your AI foundry.
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:19:32,730'); seek(1172.0)">
              Even I would say deep seek.
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:19:34,230'); seek(1174.0)">
              One of the more recent, large language models integrated
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:19:37,850'); seek(1177.0)">
              only a couple of weeks ago.
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:19:39,380'); seek(1179.0)">
              It's already available, and we got more on the list coming out in the near future.
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:19:44,380'); seek(1184.0)">
              So for that, let me jump back to my demo environment and show you how
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:19:48,580'); seek(1188.0)">
              easy it can be to search for models, deploy the models, and also covering
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:19:52,930'); seek(1192.0)">
              a few other, I would say, baseline tasks once you start using models
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:19:57,550'); seek(1197.0)">
              and all from within AI Foundry.
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:20:00,030'); seek(1200.0)">
              All right.
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:20:00,420'); seek(1200.0)">
              So with that, let's have a look at, the actual large language models can be
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:20:04,710'); seek(1204.0)">
              deployed again from within our AI foundry.
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:20:08,490'); seek(1208.0)">
              So I'm still at the screen where, I finished my previous demo.
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:20:12,120'); seek(1212.0)">
              There was actually one part I forgot to show you.
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:20:14,730'); seek(1214.0)">
              And that's, the connectors or connected resources.
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:20:18,540'); seek(1218.0)">
              Now, if you think about how a developer interacts with.
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:20:22,455'); seek(1222.0)">
              The AI service, as I showed you, there's the endpoint, but there's also the keys.
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:20:27,405'); seek(1227.0)">
              And later on we'll talk about rag architecture, which means you're
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:20:30,735'); seek(1230.0)">
              probably gonna integrate, like AI search.
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:20:33,775'); seek(1233.0)">
              And then in the last part there's a little bit, I'll talk about content
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:20:37,195'); seek(1237.0)">
              safety, making sure that your application is following our Microsoft
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:20:41,815'); seek(1241.0)">
              responsible AI framework guidelines.
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:20:45,175'); seek(1245.0)">
              So all of these are standalone services, standalone resources
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:20:49,225'); seek(1249.0)">
              in the Azure platform.
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:20:50,975'); seek(1250.0)">
              We're now again, in that mindset that your developer will probably
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:20:54,635'); seek(1254.0)">
              need access to all those resources.
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:20:57,155'); seek(1257.0)">
              Instead of giving them access from an Azure perspective, you could now
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:21:01,535'); seek(1261.0)">
              allocate them as an available resource for the hub or an individual project.
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:21:07,840'); seek(1267.0)">
              And that's mainly what you could manage from here.
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:21:10,390'); seek(1270.0)">
              So just to clarify the interface, if you've never really seen, AI Foundry
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:21:14,570'); seek(1274.0)">
              in action, the highest level AI foundry is available from ai.azure.com and
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:21:22,040'); seek(1282.0)">
              underneath you're gonna create a hub.
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:21:24,920'); seek(1284.0)">
              Within the hub.
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:21:26,090'); seek(1286.0)">
              You later on gonna create a project that we already talked about,
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:21:29,810'); seek(1289.0)">
              and then from there we interact with our connected resources.
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:21:34,250'); seek(1294.0)">
              So from here I could interact with new.
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:21:37,610'); seek(1297.0)">
              I talked about Key Vault.
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:21:39,350'); seek(1299.0)">
              I didn't really, deploy it yet, but you could interact with OpenAI, with your
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:21:43,960'); seek(1303.0)">
              speech and other, some other services.
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:21:46,770'); seek(1306.0)">
              And if you want, you could actually directly connect to other service
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:21:50,520'); seek(1310.0)">
              building blocks in Azure or even outside of Azure as well.
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:21:54,470'); seek(1314.0)">
              Now, from here, we can shift to our models.
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:21:57,380'); seek(1317.0)">
              Now, there's a few different ways, I would say within the portal to do this,
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:22:01,100'); seek(1321.0)">
              depending if you are active on a project, active on a. Are active in the open AI
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:22:06,950'); seek(1326.0)">
              services that I showed you at the start.
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:22:09,430'); seek(1329.0)">
              From here, I navigated inside the hub and I'm now inside this specific project
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:22:16,320'); seek(1336.0)">
              where you can see, as you already know from my previous demo, I already
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:22:19,710'); seek(1339.0)">
              have some of my connections available.
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:22:22,680'); seek(1342.0)">
              So what this means is that, for example, my cloud admin pre deploy the connections
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:22:27,570'); seek(1347.0)">
              and they're now becoming available.
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:22:29,670'); seek(1349.0)">
              But imagine that I also wanna deploy my own specific.
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:22:33,330'); seek(1353.0)">
              That I only want to use within this specific project.
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:22:36,960'); seek(1356.0)">
              So I could do this again from here since I'm already in the project, right?
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:22:41,460'); seek(1361.0)">
              I could manage it all from here, or why not?
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:22:44,730'); seek(1364.0)">
              I could open up my project in a separate blade.
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:22:48,860'); seek(1368.0)">
              And then from here I get again, my models and endpoints.
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:22:53,000'); seek(1373.0)">
              So it looks about the same.
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:22:54,110'); seek(1374.0)">
              It just depends on how you're gonna navigate to it.
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:22:57,455'); seek(1377.0)">
              So let's show you how we can add a new model, and this is now
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:23:02,135'); seek(1382.0)">
              giving me access to all possible models within our environment.
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:23:07,115'); seek(1387.0)">
              So you can see I talked about, a bit more than a thousand, and we actually
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:23:11,495'); seek(1391.0)">
              have almost 2000 available in there.
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:23:14,675'); seek(1394.0)">
              So you can start with pre-built collections.
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:23:17,435'); seek(1397.0)">
              So if you want, you could filter based on only the ones from OpenAI.
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:23:22,110'); seek(1402.0)">
              Like an easy example and then the list will only obviously present those ones.
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:23:27,330'); seek(1407.0)">
              Or if you wanna filter based on what I can do with them and then maybe
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:23:32,850'); seek(1412.0)">
              some specific features, like I only wanna have the ones supporting chat
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:23:37,710'); seek(1417.0)">
              completions and overall completions.
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:23:40,650'); seek(1420.0)">
              Then you can see that there are, open AI ones.
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:23:43,720'); seek(1423.0)">
              The Microsoft five one, there's minus one, there's Lama from Meta, and again,
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:23:48,700'); seek(1428.0)">
              all the other ones showing up here.
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:23:50,850'); seek(1430.0)">
              So the next step now is selecting your model.
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:23:55,200'); seek(1435.0)">
              It always provides you a pretty detailed description, what that model actually
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:23:59,850'); seek(1439.0)">
              represents, and then you could also define some of its, capabilities.
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:24:05,710'); seek(1445.0)">
              From there, you would confirm, now, since I already deployed this, it's not gonna
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:24:09,670'); seek(1449.0)">
              allow me to deploy this anymore, so let's.
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:24:12,890'); seek(1452.0)">
              Try and select another one here, GPT-4 oh.
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:24:16,370'); seek(1456.0)">
              Still one of the more recent ones.
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:24:18,770'); seek(1458.0)">
              Again, explanation, sharing information about the latest, version you could
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:24:23,370'); seek(1463.0)">
              say, and then some description what it actually allows you to do.
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:24:27,180'); seek(1467.0)">
              So I'm gonna confirm, and the next step is now defining the specifics
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:24:32,090'); seek(1472.0)">
              for my project so I can choose the deployment type global standard.
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:24:36,830'); seek(1476.0)">
              It means that you're gonna pay per API call.
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:24:40,475'); seek(1480.0)">
              And if you want, if the model supports it, there's a few other ones as well.
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:24:44,735'); seek(1484.0)">
              I would say if you wanna know more details, then please consult our,
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:24:48,135'); seek(1488.0)">
              Microsoft documentation, because I don't have the time in this
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:24:51,075'); seek(1491.0)">
              demo to expand on all of these.
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:24:53,145'); seek(1493.0)">
              But it has a lot to do with.
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:24:55,410'); seek(1495.0)">
              The high variability aspects of the Azure architecture in the backend.
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:25:00,330'); seek(1500.0)">
              Next, in our deployment details, we can fine tune, customize this a little bit, so
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:25:05,430'); seek(1505.0)">
              you've got the different model versions.
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:25:07,250'); seek(1507.0)">
              some versions up and down.
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:25:08,570'); seek(1508.0)">
              You could say typically, my guidance is to use the most up-to-date version,
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:25:13,790'); seek(1513.0)">
              but there might be specific use cases where maybe you don't have
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:25:17,120'); seek(1517.0)">
              to or you don't want to do that.
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:25:19,495'); seek(1519.0)">
              If you wanna integrate it with one of your previously discussed
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:25:22,555'); seek(1522.0)">
              connections, you could do that as well.
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:25:24,595'); seek(1524.0)">
              And then defining the tokens per minute rate limit.
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:25:27,775'); seek(1527.0)">
              And again, this influences the use cases of your application if you
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:25:32,785'); seek(1532.0)">
              wanna integrate content filtering.
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:25:34,465'); seek(1534.0)">
              So again, the content safety, right?
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:25:36,770'); seek(1536.0)">
              That's where, you could at least for now, pick the default, because I'll talk about
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:25:40,930'); seek(1540.0)">
              this, a little bit more towards the end.
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:25:43,790'); seek(1543.0)">
              So you pick your model, use, confirm some of the settings,
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:25:47,480'); seek(1547.0)">
              and from there you're gonna.
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:25:48,740'); seek(1548.0)">
              To run the deployment.
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:25:50,090'); seek(1550.0)">
              So pretty easy.
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:25:51,260'); seek(1551.0)">
              I would say pretty straightforward.
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:25:53,410'); seek(1553.0)">
              Once we have a model deployed, like in this case, we typically
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:25:57,750'); seek(1557.0)">
              provide you some starting points.
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:25:59,580'); seek(1559.0)">
              And again, we're targeting developers, right?
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:26:02,100'); seek(1562.0)">
              So what do you need here is.
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:26:04,745'); seek(1564.0)">
              Azure credentials.
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:26:05,915'); seek(1565.0)">
              Installing like Python example in this case, and how to actually
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:26:09,905'); seek(1569.0)">
              start testing, validating, and it's almost literally copy pasting.
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:26:14,855'); seek(1574.0)">
              If Python is your, language of choice.
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:26:17,905'); seek(1577.0)">
              If you go oh, actually I want to use another language, I'm gonna do C sharp,
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:26:21,855'); seek(1581.0)">
              bam, within just a split second, it's gonna give you the different steps,
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:26:25,965'); seek(1585.0)">
              how to import the necessary packages.
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:26:31,255'); seek(1591.0)">
              To install Azure AI and then obviously the identity, and then from there, creating
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:26:38,095'); seek(1598.0)">
              a point to your AI service endpoint.
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:26:40,975'); seek(1600.0)">
              What's important here is the name of your endpoint together with the deployment
            </span>
            
            <span id="chunk-417" class="transcript-chunks" onclick="console.log('00:26:46,045'); seek(1606.0)">
              and the name of your deployment.
            </span>
            
            <span id="chunk-418" class="transcript-chunks" onclick="console.log('00:26:48,455'); seek(1608.0)">
              And then you're gonna tune your chat conversations.
            </span>
            
            <span id="chunk-419" class="transcript-chunks" onclick="console.log('00:26:50,915'); seek(1610.0)">
              I'll talk about this a little bit later on.
            </span>
            
            <span id="chunk-420" class="transcript-chunks" onclick="console.log('00:26:53,345'); seek(1613.0)">
              And then if you want some additional samples, how to interact with,
            </span>
            
            <span id="chunk-421" class="transcript-chunks" onclick="console.log('00:26:58,165'); seek(1618.0)">
              conversational context, how to keep the history and so on.
            </span>
            
            <span id="chunk-422" class="transcript-chunks" onclick="console.log('00:27:02,005'); seek(1622.0)">
              Another angle to validate some model information is now I
            </span>
            
            <span id="chunk-423" class="transcript-chunks" onclick="console.log('00:27:07,585'); seek(1627.0)">
              moved from project into the hub.
            </span>
            
            <span id="chunk-424" class="transcript-chunks" onclick="console.log('00:27:10,345'); seek(1630.0)">
              The way to deploy is obviously, a hundred percent the same.
            </span>
            
            <span id="chunk-425" class="transcript-chunks" onclick="console.log('00:27:13,625'); seek(1633.0)">
              So if I wanna search for LAMA instead of using any of the
            </span>
            
            <span id="chunk-426" class="transcript-chunks" onclick="console.log('00:27:18,325'); seek(1638.0)">
              pre-built categories and filters.
            </span>
            
            <span id="chunk-427" class="transcript-chunks" onclick="console.log('00:27:20,620'); seek(1640.0)">
              You could now interact with, any of these models.
            </span>
            
            <span id="chunk-428" class="transcript-chunks" onclick="console.log('00:27:23,780'); seek(1643.0)">
              So the baseline is the same on the hub level, on the project level,
            </span>
            
            <span id="chunk-429" class="transcript-chunks" onclick="console.log('00:27:27,500'); seek(1647.0)">
              so nothing really different.
            </span>
            
            <span id="chunk-430" class="transcript-chunks" onclick="console.log('00:27:29,560'); seek(1649.0)">
              Another scenario that I would like to highlight here, this is the playground,
            </span>
            
            <span id="chunk-431" class="transcript-chunks" onclick="console.log('00:27:34,990'); seek(1654.0)">
              but I'll talk about the playground, a little bit later on, is inside.
            </span>
            
            <span id="chunk-432" class="transcript-chunks" onclick="console.log('00:27:39,575'); seek(1659.0)">
              Our model catalog.
            </span>
            
            <span id="chunk-433" class="transcript-chunks" onclick="console.log('00:27:40,865'); seek(1660.0)">
              From here, it's basically giving you the exact same view.
            </span>
            
            <span id="chunk-434" class="transcript-chunks" onclick="console.log('00:27:44,885'); seek(1664.0)">
              Now, where it is slightly different is that again, here I'm inside the
            </span>
            
            <span id="chunk-435" class="transcript-chunks" onclick="console.log('00:27:49,745'); seek(1669.0)">
              open AI service specific option.
            </span>
            
            <span id="chunk-436" class="transcript-chunks" onclick="console.log('00:27:52,895'); seek(1672.0)">
              And again, I like to highlight that it's all based on AI Foundry, but
            </span>
            
            <span id="chunk-437" class="transcript-chunks" onclick="console.log('00:27:56,705'); seek(1676.0)">
              every now and then, depending on the model you deploy, it might show
            </span>
            
            <span id="chunk-438" class="transcript-chunks" onclick="console.log('00:28:00,335'); seek(1680.0)">
              you more or less, integrations.
            </span>
            
            <span id="chunk-439" class="transcript-chunks" onclick="console.log('00:28:03,435'); seek(1683.0)">
              If I now move to another open model here.
            </span>
            
            <span id="chunk-440" class="transcript-chunks" onclick="console.log('00:28:07,895'); seek(1687.0)">
              You can see that it also allows me to deploy it.
            </span>
            
            <span id="chunk-441" class="transcript-chunks" onclick="console.log('00:28:11,195'); seek(1691.0)">
              It still provides all those details, but now I could also look into why
            </span>
            
            <span id="chunk-442" class="transcript-chunks" onclick="console.log('00:28:15,515'); seek(1695.0)">
              should I maybe deploy this if one of my colleagues already deployed this scenario?
            </span>
            
            <span id="chunk-443" class="transcript-chunks" onclick="console.log('00:28:21,305'); seek(1701.0)">
              So giving you, again, quite some, some options.
            </span>
            
            <span id="chunk-444" class="transcript-chunks" onclick="console.log('00:28:24,835'); seek(1704.0)">
              Another question that we sometimes get about the model
            </span>
            
            <span id="chunk-445" class="transcript-chunks" onclick="console.log('00:28:28,015'); seek(1708.0)">
              is getting access to metrics.
            </span>
            
            <span id="chunk-446" class="transcript-chunks" onclick="console.log('00:28:31,135'); seek(1711.0)">
              Now this is not showing you, like specific details I would say about
            </span>
            
            <span id="chunk-447" class="transcript-chunks" onclick="console.log('00:28:35,225'); seek(1715.0)">
              the model, but more about how your applications, how your developers
            </span>
            
            <span id="chunk-448" class="transcript-chunks" onclick="console.log('00:28:40,265'); seek(1720.0)">
              are using, targeting this model.
            </span>
            
            <span id="chunk-449" class="transcript-chunks" onclick="console.log('00:28:42,995'); seek(1722.0)">
              I just deployed this without actually having a sample app in the front
            </span>
            
            <span id="chunk-450" class="transcript-chunks" onclick="console.log('00:28:46,955'); seek(1726.0)">
              of it, so that's why my metrics are not really impressive, right?
            </span>
            
            <span id="chunk-451" class="transcript-chunks" onclick="console.log('00:28:50,885'); seek(1730.0)">
              But it should give.
            </span>
            
            <span id="chunk-452" class="transcript-chunks" onclick="console.log('00:28:51,605'); seek(1731.0)">
              You some idea that auditing monitoring is also baked in.
            </span>
            
            <span id="chunk-453" class="transcript-chunks" onclick="console.log('00:28:56,345'); seek(1736.0)">
              And then a bit on our Microsoft security framework or the responsible AI framework.
            </span>
            
            <span id="chunk-454" class="transcript-chunks" onclick="console.log('00:29:02,470'); seek(1742.0)">
              We have, since I deployed my model using a default filter, it's already
            </span>
            
            <span id="chunk-455" class="transcript-chunks" onclick="console.log('00:29:08,020'); seek(1748.0)">
              having, some content safety as part of my language model baked in.
            </span>
            
            <span id="chunk-456" class="transcript-chunks" onclick="console.log('00:29:14,740'); seek(1754.0)">
              And obviously for now, because I didn't use it, there's no violations,
            </span>
            
            <span id="chunk-457" class="transcript-chunks" onclick="console.log('00:29:18,040'); seek(1758.0)">
              there's no abusive use and so on.
            </span>
            
            <span id="chunk-458" class="transcript-chunks" onclick="console.log('00:29:20,280'); seek(1760.0)">
              But again, giving you a pretty nice idea about, what you could use it for.
            </span>
            
            <span id="chunk-459" class="transcript-chunks" onclick="console.log('00:29:25,260'); seek(1765.0)">
              Another example I can show you is using the model catalog.
            </span>
            
            <span id="chunk-460" class="transcript-chunks" onclick="console.log('00:29:29,490'); seek(1769.0)">
              And again, this is the same catalog, what I showed you before, it just giving
            </span>
            
            <span id="chunk-461" class="transcript-chunks" onclick="console.log('00:29:33,720'); seek(1773.0)">
              you the full list and a different view.
            </span>
            
            <span id="chunk-462" class="transcript-chunks" onclick="console.log('00:29:36,180'); seek(1776.0)">
              Why did I switch yet to another view?
            </span>
            
            <span id="chunk-463" class="transcript-chunks" onclick="console.log('00:29:38,820'); seek(1778.0)">
              Because there's another question that we can answer from here
            </span>
            
            <span id="chunk-464" class="transcript-chunks" onclick="console.log('00:29:42,270'); seek(1782.0)">
              and that's what is, the model?
            </span>
            
            <span id="chunk-465" class="transcript-chunks" onclick="console.log('00:29:44,450'); seek(1784.0)">
              Supposed to help me with, or also answering the question,
            </span>
            
            <span id="chunk-466" class="transcript-chunks" onclick="console.log('00:29:48,530'); seek(1788.0)">
              what model is better for a specific purpose than another?
            </span>
            
            <span id="chunk-467" class="transcript-chunks" onclick="console.log('00:29:52,850'); seek(1792.0)">
              Since I got deep seek up here, I'm gonna check out that model.
            </span>
            
            <span id="chunk-468" class="transcript-chunks" onclick="console.log('00:29:56,570'); seek(1796.0)">
              And same as before, providing a description, but now it also
            </span>
            
            <span id="chunk-469" class="transcript-chunks" onclick="console.log('00:30:01,280'); seek(1801.0)">
              gives me a link to benchmarks.
            </span>
            
            <span id="chunk-470" class="transcript-chunks" onclick="console.log('00:30:04,190'); seek(1804.0)">
              So by design, what it's gonna do is looking at, I would say its
            </span>
            
            <span id="chunk-471" class="transcript-chunks" onclick="console.log('00:30:07,730'); seek(1807.0)">
              own, core competition, right?
            </span>
            
            <span id="chunk-472" class="transcript-chunks" onclick="console.log('00:30:10,540'); seek(1810.0)">
              'cause as a developer.
            </span>
            
            <span id="chunk-473" class="transcript-chunks" onclick="console.log('00:30:12,580'); seek(1812.0)">
              You need to think about all these different language models, and I'm
            </span>
            
            <span id="chunk-474" class="transcript-chunks" onclick="console.log('00:30:15,520'); seek(1815.0)">
              pretty sure that the conference sessions will help you with a lot of this.
            </span>
            
            <span id="chunk-475" class="transcript-chunks" onclick="console.log('00:30:19,600'); seek(1819.0)">
              But then within our AI Foundry, knowing that you get access to
            </span>
            
            <span id="chunk-476" class="transcript-chunks" onclick="console.log('00:30:22,990'); seek(1822.0)">
              more than, 1800, now, how do you decide across those language models?
            </span>
            
            <span id="chunk-477" class="transcript-chunks" onclick="console.log('00:30:28,970'); seek(1828.0)">
              So that's where now you can easily select any of the models and
            </span>
            
            <span id="chunk-478" class="transcript-chunks" onclick="console.log('00:30:32,270'); seek(1832.0)">
              there will always be benchmarking.
            </span>
            
            <span id="chunk-479" class="transcript-chunks" onclick="console.log('00:30:34,910'); seek(1834.0)">
              In this case, it's comparing the deep seek feed three that I selected with
            </span>
            
            <span id="chunk-480" class="transcript-chunks" onclick="console.log('00:30:39,530'); seek(1839.0)">
              some of the other popular counterparts.
            </span>
            
            <span id="chunk-481" class="transcript-chunks" onclick="console.log('00:30:41,870'); seek(1841.0)">
              Parts, but nothing blocks you from also integrating a comparison
            </span>
            
            <span id="chunk-482" class="transcript-chunks" onclick="console.log('00:30:46,850'); seek(1846.0)">
              that you can manage, that you can tune with some other models.
            </span>
            
            <span id="chunk-483" class="transcript-chunks" onclick="console.log('00:30:51,310'); seek(1851.0)">
              I think with that, you should have a pretty good idea about, using
            </span>
            
            <span id="chunk-484" class="transcript-chunks" onclick="console.log('00:30:54,870'); seek(1854.0)">
              different parts of the AI Foundry portal, how to deploy the different
            </span>
            
            <span id="chunk-485" class="transcript-chunks" onclick="console.log('00:30:59,490'); seek(1859.0)">
              models using open AI service, using other services within the hub and
            </span>
            
            <span id="chunk-486" class="transcript-chunks" onclick="console.log('00:31:05,700'); seek(1865.0)">
              project, and then also talked about.
            </span>
            
            <span id="chunk-487" class="transcript-chunks" onclick="console.log('00:31:08,085'); seek(1868.0)">
              The higher level model, catalog, and the benchmarking, so that, let's
            </span>
            
            <span id="chunk-488" class="transcript-chunks" onclick="console.log('00:31:13,425'); seek(1873.0)">
              switch back to the presentation.
            </span>
            
            <span id="chunk-489" class="transcript-chunks" onclick="console.log('00:31:15,215'); seek(1875.0)">
              Nice.
            </span>
            
            <span id="chunk-490" class="transcript-chunks" onclick="console.log('00:31:15,875'); seek(1875.0)">
              So we're now at the point where we have our large language models deployed.
            </span>
            
            <span id="chunk-491" class="transcript-chunks" onclick="console.log('00:31:20,105'); seek(1880.0)">
              We did some benchmark testing and I briefly talked about some
            </span>
            
            <span id="chunk-492" class="transcript-chunks" onclick="console.log('00:31:23,675'); seek(1883.0)">
              other capabilities, like the fine tuning I briefly touched on.
            </span>
            
            <span id="chunk-493" class="transcript-chunks" onclick="console.log('00:31:27,675'); seek(1887.0)">
              So I can hear your next question already.
            </span>
            
            <span id="chunk-494" class="transcript-chunks" onclick="console.log('00:31:30,445'); seek(1890.0)">
              coming up.
            </span>
            
            <span id="chunk-495" class="transcript-chunks" onclick="console.log('00:31:31,425'); seek(1891.0)">
              okay.
            </span>
            
            <span id="chunk-496" class="transcript-chunks" onclick="console.log('00:31:32,055'); seek(1892.0)">
              AI Foundry is the go-to portal I use for generative AI with large language models.
            </span>
            
            <span id="chunk-497" class="transcript-chunks" onclick="console.log('00:31:37,695'); seek(1897.0)">
              But what about all the other more traditional AI services that we had
            </span>
            
            <span id="chunk-498" class="transcript-chunks" onclick="console.log('00:31:41,865'); seek(1901.0)">
              in the Azure portal in the past?
            </span>
            
            <span id="chunk-499" class="transcript-chunks" onclick="console.log('00:31:44,145'); seek(1904.0)">
              I would say that's actually a great question.
            </span>
            
            <span id="chunk-500" class="transcript-chunks" onclick="console.log('00:31:46,545'); seek(1906.0)">
              Now remember in the introduction section we talked about the paradigm
            </span>
            
            <span id="chunk-501" class="transcript-chunks" onclick="console.log('00:31:50,595'); seek(1910.0)">
              shift in application development where customers and users somewhat
            </span>
            
            <span id="chunk-502" class="transcript-chunks" onclick="console.log('00:31:55,125'); seek(1915.0)">
              expect to have AI capabilities.
            </span>
            
            <span id="chunk-503" class="transcript-chunks" onclick="console.log('00:31:57,570'); seek(1917.0)">
              In basically any kind of application they're building or using.
            </span>
            
            <span id="chunk-504" class="transcript-chunks" onclick="console.log('00:32:02,130'); seek(1922.0)">
              While generative f AI seems to provide a lot of those capabilities, all other
            </span>
            
            <span id="chunk-505" class="transcript-chunks" onclick="console.log('00:32:06,840'); seek(1926.0)">
              AI services you might know from the past existing in Azure already are now
            </span>
            
            <span id="chunk-506" class="transcript-chunks" onclick="console.log('00:32:12,180'); seek(1932.0)">
              also gradually moving into AI Foundry as that management, AI services portal.
            </span>
            
            <span id="chunk-507" class="transcript-chunks" onclick="console.log('00:32:18,750'); seek(1938.0)">
              For example, AI search for architecture, although I'll talk about that later on,
            </span>
            
            <span id="chunk-508" class="transcript-chunks" onclick="console.log('00:32:23,370'); seek(1943.0)">
              but also talking about AI speech, AI Vision, document intelligence, language
            </span>
            
            <span id="chunk-509" class="transcript-chunks" onclick="console.log('00:32:28,820'); seek(1948.0)">
              translator, all those services have been around in Azure for close to 10 years
            </span>
            
            <span id="chunk-510" class="transcript-chunks" onclick="console.log('00:32:34,100'); seek(1954.0)">
              and can now gradually be integrated and managed from within AI Foundry as well.
            </span>
            
            <span id="chunk-511" class="transcript-chunks" onclick="console.log('00:32:39,850'); seek(1959.0)">
              Now the magic behind the scenes to manage all this is Foundry playground.
            </span>
            
            <span id="chunk-512" class="transcript-chunks" onclick="console.log('00:32:45,780'); seek(1965.0)">
              I already showed you a little bit of this from within our AI Foundry
            </span>
            
            <span id="chunk-513" class="transcript-chunks" onclick="console.log('00:32:50,820'); seek(1970.0)">
              portal, especially around a large language model deployment, but there's
            </span>
            
            <span id="chunk-514" class="transcript-chunks" onclick="console.log('00:32:55,110'); seek(1975.0)">
              actually a lot more you can do with it.
            </span>
            
            <span id="chunk-515" class="transcript-chunks" onclick="console.log('00:32:57,540'); seek(1977.0)">
              I would say let's have another look.
            </span>
            
            <span id="chunk-516" class="transcript-chunks" onclick="console.log('00:32:59,795'); seek(1979.0)">
              In this next demo, I'm gonna walk you through AI Foundry, showing you some
            </span>
            
            <span id="chunk-517" class="transcript-chunks" onclick="console.log('00:33:03,695'); seek(1983.0)">
              of the capabilities around playground, allowing you to test and validate
            </span>
            
            <span id="chunk-518" class="transcript-chunks" onclick="console.log('00:33:08,135'); seek(1988.0)">
              your models, and also switching to some more traditional AI capabilities.
            </span>
            
            <span id="chunk-519" class="transcript-chunks" onclick="console.log('00:33:13,375'); seek(1993.0)">
              Good.
            </span>
            
            <span id="chunk-520" class="transcript-chunks" onclick="console.log('00:33:13,825'); seek(1993.0)">
              So we have our models deployed in the previous part of the presentation,
            </span>
            
            <span id="chunk-521" class="transcript-chunks" onclick="console.log('00:33:18,595'); seek(1998.0)">
              which now means that we're ready to actually test and validate.
            </span>
            
            <span id="chunk-522" class="transcript-chunks" onclick="console.log('00:33:22,435'); seek(2002.0)">
              So the way to do this is from within once more AI Foundry,
            </span>
            
            <span id="chunk-523" class="transcript-chunks" onclick="console.log('00:33:26,955'); seek(2006.0)">
              we're now selecting playgrounds.
            </span>
            
            <span id="chunk-524" class="transcript-chunks" onclick="console.log('00:33:29,115'); seek(2009.0)">
              You could do this directly navigating to ai.azure.com/playgrounds, and
            </span>
            
            <span id="chunk-525" class="transcript-chunks" onclick="console.log('00:33:35,895'); seek(2015.0)">
              then it's gonna pull up your project.
            </span>
            
            <span id="chunk-526" class="transcript-chunks" onclick="console.log('00:33:37,995'); seek(2017.0)">
              And allowing you to actually build out your playgrounds.
            </span>
            
            <span id="chunk-527" class="transcript-chunks" onclick="console.log('00:33:41,895'); seek(2021.0)">
              Remember, we're primarily focusing on generative AI using chat co
            </span>
            
            <span id="chunk-528" class="transcript-chunks" onclick="console.log('00:33:47,325'); seek(2027.0)">
              conversations, but remember that we do have other AI services as well.
            </span>
            
            <span id="chunk-529" class="transcript-chunks" onclick="console.log('00:33:53,415'); seek(2033.0)">
              So if you wanna integrate with like speech or the newer agents based, like auto gen
            </span>
            
            <span id="chunk-530" class="transcript-chunks" onclick="console.log('00:33:58,195'); seek(2038.0)">
              alike syns, or you wanna integrate with like images using, for example, Dali or
            </span>
            
            <span id="chunk-531" class="transcript-chunks" onclick="console.log('00:34:03,955'); seek(2043.0)">
              some other large language model using.
            </span>
            
            <span id="chunk-532" class="transcript-chunks" onclick="console.log('00:34:07,015'); seek(2047.0)">
              Language playground.
            </span>
            
            <span id="chunk-533" class="transcript-chunks" onclick="console.log('00:34:08,095'); seek(2048.0)">
              And again, there's so many different ways to start testing interacting.
            </span>
            
            <span id="chunk-534" class="transcript-chunks" onclick="console.log('00:34:12,535'); seek(2052.0)">
              The most obvious one is using the chat playground.
            </span>
            
            <span id="chunk-535" class="transcript-chunks" onclick="console.log('00:34:16,615'); seek(2056.0)">
              So in the previous part of the demo, we deployed our GPT model
            </span>
            
            <span id="chunk-536" class="transcript-chunks" onclick="console.log('00:34:21,475'); seek(2061.0)">
              as part of our hub and project.
            </span>
            
            <span id="chunk-537" class="transcript-chunks" onclick="console.log('00:34:23,275'); seek(2063.0)">
              I got two of them linked to different connectors.
            </span>
            
            <span id="chunk-538" class="transcript-chunks" onclick="console.log('00:34:26,425'); seek(2066.0)">
              So again, emphasizing that all those building blocks from the
            </span>
            
            <span id="chunk-539" class="transcript-chunks" onclick="console.log('00:34:29,155'); seek(2069.0)">
              start are still nicely coming back here, I could start easy.
            </span>
            
            <span id="chunk-540" class="transcript-chunks" onclick="console.log('00:34:34,155'); seek(2074.0)">
              I got an AI assistant pretty.
            </span>
            
            <span id="chunk-541" class="transcript-chunks" onclick="console.log('00:34:36,165'); seek(2076.0)">
              Generic message here, and I'm gonna ask something like, what is the
            </span>
            
            <span id="chunk-542" class="transcript-chunks" onclick="console.log('00:34:40,215'); seek(2080.0)">
              typical weather in Seattle mid-March?
            </span>
            
            <span id="chunk-543" class="transcript-chunks" onclick="console.log('00:34:45,625'); seek(2085.0)">
              now it's nicely responding in mid-March and so on.
            </span>
            
            <span id="chunk-544" class="transcript-chunks" onclick="console.log('00:34:48,565'); seek(2088.0)">
              Obviously it's not about, the details, although in a real life scenario, I
            </span>
            
            <span id="chunk-545" class="transcript-chunks" onclick="console.log('00:34:52,505'); seek(2092.0)">
              would obviously encourage you to really validate and verify the actual response.
            </span>
            
            <span id="chunk-546" class="transcript-chunks" onclick="console.log('00:34:58,235'); seek(2098.0)">
              Now, again, based on your model, what do we get as a confirmation here?
            </span>
            
            <span id="chunk-547" class="transcript-chunks" onclick="console.log('00:35:02,105'); seek(2102.0)">
              Is that the model is working, it is responding well.
            </span>
            
            <span id="chunk-548" class="transcript-chunks" onclick="console.log('00:35:05,885'); seek(2105.0)">
              Now, if I would ask something like,
            </span>
            
            <span id="chunk-549" class="transcript-chunks" onclick="console.log('00:35:08,185'); seek(2108.0)">
              can you provide Belgian food recipe?
            </span>
            
            <span id="chunk-550" class="transcript-chunks" onclick="console.log('00:35:11,095'); seek(2111.0)">
              Remember my Belgian roots, it's gonna come up with some ingredients, and again,
            </span>
            
            <span id="chunk-551" class="transcript-chunks" onclick="console.log('00:35:16,735'); seek(2116.0)">
              it's still doing a pretty good job.
            </span>
            
            <span id="chunk-552" class="transcript-chunks" onclick="console.log('00:35:19,135'); seek(2119.0)">
              Let's see.
            </span>
            
            <span id="chunk-553" class="transcript-chunks" onclick="console.log('00:35:19,795'); seek(2119.0)">
              It came up with a, so mussels and fries.
            </span>
            
            <span id="chunk-554" class="transcript-chunks" onclick="console.log('00:35:22,585'); seek(2122.0)">
              Perfect.
            </span>
            
            <span id="chunk-555" class="transcript-chunks" onclick="console.log('00:35:23,095'); seek(2123.0)">
              Like a typical Belgian dish.
            </span>
            
            <span id="chunk-556" class="transcript-chunks" onclick="console.log('00:35:25,285'); seek(2125.0)">
              It provides me the ingredients, and next to that, it also provides.
            </span>
            
            <span id="chunk-557" class="transcript-chunks" onclick="console.log('00:35:28,795'); seek(2128.0)">
              The instructions and I'm actually getting a little bit hungry now out
            </span>
            
            <span id="chunk-558" class="transcript-chunks" onclick="console.log('00:35:32,485'); seek(2132.0)">
              of that, but not there yet because I need to show you a few other things.
            </span>
            
            <span id="chunk-559" class="transcript-chunks" onclick="console.log('00:35:37,405'); seek(2137.0)">
              Now, back to our starting point.
            </span>
            
            <span id="chunk-560" class="transcript-chunks" onclick="console.log('00:35:40,645'); seek(2140.0)">
              I got another project here, so quickly switching where this time I
            </span>
            
            <span id="chunk-561" class="transcript-chunks" onclick="console.log('00:35:44,965'); seek(2144.0)">
              got two different language models.
            </span>
            
            <span id="chunk-562" class="transcript-chunks" onclick="console.log('00:35:47,455'); seek(2147.0)">
              Now remember, the language model is trained on public data
            </span>
            
            <span id="chunk-563" class="transcript-chunks" onclick="console.log('00:35:52,525'); seek(2152.0)">
              up to a certain point in time.
            </span>
            
            <span id="chunk-564" class="transcript-chunks" onclick="console.log('00:35:54,925'); seek(2154.0)">
              Easy set.
            </span>
            
            <span id="chunk-565" class="transcript-chunks" onclick="console.log('00:35:55,615'); seek(2155.0)">
              GPT-3 five is.
            </span>
            
            <span id="chunk-566" class="transcript-chunks" onclick="console.log('00:35:57,885'); seek(2157.0)">
              Less up to date than GPT-4.
            </span>
            
            <span id="chunk-567" class="transcript-chunks" onclick="console.log('00:36:00,945'); seek(2160.0)">
              An easy example I can use to show you how this works is who
            </span>
            
            <span id="chunk-568" class="transcript-chunks" onclick="console.log('00:36:06,705'); seek(2166.0)">
              is the Prime Minister of the uk?
            </span>
            
            <span id="chunk-569" class="transcript-chunks" onclick="console.log('00:36:10,555'); seek(2170.0)">
              now it's gonna tell me based on a date.
            </span>
            
            <span id="chunk-570" class="transcript-chunks" onclick="console.log('00:36:12,775'); seek(2172.0)">
              October 21.
            </span>
            
            <span id="chunk-571" class="transcript-chunks" onclick="console.log('00:36:14,275'); seek(2174.0)">
              The Prime Minister is Boris Johnson.
            </span>
            
            <span id="chunk-572" class="transcript-chunks" onclick="console.log('00:36:16,910'); seek(2176.0)">
              Pretty cool.
            </span>
            
            <span id="chunk-573" class="transcript-chunks" onclick="console.log('00:36:17,480'); seek(2177.0)">
              I got my answer.
            </span>
            
            <span id="chunk-574" class="transcript-chunks" onclick="console.log('00:36:19,370'); seek(2179.0)">
              Where now if I switch to my GPT-4 model and I'm gonna run the same prompt,
            </span>
            
            <span id="chunk-575" class="transcript-chunks" onclick="console.log('00:36:26,510'); seek(2186.0)">
              I'm just gonna copy it from here.
            </span>
            
            <span id="chunk-576" class="transcript-chunks" onclick="console.log('00:36:28,900'); seek(2188.0)">
              You can see that now the answer is different and not
            </span>
            
            <span id="chunk-577" class="transcript-chunks" onclick="console.log('00:36:32,140'); seek(2192.0)">
              only different in context.
            </span>
            
            <span id="chunk-578" class="transcript-chunks" onclick="console.log('00:36:34,120'); seek(2194.0)">
              Like the actual answer I would say is.
            </span>
            
            <span id="chunk-579" class="transcript-chunks" onclick="console.log('00:36:36,895'); seek(2196.0)">
              More up to date, but also just by switching the model, you can
            </span>
            
            <span id="chunk-580" class="transcript-chunks" onclick="console.log('00:36:41,125'); seek(2201.0)">
              see that now I get access to more tokens, a short answer, a
            </span>
            
            <span id="chunk-581" class="transcript-chunks" onclick="console.log('00:36:45,055'); seek(2205.0)">
              pretty, little bit longer answer.
            </span>
            
            <span id="chunk-582" class="transcript-chunks" onclick="console.log('00:36:47,335'); seek(2207.0)">
              And if you wanna tune all this a little bit more, that's where you can go back
            </span>
            
            <span id="chunk-583" class="transcript-chunks" onclick="console.log('00:36:50,965'); seek(2210.0)">
              to, the previous part of the demo.
            </span>
            
            <span id="chunk-584" class="transcript-chunks" onclick="console.log('00:36:53,125'); seek(2213.0)">
              Another thing that's pretty cool is interacting with what
            </span>
            
            <span id="chunk-585" class="transcript-chunks" onclick="console.log('00:36:57,055'); seek(2217.0)">
              your chat actually can do.
            </span>
            
            <span id="chunk-586" class="transcript-chunks" onclick="console.log('00:36:59,755'); seek(2219.0)">
              So right now I used an easy example.
            </span>
            
            <span id="chunk-587" class="transcript-chunks" onclick="console.log('00:37:02,275'); seek(2222.0)">
              This could be used for I dunno, writing an essay on UK politics or something.
            </span>
            
            <span id="chunk-588" class="transcript-chunks" onclick="console.log('00:37:06,955'); seek(2226.0)">
              I don't know where.
            </span>
            
            <span id="chunk-589" class="transcript-chunks" onclick="console.log('00:37:08,215'); seek(2228.0)">
              Now we could tune this a little bit more, where I could do
            </span>
            
            <span id="chunk-590" class="transcript-chunks" onclick="console.log('00:37:12,145'); seek(2232.0)">
              something like, you are, Microsoft.
            </span>
            
            <span id="chunk-591" class="transcript-chunks" onclick="console.log('00:37:15,875'); seek(2235.0)">
              Technical trainer with expertise in Azure and Azure ai.
            </span>
            
            <span id="chunk-592" class="transcript-chunks" onclick="console.log('00:37:23,465'); seek(2243.0)">
              You can answer questions as long as you keep it polite and professional.
            </span>
            
            <span id="chunk-593" class="transcript-chunks" onclick="console.log('00:37:30,115'); seek(2250.0)">
              There we go.
            </span>
            
            <span id="chunk-594" class="transcript-chunks" onclick="console.log('00:37:30,825'); seek(2250.0)">
              You cannot answer questions about Amazon AWS or Google Cloud platform
            </span>
            
            <span id="chunk-595" class="transcript-chunks" onclick="console.log('00:37:40,825'); seek(2260.0)">
              to apologize in those scenarios.
            </span>
            
            <span id="chunk-596" class="transcript-chunks" onclick="console.log('00:37:44,805'); seek(2264.0)">
              Offer a Belgian beer flavor to try out instead.
            </span>
            
            <span id="chunk-597" class="transcript-chunks" onclick="console.log('00:37:50,765'); seek(2270.0)">
              So now what I'm doing here is tweaking, fine tuning if you want.
            </span>
            
            <span id="chunk-598" class="transcript-chunks" onclick="console.log('00:37:54,755'); seek(2274.0)">
              I use case where this could almost be like a virtual Microsoft technical trainer.
            </span>
            
            <span id="chunk-599" class="transcript-chunks" onclick="console.log('00:38:01,045'); seek(2281.0)">
              I'm gonna run a new chat conversation and from here I could do, can you explain
            </span>
            
            <span id="chunk-600" class="transcript-chunks" onclick="console.log('00:38:07,095'); seek(2287.0)">
              a bit about Azure Kubernetes service?
            </span>
            
            <span id="chunk-601" class="transcript-chunks" onclick="console.log('00:38:11,845'); seek(2291.0)">
              So it comes back as expected with a nice detailed prompt.
            </span>
            
            <span id="chunk-602" class="transcript-chunks" onclick="console.log('00:38:15,955'); seek(2295.0)">
              I'm using GPT-4 oh latest version, quite some tokens available in my
            </span>
            
            <span id="chunk-603" class="transcript-chunks" onclick="console.log('00:38:20,485'); seek(2300.0)">
              subscription when Now from here I could ask, what is the use case for AWS Beans
            </span>
            
            <span id="chunk-604" class="transcript-chunks" onclick="console.log('00:38:30,075'); seek(2310.0)">
              stock, like an existing AWS service.
            </span>
            
            <span id="chunk-605" class="transcript-chunks" onclick="console.log('00:38:33,935'); seek(2313.0)">
              When now it tells me like, oh, I'm sorry.
            </span>
            
            <span id="chunk-606" class="transcript-chunks" onclick="console.log('00:38:36,005'); seek(2316.0)">
              So I asked it to be professional and polite.
            </span>
            
            <span id="chunk-607" class="transcript-chunks" onclick="console.log('00:38:38,675'); seek(2318.0)">
              I think that's, pretty well covered here.
            </span>
            
            <span id="chunk-608" class="transcript-chunks" onclick="console.log('00:38:41,735'); seek(2321.0)">
              Unable to answer questions about AWS or any other AWS service and then however.
            </span>
            
            <span id="chunk-609" class="transcript-chunks" onclick="console.log('00:38:48,430'); seek(2328.0)">
              To make up for it.
            </span>
            
            <span id="chunk-610" class="transcript-chunks" onclick="console.log('00:38:49,660'); seek(2329.0)">
              Again, being nice and professional, I could recommend a Belgium beer.
            </span>
            
            <span id="chunk-611" class="transcript-chunks" onclick="console.log('00:38:54,580'); seek(2334.0)">
              How cool is that?
            </span>
            
            <span id="chunk-612" class="transcript-chunks" onclick="console.log('00:38:55,660'); seek(2335.0)">
              You can actually tune your environment, your chat conversations, using by the
            </span>
            
            <span id="chunk-613" class="transcript-chunks" onclick="console.log('00:39:01,600'); seek(2341.0)">
              way, what we call the system message.
            </span>
            
            <span id="chunk-614" class="transcript-chunks" onclick="console.log('00:39:04,930'); seek(2344.0)">
              And then as a developer you would integrate that, obviously
            </span>
            
            <span id="chunk-615" class="transcript-chunks" onclick="console.log('00:39:08,840'); seek(2348.0)">
              as part of your code as well.
            </span>
            
            <span id="chunk-616" class="transcript-chunks" onclick="console.log('00:39:10,760'); seek(2350.0)">
              And then allowing the chat conversations, going back and forth.
            </span>
            
            <span id="chunk-617" class="transcript-chunks" onclick="console.log('00:39:14,960'); seek(2354.0)">
              So that's pretty much it.
            </span>
            
            <span id="chunk-618" class="transcript-chunks" onclick="console.log('00:39:16,160'); seek(2356.0)">
              Out of this demo showed you.
            </span>
            
            <span id="chunk-619" class="transcript-chunks" onclick="console.log('00:39:17,930'); seek(2357.0)">
              How to interact with the playground, specifically this one for chat or
            </span>
            
            <span id="chunk-620" class="transcript-chunks" onclick="console.log('00:39:22,790'); seek(2362.0)">
              going back to the previous part of the demo where you can choose across
            </span>
            
            <span id="chunk-621" class="transcript-chunks" onclick="console.log('00:39:26,600'); seek(2366.0)">
              different playgrounds depending on use cases for images, integrating audio,
            </span>
            
            <span id="chunk-622" class="transcript-chunks" onclick="console.log('00:39:31,880'); seek(2371.0)">
              integrating other, assistant alike scenarios back to the presentation.
            </span>
            
            <span id="chunk-623" class="transcript-chunks" onclick="console.log('00:39:37,230'); seek(2377.0)">
              Sweet.
            </span>
            
            <span id="chunk-624" class="transcript-chunks" onclick="console.log('00:39:37,920'); seek(2377.0)">
              This brings me to the last topic in today's session covering rag architecture
            </span>
            
            <span id="chunk-625" class="transcript-chunks" onclick="console.log('00:39:42,510'); seek(2382.0)">
              or retrieval augmented generation.
            </span>
            
            <span id="chunk-626" class="transcript-chunks" onclick="console.log('00:39:45,500'); seek(2385.0)">
              Now, we heavily discussed large language models and how they
            </span>
            
            <span id="chunk-627" class="transcript-chunks" onclick="console.log('00:39:48,560'); seek(2388.0)">
              enrich your applications with generative AI capabilities.
            </span>
            
            <span id="chunk-628" class="transcript-chunks" onclick="console.log('00:39:52,145'); seek(2392.0)">
              For example, conversational context, natural language,
            </span>
            
            <span id="chunk-629" class="transcript-chunks" onclick="console.log('00:39:56,285'); seek(2396.0)">
              and primarily chat driven.
            </span>
            
            <span id="chunk-630" class="transcript-chunks" onclick="console.log('00:39:58,985'); seek(2398.0)">
              One main characteristic for most LMS is that they're trained using public
            </span>
            
            <span id="chunk-631" class="transcript-chunks" onclick="console.log('00:40:03,755'); seek(2403.0)">
              internet data, which obviously is totally fine, but what if your app
            </span>
            
            <span id="chunk-632" class="transcript-chunks" onclick="console.log('00:40:08,405'); seek(2408.0)">
              needs to know about your organizational data specifically, or your customer?
            </span>
            
            <span id="chunk-633" class="transcript-chunks" onclick="console.log('00:40:13,745'); seek(2413.0)">
              Your user can only use internal company specific information, not
            </span>
            
            <span id="chunk-634" class="transcript-chunks" onclick="console.log('00:40:18,455'); seek(2418.0)">
              using the context from public models.
            </span>
            
            <span id="chunk-635" class="transcript-chunks" onclick="console.log('00:40:21,450'); seek(2421.0)">
              That's exactly what RAG or retrieval augmented Generation is about.
            </span>
            
            <span id="chunk-636" class="transcript-chunks" onclick="console.log('00:40:26,850'); seek(2426.0)">
              Starting from a large language model approach, you are now augmenting
            </span>
            
            <span id="chunk-637" class="transcript-chunks" onclick="console.log('00:40:30,990'); seek(2430.0)">
              enriching if you want the dataset your AI application is using within your own data.
            </span>
            
            <span id="chunk-638" class="transcript-chunks" onclick="console.log('00:40:38,405'); seek(2438.0)">
              Which can be images, documents, knowledge bases, and they can be
            </span>
            
            <span id="chunk-639" class="transcript-chunks" onclick="console.log('00:40:43,145'); seek(2443.0)">
              stored within the Azure backend.
            </span>
            
            <span id="chunk-640" class="transcript-chunks" onclick="console.log('00:40:45,445'); seek(2445.0)">
              And that's really the next step, right?
            </span>
            
            <span id="chunk-641" class="transcript-chunks" onclick="console.log('00:40:47,305'); seek(2447.0)">
              So if you are wondering like where does this data come from,
            </span>
            
            <span id="chunk-642" class="transcript-chunks" onclick="console.log('00:40:50,485'); seek(2450.0)">
              like how do I integrate it?
            </span>
            
            <span id="chunk-643" class="transcript-chunks" onclick="console.log('00:40:52,885'); seek(2452.0)">
              There's a lot of different options.
            </span>
            
            <span id="chunk-644" class="transcript-chunks" onclick="console.log('00:40:54,655'); seek(2454.0)">
              So the easiest one I would say is using Azure blob storage.
            </span>
            
            <span id="chunk-645" class="transcript-chunks" onclick="console.log('00:40:58,650'); seek(2458.0)">
              But nothing blocks you from integrating with, for example,
            </span>
            
            <span id="chunk-646" class="transcript-chunks" onclick="console.log('00:41:01,260'); seek(2461.0)">
              Amazon S3 buckets as well.
            </span>
            
            <span id="chunk-647" class="transcript-chunks" onclick="console.log('00:41:03,990'); seek(2463.0)">
              And yes, I can show you also how to upload files manually in the
            </span>
            
            <span id="chunk-648" class="transcript-chunks" onclick="console.log('00:41:08,010'); seek(2468.0)">
              Azure portal, although I don't think it's like an enterprise
            </span>
            
            <span id="chunk-649" class="transcript-chunks" onclick="console.log('00:41:10,860'); seek(2470.0)">
              recommended approach to do that.
            </span>
            
            <span id="chunk-650" class="transcript-chunks" onclick="console.log('00:41:12,950'); seek(2472.0)">
              The backend interaction happens out of Azure AI search, building up
            </span>
            
            <span id="chunk-651" class="transcript-chunks" onclick="console.log('00:41:17,810'); seek(2477.0)">
              what we call vector information for each and every of your data sets.
            </span>
            
            <span id="chunk-652" class="transcript-chunks" onclick="console.log('00:41:22,250'); seek(2482.0)">
              And then once the indexing is done, your AI application will be able to respond to
            </span>
            
            <span id="chunk-653" class="transcript-chunks" onclick="console.log('00:41:27,650'); seek(2487.0)">
              prompts in the same way you expect from your large language model, but now using
            </span>
            
            <span id="chunk-654" class="transcript-chunks" onclick="console.log('00:41:32,420'); seek(2492.0)">
              knowledge coming in from your own data.
            </span>
            
            <span id="chunk-655" class="transcript-chunks" onclick="console.log('00:41:35,320'); seek(2495.0)">
              And you can expect it also brings me to the last demo here, showing you
            </span>
            
            <span id="chunk-656" class="transcript-chunks" onclick="console.log('00:41:39,580'); seek(2499.0)">
              what this rag architecture looks like and how to use it from within ai.
            </span>
            
            <span id="chunk-657" class="transcript-chunks" onclick="console.log('00:41:45,030'); seek(2505.0)">
              So regarding the, rag architecture, the main idea we wanna do from
            </span>
            
            <span id="chunk-658" class="transcript-chunks" onclick="console.log('00:41:49,070'); seek(2509.0)">
              here, and again, I'm just using the playground again, is importing
            </span>
            
            <span id="chunk-659" class="transcript-chunks" onclick="console.log('00:41:53,120'); seek(2513.0)">
              or linking it to our custom data.
            </span>
            
            <span id="chunk-660" class="transcript-chunks" onclick="console.log('00:41:56,360'); seek(2516.0)">
              So I'm, inside my project and I'm gonna.
            </span>
            
            <span id="chunk-661" class="transcript-chunks" onclick="console.log('00:42:00,520'); seek(2520.0)">
              Select here a new section where I could define other system messages, but
            </span>
            
            <span id="chunk-662" class="transcript-chunks" onclick="console.log('00:42:05,970'); seek(2525.0)">
              that's not specifically to re anymore.
            </span>
            
            <span id="chunk-663" class="transcript-chunks" onclick="console.log('00:42:08,490'); seek(2528.0)">
              So we're shifting down to the next section, and that's using your own data.
            </span>
            
            <span id="chunk-664" class="transcript-chunks" onclick="console.log('00:42:13,130'); seek(2533.0)">
              We can add new data sources and for now, I'll make it a little bit bigger.
            </span>
            
            <span id="chunk-665" class="transcript-chunks" onclick="console.log('00:42:19,070'); seek(2539.0)">
              You can choose from any of these using Azure AI search a service that's been
            </span>
            
            <span id="chunk-666" class="transcript-chunks" onclick="console.log('00:42:23,780'); seek(2543.0)">
              around in the platform for a couple of years already and now nicely integrating.
            </span>
            
            <span id="chunk-667" class="transcript-chunks" onclick="console.log('00:42:29,060'); seek(2549.0)">
              With, the generative AI capabilities of what an AI solution is, offering today
            </span>
            
            <span id="chunk-668" class="transcript-chunks" onclick="console.log('00:42:35,870'); seek(2555.0)">
              Azure blob storage, where obviously the idea is to have your data sets
            </span>
            
            <span id="chunk-669" class="transcript-chunks" onclick="console.log('00:42:41,420'); seek(2561.0)">
              like, PDF documents, images, word files, any other text files, json
            </span>
            
            <span id="chunk-670" class="transcript-chunks" onclick="console.log('00:42:46,000'); seek(2566.0)">
              alike scenarios in Azure blob storage.
            </span>
            
            <span id="chunk-671" class="transcript-chunks" onclick="console.log('00:42:48,970'); seek(2568.0)">
              Remember, you could link this to your hub and project, making sure that not.
            </span>
            
            <span id="chunk-672" class="transcript-chunks" onclick="console.log('00:42:53,800'); seek(2573.0)">
              Everyone needs access to the blob storage.
            </span>
            
            <span id="chunk-673" class="transcript-chunks" onclick="console.log('00:42:56,500'); seek(2576.0)">
              I would also recommend using, role-based access, preferably managed identities
            </span>
            
            <span id="chunk-674" class="transcript-chunks" onclick="console.log('00:43:02,380'); seek(2582.0)">
              to interact with those data endpoints.
            </span>
            
            <span id="chunk-675" class="transcript-chunks" onclick="console.log('00:43:04,980'); seek(2584.0)">
              Azure Cosmos database, our non-relational database here, which could be a
            </span>
            
            <span id="chunk-676" class="transcript-chunks" onclick="console.log('00:43:09,840'); seek(2589.0)">
              perfect, data set or database endpoint interacting with elastic search.
            </span>
            
            <span id="chunk-677" class="transcript-chunks" onclick="console.log('00:43:15,100'); seek(2595.0)">
              If you want, you could straight point to your web address
            </span>
            
            <span id="chunk-678" class="transcript-chunks" onclick="console.log('00:43:19,120'); seek(2599.0)">
              connecting to, a knowledge base.
            </span>
            
            <span id="chunk-679" class="transcript-chunks" onclick="console.log('00:43:21,890'); seek(2601.0)">
              Website, intranet, maybe SharePoint alike scenario, or, why not uploading
            </span>
            
            <span id="chunk-680" class="transcript-chunks" onclick="console.log('00:43:27,300'); seek(2607.0)">
              files and then still allowing you to turn them into an index.
            </span>
            
            <span id="chunk-681" class="transcript-chunks" onclick="console.log('00:43:32,130'); seek(2612.0)">
              So quite some options.
            </span>
            
            <span id="chunk-682" class="transcript-chunks" onclick="console.log('00:43:33,450'); seek(2613.0)">
              So imagine we are gonna go for blob storage.
            </span>
            
            <span id="chunk-683" class="transcript-chunks" onclick="console.log('00:43:36,720'); seek(2616.0)">
              You need to identify your subscription, the storage container,
            </span>
            
            <span id="chunk-684" class="transcript-chunks" onclick="console.log('00:43:42,060'); seek(2622.0)">
              the BLO storage, obviously.
            </span>
            
            <span id="chunk-685" class="transcript-chunks" onclick="console.log('00:43:43,650'); seek(2623.0)">
              And then if you wanna use a specific Azure search, you're gonna define the index.
            </span>
            
            <span id="chunk-686" class="transcript-chunks" onclick="console.log('00:43:50,310'); seek(2630.0)">
              And then from there.
            </span>
            
            <span id="chunk-687" class="transcript-chunks" onclick="console.log('00:43:51,510'); seek(2631.0)">
              How frequently is my information changing, which influences my index?
            </span>
            
            <span id="chunk-688" class="transcript-chunks" onclick="console.log('00:43:58,410'); seek(2638.0)">
              So from here, pretty straightforward.
            </span>
            
            <span id="chunk-689" class="transcript-chunks" onclick="console.log('00:44:00,840'); seek(2640.0)">
              You point to the data endpoints and that's pretty much it.
            </span>
            
            <span id="chunk-690" class="transcript-chunks" onclick="console.log('00:44:04,950'); seek(2644.0)">
              If I switch here to uploading files, it's still gonna ask for storage.
            </span>
            
            <span id="chunk-691" class="transcript-chunks" onclick="console.log('00:44:09,810'); seek(2649.0)">
              So you still need to have that storage background where now it's gonna enable
            </span>
            
            <span id="chunk-692" class="transcript-chunks" onclick="console.log('00:44:14,160'); seek(2654.0)">
              cross, origin to allow me to interact from my AI service here, my playground into.
            </span>
            
            <span id="chunk-693" class="transcript-chunks" onclick="console.log('00:44:21,730'); seek(2661.0)">
              My, blob storage container, I would still need to identify the index,
            </span>
            
            <span id="chunk-694" class="transcript-chunks" onclick="console.log('00:44:26,800'); seek(2666.0)">
              so this could be the live PDT index,
            </span>
            
            <span id="chunk-695" class="transcript-chunks" onclick="console.log('00:44:30,330'); seek(2670.0)">
              where now I can basically from here start uploading my files like a Word document.
            </span>
            
            <span id="chunk-696" class="transcript-chunks" onclick="console.log('00:44:36,530'); seek(2676.0)">
              Where for some reason it didn't pick up my REC that I specified like a
            </span>
            
            <span id="chunk-697" class="transcript-chunks" onclick="console.log('00:44:41,330'); seek(2681.0)">
              few minutes before the recording, so I'm gonna save this for now.
            </span>
            
            <span id="chunk-698" class="transcript-chunks" onclick="console.log('00:44:45,980'); seek(2685.0)">
              But you probably get the idea, and again, most probably you're not gonna do this
            </span>
            
            <span id="chunk-699" class="transcript-chunks" onclick="console.log('00:44:49,760'); seek(2689.0)">
              from here 'cause you're gonna ask your data team, your data admins, your data
            </span>
            
            <span id="chunk-700" class="transcript-chunks" onclick="console.log('00:44:54,950'); seek(2694.0)">
              scientists, maybe to upload the data in the Azure storage or in a Cosmos database.
            </span>
            
            <span id="chunk-701" class="transcript-chunks" onclick="console.log('00:45:02,305'); seek(2702.0)">
              But then the way to interact with it from here would be basically the same.
            </span>
            
            <span id="chunk-702" class="transcript-chunks" onclick="console.log('00:45:07,465'); seek(2707.0)">
              That's, I would say mainly what I wanted to show you.
            </span>
            
            <span id="chunk-703" class="transcript-chunks" onclick="console.log('00:45:10,645'); seek(2710.0)">
              Different capabilities, different ways to interact your GPT alike
            </span>
            
            <span id="chunk-704" class="transcript-chunks" onclick="console.log('00:45:16,555'); seek(2716.0)">
              scenario, at least in this case, your overall AI inspired scenarios.
            </span>
            
            <span id="chunk-705" class="transcript-chunks" onclick="console.log('00:45:21,765'); seek(2721.0)">
              Instead of just using the large language model, how to interact with
            </span>
            
            <span id="chunk-706" class="transcript-chunks" onclick="console.log('00:45:25,880'); seek(2725.0)">
              your own custom data, where again, you got a multitude of sources.
            </span>
            
            <span id="chunk-707" class="transcript-chunks" onclick="console.log('00:45:30,990'); seek(2730.0)">
              I am close to running out of time, so I guess I'm gonna switch back to the
            </span>
            
            <span id="chunk-708" class="transcript-chunks" onclick="console.log('00:45:34,950'); seek(2734.0)">
              presentation for the last couple of words before closing the session boundary.
            </span>
            
            <span id="chunk-709" class="transcript-chunks" onclick="console.log('00:45:40,420'); seek(2740.0)">
              Now, before we wrap it up here, I wanted to highlight one other actually crucial
            </span>
            
            <span id="chunk-710" class="transcript-chunks" onclick="console.log('00:45:44,950'); seek(2744.0)">
              aspect in developing AI solutions.
            </span>
            
            <span id="chunk-711" class="transcript-chunks" onclick="console.log('00:45:47,510'); seek(2747.0)">
              And that's our Microsoft responsible AI framework.
            </span>
            
            <span id="chunk-712" class="transcript-chunks" onclick="console.log('00:45:51,050'); seek(2751.0)">
              In short, we keep responsibility high across all levels of our
            </span>
            
            <span id="chunk-713" class="transcript-chunks" onclick="console.log('00:45:55,370'); seek(2755.0)">
              AI development cycle and also in our AI and copilot solutions.
            </span>
            
            <span id="chunk-714" class="transcript-chunks" onclick="console.log('00:46:00,740'); seek(2760.0)">
              Now, for example, we don't train on your data.
            </span>
            
            <span id="chunk-715" class="transcript-chunks" onclick="console.log('00:46:04,130'); seek(2764.0)">
              We also do not use your prompts to train the models, and eventually
            </span>
            
            <span id="chunk-716" class="transcript-chunks" onclick="console.log('00:46:08,450'); seek(2768.0)">
              your data remains your data.
            </span>
            
            <span id="chunk-717" class="transcript-chunks" onclick="console.log('00:46:11,020'); seek(2771.0)">
              Specifically within AI Foundry, you can manage an integration with our
            </span>
            
            <span id="chunk-718" class="transcript-chunks" onclick="console.log('00:46:15,430'); seek(2775.0)">
              responsible framework out of Azure AI content safety, which is, robust,
            </span>
            
            <span id="chunk-719" class="transcript-chunks" onclick="console.log('00:46:20,830'); seek(2780.0)">
              safe content moderation platform.
            </span>
            
            <span id="chunk-720" class="transcript-chunks" onclick="console.log('00:46:23,590'); seek(2783.0)">
              Leveraging AI to ensure that whatever you are building keeps safety, in mind,
            </span>
            
            <span id="chunk-721" class="transcript-chunks" onclick="console.log('00:46:30,560'); seek(2790.0)">
              and also enhances user experiences.
            </span>
            
            <span id="chunk-722" class="transcript-chunks" onclick="console.log('00:46:33,530'); seek(2793.0)">
              It integrates with a lot of powerful AI models.
            </span>
            
            <span id="chunk-723" class="transcript-chunks" onclick="console.log('00:46:36,965'); seek(2796.0)">
              Allowing you to detect, but also eliminate inappropriate content.
            </span>
            
            <span id="chunk-724" class="transcript-chunks" onclick="console.log('00:46:41,285'); seek(2801.0)">
              For example, hateful, sexual, violent, or self-harm inducing responses.
            </span>
            
            <span id="chunk-725" class="transcript-chunks" onclick="console.log('00:46:47,555'); seek(2807.0)">
              Using filters and safety thresholds, organizations can tailor content safety
            </span>
            
            <span id="chunk-726" class="transcript-chunks" onclick="console.log('00:46:53,225'); seek(2813.0)">
              measures to, again, make sure that once the application goes live, a lot of the
            </span>
            
            <span id="chunk-727" class="transcript-chunks" onclick="console.log('00:46:57,845'); seek(2817.0)">
              safety measures are already in place.
            </span>
            
            <span id="chunk-728" class="transcript-chunks" onclick="console.log('00:47:00,715'); seek(2820.0)">
              This brings me to the end of this session where I would like to highlight several
            </span>
            
            <span id="chunk-729" class="transcript-chunks" onclick="console.log('00:47:05,365'); seek(2825.0)">
              of our top use cases for Azure AI Foundry, starting from deploying your Azure AI
            </span>
            
            <span id="chunk-730" class="transcript-chunks" onclick="console.log('00:47:11,425'); seek(2831.0)">
              services and AI foundry hubs and projects.
            </span>
            
            <span id="chunk-731" class="transcript-chunks" onclick="console.log('00:47:14,425'); seek(2834.0)">
              Starting the development project governance.
            </span>
            
            <span id="chunk-732" class="transcript-chunks" onclick="console.log('00:47:17,155'); seek(2837.0)">
              You would use AI Foundry to deploy, test, validate your
            </span>
            
            <span id="chunk-733" class="transcript-chunks" onclick="console.log('00:47:20,785'); seek(2840.0)">
              large language models of choice.
            </span>
            
            <span id="chunk-734" class="transcript-chunks" onclick="console.log('00:47:23,185'); seek(2843.0)">
              From there, you're gonna primarily use it, out of the playground that
            </span>
            
            <span id="chunk-735" class="transcript-chunks" onclick="console.log('00:47:26,595'); seek(2846.0)">
              I talked about and showed you.
            </span>
            
            <span id="chunk-736" class="transcript-chunks" onclick="console.log('00:47:28,285'); seek(2848.0)">
              To validate the models, configure system messages, validate your prompt responses,
            </span>
            
            <span id="chunk-737" class="transcript-chunks" onclick="console.log('00:47:33,595'); seek(2853.0)">
              and then last fine tuning the model, and then obviously integrating your
            </span>
            
            <span id="chunk-738" class="transcript-chunks" onclick="console.log('00:47:37,975'); seek(2857.0)">
              safety net, your responsible AI as well.
            </span>
            
            <span id="chunk-739" class="transcript-chunks" onclick="console.log('00:47:41,325'); seek(2861.0)">
              I hope with this session I managed to walk you through a sneak peek of what Azure
            </span>
            
            <span id="chunk-740" class="transcript-chunks" onclick="console.log('00:47:45,285'); seek(2865.0)">
              AI services using AI Foundry can do for your organizations, especially when you
            </span>
            
            <span id="chunk-741" class="transcript-chunks" onclick="console.log('00:47:51,615'); seek(2871.0)">
              are thinking about developing your own custom co-pilots, as we like to call it.
            </span>
            
            <span id="chunk-742" class="transcript-chunks" onclick="console.log('00:47:56,405'); seek(2876.0)">
              I wanna thank you for having joined me in this session.
            </span>
            
            <span id="chunk-743" class="transcript-chunks" onclick="console.log('00:47:59,105'); seek(2879.0)">
              I also would like to thank the com 42 team for having invited me as a
            </span>
            
            <span id="chunk-744" class="transcript-chunks" onclick="console.log('00:48:03,065'); seek(2883.0)">
              speaker to present at this conference.
            </span>
            
            <span id="chunk-745" class="transcript-chunks" onclick="console.log('00:48:06,065'); seek(2886.0)">
              I hope you enjoyed the rest of com 42 large language model conference
            </span>
            
            <span id="chunk-746" class="transcript-chunks" onclick="console.log('00:48:10,355'); seek(2890.0)">
              and hopefully we'll meet again soon in any of the other com 42
            </span>
            
            <span id="chunk-747" class="transcript-chunks" onclick="console.log('00:48:14,225'); seek(2894.0)">
              conferences in the near future.
            </span>
            
            <span id="chunk-748" class="transcript-chunks" onclick="console.log('00:48:16,595'); seek(2896.0)">
              Take care for now.
            </span>
            
            <span id="chunk-749" class="transcript-chunks" onclick="console.log('00:48:17,435'); seek(2897.0)">
              Have a great day and don't hesitate reaching out if you
            </span>
            
            <span id="chunk-750" class="transcript-chunks" onclick="console.log('00:48:20,375'); seek(2900.0)">
              should have any more questions.
            </span>
            
            <span id="chunk-751" class="transcript-chunks" onclick="console.log('00:48:22,385'); seek(2902.0)">
              Take care my friends.
            </span>
            
            </div>
          </div>
          
          

          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/llms2025" class="btn btn-sm btn-danger shadow lift" style="background-color: #CCB87B;">
                <i class="fe fe-grid me-2"></i>
                See all 39 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/Peter%20De%20Tender_llm.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Peter De Tender
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Business Program Manager - Azure Technical Trainer @ Microsoft
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/pdtit/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Peter De Tender's LinkedIn account" />
                  </a>
                  
                  
                  <a href="https://twitter.com/@pdtit" target="_blank">
                    <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="Peter De Tender's twitter account" />
                  </a>
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by @pdtit"
                  data-url="https://www.conf42.com/llms2025"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/llms2025"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>






    <!-- WELCOME -->
    <section class="pt-8 pt-md-11 pb-10 pb-md-15 bg-info" id="register">

      <!-- Shape -->
      <div class="shape shape-blur-3 text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>      </div>

      <!-- Content -->
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 col-md-10 col-lg-8 text-center">

            <!-- Heading -->
            <h1 class="display-2 text-white">
              Join the community!
            </h1>

            <!-- Text -->
            <p class="lead text-white text-opacity-80 mb-6 mb-md-8">
              Learn for free, join the best tech learning community 
              for a <a class="text-white" href="https://www.reddit.com/r/sanfrancisco/comments/1bz90f6/why_are_coffee_shops_in_sf_so_expensive/" target="_blank">price of a pumpkin latte</a>.
            </p>

            <!-- Form -->
            <form class="d-flex align-items-center justify-content-center mb-7 mb-md-9">

              <!-- Label -->
              <span class="text-white text-opacity-80">
                Annual
              </span>

              <!-- Switch -->
              <div class="form-check form-check-dark form-switch mx-3">
                <input class="form-check-input" type="checkbox" id="billingSwitch" data-toggle="price" data-target=".price">
              </div>

              <!-- Label -->
              <span class="text-white text-opacity-80">
                Monthly
              </span>

            </form>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->

    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- PRICING -->
    <section class="mt-n8 mt-md-n15">
      <div class="container">
        <div class="row gx-4">
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-1">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Newsletter</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="0" data-monthly="0">0</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Event notifications, weekly newsletter
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Delayed access</b> to all content
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Immediate access to Keynotes & Panels
                  </p>
                </div>
              
              
              </div>
            </div>

            <!-- Card -->
            <div class="card shadow-lg mb-6 border border-success">
              <div class="card-body">

                <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
</script>

<!-- Form -->
<link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
<p class="emailoctopus-success-message text-success"></p>
<p class="emailoctopus-error-message text-danger"></p>
<form
    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
    method="post"
    data-message-success="Thanks! Check your email for further directions!"
    data-message-missing-email-address="Your email address is required."
    data-message-invalid-email-address="Your email address looks incorrect, please try again."
    data-message-bot-submission-error="This doesn't look like a human submission."
    data-message-consent-required="Please check the checkbox to indicate your consent."
    data-message-invalid-parameters-error="This form has missing or invalid fields."
    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
    class="emailoctopus-form"
    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
>
<div class="form-floating emailoctopus-form-row">
    <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
    <label for="field_0">Email address</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
    <label for="field_1">First Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
    <label for="field_2">Last Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
    <label for="field_4">Company</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
    <label for="field_5">Job Title</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
    <label for="field_3">Phone Number</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
    oninput="updateCountry()"
    >
    <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
    </select>
    <label for="field_7">Country</label>
</div>
<input id="country-destination" name="field_7" type="hidden">
<input id="tz-country" name="field_8" type="hidden">

<input
    name="field_6"
    type="hidden"
    value="Large Language Models"
>

<div class="emailoctopus-form-row-consent">
    <input
    type="checkbox"
    id="consent"
    name="consent"
    >
    <label for="consent">
    I consent to the following terms:
    </label>
    <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
    Terms and Conditions
    </a>
    &amp;
    <a href="./code-of-conduct" target="_blank">
    Code of Conduct
    </a>
</div>
<div
    aria-hidden="true"
    class="emailoctopus-form-row-hp"
>
    <input
    type="text"
    name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
    tabindex="-1"
    autocomplete="nope"
    >
</div>
<div class="mt-6 emailoctopus-form-row-subscribe">
    <input
    type="hidden"
    name="successRedirectUrl"
    >
    <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
    Subscribe to free newsletter <i class="fe fe-arrow-right ms-3"></i>
    </button>
</div>
</form>

<!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
<script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

              </div>
            </div>
          </div>
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-0">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Community</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="8.34" data-monthly="10">8.34</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Access to <a href="https://conf42.circle.so/">Circle community platform</a>
                  </p>
                </div>

                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Immediate access</b> to all content
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <a href="https://conf42.circle.so/c/live-events/" target="_blank"><b>Live events!</b></a>
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <a href="https://conf42.circle.so/c/live-events/" target="_blank">Regular office hours, Q&As, CV reviews</a>
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Courses, quizes & certificates
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Community chats
                  </p>
                </div>
                

                <!-- Button -->
                <a href="https://conf42.circle.so/checkout/subscribe" class="btn w-100 btn-primary">
                  Join the community (7 day free trial)<i class="fe fe-arrow-right ms-3"></i>
                </a>

              </div>
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2025">
                  Site Reliability Engineering (SRE) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2025">
                  Machine Learning 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2025">
                  Observability 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2025">
                  Quantum Computing 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2025">
                  Rustlang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2025">
                  Platform Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2025">
                  MLOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2025">
                  Incident Management 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2025">
                  Kube Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2025">
                  JavaScript 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2025">
                  Prompt Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/robotics2025">
                  Robotics 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2025">
                  DevSecOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2025">
                  Internet of Things (IoT) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>