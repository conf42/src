<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: Introducing FireDucks: A Multithreaded DataFrame Library with JIT Compilation</title>
    <meta name="description" content="Get inspired by fellow Pythonistas, Snakes and Pandas united!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/Sourav%20Saha_python.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Introducing FireDucks: A Multithreaded DataFrame Library with JIT Compilation | Conf42"/>
    <meta property="og:description" content="We introduce a couple of frequently occurring intricate performance issues in large-scale data processing using pandas, along with a compiler-accelerated high-performance DataFrame library named FireDucks to auto-detect and optimize those issues without any manual effort."/>
    <meta property="og:url" content="https://conf42.com/Python_2025_Sourav_Saha_firedricks_dataframe_jit"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/KUBE2025_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Kube Native 2025
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2025-10-16
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/kubenative2025" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2025">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2025">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2025">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2025">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2025">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2025">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2025">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2025">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2025">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2025">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2025">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/robotics2025">
                            Robotics
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2025">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2025">
                            Internet of Things (IoT)
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="https://conf42.circle.so/">
                            <b>Community platform login</b>
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Join the community!
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #69811f;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Python 2025 - Online
            </h1>

            <h2 class="text-white">
              
              Content unlocked! Welcome to the community!
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Get inspired by fellow Pythonistas, Snakes and Pandas united!
 -->
              <script>
                const event_date = new Date("2025-02-06T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2025-02-06T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "FPUby5Ecqj0"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://www.youtube.com/playlist?list=PLIuxSyKxlQrBo176Is4wP2F6UCB0yEkWO" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hello, everyone.", "timestamp": "00:00:00,220", "timestamp_s": 0.0}, {"text": "Welcome to my talk.", "timestamp": "00:00:01,740", "timestamp_s": 1.0}, {"text": "Today I\u0027ll be talking about a data frame library named fire ducks that", "timestamp": "00:00:03,090", "timestamp_s": 3.0}, {"text": "we are working at the research lab.", "timestamp": "00:00:07,790", "timestamp_s": 7.0}, {"text": "So we will explore, the motivation behind developing the fighters by stating", "timestamp": "00:00:10,520", "timestamp_s": 10.0}, {"text": "some of the key challenges with pandas.", "timestamp": "00:00:16,460", "timestamp_s": 16.0}, {"text": "And of course we\u0027ll be talking about the tips and tricks and the best", "timestamp": "00:00:19,505", "timestamp_s": 19.0}, {"text": "practices when dealing with large scale data processing in pandas What", "timestamp": "00:00:22,585", "timestamp_s": 22.0}, {"text": "fireducks is and what it is offering the optimization strategy available", "timestamp": "00:00:26,325", "timestamp_s": 26.0}, {"text": "with it With some live demo and the resources available on fireducks", "timestamp": "00:00:30,495", "timestamp_s": 30.0}, {"text": "so Let\u0027s have a quick introduction.", "timestamp": "00:00:36,095", "timestamp_s": 36.0}, {"text": "My name is Saurav.", "timestamp": "00:00:38,765", "timestamp_s": 38.0}, {"text": "I\u0027m currently doing in the I\u0027m currently working as a resource", "timestamp": "00:00:40,255", "timestamp_s": 40.0}, {"text": "engineer at NSE Corporation.", "timestamp": "00:00:43,645", "timestamp_s": 43.0}, {"text": "So I have been associated with NSE over the last 11 years where", "timestamp": "00:00:45,745", "timestamp_s": 45.0}, {"text": "I\u0027m doing different work in the field of high performance", "timestamp": "00:00:49,395", "timestamp_s": 49.0}, {"text": "computing, distributed processing, AI machine learning and desktop.", "timestamp": "00:00:52,785", "timestamp_s": 52.0}, {"text": "So we have a long history of working with the vector supercomputer.", "timestamp": "00:00:57,115", "timestamp_s": 57.0}, {"text": "where we start with S6 series of supercomputers and, work with various", "timestamp": "00:01:01,290", "timestamp_s": 61.0}, {"text": "legacy applications from tsunami prediction to earthquake simulations", "timestamp": "00:01:06,920", "timestamp_s": 66.0}, {"text": "on this vector architecture.", "timestamp": "00:01:11,570", "timestamp_s": 71.0}, {"text": "my leader at my team, Stacy Sarkar, first thought that we including our expertise in", "timestamp": "00:01:13,070", "timestamp_s": 73.0}, {"text": "the field of HPC and the compiler and this kind of distributed processing related", "timestamp": "00:01:20,490", "timestamp_s": 80.0}, {"text": "tasks, How about creating something that will use the compiler technology", "timestamp": "00:01:24,650", "timestamp_s": 84.0}, {"text": "because we have a keen interest in compiler And at the same time do something", "timestamp": "00:01:28,585", "timestamp_s": 88.0}, {"text": "with the python for the data science community So that is the time when you", "timestamp": "00:01:32,735", "timestamp_s": 92.0}, {"text": "thought okay data scientist often face challenges With the pandas computation.", "timestamp": "00:01:36,415", "timestamp_s": 96.0}, {"text": "So let\u0027s create some library That will look completely same as pandas But", "timestamp": "00:01:40,875", "timestamp_s": 100.0}, {"text": "internally it will have a compiler and do a lot of magic kind of stuff", "timestamp": "00:01:46,795", "timestamp_s": 106.0}, {"text": "Such that a programmer, a pandas programmer can experience much faster,", "timestamp": "00:01:51,470", "timestamp_s": 111.0}, {"text": "data processing when using firetrucks.", "timestamp": "00:01:57,070", "timestamp_s": 117.0}, {"text": "So please stay with me till the end of this presentation where I\u0027ll be talking", "timestamp": "00:01:59,345", "timestamp_s": 119.0}, {"text": "about various best practices I will give you walkthrough with the finders the", "timestamp": "00:02:04,025", "timestamp_s": 124.0}, {"text": "offering the motivation the Comparison with other data frame libraries that is", "timestamp": "00:02:09,235", "timestamp_s": 129.0}, {"text": "available and of course the end of the end I\u0027ll have some frequently asked questions", "timestamp": "00:02:13,655", "timestamp_s": 133.0}, {"text": "because this is something online.", "timestamp": "00:02:18,565", "timestamp_s": 138.0}, {"text": "So and Of course if you have any questions, you can get in touch with", "timestamp": "00:02:20,225", "timestamp_s": 140.0}, {"text": "me over the linkedin or other social media i\u0027ll be happy to collaborate", "timestamp": "00:02:24,865", "timestamp_s": 144.0}, {"text": "and help you in whatever matter I can.", "timestamp": "00:02:28,995", "timestamp_s": 148.0}, {"text": "Yes So this is the flow.", "timestamp": "00:02:31,345", "timestamp_s": 151.0}, {"text": "I believe all of you can relate what we do as a data scientist, we", "timestamp": "00:02:34,605", "timestamp_s": 154.0}, {"text": "collect data from various resources and the data in the raw format is", "timestamp": "00:02:39,415", "timestamp_s": 159.0}, {"text": "not resilient digestible by the AI algorithm, AI machine learning algorithm.", "timestamp": "00:02:43,775", "timestamp_s": 163.0}, {"text": "So what we do is we clean the data, make it more meaningful so that we", "timestamp": "00:02:47,425", "timestamp_s": 167.0}, {"text": "can get a better features out of it and we can do a better model.", "timestamp": "00:02:51,705", "timestamp_s": 171.0}, {"text": "So better the data is the better the model.", "timestamp": "00:02:55,335", "timestamp_s": 175.0}, {"text": "That is some kind of old story that we have been learned about.", "timestamp": "00:02:57,235", "timestamp_s": 177.0}, {"text": "But the important thing for this entire cycle to understand that, although", "timestamp": "00:03:00,525", "timestamp_s": 180.0}, {"text": "AI machine learning is taking time and deploying model is also taking", "timestamp": "00:03:05,155", "timestamp_s": 185.0}, {"text": "time, but the most time consuming part is the creation of the data as", "timestamp": "00:03:09,165", "timestamp_s": 189.0}, {"text": "per the research from the anaconda.", "timestamp": "00:03:13,095", "timestamp_s": 193.0}, {"text": "It says that the data loading, cleaning, and the visualization is something", "timestamp": "00:03:14,945", "timestamp_s": 194.0}, {"text": "that occupies almost 75 percent of the effort of a data scientist.", "timestamp": "00:03:18,385", "timestamp_s": 198.0}, {"text": "So if you have a lot of questions in mind, if you want to extract a lot of", "timestamp": "00:03:22,025", "timestamp_s": 202.0}, {"text": "many features, You need to spend a lot of time in during the first a few months.", "timestamp": "00:03:25,505", "timestamp_s": 205.0}, {"text": "I would say for doing the efficient data exploration So that is why", "timestamp": "00:03:30,740", "timestamp_s": 210.0}, {"text": "various researches has been happening in this field Because this is one of", "timestamp": "00:03:36,120", "timestamp_s": 216.0}, {"text": "the most important areas where we need optimization Now with these ladies,", "timestamp": "00:03:40,940", "timestamp_s": 220.0}, {"text": "let me have something about pandas.", "timestamp": "00:03:45,720", "timestamp_s": 225.0}, {"text": "I believe all of you are from the data science background So", "timestamp": "00:03:47,759", "timestamp_s": 227.0}, {"text": "you must have Work with pandas.", "timestamp": "00:03:50,669", "timestamp_s": 230.0}, {"text": "So it is one of the most popular libraries even today It is having the", "timestamp": "00:03:53,399", "timestamp_s": 233.0}, {"text": "second most download after numpy But it comes with some kind of problems.", "timestamp": "00:03:57,099", "timestamp_s": 237.0}, {"text": "The very common one is it\u0027s not multi threaded So if you have a good", "timestamp": "00:04:02,929", "timestamp_s": 242.0}, {"text": "system with many core available, you cannot be able to leverage", "timestamp": "00:04:07,329", "timestamp_s": 247.0}, {"text": "that so Your program will be slow.", "timestamp": "00:04:10,839", "timestamp_s": 250.0}, {"text": "You have to wait for a longer time to get your result if you are working", "timestamp": "00:04:13,469", "timestamp_s": 253.0}, {"text": "with large data So So longer waiting times, slow execution, if you\u0027re running", "timestamp": "00:04:16,739", "timestamp_s": 256.0}, {"text": "this on the cloud side, a higher cloud cost, and of course, longer execution", "timestamp": "00:04:21,424", "timestamp_s": 261.0}, {"text": "will activate a lot of carbon dioxide.", "timestamp": "00:04:26,054", "timestamp_s": 266.0}, {"text": "So these is, these are something that is associated with bundles.", "timestamp": "00:04:28,144", "timestamp_s": 268.0}, {"text": "So it is ideally not ideal for the large scale.", "timestamp": "00:04:32,214", "timestamp_s": 272.0}, {"text": "scale exhibition, right?", "timestamp": "00:04:35,514", "timestamp_s": 275.0}, {"text": "So now Although these are the challenges related with pandas But the key challenge", "timestamp": "00:04:37,534", "timestamp_s": 277.0}, {"text": "is like there are various way of writing the same programming pandas So if we", "timestamp": "00:04:42,744", "timestamp_s": 282.0}, {"text": "ourselves can identify the best approaches the best practices and take care of that", "timestamp": "00:04:48,784", "timestamp_s": 288.0}, {"text": "when writing our program It\u0027s fine enough because by default pandas doesn\u0027t offer", "timestamp": "00:04:53,544", "timestamp_s": 293.0}, {"text": "you optimization as it is eager in nature so whatever you Ask it to do it will do it", "timestamp": "00:04:58,384", "timestamp_s": 298.0}, {"text": "for you So if you have written a good code unoptimized one yet, you are at good stage", "timestamp": "00:05:03,864", "timestamp_s": 303.0}, {"text": "But if your program has performance issue You may need to pay a lot of performance", "timestamp": "00:05:10,004", "timestamp_s": 310.0}, {"text": "cost when your data goes in size or your program goes in complexity So we\u0027re", "timestamp": "00:05:14,094", "timestamp_s": 314.0}, {"text": "talking about some crucial performance issue that involves in a pandas program", "timestamp": "00:05:19,084", "timestamp_s": 319.0}, {"text": "and how to take care of that And what are the automation possibility for those", "timestamp": "00:05:22,964", "timestamp_s": 322.0}, {"text": "cases using fireducks and other library?", "timestamp": "00:05:28,524", "timestamp_s": 328.0}, {"text": "So to going forward let us understand one by one the best practices and", "timestamp": "00:05:31,174", "timestamp_s": 331.0}, {"text": "challenges associated with data large scale data analysis program So", "timestamp": "00:05:36,214", "timestamp_s": 336.0}, {"text": "with that let us have a first quiz.", "timestamp": "00:05:41,124", "timestamp_s": 341.0}, {"text": "can you identify?", "timestamp": "00:05:43,474", "timestamp_s": 343.0}, {"text": "Which one is a better code whether the left one or the right one?", "timestamp": "00:05:45,294", "timestamp_s": 345.0}, {"text": "yeah since i\u0027m doing this online, so definitely cannot take the response", "timestamp": "00:05:50,024", "timestamp_s": 350.0}, {"text": "from you But when I asked this kind of question in one of the event last time,", "timestamp": "00:05:53,894", "timestamp_s": 353.0}, {"text": "so I believe I had Mostly around 90 percent of them answered the rightmost", "timestamp": "00:05:58,754", "timestamp_s": 358.0}, {"text": "one is the best performing query Because of many reasons so as you can see this", "timestamp": "00:06:04,524", "timestamp_s": 364.0}, {"text": "is written in chain and that is ideally the best way of writing This kind of", "timestamp": "00:06:09,894", "timestamp_s": 369.0}, {"text": "query in pandas or pandas like library.", "timestamp": "00:06:15,264", "timestamp_s": 375.0}, {"text": "Why Let\u0027s have let\u0027s understand that with some kind of Illustration.", "timestamp": "00:06:17,464", "timestamp_s": 377.0}, {"text": "So let\u0027s say this is the data that I have loaded from file Of course, you can see", "timestamp": "00:06:22,834", "timestamp_s": 382.0}, {"text": "there are some duplicates once I remove the duplicate This will be the data my", "timestamp": "00:06:27,134", "timestamp_s": 387.0}, {"text": "data might be reduced to its half Then I will shorting the result by b column", "timestamp": "00:06:30,534", "timestamp_s": 390.0}, {"text": "selecting, the top two of the result and that\u0027s it Now, let\u0027s assume some kind of", "timestamp": "00:06:34,804", "timestamp_s": 394.0}, {"text": "memory footprint associated with the data.", "timestamp": "00:06:39,834", "timestamp_s": 399.0}, {"text": "Let\u0027s say my data is 16 gb You After the removing duplicate it will be", "timestamp": "00:06:41,954", "timestamp_s": 401.0}, {"text": "8gb, 8gb and some other gb, so at the end of the thing it will be 32gb.", "timestamp": "00:06:46,054", "timestamp_s": 406.0}, {"text": "But till the time the foo is alive all these references like df2 t3 are", "timestamp": "00:06:51,599", "timestamp_s": 411.0}, {"text": "alive because pandas not pandas python cannot Make them ready for the garbage", "timestamp": "00:06:56,729", "timestamp_s": 416.0}, {"text": "collection because they have the reference alive in them alive, right?", "timestamp": "00:07:02,799", "timestamp_s": 422.0}, {"text": "So that is the challenge with not writing zend expression what happens", "timestamp": "00:07:06,599", "timestamp_s": 426.0}, {"text": "when you go for the zend expression It will be like, the data is loaded.", "timestamp": "00:07:10,689", "timestamp_s": 430.0}, {"text": "We remove the duplicates But now when we\u0027ll be applying the shorting at that", "timestamp": "00:07:15,619", "timestamp_s": 435.0}, {"text": "moment, I only need the input from the drop duplicate side So I don\u0027t need", "timestamp": "00:07:20,584", "timestamp_s": 440.0}, {"text": "this data anymore So this data will be out of reference and python can make it", "timestamp": "00:07:25,954", "timestamp_s": 445.0}, {"text": "garbage collected based on It\u0027s neat.", "timestamp": "00:07:31,834", "timestamp_s": 451.0}, {"text": "So the same way when I will perform the top two, I don\u0027t need the", "timestamp": "00:07:34,564", "timestamp_s": 454.0}, {"text": "duplicated result drop duplicates result I only need the shorter result.", "timestamp": "00:07:38,374", "timestamp_s": 458.0}, {"text": "So this way at the end of my program I can remove the intermediate data that", "timestamp": "00:07:42,154", "timestamp_s": 462.0}, {"text": "is there that is generated during my query of the long expression So and that", "timestamp": "00:07:47,044", "timestamp_s": 467.0}, {"text": "is definitely going to help you when you\u0027ll be dealing with large scale data.", "timestamp": "00:07:52,764", "timestamp_s": 472.0}, {"text": "I\u0027ll be showing this kind of thing with example in my upcoming slides.", "timestamp": "00:07:55,984", "timestamp_s": 475.0}, {"text": "So that is one of the best practices that write your expression in chained", "timestamp": "00:07:59,854", "timestamp_s": 479.0}, {"text": "expression and it is possible in pandas, of course it\u0027s possible.", "timestamp": "00:08:04,304", "timestamp_s": 484.0}, {"text": "So as much as possible try to go for the chained expression such", "timestamp": "00:08:08,844", "timestamp_s": 488.0}, {"text": "that you can avoid this kind of memory and performance issues.", "timestamp": "00:08:12,874", "timestamp_s": 492.0}, {"text": "Now let\u0027s consider the second one.", "timestamp": "00:08:16,334", "timestamp_s": 496.0}, {"text": "So here is a quiz.", "timestamp": "00:08:18,494", "timestamp_s": 498.0}, {"text": "Where it is trying to solve the same problem it is trying to find the", "timestamp": "00:08:19,924", "timestamp_s": 499.0}, {"text": "top five of a value based on the shorting from the b column, right?", "timestamp": "00:08:23,494", "timestamp_s": 503.0}, {"text": "Now, can you guess which one is a better code if you give the if you\u0027re", "timestamp": "00:08:29,394", "timestamp_s": 509.0}, {"text": "about to write the code whether you\u0027ll go for the top one or you\u0027ll go for", "timestamp": "00:08:33,974", "timestamp_s": 513.0}, {"text": "the bottom one yeah, so when I asked this kind of question in a recent", "timestamp": "00:08:37,504", "timestamp_s": 517.0}, {"text": "event, so almost I have mixed answer So 40 to 50 percent answer that the", "timestamp": "00:08:42,174", "timestamp_s": 522.0}, {"text": "top one is the good one And 50 to 60 percent answer that the bottom one is", "timestamp": "00:08:47,674", "timestamp_s": 527.0}, {"text": "the good one So with the majority the answer is of course the bottom one.", "timestamp": "00:08:52,834", "timestamp_s": 532.0}, {"text": "So if you yourself, thought it is the bottom one Give a pat on your", "timestamp": "00:08:58,054", "timestamp_s": 538.0}, {"text": "back Now, let\u0027s understand why it is.", "timestamp": "00:09:02,804", "timestamp_s": 542.0}, {"text": "So what happens ideally your data may have many columns in relative, right?", "timestamp": "00:09:05,734", "timestamp_s": 545.0}, {"text": "Not only a and b if you are going to perform the shorting on the entire", "timestamp": "00:09:11,479", "timestamp_s": 551.0}, {"text": "data, what will happen, not only the target columns A and B, rest of the", "timestamp": "00:09:16,644", "timestamp_s": 556.0}, {"text": "columns like C to J will get shorted.", "timestamp": "00:09:21,494", "timestamp_s": 561.0}, {"text": "And that will never be used in your final result because you\u0027re only interested", "timestamp": "00:09:24,119", "timestamp_s": 564.0}, {"text": "To have the shorted value from the a column after the result is shorted by", "timestamp": "00:09:28,299", "timestamp_s": 568.0}, {"text": "b So the c to g column will get shorted based on the b columns It will occupy the", "timestamp": "00:09:31,789", "timestamp_s": 571.0}, {"text": "memory, but it will no longer be needed.", "timestamp": "00:09:37,939", "timestamp_s": 577.0}, {"text": "So it is waste of competition time and memory So what you can do you can create", "timestamp": "00:09:40,059", "timestamp_s": 580.0}, {"text": "a view of the data of my interest that i\u0027m interested in a and b column only So", "timestamp": "00:09:44,659", "timestamp_s": 584.0}, {"text": "why not just create a view of that data?", "timestamp": "00:09:49,179", "timestamp_s": 589.0}, {"text": "You Perform the same steps do the same thing and this will definitely", "timestamp": "00:09:51,389", "timestamp_s": 591.0}, {"text": "going to reduce a lot of competition calls because it doesn\u0027t matter How", "timestamp": "00:09:56,479", "timestamp_s": 596.0}, {"text": "many column you will data may have?", "timestamp": "00:09:59,679", "timestamp_s": 599.0}, {"text": "Because you also understand.", "timestamp": "00:10:01,609", "timestamp_s": 601.0}, {"text": "I am interested in a and b so let\u0027s not bother about rest of the column", "timestamp": "00:10:02,849", "timestamp_s": 602.0}, {"text": "Let\u0027s create a view and work on that This kind of optimization is something", "timestamp": "00:10:07,519", "timestamp_s": 607.0}, {"text": "called projection pushdown and it is very important that we should take care when", "timestamp": "00:10:11,449", "timestamp_s": 611.0}, {"text": "dealing with large scale data analysis Now, let\u0027s consider another example You", "timestamp": "00:10:15,319", "timestamp_s": 615.0}, {"text": "So before going to the quiz, let me show what it is trying to do For example, I am", "timestamp": "00:10:20,884", "timestamp_s": 620.0}, {"text": "an, I have an employee table in a country table and I want to perform some kind", "timestamp": "00:10:25,949", "timestamp_s": 625.0}, {"text": "of merging to have a larger joint result and see who are the employee, who are the", "timestamp": "00:10:29,849", "timestamp_s": 629.0}, {"text": "male employees from which country, like how many, like country wise count of the", "timestamp": "00:10:35,439", "timestamp_s": 635.0}, {"text": "male employee is something of my problem.", "timestamp": "00:10:40,869", "timestamp_s": 640.0}, {"text": "So how it can be done, one thing that I can just join these two tables.", "timestamp": "00:10:43,529", "timestamp_s": 643.0}, {"text": "Then I can filter all the male category from the result in data and I can", "timestamp": "00:10:48,634", "timestamp_s": 648.0}, {"text": "perform a group by count So by looking at this illustration, can you identify", "timestamp": "00:10:53,824", "timestamp_s": 653.0}, {"text": "what is the performance bottleneck?", "timestamp": "00:10:59,154", "timestamp_s": 659.0}, {"text": "Yes The issue is with the expensive merge operation So although we are", "timestamp": "00:11:01,344", "timestamp_s": 661.0}, {"text": "only interested in the male category employee What we did is we performed the", "timestamp": "00:11:08,064", "timestamp_s": 668.0}, {"text": "merging on the entire employee table.", "timestamp": "00:11:13,044", "timestamp_s": 673.0}, {"text": "We could instead do what?", "timestamp": "00:11:15,684", "timestamp_s": 675.0}, {"text": "We could first filter only the male category from my employee table and", "timestamp": "00:11:17,994", "timestamp_s": 677.0}, {"text": "then we can do the merging operation.", "timestamp": "00:11:23,154", "timestamp_s": 683.0}, {"text": "Followed by the group by count It will do a lot of benefit when you have like", "timestamp": "00:11:25,594", "timestamp_s": 685.0}, {"text": "kind of 50 50 percent of the employee ratio Or you have very less amount of mail", "timestamp": "00:11:32,434", "timestamp_s": 692.0}, {"text": "Like employees because it can reduce your data by to a great extent and the merge", "timestamp": "00:11:37,364", "timestamp_s": 697.0}, {"text": "will not take much time in that case So this is something called predicate push", "timestamp": "00:11:42,474", "timestamp_s": 702.0}, {"text": "down In terms of compiler technology.", "timestamp": "00:11:47,374", "timestamp_s": 707.0}, {"text": "So again, this is one of the very important optimization strategy We", "timestamp": "00:11:50,559", "timestamp_s": 710.0}, {"text": "should ideally take care of that And we\u0027ll see with some demo that how", "timestamp": "00:11:54,639", "timestamp_s": 714.0}, {"text": "this kind of strategy is important when dealing with large scale", "timestamp": "00:11:59,679", "timestamp_s": 719.0}, {"text": "data analysis in upcoming slides.", "timestamp": "00:12:02,609", "timestamp_s": 722.0}, {"text": "So now let\u0027s put these two in, some kind of, like rule of thumb.", "timestamp": "00:12:05,269", "timestamp_s": 725.0}, {"text": "So again, in order to understand that the importance of such execution", "timestamp": "00:12:10,159", "timestamp_s": 730.0}, {"text": "order, let\u0027s take this example where it is trying to perform shorting", "timestamp": "00:12:14,019", "timestamp_s": 734.0}, {"text": "by the E column, do the filtration based on some conditional B column.", "timestamp": "00:12:18,459", "timestamp_s": 738.0}, {"text": "Select the E column and get the top two.", "timestamp": "00:12:22,619", "timestamp_s": 742.0}, {"text": "Now, in order to illustrate that, let\u0027s consider this is my data and", "timestamp": "00:12:25,409", "timestamp_s": 745.0}, {"text": "if I short the data with this color code, I will have the shorted result", "timestamp": "00:12:29,639", "timestamp_s": 749.0}, {"text": "from the yellow, red, green, and blue.", "timestamp": "00:12:34,139", "timestamp_s": 754.0}, {"text": "this is my data after I shorted, something like yellow, red, green,", "timestamp": "00:12:36,259", "timestamp_s": 756.0}, {"text": "and blue will be the result.", "timestamp": "00:12:39,909", "timestamp_s": 759.0}, {"text": "Let\u0027s consider b equals to 1 for the darker shade and b equals", "timestamp": "00:12:41,469", "timestamp_s": 761.0}, {"text": "to 1, 2 for the lighter shade.", "timestamp": "00:12:44,699", "timestamp_s": 764.0}, {"text": "if I filter, I\u0027ll only have the lighter shaded part, then I will select the", "timestamp": "00:12:46,814", "timestamp_s": 766.0}, {"text": "only E column and find the top two.", "timestamp": "00:12:51,336", "timestamp_s": 771.0}, {"text": "Now, if we carefully notice this entire data flow, can you identify", "timestamp": "00:12:54,086", "timestamp_s": 774.0}, {"text": "what is wrong in this journey?", "timestamp": "00:13:00,636", "timestamp_s": 780.0}, {"text": "Of course you can, right?", "timestamp": "00:13:03,396", "timestamp_s": 783.0}, {"text": "you can say that although I am interested in only A, B and E columns.", "timestamp": "00:13:05,126", "timestamp_s": 785.0}, {"text": "I have already involved rest of the columns like c and d that is there", "timestamp": "00:13:11,111", "timestamp_s": 791.0}, {"text": "in my data that have been used But never referenced so that is ideally", "timestamp": "00:13:16,651", "timestamp_s": 796.0}, {"text": "a waste of membrane competition time So instead what we can do is we can", "timestamp": "00:13:20,961", "timestamp_s": 800.0}, {"text": "first identify that for this query.", "timestamp": "00:13:26,431", "timestamp_s": 806.0}, {"text": "I only did a b and e column so why not just create a view of a b e column", "timestamp": "00:13:28,831", "timestamp_s": 808.0}, {"text": "such that we can reduce my scope of the data first in the Horizontal direction", "timestamp": "00:13:33,851", "timestamp_s": 813.0}, {"text": "by applying pushdown projection Okay.", "timestamp": "00:13:38,461", "timestamp_s": 818.0}, {"text": "projection poster.", "timestamp": "00:13:41,666", "timestamp_s": 821.0}, {"text": "Then I can see that, okay, this is my data and, but instead,", "timestamp": "00:13:43,086", "timestamp_s": 823.0}, {"text": "why to short this entire data?", "timestamp": "00:13:47,796", "timestamp_s": 827.0}, {"text": "Because I\u0027m only interested in the lighter shaded part, right?", "timestamp": "00:13:49,426", "timestamp_s": 829.0}, {"text": "So what I can do, I can, for, before going to do shorting, I can reduce the", "timestamp": "00:13:53,846", "timestamp_s": 833.0}, {"text": "data further by applying the filter.", "timestamp": "00:13:58,796", "timestamp_s": 838.0}, {"text": "Once the filtration is done, I can have my further reduced data and this data", "timestamp": "00:14:01,381", "timestamp_s": 841.0}, {"text": "is ready for the shorting because that is ideally part of the data that I\u0027m", "timestamp": "00:14:06,171", "timestamp_s": 846.0}, {"text": "interested to perform the shorting on.", "timestamp": "00:14:10,011", "timestamp_s": 850.0}, {"text": "Now apply the shorting, find the E column and find the top two.", "timestamp": "00:14:12,281", "timestamp_s": 852.0}, {"text": "This is the way by applying kind of projection pushdown You can ideally", "timestamp": "00:14:16,141", "timestamp_s": 856.0}, {"text": "optimize the data flow and this is a very important execution order.", "timestamp": "00:14:21,721", "timestamp_s": 861.0}, {"text": "Following that in your large scale data analysis, you can", "timestamp": "00:14:26,461", "timestamp_s": 866.0}, {"text": "definitely make sure a lot of it.", "timestamp": "00:14:29,211", "timestamp_s": 869.0}, {"text": "Benefit from the execution time and the memory.", "timestamp": "00:14:32,561", "timestamp_s": 872.0}, {"text": "So we\u0027ll understand this with some Demo with some example real example in upcoming", "timestamp": "00:14:35,011", "timestamp_s": 875.0}, {"text": "slides Now with that, let\u0027s understand what fire ducks is and why to explore this", "timestamp": "00:14:40,311", "timestamp_s": 880.0}, {"text": "library So the first thing, the fireducks is a DataFrame library, high performance", "timestamp": "00:14:47,081", "timestamp_s": 887.0}, {"text": "compiler accelerated DataFrame library.", "timestamp": "00:14:52,461", "timestamp_s": 892.0}, {"text": "why it is called so?", "timestamp": "00:14:55,101", "timestamp_s": 895.0}, {"text": "Basically, the ducks is, it\u0027s just a name of the animal because all the DataFrame", "timestamp": "00:14:56,601", "timestamp_s": 896.0}, {"text": "libraries, they\u0027re like the pandas, boulders, they are named after an animal.", "timestamp": "00:15:00,591", "timestamp_s": 900.0}, {"text": "So we just thought of, first of all, we thought of DAX.", "timestamp": "00:15:04,521", "timestamp_s": 904.0}, {"text": "Some data frame accelerator, but dx is already a name that time.", "timestamp": "00:15:07,731", "timestamp_s": 907.0}, {"text": "So we thought of naming it as a ducks So it doesn\u0027t have any link with the", "timestamp": "00:15:11,511", "timestamp_s": 911.0}, {"text": "duck db for information But the fire has a meaning fire is from the flexible", "timestamp": "00:15:15,511", "timestamp_s": 915.0}, {"text": "ir engine What is ir is something called intermediary representation.", "timestamp": "00:15:20,921", "timestamp_s": 920.0}, {"text": "That is the backbone of the fire dogs jit compilation So what fire does do is?", "timestamp": "00:15:25,191", "timestamp_s": 925.0}, {"text": "It\u0027s lazy execution not like pandas like you ask and it do instead you ask and", "timestamp": "00:15:31,656", "timestamp_s": 931.0}, {"text": "it creates some instruction for example you ask it to do shorting instead of", "timestamp": "00:15:37,106", "timestamp_s": 937.0}, {"text": "shorting it will just create okay you ask me to do short on this data on this", "timestamp": "00:15:41,246", "timestamp_s": 941.0}, {"text": "column perfect then you ask it to do please filter based on this condition", "timestamp": "00:15:45,916", "timestamp_s": 945.0}, {"text": "it will just create an instruction Without any calculation or, like", "timestamp": "00:15:50,546", "timestamp_s": 950.0}, {"text": "computations, just create an instruction followed by a projection instruction", "timestamp": "00:15:54,731", "timestamp_s": 954.0}, {"text": "and followed by a slicing instruction.", "timestamp": "00:15:58,641", "timestamp_s": 958.0}, {"text": "Just some instruction will be generated.", "timestamp": "00:16:00,751", "timestamp_s": 960.0}, {"text": "So if you measure the execution time for this part, you will see that it\u0027s", "timestamp": "00:16:02,631", "timestamp_s": 962.0}, {"text": "executed blink of the eyes because it does nothing in, but creating the instruction.", "timestamp": "00:16:05,921", "timestamp_s": 965.0}, {"text": "Now you can tell me like when this instruction will be executed.", "timestamp": "00:16:11,451", "timestamp_s": 971.0}, {"text": "these are the instruction that will be automatically triggered by", "timestamp": "00:16:15,561", "timestamp_s": 975.0}, {"text": "some of your action on the result.", "timestamp": "00:16:19,221", "timestamp_s": 979.0}, {"text": "For example, when you want the result to be printed, when you want the", "timestamp": "00:16:21,181", "timestamp_s": 981.0}, {"text": "result to be dumped in a file by two csv2 parquet kind of operation, when", "timestamp": "00:16:25,271", "timestamp_s": 985.0}, {"text": "you apply some kind of aggregation on this result, for example, finding some", "timestamp": "00:16:30,241", "timestamp_s": 990.0}, {"text": "maximum minimum value or something.", "timestamp": "00:16:34,021", "timestamp_s": 994.0}, {"text": "So that is the time by when these kind of expression will be automatically", "timestamp": "00:16:36,151", "timestamp_s": 996.0}, {"text": "triggered and it will be executed.", "timestamp": "00:16:40,531", "timestamp_s": 1000.0}, {"text": "With some compilation related optimization now, let\u0027s say like I want to print", "timestamp": "00:16:42,521", "timestamp_s": 1002.0}, {"text": "the result So that is the time the compiler will be activated and it", "timestamp": "00:16:47,081", "timestamp_s": 1007.0}, {"text": "will try to figure out the instruction associated with the result And what are", "timestamp": "00:16:51,511", "timestamp_s": 1011.0}, {"text": "the instruction it will say that okay.", "timestamp": "00:16:55,821", "timestamp_s": 1015.0}, {"text": "I want to find the top two based on e column So it based on the", "timestamp": "00:16:57,561", "timestamp_s": 1017.0}, {"text": "filtration b column based on the shorting on the a column This", "timestamp": "00:17:02,701", "timestamp_s": 1022.0}, {"text": "is how the compiler understand.", "timestamp": "00:17:07,156", "timestamp_s": 1027.0}, {"text": "Okay, I have this data, but I\u0027m only interested in a b and e column So it will", "timestamp": "00:17:09,266", "timestamp_s": 1029.0}, {"text": "add a new instruction To project only the target columns of a b and e before", "timestamp": "00:17:15,206", "timestamp_s": 1035.0}, {"text": "doing the further operation Such that it can reduce the data in the horizontal", "timestamp": "00:17:20,976", "timestamp_s": 1040.0}, {"text": "iteration first Then it will figure okay.", "timestamp": "00:17:24,516", "timestamp_s": 1044.0}, {"text": "You want to do short then you want to do filter That means you\u0027re only", "timestamp": "00:17:27,726", "timestamp_s": 1047.0}, {"text": "interested to perform shorting on a selective set of rows it can do some", "timestamp": "00:17:31,186", "timestamp_s": 1051.0}, {"text": "interchanges of the instruction.", "timestamp": "00:17:35,496", "timestamp_s": 1055.0}, {"text": "It can do the filter first, then it can do the short and rest of", "timestamp": "00:17:37,536", "timestamp_s": 1057.0}, {"text": "the operation will remain as it is.", "timestamp": "00:17:41,116", "timestamp_s": 1061.0}, {"text": "This way the compiler will optimize the generated IR.", "timestamp": "00:17:42,936", "timestamp_s": 1062.0}, {"text": "Once the optimized IR is generated, it can be translated to another pandas version.", "timestamp": "00:17:46,866", "timestamp_s": 1066.0}, {"text": "For example, if you consider it\u0027s a pandas program, it can be something like.", "timestamp": "00:17:51,506", "timestamp_s": 1071.0}, {"text": "Project a b e filter based on this condition perform the shorting", "timestamp": "00:17:55,176", "timestamp_s": 1075.0}, {"text": "project the column and take the top two Now this can be a pandas program.", "timestamp": "00:17:59,466", "timestamp_s": 1079.0}, {"text": "This can be a c Api call this can be any other library call of your interest", "timestamp": "00:18:04,286", "timestamp_s": 1084.0}, {"text": "because this ir is quite flexible It can be translated to any other data", "timestamp": "00:18:09,586", "timestamp_s": 1089.0}, {"text": "frame library or any other method call for your reference I just ported it", "timestamp": "00:18:13,586", "timestamp_s": 1093.0}, {"text": "to pandas to understand it better.", "timestamp": "00:18:17,926", "timestamp_s": 1097.0}, {"text": "So that is why write one query You Use this design and it can execute", "timestamp": "00:18:19,616", "timestamp_s": 1099.0}, {"text": "anywhere of your target choice So we have developed this multi core kernel", "timestamp": "00:18:25,076", "timestamp_s": 1105.0}, {"text": "in c where we use the multi threaded and other high performance related stuff", "timestamp": "00:18:29,556", "timestamp_s": 1109.0}, {"text": "like effective utilization of the caches the vectorization and other related", "timestamp": "00:18:33,966", "timestamp_s": 1113.0}, {"text": "stuff such that not only, the results, but also it can do much faster when", "timestamp": "00:18:38,476", "timestamp_s": 1118.0}, {"text": "just comparing the kernel operations, like the only filter, only join, only", "timestamp": "00:18:43,811", "timestamp_s": 1123.0}, {"text": "group by itself will be faster because of the careful optimization, careful", "timestamp": "00:18:48,501", "timestamp_s": 1128.0}, {"text": "implementation of the algorithm.", "timestamp": "00:18:52,131", "timestamp_s": 1132.0}, {"text": "So again, I\u0027ll be talking about these in details in the benchmarking slides.", "timestamp": "00:18:54,031", "timestamp_s": 1134.0}, {"text": "So now why you should be understanding or you should be interested in exploring", "timestamp": "00:18:58,201", "timestamp_s": 1138.0}, {"text": "this library because the first thing Pandas doesn\u0027t offer you optimization, but", "timestamp": "00:19:02,761", "timestamp_s": 1142.0}, {"text": "firetax is lazy So because of the lazy it can do just in time optimization for you", "timestamp": "00:19:07,501", "timestamp_s": 1147.0}, {"text": "If you have a good system with multiple core available it can distribute it can", "timestamp": "00:19:12,731", "timestamp_s": 1152.0}, {"text": "parallelize the workload not distribute parallelize the workload among the", "timestamp": "00:19:17,254", "timestamp_s": 1157.0}, {"text": "multiple threads So that will result much faster data analysis If you work in the", "timestamp": "00:19:20,924", "timestamp_s": 1160.0}, {"text": "cloud you will experience less cloud, cost and of course, it will run much faster So", "timestamp": "00:19:26,864", "timestamp_s": 1166.0}, {"text": "it will attribute to less carbon dioxide, but the most important thing is if pandas,", "timestamp": "00:19:31,734", "timestamp_s": 1171.0}, {"text": "that\u0027s fine You don\u0027t need to understand.", "timestamp": "00:19:36,754", "timestamp_s": 1176.0}, {"text": "You don\u0027t need to learn a new library new data frame library So when the", "timestamp": "00:19:38,864", "timestamp_s": 1178.0}, {"text": "technology like ai and these kind of llm things is progressing so far", "timestamp": "00:19:42,694", "timestamp_s": 1182.0}, {"text": "It\u0027s better to learn a new technology than to learn a new library, right?", "timestamp": "00:19:46,744", "timestamp_s": 1186.0}, {"text": "So just you know pandas because we all of us usually start from pandas So", "timestamp": "00:19:50,619", "timestamp_s": 1190.0}, {"text": "knowing pandas is sufficient, but the challenges associated with pandas can", "timestamp": "00:19:55,249", "timestamp_s": 1195.0}, {"text": "be addressed by firedesk automatically Now the question is does it handle", "timestamp": "00:19:58,849", "timestamp_s": 1198.0}, {"text": "any kind of pandas application?", "timestamp": "00:20:02,969", "timestamp_s": 1202.0}, {"text": "Yes, it does handle any kind of pandas application not only pandas application", "timestamp": "00:20:04,619", "timestamp_s": 1204.0}, {"text": "but also the library that expect you to provide the pandas data for example", "timestamp": "00:20:09,249", "timestamp_s": 1209.0}, {"text": "seaborn matplotlib, scikit learn, imbalance learn, category encoders all", "timestamp": "00:20:13,489", "timestamp_s": 1213.0}, {"text": "the library that expect the you to input the pandas data frame You can provide", "timestamp": "00:20:18,329", "timestamp_s": 1218.0}, {"text": "a firedash data frame and it can work seamlessly with those as well So no extra", "timestamp": "00:20:21,989", "timestamp_s": 1221.0}, {"text": "learning no code modification You can experience much better performance benefit", "timestamp": "00:20:26,299", "timestamp_s": 1226.0}, {"text": "when switching from pandas to firetax.", "timestamp": "00:20:30,709", "timestamp_s": 1230.0}, {"text": "Now, let\u0027s understand some kind of demo with this.", "timestamp": "00:20:33,019", "timestamp_s": 1233.0}, {"text": "So here in this example, I am using some kind of Bitcoin data of the", "timestamp": "00:20:36,799", "timestamp_s": 1236.0}, {"text": "last three to five years and it is trying to perform some moving average.", "timestamp": "00:20:41,659", "timestamp_s": 1241.0}, {"text": "Just load the data creating a window and perform the average, perform the mean", "timestamp": "00:20:45,919", "timestamp_s": 1245.0}, {"text": "average calculation and plot the result.", "timestamp": "00:20:50,089", "timestamp_s": 1250.0}, {"text": "So the code is same in both the left and right side.", "timestamp": "00:20:52,544", "timestamp_s": 1252.0}, {"text": "The only difference is in the import So left side is important pandas and", "timestamp": "00:20:55,244", "timestamp_s": 1255.0}, {"text": "the right side is importing firedex.", "timestamp": "00:20:58,874", "timestamp_s": 1258.0}, {"text": "pandas.", "timestamp": "00:21:00,504", "timestamp_s": 1260.0}, {"text": "That is the only change But if you see in the execution time, you can", "timestamp": "00:21:00,784", "timestamp_s": 1260.0}, {"text": "see that pandas takes around 4.", "timestamp": "00:21:04,454", "timestamp_s": 1264.0}, {"text": "06 whereas firedex can complete it Within 275 milliseconds.", "timestamp": "00:21:06,535", "timestamp_s": 1266.0}, {"text": "So this simple code No modification you can experience 15 times build up.", "timestamp": "00:21:10,144", "timestamp_s": 1270.0}, {"text": "So that is some kind of quick demo I\u0027ll be talking about another demo", "timestamp": "00:21:15,419", "timestamp_s": 1275.0}, {"text": "another thing in upcoming slides for sure Okay, so with that let me", "timestamp": "00:21:18,959", "timestamp_s": 1278.0}, {"text": "explain you the usage of firedug.", "timestamp": "00:21:23,789", "timestamp_s": 1283.0}, {"text": "So first of all Firedux is currently available for Linux only, so if", "timestamp": "00:21:26,089", "timestamp_s": 1286.0}, {"text": "you\u0027re from the Windows or Mac users, so at this moment, probably", "timestamp": "00:21:30,439", "timestamp_s": 1290.0}, {"text": "you can consider using Google Colab or the platform that support Linux.", "timestamp": "00:21:34,419", "timestamp_s": 1294.0}, {"text": "For Windows, definitely you can try WSL because it can work with WSL.", "timestamp": "00:21:37,548", "timestamp_s": 1297.0}, {"text": "And the supported Pythons are from 3.", "timestamp": "00:21:41,779", "timestamp_s": 1301.0}, {"text": "9 to 3.", "timestamp": "00:21:44,940", "timestamp_s": 1304.0}, {"text": "12. So if you can satisfy these two conditions, you can install it using pip", "timestamp": "00:21:45,247", "timestamp_s": 1305.0}, {"text": "and you can use instead of import pandas, import firedux pandas and that will", "timestamp": "00:21:49,929", "timestamp_s": 1309.0}, {"text": "be sufficient to execute your existing program using firedux and optimize it.", "timestamp": "00:21:54,379", "timestamp_s": 1314.0}, {"text": "Now, how about zero code modification?", "timestamp": "00:21:59,779", "timestamp_s": 1319.0}, {"text": "if you are using program that is you importing pandas and it is importing", "timestamp": "00:22:02,749", "timestamp_s": 1322.0}, {"text": "other modules All those module might in turn importing pandas as well.", "timestamp": "00:22:07,679", "timestamp_s": 1327.0}, {"text": "So do you need to replace all this import by yourself?", "timestamp": "00:22:12,369", "timestamp_s": 1332.0}, {"text": "No There is monkey passing thing.", "timestamp": "00:22:15,309", "timestamp_s": 1335.0}, {"text": "So when executing the program using the python command, just pass hyphen", "timestamp": "00:22:18,154", "timestamp_s": 1338.0}, {"text": "option followed by firetus pandas.", "timestamp": "00:22:22,444", "timestamp_s": 1342.0}, {"text": "It can automatically replace all the pandas with firetus pandas.", "timestamp": "00:22:24,514", "timestamp_s": 1344.0}, {"text": "And it can do the optimization for you without any code modification.", "timestamp": "00:22:28,444", "timestamp_s": 1348.0}, {"text": "For notebook like platform, the same thing, your rest", "timestamp": "00:22:32,564", "timestamp_s": 1352.0}, {"text": "of the notebook can be same.", "timestamp": "00:22:35,604", "timestamp_s": 1355.0}, {"text": "Just on top of import pandas, you can add this extension module.", "timestamp": "00:22:37,024", "timestamp_s": 1357.0}, {"text": "And it can automatically replace the pandas with fireducks pandas and you", "timestamp": "00:22:40,789", "timestamp_s": 1360.0}, {"text": "can experience the benefit out of it So now let\u0027s understand, what is the", "timestamp": "00:22:44,469", "timestamp_s": 1364.0}, {"text": "challenge with seamless integration with pandas like, Of course wire ducks", "timestamp": "00:22:48,399", "timestamp_s": 1368.0}, {"text": "is something that i\u0027m talking about But there are other high performance pandas", "timestamp": "00:22:52,159", "timestamp_s": 1372.0}, {"text": "alternatives as well, right like duckdb, polars, dusk These are the library that", "timestamp": "00:22:55,609", "timestamp_s": 1375.0}, {"text": "try to achieve the same kind of problem like because pandas is slow So they", "timestamp": "00:23:00,269", "timestamp_s": 1380.0}, {"text": "have their own version of optimization that can address the slow performance", "timestamp": "00:23:04,159", "timestamp_s": 1384.0}, {"text": "of pandas But the major challenge comes with the compatibility with pandas", "timestamp": "00:23:08,514", "timestamp_s": 1388.0}, {"text": "like, if you want to use those library you have to learn that library first if", "timestamp": "00:23:13,129", "timestamp_s": 1393.0}, {"text": "because Either they are not compatible or they are not fully compatible.", "timestamp": "00:23:18,229", "timestamp_s": 1398.0}, {"text": "So you need to understand the library first and sometime it", "timestamp": "00:23:23,269", "timestamp_s": 1403.0}, {"text": "may happen that pandas because pandas is full of features, right?", "timestamp": "00:23:26,829", "timestamp_s": 1406.0}, {"text": "But those library might not offer that feature.", "timestamp": "00:23:31,634", "timestamp_s": 1411.0}, {"text": "So you need to convert, the library to pandas using from", "timestamp": "00:23:33,804", "timestamp_s": 1413.0}, {"text": "pandas into pandas mechanism.", "timestamp": "00:23:37,264", "timestamp_s": 1417.0}, {"text": "And, when, comparing the result in the performance, once your complete program", "timestamp": "00:23:39,234", "timestamp_s": 1419.0}, {"text": "can be migrated, you can compare the performances, or taste the results.", "timestamp": "00:23:43,474", "timestamp_s": 1423.0}, {"text": "So that are the challenges associated with it.", "timestamp": "00:23:47,054", "timestamp_s": 1427.0}, {"text": "So whether you want to take that effort, For that cost optimization.", "timestamp": "00:23:49,084", "timestamp_s": 1429.0}, {"text": "So there is always a cost performance thing in your mind so yeah, you have", "timestamp": "00:23:54,074", "timestamp_s": 1434.0}, {"text": "options like modern does vex, but they are ideally for the multi Node", "timestamp": "00:23:58,484", "timestamp_s": 1438.0}, {"text": "environment there is something called polars that is for the single node", "timestamp": "00:24:03,874", "timestamp_s": 1443.0}, {"text": "environment that is super fast But it is not much compatible with pandas.", "timestamp": "00:24:07,164", "timestamp_s": 1447.0}, {"text": "So if you want to use folders probably you need to understand the library", "timestamp": "00:24:11,664", "timestamp_s": 1451.0}, {"text": "in the very first place that is where fireducks can help you like being it", "timestamp": "00:24:14,394", "timestamp_s": 1454.0}, {"text": "highly compatible with pandas No code modification, no node learning associated", "timestamp": "00:24:19,224", "timestamp_s": 1459.0}, {"text": "with it And you can experience the single node speed up If you\u0027re working", "timestamp": "00:24:23,384", "timestamp_s": 1463.0}, {"text": "on the data and that can be fit into memory, you can work with firetrucks.", "timestamp": "00:24:27,724", "timestamp_s": 1467.0}, {"text": "Of course, it provides optimization.", "timestamp": "00:24:32,384", "timestamp_s": 1472.0}, {"text": "it may happen that although you have a bigger data, but you\u0027re not", "timestamp": "00:24:34,354", "timestamp_s": 1474.0}, {"text": "interested in every part of the data.", "timestamp": "00:24:37,784", "timestamp_s": 1477.0}, {"text": "it can do the optimization for you and it can just selectively load the", "timestamp": "00:24:39,504", "timestamp_s": 1479.0}, {"text": "target columns and rows so that it can do a lot of justice with your,", "timestamp": "00:24:43,154", "timestamp_s": 1483.0}, {"text": "like limited set of resources, the memory and the number of cores.", "timestamp": "00:24:47,504", "timestamp_s": 1487.0}, {"text": "let\u0027s see like how seamless integration is possible with pandas.", "timestamp": "00:24:51,729", "timestamp_s": 1491.0}, {"text": "For example, this is a demo notebook.", "timestamp": "00:24:55,749", "timestamp_s": 1495.0}, {"text": "You can consider the actual notebook from this link.", "timestamp": "00:24:57,619", "timestamp_s": 1497.0}, {"text": "But let\u0027s understand what it\u0027s trying to do.", "timestamp": "00:25:00,449", "timestamp_s": 1500.0}, {"text": "It is trying to load parquet data from InnoIC parking violation.", "timestamp": "00:25:02,939", "timestamp_s": 1502.0}, {"text": "After the data loading is done, it is trying to, perform a query where it is", "timestamp": "00:25:07,304", "timestamp_s": 1507.0}, {"text": "trying to see, which parking violation is the most commonly committed by", "timestamp": "00:25:11,324", "timestamp_s": 1511.0}, {"text": "vehicles from various United States.", "timestamp": "00:25:14,764", "timestamp_s": 1514.0}, {"text": "because of, in order to execute the query, it does some group by", "timestamp": "00:25:18,124", "timestamp_s": 1518.0}, {"text": "head and shorting kind of stuff.", "timestamp": "00:25:21,034", "timestamp_s": 1521.0}, {"text": "So the basic code is entirely written in pandas.", "timestamp": "00:25:22,829", "timestamp_s": 1522.0}, {"text": "So there is nothing that you can identify new So everything is written in pandas.", "timestamp": "00:25:26,379", "timestamp_s": 1526.0}, {"text": "Now simply I executed the same program using python followed by", "timestamp": "00:25:30,899", "timestamp_s": 1530.0}, {"text": "the program name So you can see that the data loading take around 2.", "timestamp": "00:25:34,519", "timestamp_s": 1534.0}, {"text": "4 and the query one takes around 2.", "timestamp": "00:25:39,819", "timestamp_s": 1539.0}, {"text": "8 seconds Overall, it takes around 5.", "timestamp": "00:25:40,879", "timestamp_s": 1540.0}, {"text": "3 seconds But in order to execute the same program with fire dogs, no code change", "timestamp": "00:25:43,199", "timestamp_s": 1543.0}, {"text": "just add hyphenium fire dust and pandas And it can be done much faster like almost", "timestamp": "00:25:49,169", "timestamp_s": 1549.0}, {"text": "eight times can eight times faster but the data loading as well as the query", "timestamp": "00:25:55,334", "timestamp_s": 1555.0}, {"text": "processing can be done much faster when we\u0027re switching to Pandas to firetrucks", "timestamp": "00:25:59,494", "timestamp_s": 1559.0}, {"text": "just by adding a program option.", "timestamp": "00:26:03,764", "timestamp_s": 1563.0}, {"text": "Nothing else.", "timestamp": "00:26:05,684", "timestamp_s": 1565.0}, {"text": "So that is how it is very like Easy to integrate once you download it.", "timestamp": "00:26:06,724", "timestamp_s": 1566.0}, {"text": "It can be integrated to any pandas application and you can experience", "timestamp": "00:26:11,324", "timestamp_s": 1571.0}, {"text": "this better So definitely you can try the notebook for Further exploration", "timestamp": "00:26:14,544", "timestamp_s": 1574.0}, {"text": "So now let\u0027s consider the optimizing features that is available in FireDogs.", "timestamp": "00:26:20,174", "timestamp_s": 1580.0}, {"text": "So this is the design of FireDogs like It looks like a pandas program because we", "timestamp": "00:26:24,514", "timestamp_s": 1584.0}, {"text": "mock all the api that is written All the user interface in a pandas like interface", "timestamp": "00:26:30,594", "timestamp_s": 1590.0}, {"text": "But down the line everything is written in c once the instruction is optimized", "timestamp": "00:26:36,404", "timestamp_s": 1596.0}, {"text": "by the compiler So what happens is pandas is like you write the program and it", "timestamp": "00:26:40,454", "timestamp_s": 1600.0}, {"text": "execute it right after you click But in case of Firedux, as I explained that it", "timestamp": "00:26:44,594", "timestamp_s": 1604.0}, {"text": "will create some kind of instructions and those instructions will be optimized by", "timestamp": "00:26:49,814", "timestamp_s": 1609.0}, {"text": "the compiler and the optimized instruction will be converted by a system call and", "timestamp": "00:26:54,454", "timestamp_s": 1614.0}, {"text": "then it will be executed by the multiple code that is available in your system.", "timestamp": "00:26:59,324", "timestamp_s": 1619.0}, {"text": "So all the available code in your system will be effectively used.", "timestamp": "00:27:03,094", "timestamp_s": 1623.0}, {"text": "the system cache will be effectively used, the vectorization", "timestamp": "00:27:06,764", "timestamp_s": 1626.0}, {"text": "will be effectively used.", "timestamp": "00:27:09,504", "timestamp_s": 1629.0}, {"text": "So because of this you can experience much faster speedup when using firetux.", "timestamp": "00:27:10,734", "timestamp_s": 1630.0}, {"text": "So now what is the offering from these two layers?", "timestamp": "00:27:15,114", "timestamp_s": 1635.0}, {"text": "So first of all there is a compiler, so definitely you can expect compiler", "timestamp": "00:27:17,234", "timestamp_s": 1637.0}, {"text": "specific optimization like common sub expression elimination, date", "timestamp": "00:27:20,594", "timestamp_s": 1640.0}, {"text": "code elimination kind of stuff.", "timestamp": "00:27:24,434", "timestamp_s": 1644.0}, {"text": "So you can expect domain specific optimization like get", "timestamp": "00:27:26,364", "timestamp_s": 1646.0}, {"text": "pushed down a projection post on that I talked about so far.", "timestamp": "00:27:30,049", "timestamp_s": 1650.0}, {"text": "You can expect some pandas specific tuning here as well.", "timestamp": "00:27:33,519", "timestamp_s": 1653.0}, {"text": "So I\u0027ll be talking about it in upcoming slides.", "timestamp": "00:27:36,719", "timestamp_s": 1656.0}, {"text": "Now, what about the second most layer that is the backend?", "timestamp": "00:27:39,249", "timestamp_s": 1659.0}, {"text": "The backend is multithreaded first of all.", "timestamp": "00:27:42,649", "timestamp_s": 1662.0}, {"text": "So If you have a very good, system with multiple threads available, you can", "timestamp": "00:27:44,759", "timestamp_s": 1664.0}, {"text": "experience much, throughput out of that.", "timestamp": "00:27:49,214", "timestamp_s": 1669.0}, {"text": "The, it can take good, use of the memory because it is backed", "timestamp": "00:27:51,854", "timestamp_s": 1671.0}, {"text": "by Apache Parallel Memory.", "timestamp": "00:27:55,164", "timestamp_s": 1675.0}, {"text": "The major data structure is backed by Apache Arrow, so you can have Compact", "timestamp": "00:27:56,664", "timestamp_s": 1676.0}, {"text": "usage of the memory as well and all the kernels like join, group by filter,", "timestamp": "00:28:00,339", "timestamp_s": 1680.0}, {"text": "drop in, everything is written from scratch by our own patented algorithms.", "timestamp": "00:28:04,849", "timestamp_s": 1684.0}, {"text": "So this kernel operation itself is much faster when comparing to pandas or other", "timestamp": "00:28:09,179", "timestamp_s": 1689.0}, {"text": "high performance pandas alternatives.", "timestamp": "00:28:13,909", "timestamp_s": 1693.0}, {"text": "We\u0027ll be experiencing it in upcoming slide for sure.", "timestamp": "00:28:16,329", "timestamp_s": 1696.0}, {"text": "So yes, so let\u0027s understand what is compiler specific optimization.", "timestamp": "00:28:19,049", "timestamp_s": 1699.0}, {"text": "I took this example from one of the Kaggle notebook that I recently noticed like you", "timestamp": "00:28:22,949", "timestamp_s": 1702.0}, {"text": "can see that here df time is a column of string type So since it is string type", "timestamp": "00:28:27,149", "timestamp_s": 1707.0}, {"text": "and the pop the person wants to perform some group by based on the year and", "timestamp": "00:28:33,649", "timestamp_s": 1713.0}, {"text": "month he wants to find the average sales.", "timestamp": "00:28:37,539", "timestamp_s": 1717.0}, {"text": "So what he does it he performed the string column to date time In order to extract", "timestamp": "00:28:39,959", "timestamp_s": 1719.0}, {"text": "the year field and the month field And do the stuff but as you can understand the", "timestamp": "00:28:44,749", "timestamp_s": 1724.0}, {"text": "two data itself is a complex operation because you try to parse a string to", "timestamp": "00:28:49,799", "timestamp_s": 1729.0}, {"text": "Convert it to datetime So if you do the same operation the same data more", "timestamp": "00:28:53,839", "timestamp_s": 1733.0}, {"text": "than once it is going to cost you when your data is putting in size So ideally", "timestamp": "00:28:58,439", "timestamp_s": 1738.0}, {"text": "what is better is You can just compute it once put it in some placeholder and", "timestamp": "00:29:04,429", "timestamp_s": 1744.0}, {"text": "use it wherever you need it So this is something a basic programming know how", "timestamp": "00:29:08,714", "timestamp_s": 1748.0}, {"text": "But because find x uses a compiler and the compiler can identify this kind of common", "timestamp": "00:29:13,564", "timestamp_s": 1753.0}, {"text": "expression So well, I already have do it.", "timestamp": "00:29:17,984", "timestamp_s": 1757.0}, {"text": "So so because compiler will create an instruction for that Again, it", "timestamp": "00:29:21,104", "timestamp_s": 1761.0}, {"text": "will create an instruction for this And then it will say, I already", "timestamp": "00:29:25,574", "timestamp_s": 1765.0}, {"text": "have created the instruction.", "timestamp": "00:29:29,179", "timestamp_s": 1769.0}, {"text": "So let me use that.", "timestamp": "00:29:30,389", "timestamp_s": 1770.0}, {"text": "And wherever I, wherever it is referred, instead of creating", "timestamp": "00:29:32,149", "timestamp_s": 1772.0}, {"text": "a new instruction, this kind of optimization possible by FireDogs.", "timestamp": "00:29:35,449", "timestamp_s": 1775.0}, {"text": "So this kind of, CAC, Common Sub Explanatory Elimination", "timestamp": "00:29:38,969", "timestamp_s": 1778.0}, {"text": "Optimization Benefit, you can definitely get from FireDogs.", "timestamp": "00:29:42,829", "timestamp_s": 1782.0}, {"text": "Another thing is something called Dead Code Elimination.", "timestamp": "00:29:46,679", "timestamp_s": 1786.0}, {"text": "So for example, this is a piece of function.", "timestamp": "00:29:48,849", "timestamp_s": 1788.0}, {"text": "So where it is trying to merge x. Table with the y table And after merging it", "timestamp": "00:29:51,199", "timestamp_s": 1791.0}, {"text": "is trying to do the shorting operation after shorting It is doing the group", "timestamp": "00:29:57,064", "timestamp_s": 1797.0}, {"text": "by but the group by using the merged variable not the shorted variable, right?", "timestamp": "00:30:01,044", "timestamp_s": 1801.0}, {"text": "So in the entire function This is the line that is used but have never referenced So", "timestamp": "00:30:06,014", "timestamp_s": 1806.0}, {"text": "when you use pandas like eager execution model, it will be executed because the", "timestamp": "00:30:11,974", "timestamp_s": 1811.0}, {"text": "shorting is you ask it to short, right?", "timestamp": "00:30:16,334", "timestamp_s": 1816.0}, {"text": "But fired us can identify.", "timestamp": "00:30:18,874", "timestamp_s": 1818.0}, {"text": "Okay, you asked me to do That is fine.", "timestamp": "00:30:20,354", "timestamp_s": 1820.0}, {"text": "I create an instruction, but you never used it.", "timestamp": "00:30:23,134", "timestamp_s": 1823.0}, {"text": "So I will not execute the instruction I will eliminate that date code", "timestamp": "00:30:26,094", "timestamp_s": 1826.0}, {"text": "out of my execution, graph, right?", "timestamp": "00:30:29,364", "timestamp_s": 1829.0}, {"text": "So this kind of date code elimination is possible when you switch to firetux,", "timestamp": "00:30:32,364", "timestamp_s": 1832.0}, {"text": "from pandas if you want to explore more, so you can definitely take, read the", "timestamp": "00:30:36,604", "timestamp_s": 1836.0}, {"text": "article that explored about this kind of compiler specific optimization details.", "timestamp": "00:30:40,684", "timestamp_s": 1840.0}, {"text": "yes, now let\u0027s talk about some, domain specific optimization that", "timestamp": "00:30:45,744", "timestamp_s": 1845.0}, {"text": "we discussed so far like projection pushdown and predicate pushdown.", "timestamp": "00:30:49,844", "timestamp_s": 1849.0}, {"text": "for that, I have taken one sample query from TPCS benchmark, the query, Q3 10", "timestamp": "00:30:53,354", "timestamp_s": 1853.0}, {"text": "unshipped orders with the highest value.", "timestamp": "00:31:00,991", "timestamp_s": 1860.0}, {"text": "Ideally it was written in SQL.", "timestamp": "00:31:03,371", "timestamp_s": 1863.0}, {"text": "I first let\u0027s convert it to pandas and see what it does So if you carefully notice", "timestamp": "00:31:05,131", "timestamp_s": 1865.0}, {"text": "the query It doesn\u0027t perform any kind of best practices that we understand like", "timestamp": "00:31:09,701", "timestamp_s": 1869.0}, {"text": "kind of reduction the data in the row direction the column direction It doesn\u0027t", "timestamp": "00:31:14,331", "timestamp_s": 1874.0}, {"text": "do anything as such it load the entire data from three tables customer orders", "timestamp": "00:31:18,071", "timestamp_s": 1878.0}, {"text": "and line item After loading the data it can Just join them to create a bigger", "timestamp": "00:31:22,351", "timestamp_s": 1882.0}, {"text": "table such that it can perform Rest of the operation like filtration and group", "timestamp": "00:31:27,636", "timestamp_s": 1887.0}, {"text": "by rest of the stuff as per the demand of the query So when we execute this query", "timestamp": "00:31:32,756", "timestamp_s": 1892.0}, {"text": "using python using pandas, that pandas took around 203 seconds and the memory", "timestamp": "00:31:37,776", "timestamp_s": 1897.0}, {"text": "consumption was around 60 gb for the scale factor 10 but when we execute the same", "timestamp": "00:31:44,461", "timestamp_s": 1904.0}, {"text": "program using fire dogs just by adding this Plug in, it can be finished within 4.", "timestamp": "00:31:50,331", "timestamp_s": 1910.0}, {"text": "24 seconds and the memory consumption was around 3.", "timestamp": "00:31:56,442", "timestamp_s": 1916.0}, {"text": "3 gb Yes, because fire although we have written it without consideration", "timestamp": "00:31:59,081", "timestamp_s": 1919.0}, {"text": "of the optimization Fighters compiler will do it for you.", "timestamp": "00:32:04,711", "timestamp_s": 1924.0}, {"text": "It can figure out All those stuff like the reduction of the data in the horizontal", "timestamp": "00:32:08,941", "timestamp_s": 1928.0}, {"text": "direction and the vertical direction and apply it automatically, because of", "timestamp": "00:32:13,111", "timestamp_s": 1933.0}, {"text": "which you can explain much, much speed up, from this kind of program that", "timestamp": "00:32:17,831", "timestamp_s": 1937.0}, {"text": "doesn\u0027t take care of the optimization.", "timestamp": "00:32:22,481", "timestamp_s": 1942.0}, {"text": "In order to understand that, let\u0027s manually optimize this program.", "timestamp": "00:32:24,471", "timestamp_s": 1944.0}, {"text": "So what is the best practices?", "timestamp": "00:32:28,046", "timestamp_s": 1948.0}, {"text": "First of all, the practice is to instead of operating on the entire data, reduce", "timestamp": "00:32:31,126", "timestamp_s": 1951.0}, {"text": "the data in the columnar direction, right?", "timestamp": "00:32:35,906", "timestamp_s": 1955.0}, {"text": "In the vertical direction.", "timestamp": "00:32:38,016", "timestamp_s": 1958.0}, {"text": "So by carefully observing the query, you can see that we only need these", "timestamp": "00:32:39,666", "timestamp_s": 1959.0}, {"text": "two columns from the customer table.", "timestamp": "00:32:44,346", "timestamp_s": 1964.0}, {"text": "Although there are eight columns, we only need these", "timestamp": "00:32:45,956", "timestamp_s": 1965.0}, {"text": "four columns from the line item.", "timestamp": "00:32:48,556", "timestamp_s": 1968.0}, {"text": "Although there are 16 columns, we only need these four", "timestamp": "00:32:50,016", "timestamp_s": 1970.0}, {"text": "columns from the order table.", "timestamp": "00:32:52,226", "timestamp_s": 1972.0}, {"text": "Although there are nine columns.", "timestamp": "00:32:53,996", "timestamp_s": 1973.0}, {"text": "So instead of loading the entire data, I will only load these selective columns.", "timestamp": "00:32:55,736", "timestamp_s": 1975.0}, {"text": "Then I only need some particular rows from these tables because", "timestamp": "00:33:00,586", "timestamp_s": 1980.0}, {"text": "of the filter operation.", "timestamp": "00:33:04,846", "timestamp_s": 1984.0}, {"text": "So I will filter all the target table based on the given condition.", "timestamp": "00:33:06,256", "timestamp_s": 1986.0}, {"text": "Then I will just join the tables to the group by an aggregate", "timestamp": "00:33:10,556", "timestamp_s": 1990.0}, {"text": "and the shorting operation.", "timestamp": "00:33:14,346", "timestamp_s": 1994.0}, {"text": "Now when I execute the same optimized query in pandas, it becomes 13 seconds.", "timestamp": "00:33:15,896", "timestamp_s": 1995.0}, {"text": "So 203 seconds can be optimized to 13 seconds with this manual", "timestamp": "00:33:21,230", "timestamp_s": 2001.0}, {"text": "optimization and the memory can also be reduced from 60 GB to 5.", "timestamp": "00:33:25,186", "timestamp_s": 2005.0}, {"text": "5 GB.", "timestamp": "00:33:28,561", "timestamp_s": 2008.0}, {"text": "Even when you use pandas effectively But when you see the fire ducks, even though", "timestamp": "00:33:30,381", "timestamp_s": 2010.0}, {"text": "you try q3 and opt q3 Manual optimization is present or it is absent doesn\u0027t matter", "timestamp": "00:33:36,601", "timestamp_s": 2016.0}, {"text": "It can execute with the same speed and with the same memory command Because if", "timestamp": "00:33:42,901", "timestamp_s": 2022.0}, {"text": "you do a panel optimization fair enough when you cannot do it firedust can do", "timestamp": "00:33:47,401", "timestamp_s": 2027.0}, {"text": "it for you So you can rely such optimize rely for such optimization on fire ducks", "timestamp": "00:33:51,511", "timestamp_s": 2031.0}, {"text": "definitely Now let\u0027s understand one of the parameter tuning that is possible", "timestamp": "00:33:57,211", "timestamp_s": 2037.0}, {"text": "in FireDogs, not FireDogs actually.", "timestamp": "00:34:01,581", "timestamp_s": 2041.0}, {"text": "First of all, what is the parameter tuning that you can do in Pandas, then", "timestamp": "00:34:04,011", "timestamp_s": 2044.0}, {"text": "how FireDogs can take care of that.", "timestamp": "00:34:07,041", "timestamp_s": 2047.0}, {"text": "So in order to understand that, let\u0027s consider that this query where it is", "timestamp": "00:34:08,911", "timestamp_s": 2048.0}, {"text": "trying to perform, Group by on the department column of the employee table", "timestamp": "00:34:13,641", "timestamp_s": 2053.0}, {"text": "followed by that it is calculating the average salary and shorting the Salary", "timestamp": "00:34:18,661", "timestamp_s": 2058.0}, {"text": "based on the descending order, right?", "timestamp": "00:34:23,681", "timestamp_s": 2063.0}, {"text": "So what will happen it will create the group So it group admin group finance", "timestamp": "00:34:25,901", "timestamp_s": 2065.0}, {"text": "group corporate and sales group and it will perform the average of each group So", "timestamp": "00:34:30,581", "timestamp_s": 2070.0}, {"text": "that is ideally the group by operations But there is a hidden cost associated", "timestamp": "00:34:34,891", "timestamp_s": 2074.0}, {"text": "with it You And the cost is the group by is by default has a parameter called", "timestamp": "00:34:40,161", "timestamp_s": 2080.0}, {"text": "short and the value is true But the meaning of the short parameter is It is", "timestamp": "00:34:46,241", "timestamp_s": 2086.0}, {"text": "trying to short the result of the group by based on the key column here The key", "timestamp": "00:34:53,631", "timestamp_s": 2093.0}, {"text": "is the department so it will not only compute the group by aggregation, but", "timestamp": "00:34:58,161", "timestamp_s": 2098.0}, {"text": "also short the result by the key column So admin will come first followed by", "timestamp": "00:35:02,411", "timestamp_s": 2102.0}, {"text": "corporate finance id and sales shorted by the department but In your query,", "timestamp": "00:35:07,311", "timestamp_s": 2107.0}, {"text": "you don\u0027t need this shorting to happen.", "timestamp": "00:35:13,721", "timestamp_s": 2113.0}, {"text": "Instead, you want the result to be shorted by the salary with the", "timestamp": "00:35:15,701", "timestamp_s": 2115.0}, {"text": "value column in descending order.", "timestamp": "00:35:19,271", "timestamp_s": 2119.0}, {"text": "So again, because you ask the pandas to do so it will do it.", "timestamp": "00:35:21,451", "timestamp_s": 2121.0}, {"text": "It will short the result by the descending order when it will", "timestamp": "00:35:25,191", "timestamp_s": 2125.0}, {"text": "encounter the short values.", "timestamp": "00:35:28,861", "timestamp_s": 2128.0}, {"text": "what you can expect that this is the step that is taking place because of", "timestamp": "00:35:31,031", "timestamp_s": 2131.0}, {"text": "this default parameter of group by but this is the redundant step it can be", "timestamp": "00:35:36,341", "timestamp_s": 2136.0}, {"text": "avoided, Even if we don\u0027t perform this step, it doesn\u0027t impact my result.", "timestamp": "00:35:42,571", "timestamp_s": 2142.0}, {"text": "So this is a redundant step.", "timestamp": "00:35:46,651", "timestamp_s": 2146.0}, {"text": "How we can avoid it?", "timestamp": "00:35:47,961", "timestamp_s": 2147.0}, {"text": "We can simply impute the short equals to false parameter for this case.", "timestamp": "00:35:49,101", "timestamp_s": 2149.0}, {"text": "And if we apply this, Pandas will skip that step and we\u0027ll", "timestamp": "00:35:53,431", "timestamp_s": 2153.0}, {"text": "get much better performance.", "timestamp": "00:35:56,751", "timestamp_s": 2156.0}, {"text": "Now, this data have very less cardinality, only 5 groups, but when you have a", "timestamp": "00:35:58,726", "timestamp_s": 2158.0}, {"text": "very high cardinality in your data, many groups are present, you can", "timestamp": "00:36:03,456", "timestamp_s": 2163.0}, {"text": "expect that this will give you much more performance in terms of speedup.", "timestamp": "00:36:07,106", "timestamp_s": 2167.0}, {"text": "Like when I try with 100 million samples with high cardinality, I expect that,", "timestamp": "00:36:11,506", "timestamp_s": 2171.0}, {"text": "without short equals to false, it was taking 50 seconds and with short", "timestamp": "00:36:17,396", "timestamp_s": 2177.0}, {"text": "equals to false, it took 30 seconds.", "timestamp": "00:36:20,746", "timestamp_s": 2180.0}, {"text": "the short itself has, A lot of like almost like more than 50 percent", "timestamp": "00:36:22,356", "timestamp_s": 2182.0}, {"text": "contribution for this query So this is something called parameter", "timestamp": "00:36:28,096", "timestamp_s": 2188.0}, {"text": "tuning and because of the compiler in firedux it can detect that After", "timestamp": "00:36:31,366", "timestamp_s": 2191.0}, {"text": "groupby you want to short the result.", "timestamp": "00:36:37,336", "timestamp_s": 2197.0}, {"text": "So the default shorting in the groupby is not needed And firedux can automatically", "timestamp": "00:36:39,536", "timestamp_s": 2199.0}, {"text": "impute such parameter by making it false such that you can avoid this kind of", "timestamp": "00:36:44,936", "timestamp_s": 2204.0}, {"text": "performance cost which is hidden in pandas So that is again one of the offering when", "timestamp": "00:36:50,681", "timestamp_s": 2210.0}, {"text": "you will be using fire tax Now with that, let me talk about some benchmarks So", "timestamp": "00:36:54,491", "timestamp_s": 2214.0}, {"text": "this is a very popular benchmark called deb benchmark where they have written", "timestamp": "00:37:00,161", "timestamp_s": 2220.0}, {"text": "several around 10 queries of different complex City of the data with different", "timestamp": "00:37:04,461", "timestamp_s": 2224.0}, {"text": "cardinality and size for the join and group operations So when you see the", "timestamp": "00:37:10,316", "timestamp_s": 2230.0}, {"text": "comparison table, of course pandas is slow So that is why it is on from the very", "timestamp": "00:37:15,026", "timestamp_s": 2235.0}, {"text": "bottom But other hyperlink alternative of pandas like colors dark divi and all you", "timestamp": "00:37:18,756", "timestamp_s": 2238.0}, {"text": "can see the products is something That can outperform all the other library as", "timestamp": "00:37:23,446", "timestamp_s": 2243.0}, {"text": "well and it is something around the top So now let\u0027s, if we talk about some general", "timestamp": "00:37:27,936", "timestamp_s": 2247.0}, {"text": "overview of this popular library, so I can have this kind of image at my mind.", "timestamp": "00:37:32,841", "timestamp_s": 2252.0}, {"text": "So in terms of pandas compatibility and single node performance, if we compare", "timestamp": "00:37:37,671", "timestamp_s": 2257.0}, {"text": "this library, so we can see duckdb is a library that duckdb and polars Are the", "timestamp": "00:37:41,391", "timestamp_s": 2261.0}, {"text": "library that can work better on single node performance Whereas park, dusk,", "timestamp": "00:37:48,421", "timestamp_s": 2268.0}, {"text": "modin are the library that works better on the multi node computation environment", "timestamp": "00:37:53,471", "timestamp_s": 2273.0}, {"text": "because they\u0027re target for the multi node In terms of pandas compatibility", "timestamp": "00:37:57,391", "timestamp_s": 2277.0}, {"text": "duckdb has very less compatible because it is for the sql api where polars is", "timestamp": "00:38:01,801", "timestamp_s": 2281.0}, {"text": "not that compatible Although it somewhat look alike interface with pandas But", "timestamp": "00:38:06,681", "timestamp_s": 2286.0}, {"text": "firedogs and modding, these are the library that are fully compatible", "timestamp": "00:38:11,931", "timestamp_s": 2291.0}, {"text": "with, like pandas kind of thing.", "timestamp": "00:38:16,101", "timestamp_s": 2296.0}, {"text": "And of course, Rapids has its own QDF.", "timestamp": "00:38:17,811", "timestamp_s": 2297.0}, {"text": "That is for GPU, although that is another, different story.", "timestamp": "00:38:21,171", "timestamp_s": 2301.0}, {"text": "But Rapids is again compatible with pandas, providing good performance.", "timestamp": "00:38:24,421", "timestamp_s": 2304.0}, {"text": "But since it is for the GPU platform, so it is something different than all these.", "timestamp": "00:38:29,931", "timestamp_s": 2309.0}, {"text": "at this moment.", "timestamp": "00:38:33,906", "timestamp_s": 2313.0}, {"text": "All the Polars has its own GPU version available.", "timestamp": "00:38:36,066", "timestamp_s": 2316.0}, {"text": "And so for the FireDUX that we are currently working on.", "timestamp": "00:38:39,236", "timestamp_s": 2319.0}, {"text": "Now, if we talk about the TPC H that is one of the popular benchmark.", "timestamp": "00:38:42,636", "timestamp_s": 2322.0}, {"text": "In this demo, I have used query three only, but actually there is 22 22", "timestamp": "00:38:46,576", "timestamp_s": 2326.0}, {"text": "queries for against Pandas and other high performance alternative like", "timestamp": "00:38:53,146", "timestamp_s": 2333.0}, {"text": "Polars and Modin, we can see that Modin was working not that good, like", "timestamp": "00:38:56,606", "timestamp_s": 2336.0}, {"text": "somewhat similar to Pandas, but older.", "timestamp": "00:39:02,616", "timestamp_s": 2342.0}, {"text": "Was quite faster.", "timestamp": "00:39:04,346", "timestamp_s": 2344.0}, {"text": "It was around 57 times faster when comparing, when", "timestamp": "00:39:05,696", "timestamp_s": 2345.0}, {"text": "performing the processing stuff.", "timestamp": "00:39:09,266", "timestamp_s": 2349.0}, {"text": "But fire desks can outperform the average around 1 25 times, so it can", "timestamp": "00:39:11,516", "timestamp_s": 2351.0}, {"text": "work much faster without even modifying a piece of existing partner code.", "timestamp": "00:39:17,206", "timestamp_s": 2357.0}, {"text": "and if you compare the scalability of the library in terms of TPCs framework also.", "timestamp": "00:39:22,146", "timestamp_s": 2362.0}, {"text": "We can see that, the polars, duck, db, fire, ducks are the library that", "timestamp": "00:39:27,186", "timestamp_s": 2367.0}, {"text": "offer multithreading, where pandas works same, even though we increase the", "timestamp": "00:39:30,886", "timestamp_s": 2370.0}, {"text": "number of cores, there is no visible change in terms of performance in", "timestamp": "00:39:35,386", "timestamp_s": 2375.0}, {"text": "pandas, even if we include the I O or exclude the I O. But, in case of duck", "timestamp": "00:39:39,576", "timestamp_s": 2379.0}, {"text": "db and fireducks, that shows somewhat good, scalability when we increase the", "timestamp": "00:39:44,506", "timestamp_s": 2384.0}, {"text": "number of threads, during the execution.", "timestamp": "00:39:51,816", "timestamp_s": 2391.0}, {"text": "Polars is again, doing scalability, but to some, after some extent, the polars,", "timestamp": "00:39:54,396", "timestamp_s": 2394.0}, {"text": "doesn\u0027t show that much of scalability when, at least for the TPC benchmark.", "timestamp": "00:39:59,036", "timestamp_s": 2399.0}, {"text": "till 8 cores, it was fine, but after 8 cores.", "timestamp": "00:40:03,826", "timestamp_s": 2403.0}, {"text": "The scalability was something that was not quite good when we compared TPC H.", "timestamp": "00:40:06,511", "timestamp_s": 2406.0}, {"text": "so here are some resources on FireDUX.", "timestamp": "00:40:13,061", "timestamp_s": 2413.0}, {"text": "If you want to know more about it, explore the articles written in, written for", "timestamp": "00:40:15,181", "timestamp_s": 2415.0}, {"text": "FireDUX and other libraries, we can check out this, Website that is there we can", "timestamp": "00:40:19,291", "timestamp_s": 2419.0}, {"text": "follow on us on twitter where we publish the information related to articles", "timestamp": "00:40:23,581", "timestamp_s": 2423.0}, {"text": "the new development the new release etc if you find any issue and want to", "timestamp": "00:40:28,361", "timestamp_s": 2428.0}, {"text": "report back to us you can refer to the github page you can definitely connect", "timestamp": "00:40:32,151", "timestamp_s": 2432.0}, {"text": "us over the slack channel we\u0027d be happy to welcome you there and collaborate", "timestamp": "00:40:37,421", "timestamp_s": 2437.0}, {"text": "directly with you if you have any questions so with that let me conclude my", "timestamp": "00:40:41,381", "timestamp_s": 2441.0}, {"text": "talk thank you once again for listening to me And I hope you enjoyed the talk.", "timestamp": "00:40:47,041", "timestamp_s": 2447.0}, {"text": "the key insight that I talked about in best practices and how fire ducks can help", "timestamp": "00:40:52,666", "timestamp_s": 2452.0}, {"text": "you to improve your journey with pandas.", "timestamp": "00:40:56,846", "timestamp_s": 2456.0}, {"text": "So enjoy green computing and explore fire ducks.", "timestamp": "00:41:00,536", "timestamp_s": 2460.0}, {"text": "If you have any questions, I understand that this is something online.", "timestamp": "00:41:04,996", "timestamp_s": 2464.0}, {"text": "So probably I cannot make it interactive this time, but if you have any questions,", "timestamp": "00:41:08,296", "timestamp_s": 2468.0}, {"text": "you can connect me over the LinkedIn or any other prefer social media network,", "timestamp": "00:41:12,441", "timestamp_s": 2472.0}, {"text": "or you can definitely get in touch with the Slack channel and other media.", "timestamp": "00:41:16,781", "timestamp_s": 2476.0}, {"text": "I\u0027d be happy to help you in optimizing whatever problems you may have with", "timestamp": "00:41:20,251", "timestamp_s": 2480.0}, {"text": "pandas and discuss some kind of collaboration if you are interested in it.", "timestamp": "00:41:25,181", "timestamp_s": 2485.0}, {"text": "Yes.", "timestamp": "00:41:30,691", "timestamp_s": 2490.0}, {"text": "With that, I\u0027m concluding my talk.", "timestamp": "00:41:31,141", "timestamp_s": 2491.0}, {"text": "Thank you very much once again for listening to me till this.", "timestamp": "00:41:33,581", "timestamp_s": 2493.0}, {"text": "till this end, I hope you enjoy rest of the presentation as well,", "timestamp": "00:41:37,551", "timestamp_s": 2497.0}, {"text": "happy collaboration, happy learning.", "timestamp": "00:41:41,461", "timestamp_s": 2501.0}, {"text": "Thank you so much.", "timestamp": "00:41:43,511", "timestamp_s": 2503.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: 'FPUby5Ecqj0',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              Introducing FireDucks: A Multithreaded DataFrame Library with JIT Compilation
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>We introduce a couple of frequently occurring intricate performance issues in large-scale data processing using pandas, along with a compiler-accelerated high-performance DataFrame library named FireDucks to auto-detect and optimize those issues without any manual effort.</p>
<!-- End Text -->
          </div>

          
          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./srt/python2025_Sourav_Saha.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:00,220'); seek(0.0)">
              Hello, everyone.
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:01,740'); seek(1.0)">
              Welcome to my talk.
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:03,090'); seek(3.0)">
              Today I'll be talking about a data frame library named fire ducks that
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:07,790'); seek(7.0)">
              we are working at the research lab.
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:10,520'); seek(10.0)">
              So we will explore, the motivation behind developing the fighters by stating
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:16,460'); seek(16.0)">
              some of the key challenges with pandas.
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:19,505'); seek(19.0)">
              And of course we'll be talking about the tips and tricks and the best
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:22,585'); seek(22.0)">
              practices when dealing with large scale data processing in pandas What
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:26,325'); seek(26.0)">
              fireducks is and what it is offering the optimization strategy available
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:30,495'); seek(30.0)">
              with it With some live demo and the resources available on fireducks
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:00:36,095'); seek(36.0)">
              so Let's have a quick introduction.
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:00:38,765'); seek(38.0)">
              My name is Saurav.
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:00:40,255'); seek(40.0)">
              I'm currently doing in the I'm currently working as a resource
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:00:43,645'); seek(43.0)">
              engineer at NSE Corporation.
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:00:45,745'); seek(45.0)">
              So I have been associated with NSE over the last 11 years where
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:00:49,395'); seek(49.0)">
              I'm doing different work in the field of high performance
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:00:52,785'); seek(52.0)">
              computing, distributed processing, AI machine learning and desktop.
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:00:57,115'); seek(57.0)">
              So we have a long history of working with the vector supercomputer.
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:01,290'); seek(61.0)">
              where we start with S6 series of supercomputers and, work with various
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:06,920'); seek(66.0)">
              legacy applications from tsunami prediction to earthquake simulations
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:11,570'); seek(71.0)">
              on this vector architecture.
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:13,070'); seek(73.0)">
              my leader at my team, Stacy Sarkar, first thought that we including our expertise in
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:20,490'); seek(80.0)">
              the field of HPC and the compiler and this kind of distributed processing related
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:24,650'); seek(84.0)">
              tasks, How about creating something that will use the compiler technology
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:28,585'); seek(88.0)">
              because we have a keen interest in compiler And at the same time do something
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:32,735'); seek(92.0)">
              with the python for the data science community So that is the time when you
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:01:36,415'); seek(96.0)">
              thought okay data scientist often face challenges With the pandas computation.
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:01:40,875'); seek(100.0)">
              So let's create some library That will look completely same as pandas But
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:01:46,795'); seek(106.0)">
              internally it will have a compiler and do a lot of magic kind of stuff
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:01:51,470'); seek(111.0)">
              Such that a programmer, a pandas programmer can experience much faster,
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:01:57,070'); seek(117.0)">
              data processing when using firetrucks.
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:01:59,345'); seek(119.0)">
              So please stay with me till the end of this presentation where I'll be talking
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:04,025'); seek(124.0)">
              about various best practices I will give you walkthrough with the finders the
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:09,235'); seek(129.0)">
              offering the motivation the Comparison with other data frame libraries that is
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:13,655'); seek(133.0)">
              available and of course the end of the end I'll have some frequently asked questions
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:18,565'); seek(138.0)">
              because this is something online.
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:20,225'); seek(140.0)">
              So and Of course if you have any questions, you can get in touch with
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:24,865'); seek(144.0)">
              me over the linkedin or other social media i'll be happy to collaborate
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:28,995'); seek(148.0)">
              and help you in whatever matter I can.
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:31,345'); seek(151.0)">
              Yes So this is the flow.
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:34,605'); seek(154.0)">
              I believe all of you can relate what we do as a data scientist, we
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:02:39,415'); seek(159.0)">
              collect data from various resources and the data in the raw format is
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:02:43,775'); seek(163.0)">
              not resilient digestible by the AI algorithm, AI machine learning algorithm.
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:02:47,425'); seek(167.0)">
              So what we do is we clean the data, make it more meaningful so that we
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:02:51,705'); seek(171.0)">
              can get a better features out of it and we can do a better model.
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:02:55,335'); seek(175.0)">
              So better the data is the better the model.
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:02:57,235'); seek(177.0)">
              That is some kind of old story that we have been learned about.
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:00,525'); seek(180.0)">
              But the important thing for this entire cycle to understand that, although
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:05,155'); seek(185.0)">
              AI machine learning is taking time and deploying model is also taking
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:09,165'); seek(189.0)">
              time, but the most time consuming part is the creation of the data as
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:13,095'); seek(193.0)">
              per the research from the anaconda.
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:14,945'); seek(194.0)">
              It says that the data loading, cleaning, and the visualization is something
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:18,385'); seek(198.0)">
              that occupies almost 75 percent of the effort of a data scientist.
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:22,025'); seek(202.0)">
              So if you have a lot of questions in mind, if you want to extract a lot of
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:25,505'); seek(205.0)">
              many features, You need to spend a lot of time in during the first a few months.
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:30,740'); seek(210.0)">
              I would say for doing the efficient data exploration So that is why
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:36,120'); seek(216.0)">
              various researches has been happening in this field Because this is one of
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:03:40,940'); seek(220.0)">
              the most important areas where we need optimization Now with these ladies,
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:03:45,720'); seek(225.0)">
              let me have something about pandas.
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:03:47,759'); seek(227.0)">
              I believe all of you are from the data science background So
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:03:50,669'); seek(230.0)">
              you must have Work with pandas.
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:03:53,399'); seek(233.0)">
              So it is one of the most popular libraries even today It is having the
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:03:57,099'); seek(237.0)">
              second most download after numpy But it comes with some kind of problems.
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:02,929'); seek(242.0)">
              The very common one is it's not multi threaded So if you have a good
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:07,329'); seek(247.0)">
              system with many core available, you cannot be able to leverage
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:10,839'); seek(250.0)">
              that so Your program will be slow.
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:13,469'); seek(253.0)">
              You have to wait for a longer time to get your result if you are working
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:16,739'); seek(256.0)">
              with large data So So longer waiting times, slow execution, if you're running
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:21,424'); seek(261.0)">
              this on the cloud side, a higher cloud cost, and of course, longer execution
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:26,054'); seek(266.0)">
              will activate a lot of carbon dioxide.
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:28,144'); seek(268.0)">
              So these is, these are something that is associated with bundles.
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:32,214'); seek(272.0)">
              So it is ideally not ideal for the large scale.
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:04:35,514'); seek(275.0)">
              scale exhibition, right?
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:04:37,534'); seek(277.0)">
              So now Although these are the challenges related with pandas But the key challenge
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:04:42,744'); seek(282.0)">
              is like there are various way of writing the same programming pandas So if we
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:04:48,784'); seek(288.0)">
              ourselves can identify the best approaches the best practices and take care of that
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:04:53,544'); seek(293.0)">
              when writing our program It's fine enough because by default pandas doesn't offer
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:04:58,384'); seek(298.0)">
              you optimization as it is eager in nature so whatever you Ask it to do it will do it
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:03,864'); seek(303.0)">
              for you So if you have written a good code unoptimized one yet, you are at good stage
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:10,004'); seek(310.0)">
              But if your program has performance issue You may need to pay a lot of performance
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:14,094'); seek(314.0)">
              cost when your data goes in size or your program goes in complexity So we're
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:19,084'); seek(319.0)">
              talking about some crucial performance issue that involves in a pandas program
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:22,964'); seek(322.0)">
              and how to take care of that And what are the automation possibility for those
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:28,524'); seek(328.0)">
              cases using fireducks and other library?
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:31,174'); seek(331.0)">
              So to going forward let us understand one by one the best practices and
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:36,214'); seek(336.0)">
              challenges associated with data large scale data analysis program So
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:41,124'); seek(341.0)">
              with that let us have a first quiz.
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:05:43,474'); seek(343.0)">
              can you identify?
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:05:45,294'); seek(345.0)">
              Which one is a better code whether the left one or the right one?
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:05:50,024'); seek(350.0)">
              yeah since i'm doing this online, so definitely cannot take the response
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:05:53,894'); seek(353.0)">
              from you But when I asked this kind of question in one of the event last time,
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:05:58,754'); seek(358.0)">
              so I believe I had Mostly around 90 percent of them answered the rightmost
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:06:04,524'); seek(364.0)">
              one is the best performing query Because of many reasons so as you can see this
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:09,894'); seek(369.0)">
              is written in chain and that is ideally the best way of writing This kind of
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:15,264'); seek(375.0)">
              query in pandas or pandas like library.
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:17,464'); seek(377.0)">
              Why Let's have let's understand that with some kind of Illustration.
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:22,834'); seek(382.0)">
              So let's say this is the data that I have loaded from file Of course, you can see
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:27,134'); seek(387.0)">
              there are some duplicates once I remove the duplicate This will be the data my
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:30,534'); seek(390.0)">
              data might be reduced to its half Then I will shorting the result by b column
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:34,804'); seek(394.0)">
              selecting, the top two of the result and that's it Now, let's assume some kind of
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:39,834'); seek(399.0)">
              memory footprint associated with the data.
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:06:41,954'); seek(401.0)">
              Let's say my data is 16 gb You After the removing duplicate it will be
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:06:46,054'); seek(406.0)">
              8gb, 8gb and some other gb, so at the end of the thing it will be 32gb.
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:06:51,599'); seek(411.0)">
              But till the time the foo is alive all these references like df2 t3 are
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:06:56,729'); seek(416.0)">
              alive because pandas not pandas python cannot Make them ready for the garbage
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:07:02,799'); seek(422.0)">
              collection because they have the reference alive in them alive, right?
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:07:06,599'); seek(426.0)">
              So that is the challenge with not writing zend expression what happens
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:07:10,689'); seek(430.0)">
              when you go for the zend expression It will be like, the data is loaded.
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:07:15,619'); seek(435.0)">
              We remove the duplicates But now when we'll be applying the shorting at that
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:07:20,584'); seek(440.0)">
              moment, I only need the input from the drop duplicate side So I don't need
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:25,954'); seek(445.0)">
              this data anymore So this data will be out of reference and python can make it
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:31,834'); seek(451.0)">
              garbage collected based on It's neat.
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:34,564'); seek(454.0)">
              So the same way when I will perform the top two, I don't need the
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:38,374'); seek(458.0)">
              duplicated result drop duplicates result I only need the shorter result.
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:42,154'); seek(462.0)">
              So this way at the end of my program I can remove the intermediate data that
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:47,044'); seek(467.0)">
              is there that is generated during my query of the long expression So and that
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:07:52,764'); seek(472.0)">
              is definitely going to help you when you'll be dealing with large scale data.
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:07:55,984'); seek(475.0)">
              I'll be showing this kind of thing with example in my upcoming slides.
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:07:59,854'); seek(479.0)">
              So that is one of the best practices that write your expression in chained
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:08:04,304'); seek(484.0)">
              expression and it is possible in pandas, of course it's possible.
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:08:08,844'); seek(488.0)">
              So as much as possible try to go for the chained expression such
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:08:12,874'); seek(492.0)">
              that you can avoid this kind of memory and performance issues.
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:08:16,334'); seek(496.0)">
              Now let's consider the second one.
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:08:18,494'); seek(498.0)">
              So here is a quiz.
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:08:19,924'); seek(499.0)">
              Where it is trying to solve the same problem it is trying to find the
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:08:23,494'); seek(503.0)">
              top five of a value based on the shorting from the b column, right?
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:29,394'); seek(509.0)">
              Now, can you guess which one is a better code if you give the if you're
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:33,974'); seek(513.0)">
              about to write the code whether you'll go for the top one or you'll go for
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:37,504'); seek(517.0)">
              the bottom one yeah, so when I asked this kind of question in a recent
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:42,174'); seek(522.0)">
              event, so almost I have mixed answer So 40 to 50 percent answer that the
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:47,674'); seek(527.0)">
              top one is the good one And 50 to 60 percent answer that the bottom one is
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:08:52,834'); seek(532.0)">
              the good one So with the majority the answer is of course the bottom one.
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:08:58,054'); seek(538.0)">
              So if you yourself, thought it is the bottom one Give a pat on your
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:09:02,804'); seek(542.0)">
              back Now, let's understand why it is.
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:09:05,734'); seek(545.0)">
              So what happens ideally your data may have many columns in relative, right?
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:09:11,479'); seek(551.0)">
              Not only a and b if you are going to perform the shorting on the entire
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:09:16,644'); seek(556.0)">
              data, what will happen, not only the target columns A and B, rest of the
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:09:21,494'); seek(561.0)">
              columns like C to J will get shorted.
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:09:24,119'); seek(564.0)">
              And that will never be used in your final result because you're only interested
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:09:28,299'); seek(568.0)">
              To have the shorted value from the a column after the result is shorted by
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:09:31,789'); seek(571.0)">
              b So the c to g column will get shorted based on the b columns It will occupy the
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:09:37,939'); seek(577.0)">
              memory, but it will no longer be needed.
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:09:40,059'); seek(580.0)">
              So it is waste of competition time and memory So what you can do you can create
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:44,659'); seek(584.0)">
              a view of the data of my interest that i'm interested in a and b column only So
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:49,179'); seek(589.0)">
              why not just create a view of that data?
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:09:51,389'); seek(591.0)">
              You Perform the same steps do the same thing and this will definitely
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:09:56,479'); seek(596.0)">
              going to reduce a lot of competition calls because it doesn't matter How
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:09:59,679'); seek(599.0)">
              many column you will data may have?
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:10:01,609'); seek(601.0)">
              Because you also understand.
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:10:02,849'); seek(602.0)">
              I am interested in a and b so let's not bother about rest of the column
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:10:07,519'); seek(607.0)">
              Let's create a view and work on that This kind of optimization is something
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:10:11,449'); seek(611.0)">
              called projection pushdown and it is very important that we should take care when
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:10:15,319'); seek(615.0)">
              dealing with large scale data analysis Now, let's consider another example You
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:10:20,884'); seek(620.0)">
              So before going to the quiz, let me show what it is trying to do For example, I am
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:10:25,949'); seek(625.0)">
              an, I have an employee table in a country table and I want to perform some kind
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:10:29,849'); seek(629.0)">
              of merging to have a larger joint result and see who are the employee, who are the
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:10:35,439'); seek(635.0)">
              male employees from which country, like how many, like country wise count of the
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:10:40,869'); seek(640.0)">
              male employee is something of my problem.
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:10:43,529'); seek(643.0)">
              So how it can be done, one thing that I can just join these two tables.
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:10:48,634'); seek(648.0)">
              Then I can filter all the male category from the result in data and I can
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:10:53,824'); seek(653.0)">
              perform a group by count So by looking at this illustration, can you identify
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:10:59,154'); seek(659.0)">
              what is the performance bottleneck?
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:11:01,344'); seek(661.0)">
              Yes The issue is with the expensive merge operation So although we are
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:11:08,064'); seek(668.0)">
              only interested in the male category employee What we did is we performed the
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:11:13,044'); seek(673.0)">
              merging on the entire employee table.
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:11:15,684'); seek(675.0)">
              We could instead do what?
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:11:17,994'); seek(677.0)">
              We could first filter only the male category from my employee table and
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:11:23,154'); seek(683.0)">
              then we can do the merging operation.
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:11:25,594'); seek(685.0)">
              Followed by the group by count It will do a lot of benefit when you have like
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:11:32,434'); seek(692.0)">
              kind of 50 50 percent of the employee ratio Or you have very less amount of mail
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:11:37,364'); seek(697.0)">
              Like employees because it can reduce your data by to a great extent and the merge
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:11:42,474'); seek(702.0)">
              will not take much time in that case So this is something called predicate push
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:11:47,374'); seek(707.0)">
              down In terms of compiler technology.
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:11:50,559'); seek(710.0)">
              So again, this is one of the very important optimization strategy We
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:11:54,639'); seek(714.0)">
              should ideally take care of that And we'll see with some demo that how
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:11:59,679'); seek(719.0)">
              this kind of strategy is important when dealing with large scale
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:12:02,609'); seek(722.0)">
              data analysis in upcoming slides.
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:12:05,269'); seek(725.0)">
              So now let's put these two in, some kind of, like rule of thumb.
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:12:10,159'); seek(730.0)">
              So again, in order to understand that the importance of such execution
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:12:14,019'); seek(734.0)">
              order, let's take this example where it is trying to perform shorting
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:12:18,459'); seek(738.0)">
              by the E column, do the filtration based on some conditional B column.
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:12:22,619'); seek(742.0)">
              Select the E column and get the top two.
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:12:25,409'); seek(745.0)">
              Now, in order to illustrate that, let's consider this is my data and
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:12:29,639'); seek(749.0)">
              if I short the data with this color code, I will have the shorted result
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:12:34,139'); seek(754.0)">
              from the yellow, red, green, and blue.
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:12:36,259'); seek(756.0)">
              this is my data after I shorted, something like yellow, red, green,
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:12:39,909'); seek(759.0)">
              and blue will be the result.
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:12:41,469'); seek(761.0)">
              Let's consider b equals to 1 for the darker shade and b equals
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:12:44,699'); seek(764.0)">
              to 1, 2 for the lighter shade.
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:12:46,814'); seek(766.0)">
              if I filter, I'll only have the lighter shaded part, then I will select the
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:12:51,336'); seek(771.0)">
              only E column and find the top two.
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:12:54,086'); seek(774.0)">
              Now, if we carefully notice this entire data flow, can you identify
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:13:00,636'); seek(780.0)">
              what is wrong in this journey?
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:13:03,396'); seek(783.0)">
              Of course you can, right?
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:13:05,126'); seek(785.0)">
              you can say that although I am interested in only A, B and E columns.
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:13:11,111'); seek(791.0)">
              I have already involved rest of the columns like c and d that is there
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:13:16,651'); seek(796.0)">
              in my data that have been used But never referenced so that is ideally
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:13:20,961'); seek(800.0)">
              a waste of membrane competition time So instead what we can do is we can
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:13:26,431'); seek(806.0)">
              first identify that for this query.
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:13:28,831'); seek(808.0)">
              I only did a b and e column so why not just create a view of a b e column
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:13:33,851'); seek(813.0)">
              such that we can reduce my scope of the data first in the Horizontal direction
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:13:38,461'); seek(818.0)">
              by applying pushdown projection Okay.
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:13:41,666'); seek(821.0)">
              projection poster.
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:13:43,086'); seek(823.0)">
              Then I can see that, okay, this is my data and, but instead,
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:13:47,796'); seek(827.0)">
              why to short this entire data?
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:13:49,426'); seek(829.0)">
              Because I'm only interested in the lighter shaded part, right?
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:13:53,846'); seek(833.0)">
              So what I can do, I can, for, before going to do shorting, I can reduce the
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:13:58,796'); seek(838.0)">
              data further by applying the filter.
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:14:01,381'); seek(841.0)">
              Once the filtration is done, I can have my further reduced data and this data
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:14:06,171'); seek(846.0)">
              is ready for the shorting because that is ideally part of the data that I'm
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:14:10,011'); seek(850.0)">
              interested to perform the shorting on.
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:14:12,281'); seek(852.0)">
              Now apply the shorting, find the E column and find the top two.
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:14:16,141'); seek(856.0)">
              This is the way by applying kind of projection pushdown You can ideally
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:14:21,721'); seek(861.0)">
              optimize the data flow and this is a very important execution order.
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:14:26,461'); seek(866.0)">
              Following that in your large scale data analysis, you can
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:14:29,211'); seek(869.0)">
              definitely make sure a lot of it.
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:14:32,561'); seek(872.0)">
              Benefit from the execution time and the memory.
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:14:35,011'); seek(875.0)">
              So we'll understand this with some Demo with some example real example in upcoming
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:14:40,311'); seek(880.0)">
              slides Now with that, let's understand what fire ducks is and why to explore this
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:14:47,081'); seek(887.0)">
              library So the first thing, the fireducks is a DataFrame library, high performance
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:14:52,461'); seek(892.0)">
              compiler accelerated DataFrame library.
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:14:55,101'); seek(895.0)">
              why it is called so?
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:14:56,601'); seek(896.0)">
              Basically, the ducks is, it's just a name of the animal because all the DataFrame
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:15:00,591'); seek(900.0)">
              libraries, they're like the pandas, boulders, they are named after an animal.
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:15:04,521'); seek(904.0)">
              So we just thought of, first of all, we thought of DAX.
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:15:07,731'); seek(907.0)">
              Some data frame accelerator, but dx is already a name that time.
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:15:11,511'); seek(911.0)">
              So we thought of naming it as a ducks So it doesn't have any link with the
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:15:15,511'); seek(915.0)">
              duck db for information But the fire has a meaning fire is from the flexible
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:15:20,921'); seek(920.0)">
              ir engine What is ir is something called intermediary representation.
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:15:25,191'); seek(925.0)">
              That is the backbone of the fire dogs jit compilation So what fire does do is?
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:15:31,656'); seek(931.0)">
              It's lazy execution not like pandas like you ask and it do instead you ask and
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:15:37,106'); seek(937.0)">
              it creates some instruction for example you ask it to do shorting instead of
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:15:41,246'); seek(941.0)">
              shorting it will just create okay you ask me to do short on this data on this
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:15:45,916'); seek(945.0)">
              column perfect then you ask it to do please filter based on this condition
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:15:50,546'); seek(950.0)">
              it will just create an instruction Without any calculation or, like
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:15:54,731'); seek(954.0)">
              computations, just create an instruction followed by a projection instruction
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:15:58,641'); seek(958.0)">
              and followed by a slicing instruction.
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:16:00,751'); seek(960.0)">
              Just some instruction will be generated.
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:16:02,631'); seek(962.0)">
              So if you measure the execution time for this part, you will see that it's
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:16:05,921'); seek(965.0)">
              executed blink of the eyes because it does nothing in, but creating the instruction.
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:16:11,451'); seek(971.0)">
              Now you can tell me like when this instruction will be executed.
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:16:15,561'); seek(975.0)">
              these are the instruction that will be automatically triggered by
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:16:19,221'); seek(979.0)">
              some of your action on the result.
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:16:21,181'); seek(981.0)">
              For example, when you want the result to be printed, when you want the
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:16:25,271'); seek(985.0)">
              result to be dumped in a file by two csv2 parquet kind of operation, when
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:16:30,241'); seek(990.0)">
              you apply some kind of aggregation on this result, for example, finding some
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:16:34,021'); seek(994.0)">
              maximum minimum value or something.
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:16:36,151'); seek(996.0)">
              So that is the time by when these kind of expression will be automatically
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:16:40,531'); seek(1000.0)">
              triggered and it will be executed.
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:16:42,521'); seek(1002.0)">
              With some compilation related optimization now, let's say like I want to print
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:16:47,081'); seek(1007.0)">
              the result So that is the time the compiler will be activated and it
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:16:51,511'); seek(1011.0)">
              will try to figure out the instruction associated with the result And what are
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:16:55,821'); seek(1015.0)">
              the instruction it will say that okay.
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:16:57,561'); seek(1017.0)">
              I want to find the top two based on e column So it based on the
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:17:02,701'); seek(1022.0)">
              filtration b column based on the shorting on the a column This
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:17:07,156'); seek(1027.0)">
              is how the compiler understand.
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:17:09,266'); seek(1029.0)">
              Okay, I have this data, but I'm only interested in a b and e column So it will
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:17:15,206'); seek(1035.0)">
              add a new instruction To project only the target columns of a b and e before
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:17:20,976'); seek(1040.0)">
              doing the further operation Such that it can reduce the data in the horizontal
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:17:24,516'); seek(1044.0)">
              iteration first Then it will figure okay.
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:17:27,726'); seek(1047.0)">
              You want to do short then you want to do filter That means you're only
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:17:31,186'); seek(1051.0)">
              interested to perform shorting on a selective set of rows it can do some
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:17:35,496'); seek(1055.0)">
              interchanges of the instruction.
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:17:37,536'); seek(1057.0)">
              It can do the filter first, then it can do the short and rest of
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:17:41,116'); seek(1061.0)">
              the operation will remain as it is.
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:17:42,936'); seek(1062.0)">
              This way the compiler will optimize the generated IR.
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:17:46,866'); seek(1066.0)">
              Once the optimized IR is generated, it can be translated to another pandas version.
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:17:51,506'); seek(1071.0)">
              For example, if you consider it's a pandas program, it can be something like.
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:17:55,176'); seek(1075.0)">
              Project a b e filter based on this condition perform the shorting
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:17:59,466'); seek(1079.0)">
              project the column and take the top two Now this can be a pandas program.
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:18:04,286'); seek(1084.0)">
              This can be a c Api call this can be any other library call of your interest
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:18:09,586'); seek(1089.0)">
              because this ir is quite flexible It can be translated to any other data
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:18:13,586'); seek(1093.0)">
              frame library or any other method call for your reference I just ported it
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:18:17,926'); seek(1097.0)">
              to pandas to understand it better.
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:18:19,616'); seek(1099.0)">
              So that is why write one query You Use this design and it can execute
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:18:25,076'); seek(1105.0)">
              anywhere of your target choice So we have developed this multi core kernel
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:18:29,556'); seek(1109.0)">
              in c where we use the multi threaded and other high performance related stuff
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:18:33,966'); seek(1113.0)">
              like effective utilization of the caches the vectorization and other related
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:18:38,476'); seek(1118.0)">
              stuff such that not only, the results, but also it can do much faster when
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:18:43,811'); seek(1123.0)">
              just comparing the kernel operations, like the only filter, only join, only
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:18:48,501'); seek(1128.0)">
              group by itself will be faster because of the careful optimization, careful
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:18:52,131'); seek(1132.0)">
              implementation of the algorithm.
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:18:54,031'); seek(1134.0)">
              So again, I'll be talking about these in details in the benchmarking slides.
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:18:58,201'); seek(1138.0)">
              So now why you should be understanding or you should be interested in exploring
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:19:02,761'); seek(1142.0)">
              this library because the first thing Pandas doesn't offer you optimization, but
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:19:07,501'); seek(1147.0)">
              firetax is lazy So because of the lazy it can do just in time optimization for you
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:19:12,731'); seek(1152.0)">
              If you have a good system with multiple core available it can distribute it can
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:19:17,254'); seek(1157.0)">
              parallelize the workload not distribute parallelize the workload among the
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:19:20,924'); seek(1160.0)">
              multiple threads So that will result much faster data analysis If you work in the
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:19:26,864'); seek(1166.0)">
              cloud you will experience less cloud, cost and of course, it will run much faster So
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:19:31,734'); seek(1171.0)">
              it will attribute to less carbon dioxide, but the most important thing is if pandas,
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:19:36,754'); seek(1176.0)">
              that's fine You don't need to understand.
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:19:38,864'); seek(1178.0)">
              You don't need to learn a new library new data frame library So when the
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:19:42,694'); seek(1182.0)">
              technology like ai and these kind of llm things is progressing so far
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:19:46,744'); seek(1186.0)">
              It's better to learn a new technology than to learn a new library, right?
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:19:50,619'); seek(1190.0)">
              So just you know pandas because we all of us usually start from pandas So
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:19:55,249'); seek(1195.0)">
              knowing pandas is sufficient, but the challenges associated with pandas can
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:19:58,849'); seek(1198.0)">
              be addressed by firedesk automatically Now the question is does it handle
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:20:02,969'); seek(1202.0)">
              any kind of pandas application?
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:20:04,619'); seek(1204.0)">
              Yes, it does handle any kind of pandas application not only pandas application
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:20:09,249'); seek(1209.0)">
              but also the library that expect you to provide the pandas data for example
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:20:13,489'); seek(1213.0)">
              seaborn matplotlib, scikit learn, imbalance learn, category encoders all
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:20:18,329'); seek(1218.0)">
              the library that expect the you to input the pandas data frame You can provide
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:20:21,989'); seek(1221.0)">
              a firedash data frame and it can work seamlessly with those as well So no extra
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:20:26,299'); seek(1226.0)">
              learning no code modification You can experience much better performance benefit
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:20:30,709'); seek(1230.0)">
              when switching from pandas to firetax.
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:20:33,019'); seek(1233.0)">
              Now, let's understand some kind of demo with this.
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:20:36,799'); seek(1236.0)">
              So here in this example, I am using some kind of Bitcoin data of the
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:20:41,659'); seek(1241.0)">
              last three to five years and it is trying to perform some moving average.
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:20:45,919'); seek(1245.0)">
              Just load the data creating a window and perform the average, perform the mean
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:20:50,089'); seek(1250.0)">
              average calculation and plot the result.
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:20:52,544'); seek(1252.0)">
              So the code is same in both the left and right side.
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:20:55,244'); seek(1255.0)">
              The only difference is in the import So left side is important pandas and
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:20:58,874'); seek(1258.0)">
              the right side is importing firedex.
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:21:00,504'); seek(1260.0)">
              pandas.
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:21:00,784'); seek(1260.0)">
              That is the only change But if you see in the execution time, you can
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:21:04,454'); seek(1264.0)">
              see that pandas takes around 4.
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:21:06,535'); seek(1266.0)">
              06 whereas firedex can complete it Within 275 milliseconds.
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:21:10,144'); seek(1270.0)">
              So this simple code No modification you can experience 15 times build up.
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:21:15,419'); seek(1275.0)">
              So that is some kind of quick demo I'll be talking about another demo
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:21:18,959'); seek(1278.0)">
              another thing in upcoming slides for sure Okay, so with that let me
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:21:23,789'); seek(1283.0)">
              explain you the usage of firedug.
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:21:26,089'); seek(1286.0)">
              So first of all Firedux is currently available for Linux only, so if
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:21:30,439'); seek(1290.0)">
              you're from the Windows or Mac users, so at this moment, probably
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:21:34,419'); seek(1294.0)">
              you can consider using Google Colab or the platform that support Linux.
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:21:37,548'); seek(1297.0)">
              For Windows, definitely you can try WSL because it can work with WSL.
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:21:41,779'); seek(1301.0)">
              And the supported Pythons are from 3.
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:21:44,940'); seek(1304.0)">
              9 to 3.
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:21:45,247'); seek(1305.0)">
              12. So if you can satisfy these two conditions, you can install it using pip
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:21:49,929'); seek(1309.0)">
              and you can use instead of import pandas, import firedux pandas and that will
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:21:54,379'); seek(1314.0)">
              be sufficient to execute your existing program using firedux and optimize it.
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:21:59,779'); seek(1319.0)">
              Now, how about zero code modification?
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:22:02,749'); seek(1322.0)">
              if you are using program that is you importing pandas and it is importing
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:22:07,679'); seek(1327.0)">
              other modules All those module might in turn importing pandas as well.
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:22:12,369'); seek(1332.0)">
              So do you need to replace all this import by yourself?
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:22:15,309'); seek(1335.0)">
              No There is monkey passing thing.
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:22:18,154'); seek(1338.0)">
              So when executing the program using the python command, just pass hyphen
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:22:22,444'); seek(1342.0)">
              option followed by firetus pandas.
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:22:24,514'); seek(1344.0)">
              It can automatically replace all the pandas with firetus pandas.
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:22:28,444'); seek(1348.0)">
              And it can do the optimization for you without any code modification.
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:22:32,564'); seek(1352.0)">
              For notebook like platform, the same thing, your rest
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:22:35,604'); seek(1355.0)">
              of the notebook can be same.
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:22:37,024'); seek(1357.0)">
              Just on top of import pandas, you can add this extension module.
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:22:40,789'); seek(1360.0)">
              And it can automatically replace the pandas with fireducks pandas and you
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:22:44,469'); seek(1364.0)">
              can experience the benefit out of it So now let's understand, what is the
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:22:48,399'); seek(1368.0)">
              challenge with seamless integration with pandas like, Of course wire ducks
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:22:52,159'); seek(1372.0)">
              is something that i'm talking about But there are other high performance pandas
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:22:55,609'); seek(1375.0)">
              alternatives as well, right like duckdb, polars, dusk These are the library that
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:23:00,269'); seek(1380.0)">
              try to achieve the same kind of problem like because pandas is slow So they
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:23:04,159'); seek(1384.0)">
              have their own version of optimization that can address the slow performance
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:23:08,514'); seek(1388.0)">
              of pandas But the major challenge comes with the compatibility with pandas
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:23:13,129'); seek(1393.0)">
              like, if you want to use those library you have to learn that library first if
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:23:18,229'); seek(1398.0)">
              because Either they are not compatible or they are not fully compatible.
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:23:23,269'); seek(1403.0)">
              So you need to understand the library first and sometime it
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:23:26,829'); seek(1406.0)">
              may happen that pandas because pandas is full of features, right?
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:23:31,634'); seek(1411.0)">
              But those library might not offer that feature.
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:23:33,804'); seek(1413.0)">
              So you need to convert, the library to pandas using from
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:23:37,264'); seek(1417.0)">
              pandas into pandas mechanism.
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:23:39,234'); seek(1419.0)">
              And, when, comparing the result in the performance, once your complete program
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:23:43,474'); seek(1423.0)">
              can be migrated, you can compare the performances, or taste the results.
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:23:47,054'); seek(1427.0)">
              So that are the challenges associated with it.
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:23:49,084'); seek(1429.0)">
              So whether you want to take that effort, For that cost optimization.
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:23:54,074'); seek(1434.0)">
              So there is always a cost performance thing in your mind so yeah, you have
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:23:58,484'); seek(1438.0)">
              options like modern does vex, but they are ideally for the multi Node
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:24:03,874'); seek(1443.0)">
              environment there is something called polars that is for the single node
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:24:07,164'); seek(1447.0)">
              environment that is super fast But it is not much compatible with pandas.
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:24:11,664'); seek(1451.0)">
              So if you want to use folders probably you need to understand the library
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:24:14,394'); seek(1454.0)">
              in the very first place that is where fireducks can help you like being it
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:24:19,224'); seek(1459.0)">
              highly compatible with pandas No code modification, no node learning associated
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:24:23,384'); seek(1463.0)">
              with it And you can experience the single node speed up If you're working
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:24:27,724'); seek(1467.0)">
              on the data and that can be fit into memory, you can work with firetrucks.
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:24:32,384'); seek(1472.0)">
              Of course, it provides optimization.
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:24:34,354'); seek(1474.0)">
              it may happen that although you have a bigger data, but you're not
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:24:37,784'); seek(1477.0)">
              interested in every part of the data.
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:24:39,504'); seek(1479.0)">
              it can do the optimization for you and it can just selectively load the
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:24:43,154'); seek(1483.0)">
              target columns and rows so that it can do a lot of justice with your,
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:24:47,504'); seek(1487.0)">
              like limited set of resources, the memory and the number of cores.
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:24:51,729'); seek(1491.0)">
              let's see like how seamless integration is possible with pandas.
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:24:55,749'); seek(1495.0)">
              For example, this is a demo notebook.
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:24:57,619'); seek(1497.0)">
              You can consider the actual notebook from this link.
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:25:00,449'); seek(1500.0)">
              But let's understand what it's trying to do.
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:25:02,939'); seek(1502.0)">
              It is trying to load parquet data from InnoIC parking violation.
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:25:07,304'); seek(1507.0)">
              After the data loading is done, it is trying to, perform a query where it is
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:25:11,324'); seek(1511.0)">
              trying to see, which parking violation is the most commonly committed by
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:25:14,764'); seek(1514.0)">
              vehicles from various United States.
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:25:18,124'); seek(1518.0)">
              because of, in order to execute the query, it does some group by
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:25:21,034'); seek(1521.0)">
              head and shorting kind of stuff.
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:25:22,829'); seek(1522.0)">
              So the basic code is entirely written in pandas.
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:25:26,379'); seek(1526.0)">
              So there is nothing that you can identify new So everything is written in pandas.
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:25:30,899'); seek(1530.0)">
              Now simply I executed the same program using python followed by
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:25:34,519'); seek(1534.0)">
              the program name So you can see that the data loading take around 2.
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:25:39,819'); seek(1539.0)">
              4 and the query one takes around 2.
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:25:40,879'); seek(1540.0)">
              8 seconds Overall, it takes around 5.
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:25:43,199'); seek(1543.0)">
              3 seconds But in order to execute the same program with fire dogs, no code change
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:25:49,169'); seek(1549.0)">
              just add hyphenium fire dust and pandas And it can be done much faster like almost
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:25:55,334'); seek(1555.0)">
              eight times can eight times faster but the data loading as well as the query
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:25:59,494'); seek(1559.0)">
              processing can be done much faster when we're switching to Pandas to firetrucks
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:26:03,764'); seek(1563.0)">
              just by adding a program option.
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:26:05,684'); seek(1565.0)">
              Nothing else.
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:26:06,724'); seek(1566.0)">
              So that is how it is very like Easy to integrate once you download it.
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:26:11,324'); seek(1571.0)">
              It can be integrated to any pandas application and you can experience
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:26:14,544'); seek(1574.0)">
              this better So definitely you can try the notebook for Further exploration
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:26:20,174'); seek(1580.0)">
              So now let's consider the optimizing features that is available in FireDogs.
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:26:24,514'); seek(1584.0)">
              So this is the design of FireDogs like It looks like a pandas program because we
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:26:30,594'); seek(1590.0)">
              mock all the api that is written All the user interface in a pandas like interface
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:26:36,404'); seek(1596.0)">
              But down the line everything is written in c once the instruction is optimized
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:26:40,454'); seek(1600.0)">
              by the compiler So what happens is pandas is like you write the program and it
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:26:44,594'); seek(1604.0)">
              execute it right after you click But in case of Firedux, as I explained that it
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:26:49,814'); seek(1609.0)">
              will create some kind of instructions and those instructions will be optimized by
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:26:54,454'); seek(1614.0)">
              the compiler and the optimized instruction will be converted by a system call and
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:26:59,324'); seek(1619.0)">
              then it will be executed by the multiple code that is available in your system.
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:27:03,094'); seek(1623.0)">
              So all the available code in your system will be effectively used.
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:27:06,764'); seek(1626.0)">
              the system cache will be effectively used, the vectorization
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:27:09,504'); seek(1629.0)">
              will be effectively used.
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:27:10,734'); seek(1630.0)">
              So because of this you can experience much faster speedup when using firetux.
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:27:15,114'); seek(1635.0)">
              So now what is the offering from these two layers?
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:27:17,234'); seek(1637.0)">
              So first of all there is a compiler, so definitely you can expect compiler
            </span>
            
            <span id="chunk-417" class="transcript-chunks" onclick="console.log('00:27:20,594'); seek(1640.0)">
              specific optimization like common sub expression elimination, date
            </span>
            
            <span id="chunk-418" class="transcript-chunks" onclick="console.log('00:27:24,434'); seek(1644.0)">
              code elimination kind of stuff.
            </span>
            
            <span id="chunk-419" class="transcript-chunks" onclick="console.log('00:27:26,364'); seek(1646.0)">
              So you can expect domain specific optimization like get
            </span>
            
            <span id="chunk-420" class="transcript-chunks" onclick="console.log('00:27:30,049'); seek(1650.0)">
              pushed down a projection post on that I talked about so far.
            </span>
            
            <span id="chunk-421" class="transcript-chunks" onclick="console.log('00:27:33,519'); seek(1653.0)">
              You can expect some pandas specific tuning here as well.
            </span>
            
            <span id="chunk-422" class="transcript-chunks" onclick="console.log('00:27:36,719'); seek(1656.0)">
              So I'll be talking about it in upcoming slides.
            </span>
            
            <span id="chunk-423" class="transcript-chunks" onclick="console.log('00:27:39,249'); seek(1659.0)">
              Now, what about the second most layer that is the backend?
            </span>
            
            <span id="chunk-424" class="transcript-chunks" onclick="console.log('00:27:42,649'); seek(1662.0)">
              The backend is multithreaded first of all.
            </span>
            
            <span id="chunk-425" class="transcript-chunks" onclick="console.log('00:27:44,759'); seek(1664.0)">
              So If you have a very good, system with multiple threads available, you can
            </span>
            
            <span id="chunk-426" class="transcript-chunks" onclick="console.log('00:27:49,214'); seek(1669.0)">
              experience much, throughput out of that.
            </span>
            
            <span id="chunk-427" class="transcript-chunks" onclick="console.log('00:27:51,854'); seek(1671.0)">
              The, it can take good, use of the memory because it is backed
            </span>
            
            <span id="chunk-428" class="transcript-chunks" onclick="console.log('00:27:55,164'); seek(1675.0)">
              by Apache Parallel Memory.
            </span>
            
            <span id="chunk-429" class="transcript-chunks" onclick="console.log('00:27:56,664'); seek(1676.0)">
              The major data structure is backed by Apache Arrow, so you can have Compact
            </span>
            
            <span id="chunk-430" class="transcript-chunks" onclick="console.log('00:28:00,339'); seek(1680.0)">
              usage of the memory as well and all the kernels like join, group by filter,
            </span>
            
            <span id="chunk-431" class="transcript-chunks" onclick="console.log('00:28:04,849'); seek(1684.0)">
              drop in, everything is written from scratch by our own patented algorithms.
            </span>
            
            <span id="chunk-432" class="transcript-chunks" onclick="console.log('00:28:09,179'); seek(1689.0)">
              So this kernel operation itself is much faster when comparing to pandas or other
            </span>
            
            <span id="chunk-433" class="transcript-chunks" onclick="console.log('00:28:13,909'); seek(1693.0)">
              high performance pandas alternatives.
            </span>
            
            <span id="chunk-434" class="transcript-chunks" onclick="console.log('00:28:16,329'); seek(1696.0)">
              We'll be experiencing it in upcoming slide for sure.
            </span>
            
            <span id="chunk-435" class="transcript-chunks" onclick="console.log('00:28:19,049'); seek(1699.0)">
              So yes, so let's understand what is compiler specific optimization.
            </span>
            
            <span id="chunk-436" class="transcript-chunks" onclick="console.log('00:28:22,949'); seek(1702.0)">
              I took this example from one of the Kaggle notebook that I recently noticed like you
            </span>
            
            <span id="chunk-437" class="transcript-chunks" onclick="console.log('00:28:27,149'); seek(1707.0)">
              can see that here df time is a column of string type So since it is string type
            </span>
            
            <span id="chunk-438" class="transcript-chunks" onclick="console.log('00:28:33,649'); seek(1713.0)">
              and the pop the person wants to perform some group by based on the year and
            </span>
            
            <span id="chunk-439" class="transcript-chunks" onclick="console.log('00:28:37,539'); seek(1717.0)">
              month he wants to find the average sales.
            </span>
            
            <span id="chunk-440" class="transcript-chunks" onclick="console.log('00:28:39,959'); seek(1719.0)">
              So what he does it he performed the string column to date time In order to extract
            </span>
            
            <span id="chunk-441" class="transcript-chunks" onclick="console.log('00:28:44,749'); seek(1724.0)">
              the year field and the month field And do the stuff but as you can understand the
            </span>
            
            <span id="chunk-442" class="transcript-chunks" onclick="console.log('00:28:49,799'); seek(1729.0)">
              two data itself is a complex operation because you try to parse a string to
            </span>
            
            <span id="chunk-443" class="transcript-chunks" onclick="console.log('00:28:53,839'); seek(1733.0)">
              Convert it to datetime So if you do the same operation the same data more
            </span>
            
            <span id="chunk-444" class="transcript-chunks" onclick="console.log('00:28:58,439'); seek(1738.0)">
              than once it is going to cost you when your data is putting in size So ideally
            </span>
            
            <span id="chunk-445" class="transcript-chunks" onclick="console.log('00:29:04,429'); seek(1744.0)">
              what is better is You can just compute it once put it in some placeholder and
            </span>
            
            <span id="chunk-446" class="transcript-chunks" onclick="console.log('00:29:08,714'); seek(1748.0)">
              use it wherever you need it So this is something a basic programming know how
            </span>
            
            <span id="chunk-447" class="transcript-chunks" onclick="console.log('00:29:13,564'); seek(1753.0)">
              But because find x uses a compiler and the compiler can identify this kind of common
            </span>
            
            <span id="chunk-448" class="transcript-chunks" onclick="console.log('00:29:17,984'); seek(1757.0)">
              expression So well, I already have do it.
            </span>
            
            <span id="chunk-449" class="transcript-chunks" onclick="console.log('00:29:21,104'); seek(1761.0)">
              So so because compiler will create an instruction for that Again, it
            </span>
            
            <span id="chunk-450" class="transcript-chunks" onclick="console.log('00:29:25,574'); seek(1765.0)">
              will create an instruction for this And then it will say, I already
            </span>
            
            <span id="chunk-451" class="transcript-chunks" onclick="console.log('00:29:29,179'); seek(1769.0)">
              have created the instruction.
            </span>
            
            <span id="chunk-452" class="transcript-chunks" onclick="console.log('00:29:30,389'); seek(1770.0)">
              So let me use that.
            </span>
            
            <span id="chunk-453" class="transcript-chunks" onclick="console.log('00:29:32,149'); seek(1772.0)">
              And wherever I, wherever it is referred, instead of creating
            </span>
            
            <span id="chunk-454" class="transcript-chunks" onclick="console.log('00:29:35,449'); seek(1775.0)">
              a new instruction, this kind of optimization possible by FireDogs.
            </span>
            
            <span id="chunk-455" class="transcript-chunks" onclick="console.log('00:29:38,969'); seek(1778.0)">
              So this kind of, CAC, Common Sub Explanatory Elimination
            </span>
            
            <span id="chunk-456" class="transcript-chunks" onclick="console.log('00:29:42,829'); seek(1782.0)">
              Optimization Benefit, you can definitely get from FireDogs.
            </span>
            
            <span id="chunk-457" class="transcript-chunks" onclick="console.log('00:29:46,679'); seek(1786.0)">
              Another thing is something called Dead Code Elimination.
            </span>
            
            <span id="chunk-458" class="transcript-chunks" onclick="console.log('00:29:48,849'); seek(1788.0)">
              So for example, this is a piece of function.
            </span>
            
            <span id="chunk-459" class="transcript-chunks" onclick="console.log('00:29:51,199'); seek(1791.0)">
              So where it is trying to merge x. Table with the y table And after merging it
            </span>
            
            <span id="chunk-460" class="transcript-chunks" onclick="console.log('00:29:57,064'); seek(1797.0)">
              is trying to do the shorting operation after shorting It is doing the group
            </span>
            
            <span id="chunk-461" class="transcript-chunks" onclick="console.log('00:30:01,044'); seek(1801.0)">
              by but the group by using the merged variable not the shorted variable, right?
            </span>
            
            <span id="chunk-462" class="transcript-chunks" onclick="console.log('00:30:06,014'); seek(1806.0)">
              So in the entire function This is the line that is used but have never referenced So
            </span>
            
            <span id="chunk-463" class="transcript-chunks" onclick="console.log('00:30:11,974'); seek(1811.0)">
              when you use pandas like eager execution model, it will be executed because the
            </span>
            
            <span id="chunk-464" class="transcript-chunks" onclick="console.log('00:30:16,334'); seek(1816.0)">
              shorting is you ask it to short, right?
            </span>
            
            <span id="chunk-465" class="transcript-chunks" onclick="console.log('00:30:18,874'); seek(1818.0)">
              But fired us can identify.
            </span>
            
            <span id="chunk-466" class="transcript-chunks" onclick="console.log('00:30:20,354'); seek(1820.0)">
              Okay, you asked me to do That is fine.
            </span>
            
            <span id="chunk-467" class="transcript-chunks" onclick="console.log('00:30:23,134'); seek(1823.0)">
              I create an instruction, but you never used it.
            </span>
            
            <span id="chunk-468" class="transcript-chunks" onclick="console.log('00:30:26,094'); seek(1826.0)">
              So I will not execute the instruction I will eliminate that date code
            </span>
            
            <span id="chunk-469" class="transcript-chunks" onclick="console.log('00:30:29,364'); seek(1829.0)">
              out of my execution, graph, right?
            </span>
            
            <span id="chunk-470" class="transcript-chunks" onclick="console.log('00:30:32,364'); seek(1832.0)">
              So this kind of date code elimination is possible when you switch to firetux,
            </span>
            
            <span id="chunk-471" class="transcript-chunks" onclick="console.log('00:30:36,604'); seek(1836.0)">
              from pandas if you want to explore more, so you can definitely take, read the
            </span>
            
            <span id="chunk-472" class="transcript-chunks" onclick="console.log('00:30:40,684'); seek(1840.0)">
              article that explored about this kind of compiler specific optimization details.
            </span>
            
            <span id="chunk-473" class="transcript-chunks" onclick="console.log('00:30:45,744'); seek(1845.0)">
              yes, now let's talk about some, domain specific optimization that
            </span>
            
            <span id="chunk-474" class="transcript-chunks" onclick="console.log('00:30:49,844'); seek(1849.0)">
              we discussed so far like projection pushdown and predicate pushdown.
            </span>
            
            <span id="chunk-475" class="transcript-chunks" onclick="console.log('00:30:53,354'); seek(1853.0)">
              for that, I have taken one sample query from TPCS benchmark, the query, Q3 10
            </span>
            
            <span id="chunk-476" class="transcript-chunks" onclick="console.log('00:31:00,991'); seek(1860.0)">
              unshipped orders with the highest value.
            </span>
            
            <span id="chunk-477" class="transcript-chunks" onclick="console.log('00:31:03,371'); seek(1863.0)">
              Ideally it was written in SQL.
            </span>
            
            <span id="chunk-478" class="transcript-chunks" onclick="console.log('00:31:05,131'); seek(1865.0)">
              I first let's convert it to pandas and see what it does So if you carefully notice
            </span>
            
            <span id="chunk-479" class="transcript-chunks" onclick="console.log('00:31:09,701'); seek(1869.0)">
              the query It doesn't perform any kind of best practices that we understand like
            </span>
            
            <span id="chunk-480" class="transcript-chunks" onclick="console.log('00:31:14,331'); seek(1874.0)">
              kind of reduction the data in the row direction the column direction It doesn't
            </span>
            
            <span id="chunk-481" class="transcript-chunks" onclick="console.log('00:31:18,071'); seek(1878.0)">
              do anything as such it load the entire data from three tables customer orders
            </span>
            
            <span id="chunk-482" class="transcript-chunks" onclick="console.log('00:31:22,351'); seek(1882.0)">
              and line item After loading the data it can Just join them to create a bigger
            </span>
            
            <span id="chunk-483" class="transcript-chunks" onclick="console.log('00:31:27,636'); seek(1887.0)">
              table such that it can perform Rest of the operation like filtration and group
            </span>
            
            <span id="chunk-484" class="transcript-chunks" onclick="console.log('00:31:32,756'); seek(1892.0)">
              by rest of the stuff as per the demand of the query So when we execute this query
            </span>
            
            <span id="chunk-485" class="transcript-chunks" onclick="console.log('00:31:37,776'); seek(1897.0)">
              using python using pandas, that pandas took around 203 seconds and the memory
            </span>
            
            <span id="chunk-486" class="transcript-chunks" onclick="console.log('00:31:44,461'); seek(1904.0)">
              consumption was around 60 gb for the scale factor 10 but when we execute the same
            </span>
            
            <span id="chunk-487" class="transcript-chunks" onclick="console.log('00:31:50,331'); seek(1910.0)">
              program using fire dogs just by adding this Plug in, it can be finished within 4.
            </span>
            
            <span id="chunk-488" class="transcript-chunks" onclick="console.log('00:31:56,442'); seek(1916.0)">
              24 seconds and the memory consumption was around 3.
            </span>
            
            <span id="chunk-489" class="transcript-chunks" onclick="console.log('00:31:59,081'); seek(1919.0)">
              3 gb Yes, because fire although we have written it without consideration
            </span>
            
            <span id="chunk-490" class="transcript-chunks" onclick="console.log('00:32:04,711'); seek(1924.0)">
              of the optimization Fighters compiler will do it for you.
            </span>
            
            <span id="chunk-491" class="transcript-chunks" onclick="console.log('00:32:08,941'); seek(1928.0)">
              It can figure out All those stuff like the reduction of the data in the horizontal
            </span>
            
            <span id="chunk-492" class="transcript-chunks" onclick="console.log('00:32:13,111'); seek(1933.0)">
              direction and the vertical direction and apply it automatically, because of
            </span>
            
            <span id="chunk-493" class="transcript-chunks" onclick="console.log('00:32:17,831'); seek(1937.0)">
              which you can explain much, much speed up, from this kind of program that
            </span>
            
            <span id="chunk-494" class="transcript-chunks" onclick="console.log('00:32:22,481'); seek(1942.0)">
              doesn't take care of the optimization.
            </span>
            
            <span id="chunk-495" class="transcript-chunks" onclick="console.log('00:32:24,471'); seek(1944.0)">
              In order to understand that, let's manually optimize this program.
            </span>
            
            <span id="chunk-496" class="transcript-chunks" onclick="console.log('00:32:28,046'); seek(1948.0)">
              So what is the best practices?
            </span>
            
            <span id="chunk-497" class="transcript-chunks" onclick="console.log('00:32:31,126'); seek(1951.0)">
              First of all, the practice is to instead of operating on the entire data, reduce
            </span>
            
            <span id="chunk-498" class="transcript-chunks" onclick="console.log('00:32:35,906'); seek(1955.0)">
              the data in the columnar direction, right?
            </span>
            
            <span id="chunk-499" class="transcript-chunks" onclick="console.log('00:32:38,016'); seek(1958.0)">
              In the vertical direction.
            </span>
            
            <span id="chunk-500" class="transcript-chunks" onclick="console.log('00:32:39,666'); seek(1959.0)">
              So by carefully observing the query, you can see that we only need these
            </span>
            
            <span id="chunk-501" class="transcript-chunks" onclick="console.log('00:32:44,346'); seek(1964.0)">
              two columns from the customer table.
            </span>
            
            <span id="chunk-502" class="transcript-chunks" onclick="console.log('00:32:45,956'); seek(1965.0)">
              Although there are eight columns, we only need these
            </span>
            
            <span id="chunk-503" class="transcript-chunks" onclick="console.log('00:32:48,556'); seek(1968.0)">
              four columns from the line item.
            </span>
            
            <span id="chunk-504" class="transcript-chunks" onclick="console.log('00:32:50,016'); seek(1970.0)">
              Although there are 16 columns, we only need these four
            </span>
            
            <span id="chunk-505" class="transcript-chunks" onclick="console.log('00:32:52,226'); seek(1972.0)">
              columns from the order table.
            </span>
            
            <span id="chunk-506" class="transcript-chunks" onclick="console.log('00:32:53,996'); seek(1973.0)">
              Although there are nine columns.
            </span>
            
            <span id="chunk-507" class="transcript-chunks" onclick="console.log('00:32:55,736'); seek(1975.0)">
              So instead of loading the entire data, I will only load these selective columns.
            </span>
            
            <span id="chunk-508" class="transcript-chunks" onclick="console.log('00:33:00,586'); seek(1980.0)">
              Then I only need some particular rows from these tables because
            </span>
            
            <span id="chunk-509" class="transcript-chunks" onclick="console.log('00:33:04,846'); seek(1984.0)">
              of the filter operation.
            </span>
            
            <span id="chunk-510" class="transcript-chunks" onclick="console.log('00:33:06,256'); seek(1986.0)">
              So I will filter all the target table based on the given condition.
            </span>
            
            <span id="chunk-511" class="transcript-chunks" onclick="console.log('00:33:10,556'); seek(1990.0)">
              Then I will just join the tables to the group by an aggregate
            </span>
            
            <span id="chunk-512" class="transcript-chunks" onclick="console.log('00:33:14,346'); seek(1994.0)">
              and the shorting operation.
            </span>
            
            <span id="chunk-513" class="transcript-chunks" onclick="console.log('00:33:15,896'); seek(1995.0)">
              Now when I execute the same optimized query in pandas, it becomes 13 seconds.
            </span>
            
            <span id="chunk-514" class="transcript-chunks" onclick="console.log('00:33:21,230'); seek(2001.0)">
              So 203 seconds can be optimized to 13 seconds with this manual
            </span>
            
            <span id="chunk-515" class="transcript-chunks" onclick="console.log('00:33:25,186'); seek(2005.0)">
              optimization and the memory can also be reduced from 60 GB to 5.
            </span>
            
            <span id="chunk-516" class="transcript-chunks" onclick="console.log('00:33:28,561'); seek(2008.0)">
              5 GB.
            </span>
            
            <span id="chunk-517" class="transcript-chunks" onclick="console.log('00:33:30,381'); seek(2010.0)">
              Even when you use pandas effectively But when you see the fire ducks, even though
            </span>
            
            <span id="chunk-518" class="transcript-chunks" onclick="console.log('00:33:36,601'); seek(2016.0)">
              you try q3 and opt q3 Manual optimization is present or it is absent doesn't matter
            </span>
            
            <span id="chunk-519" class="transcript-chunks" onclick="console.log('00:33:42,901'); seek(2022.0)">
              It can execute with the same speed and with the same memory command Because if
            </span>
            
            <span id="chunk-520" class="transcript-chunks" onclick="console.log('00:33:47,401'); seek(2027.0)">
              you do a panel optimization fair enough when you cannot do it firedust can do
            </span>
            
            <span id="chunk-521" class="transcript-chunks" onclick="console.log('00:33:51,511'); seek(2031.0)">
              it for you So you can rely such optimize rely for such optimization on fire ducks
            </span>
            
            <span id="chunk-522" class="transcript-chunks" onclick="console.log('00:33:57,211'); seek(2037.0)">
              definitely Now let's understand one of the parameter tuning that is possible
            </span>
            
            <span id="chunk-523" class="transcript-chunks" onclick="console.log('00:34:01,581'); seek(2041.0)">
              in FireDogs, not FireDogs actually.
            </span>
            
            <span id="chunk-524" class="transcript-chunks" onclick="console.log('00:34:04,011'); seek(2044.0)">
              First of all, what is the parameter tuning that you can do in Pandas, then
            </span>
            
            <span id="chunk-525" class="transcript-chunks" onclick="console.log('00:34:07,041'); seek(2047.0)">
              how FireDogs can take care of that.
            </span>
            
            <span id="chunk-526" class="transcript-chunks" onclick="console.log('00:34:08,911'); seek(2048.0)">
              So in order to understand that, let's consider that this query where it is
            </span>
            
            <span id="chunk-527" class="transcript-chunks" onclick="console.log('00:34:13,641'); seek(2053.0)">
              trying to perform, Group by on the department column of the employee table
            </span>
            
            <span id="chunk-528" class="transcript-chunks" onclick="console.log('00:34:18,661'); seek(2058.0)">
              followed by that it is calculating the average salary and shorting the Salary
            </span>
            
            <span id="chunk-529" class="transcript-chunks" onclick="console.log('00:34:23,681'); seek(2063.0)">
              based on the descending order, right?
            </span>
            
            <span id="chunk-530" class="transcript-chunks" onclick="console.log('00:34:25,901'); seek(2065.0)">
              So what will happen it will create the group So it group admin group finance
            </span>
            
            <span id="chunk-531" class="transcript-chunks" onclick="console.log('00:34:30,581'); seek(2070.0)">
              group corporate and sales group and it will perform the average of each group So
            </span>
            
            <span id="chunk-532" class="transcript-chunks" onclick="console.log('00:34:34,891'); seek(2074.0)">
              that is ideally the group by operations But there is a hidden cost associated
            </span>
            
            <span id="chunk-533" class="transcript-chunks" onclick="console.log('00:34:40,161'); seek(2080.0)">
              with it You And the cost is the group by is by default has a parameter called
            </span>
            
            <span id="chunk-534" class="transcript-chunks" onclick="console.log('00:34:46,241'); seek(2086.0)">
              short and the value is true But the meaning of the short parameter is It is
            </span>
            
            <span id="chunk-535" class="transcript-chunks" onclick="console.log('00:34:53,631'); seek(2093.0)">
              trying to short the result of the group by based on the key column here The key
            </span>
            
            <span id="chunk-536" class="transcript-chunks" onclick="console.log('00:34:58,161'); seek(2098.0)">
              is the department so it will not only compute the group by aggregation, but
            </span>
            
            <span id="chunk-537" class="transcript-chunks" onclick="console.log('00:35:02,411'); seek(2102.0)">
              also short the result by the key column So admin will come first followed by
            </span>
            
            <span id="chunk-538" class="transcript-chunks" onclick="console.log('00:35:07,311'); seek(2107.0)">
              corporate finance id and sales shorted by the department but In your query,
            </span>
            
            <span id="chunk-539" class="transcript-chunks" onclick="console.log('00:35:13,721'); seek(2113.0)">
              you don't need this shorting to happen.
            </span>
            
            <span id="chunk-540" class="transcript-chunks" onclick="console.log('00:35:15,701'); seek(2115.0)">
              Instead, you want the result to be shorted by the salary with the
            </span>
            
            <span id="chunk-541" class="transcript-chunks" onclick="console.log('00:35:19,271'); seek(2119.0)">
              value column in descending order.
            </span>
            
            <span id="chunk-542" class="transcript-chunks" onclick="console.log('00:35:21,451'); seek(2121.0)">
              So again, because you ask the pandas to do so it will do it.
            </span>
            
            <span id="chunk-543" class="transcript-chunks" onclick="console.log('00:35:25,191'); seek(2125.0)">
              It will short the result by the descending order when it will
            </span>
            
            <span id="chunk-544" class="transcript-chunks" onclick="console.log('00:35:28,861'); seek(2128.0)">
              encounter the short values.
            </span>
            
            <span id="chunk-545" class="transcript-chunks" onclick="console.log('00:35:31,031'); seek(2131.0)">
              what you can expect that this is the step that is taking place because of
            </span>
            
            <span id="chunk-546" class="transcript-chunks" onclick="console.log('00:35:36,341'); seek(2136.0)">
              this default parameter of group by but this is the redundant step it can be
            </span>
            
            <span id="chunk-547" class="transcript-chunks" onclick="console.log('00:35:42,571'); seek(2142.0)">
              avoided, Even if we don't perform this step, it doesn't impact my result.
            </span>
            
            <span id="chunk-548" class="transcript-chunks" onclick="console.log('00:35:46,651'); seek(2146.0)">
              So this is a redundant step.
            </span>
            
            <span id="chunk-549" class="transcript-chunks" onclick="console.log('00:35:47,961'); seek(2147.0)">
              How we can avoid it?
            </span>
            
            <span id="chunk-550" class="transcript-chunks" onclick="console.log('00:35:49,101'); seek(2149.0)">
              We can simply impute the short equals to false parameter for this case.
            </span>
            
            <span id="chunk-551" class="transcript-chunks" onclick="console.log('00:35:53,431'); seek(2153.0)">
              And if we apply this, Pandas will skip that step and we'll
            </span>
            
            <span id="chunk-552" class="transcript-chunks" onclick="console.log('00:35:56,751'); seek(2156.0)">
              get much better performance.
            </span>
            
            <span id="chunk-553" class="transcript-chunks" onclick="console.log('00:35:58,726'); seek(2158.0)">
              Now, this data have very less cardinality, only 5 groups, but when you have a
            </span>
            
            <span id="chunk-554" class="transcript-chunks" onclick="console.log('00:36:03,456'); seek(2163.0)">
              very high cardinality in your data, many groups are present, you can
            </span>
            
            <span id="chunk-555" class="transcript-chunks" onclick="console.log('00:36:07,106'); seek(2167.0)">
              expect that this will give you much more performance in terms of speedup.
            </span>
            
            <span id="chunk-556" class="transcript-chunks" onclick="console.log('00:36:11,506'); seek(2171.0)">
              Like when I try with 100 million samples with high cardinality, I expect that,
            </span>
            
            <span id="chunk-557" class="transcript-chunks" onclick="console.log('00:36:17,396'); seek(2177.0)">
              without short equals to false, it was taking 50 seconds and with short
            </span>
            
            <span id="chunk-558" class="transcript-chunks" onclick="console.log('00:36:20,746'); seek(2180.0)">
              equals to false, it took 30 seconds.
            </span>
            
            <span id="chunk-559" class="transcript-chunks" onclick="console.log('00:36:22,356'); seek(2182.0)">
              the short itself has, A lot of like almost like more than 50 percent
            </span>
            
            <span id="chunk-560" class="transcript-chunks" onclick="console.log('00:36:28,096'); seek(2188.0)">
              contribution for this query So this is something called parameter
            </span>
            
            <span id="chunk-561" class="transcript-chunks" onclick="console.log('00:36:31,366'); seek(2191.0)">
              tuning and because of the compiler in firedux it can detect that After
            </span>
            
            <span id="chunk-562" class="transcript-chunks" onclick="console.log('00:36:37,336'); seek(2197.0)">
              groupby you want to short the result.
            </span>
            
            <span id="chunk-563" class="transcript-chunks" onclick="console.log('00:36:39,536'); seek(2199.0)">
              So the default shorting in the groupby is not needed And firedux can automatically
            </span>
            
            <span id="chunk-564" class="transcript-chunks" onclick="console.log('00:36:44,936'); seek(2204.0)">
              impute such parameter by making it false such that you can avoid this kind of
            </span>
            
            <span id="chunk-565" class="transcript-chunks" onclick="console.log('00:36:50,681'); seek(2210.0)">
              performance cost which is hidden in pandas So that is again one of the offering when
            </span>
            
            <span id="chunk-566" class="transcript-chunks" onclick="console.log('00:36:54,491'); seek(2214.0)">
              you will be using fire tax Now with that, let me talk about some benchmarks So
            </span>
            
            <span id="chunk-567" class="transcript-chunks" onclick="console.log('00:37:00,161'); seek(2220.0)">
              this is a very popular benchmark called deb benchmark where they have written
            </span>
            
            <span id="chunk-568" class="transcript-chunks" onclick="console.log('00:37:04,461'); seek(2224.0)">
              several around 10 queries of different complex City of the data with different
            </span>
            
            <span id="chunk-569" class="transcript-chunks" onclick="console.log('00:37:10,316'); seek(2230.0)">
              cardinality and size for the join and group operations So when you see the
            </span>
            
            <span id="chunk-570" class="transcript-chunks" onclick="console.log('00:37:15,026'); seek(2235.0)">
              comparison table, of course pandas is slow So that is why it is on from the very
            </span>
            
            <span id="chunk-571" class="transcript-chunks" onclick="console.log('00:37:18,756'); seek(2238.0)">
              bottom But other hyperlink alternative of pandas like colors dark divi and all you
            </span>
            
            <span id="chunk-572" class="transcript-chunks" onclick="console.log('00:37:23,446'); seek(2243.0)">
              can see the products is something That can outperform all the other library as
            </span>
            
            <span id="chunk-573" class="transcript-chunks" onclick="console.log('00:37:27,936'); seek(2247.0)">
              well and it is something around the top So now let's, if we talk about some general
            </span>
            
            <span id="chunk-574" class="transcript-chunks" onclick="console.log('00:37:32,841'); seek(2252.0)">
              overview of this popular library, so I can have this kind of image at my mind.
            </span>
            
            <span id="chunk-575" class="transcript-chunks" onclick="console.log('00:37:37,671'); seek(2257.0)">
              So in terms of pandas compatibility and single node performance, if we compare
            </span>
            
            <span id="chunk-576" class="transcript-chunks" onclick="console.log('00:37:41,391'); seek(2261.0)">
              this library, so we can see duckdb is a library that duckdb and polars Are the
            </span>
            
            <span id="chunk-577" class="transcript-chunks" onclick="console.log('00:37:48,421'); seek(2268.0)">
              library that can work better on single node performance Whereas park, dusk,
            </span>
            
            <span id="chunk-578" class="transcript-chunks" onclick="console.log('00:37:53,471'); seek(2273.0)">
              modin are the library that works better on the multi node computation environment
            </span>
            
            <span id="chunk-579" class="transcript-chunks" onclick="console.log('00:37:57,391'); seek(2277.0)">
              because they're target for the multi node In terms of pandas compatibility
            </span>
            
            <span id="chunk-580" class="transcript-chunks" onclick="console.log('00:38:01,801'); seek(2281.0)">
              duckdb has very less compatible because it is for the sql api where polars is
            </span>
            
            <span id="chunk-581" class="transcript-chunks" onclick="console.log('00:38:06,681'); seek(2286.0)">
              not that compatible Although it somewhat look alike interface with pandas But
            </span>
            
            <span id="chunk-582" class="transcript-chunks" onclick="console.log('00:38:11,931'); seek(2291.0)">
              firedogs and modding, these are the library that are fully compatible
            </span>
            
            <span id="chunk-583" class="transcript-chunks" onclick="console.log('00:38:16,101'); seek(2296.0)">
              with, like pandas kind of thing.
            </span>
            
            <span id="chunk-584" class="transcript-chunks" onclick="console.log('00:38:17,811'); seek(2297.0)">
              And of course, Rapids has its own QDF.
            </span>
            
            <span id="chunk-585" class="transcript-chunks" onclick="console.log('00:38:21,171'); seek(2301.0)">
              That is for GPU, although that is another, different story.
            </span>
            
            <span id="chunk-586" class="transcript-chunks" onclick="console.log('00:38:24,421'); seek(2304.0)">
              But Rapids is again compatible with pandas, providing good performance.
            </span>
            
            <span id="chunk-587" class="transcript-chunks" onclick="console.log('00:38:29,931'); seek(2309.0)">
              But since it is for the GPU platform, so it is something different than all these.
            </span>
            
            <span id="chunk-588" class="transcript-chunks" onclick="console.log('00:38:33,906'); seek(2313.0)">
              at this moment.
            </span>
            
            <span id="chunk-589" class="transcript-chunks" onclick="console.log('00:38:36,066'); seek(2316.0)">
              All the Polars has its own GPU version available.
            </span>
            
            <span id="chunk-590" class="transcript-chunks" onclick="console.log('00:38:39,236'); seek(2319.0)">
              And so for the FireDUX that we are currently working on.
            </span>
            
            <span id="chunk-591" class="transcript-chunks" onclick="console.log('00:38:42,636'); seek(2322.0)">
              Now, if we talk about the TPC H that is one of the popular benchmark.
            </span>
            
            <span id="chunk-592" class="transcript-chunks" onclick="console.log('00:38:46,576'); seek(2326.0)">
              In this demo, I have used query three only, but actually there is 22 22
            </span>
            
            <span id="chunk-593" class="transcript-chunks" onclick="console.log('00:38:53,146'); seek(2333.0)">
              queries for against Pandas and other high performance alternative like
            </span>
            
            <span id="chunk-594" class="transcript-chunks" onclick="console.log('00:38:56,606'); seek(2336.0)">
              Polars and Modin, we can see that Modin was working not that good, like
            </span>
            
            <span id="chunk-595" class="transcript-chunks" onclick="console.log('00:39:02,616'); seek(2342.0)">
              somewhat similar to Pandas, but older.
            </span>
            
            <span id="chunk-596" class="transcript-chunks" onclick="console.log('00:39:04,346'); seek(2344.0)">
              Was quite faster.
            </span>
            
            <span id="chunk-597" class="transcript-chunks" onclick="console.log('00:39:05,696'); seek(2345.0)">
              It was around 57 times faster when comparing, when
            </span>
            
            <span id="chunk-598" class="transcript-chunks" onclick="console.log('00:39:09,266'); seek(2349.0)">
              performing the processing stuff.
            </span>
            
            <span id="chunk-599" class="transcript-chunks" onclick="console.log('00:39:11,516'); seek(2351.0)">
              But fire desks can outperform the average around 1 25 times, so it can
            </span>
            
            <span id="chunk-600" class="transcript-chunks" onclick="console.log('00:39:17,206'); seek(2357.0)">
              work much faster without even modifying a piece of existing partner code.
            </span>
            
            <span id="chunk-601" class="transcript-chunks" onclick="console.log('00:39:22,146'); seek(2362.0)">
              and if you compare the scalability of the library in terms of TPCs framework also.
            </span>
            
            <span id="chunk-602" class="transcript-chunks" onclick="console.log('00:39:27,186'); seek(2367.0)">
              We can see that, the polars, duck, db, fire, ducks are the library that
            </span>
            
            <span id="chunk-603" class="transcript-chunks" onclick="console.log('00:39:30,886'); seek(2370.0)">
              offer multithreading, where pandas works same, even though we increase the
            </span>
            
            <span id="chunk-604" class="transcript-chunks" onclick="console.log('00:39:35,386'); seek(2375.0)">
              number of cores, there is no visible change in terms of performance in
            </span>
            
            <span id="chunk-605" class="transcript-chunks" onclick="console.log('00:39:39,576'); seek(2379.0)">
              pandas, even if we include the I O or exclude the I O. But, in case of duck
            </span>
            
            <span id="chunk-606" class="transcript-chunks" onclick="console.log('00:39:44,506'); seek(2384.0)">
              db and fireducks, that shows somewhat good, scalability when we increase the
            </span>
            
            <span id="chunk-607" class="transcript-chunks" onclick="console.log('00:39:51,816'); seek(2391.0)">
              number of threads, during the execution.
            </span>
            
            <span id="chunk-608" class="transcript-chunks" onclick="console.log('00:39:54,396'); seek(2394.0)">
              Polars is again, doing scalability, but to some, after some extent, the polars,
            </span>
            
            <span id="chunk-609" class="transcript-chunks" onclick="console.log('00:39:59,036'); seek(2399.0)">
              doesn't show that much of scalability when, at least for the TPC benchmark.
            </span>
            
            <span id="chunk-610" class="transcript-chunks" onclick="console.log('00:40:03,826'); seek(2403.0)">
              till 8 cores, it was fine, but after 8 cores.
            </span>
            
            <span id="chunk-611" class="transcript-chunks" onclick="console.log('00:40:06,511'); seek(2406.0)">
              The scalability was something that was not quite good when we compared TPC H.
            </span>
            
            <span id="chunk-612" class="transcript-chunks" onclick="console.log('00:40:13,061'); seek(2413.0)">
              so here are some resources on FireDUX.
            </span>
            
            <span id="chunk-613" class="transcript-chunks" onclick="console.log('00:40:15,181'); seek(2415.0)">
              If you want to know more about it, explore the articles written in, written for
            </span>
            
            <span id="chunk-614" class="transcript-chunks" onclick="console.log('00:40:19,291'); seek(2419.0)">
              FireDUX and other libraries, we can check out this, Website that is there we can
            </span>
            
            <span id="chunk-615" class="transcript-chunks" onclick="console.log('00:40:23,581'); seek(2423.0)">
              follow on us on twitter where we publish the information related to articles
            </span>
            
            <span id="chunk-616" class="transcript-chunks" onclick="console.log('00:40:28,361'); seek(2428.0)">
              the new development the new release etc if you find any issue and want to
            </span>
            
            <span id="chunk-617" class="transcript-chunks" onclick="console.log('00:40:32,151'); seek(2432.0)">
              report back to us you can refer to the github page you can definitely connect
            </span>
            
            <span id="chunk-618" class="transcript-chunks" onclick="console.log('00:40:37,421'); seek(2437.0)">
              us over the slack channel we'd be happy to welcome you there and collaborate
            </span>
            
            <span id="chunk-619" class="transcript-chunks" onclick="console.log('00:40:41,381'); seek(2441.0)">
              directly with you if you have any questions so with that let me conclude my
            </span>
            
            <span id="chunk-620" class="transcript-chunks" onclick="console.log('00:40:47,041'); seek(2447.0)">
              talk thank you once again for listening to me And I hope you enjoyed the talk.
            </span>
            
            <span id="chunk-621" class="transcript-chunks" onclick="console.log('00:40:52,666'); seek(2452.0)">
              the key insight that I talked about in best practices and how fire ducks can help
            </span>
            
            <span id="chunk-622" class="transcript-chunks" onclick="console.log('00:40:56,846'); seek(2456.0)">
              you to improve your journey with pandas.
            </span>
            
            <span id="chunk-623" class="transcript-chunks" onclick="console.log('00:41:00,536'); seek(2460.0)">
              So enjoy green computing and explore fire ducks.
            </span>
            
            <span id="chunk-624" class="transcript-chunks" onclick="console.log('00:41:04,996'); seek(2464.0)">
              If you have any questions, I understand that this is something online.
            </span>
            
            <span id="chunk-625" class="transcript-chunks" onclick="console.log('00:41:08,296'); seek(2468.0)">
              So probably I cannot make it interactive this time, but if you have any questions,
            </span>
            
            <span id="chunk-626" class="transcript-chunks" onclick="console.log('00:41:12,441'); seek(2472.0)">
              you can connect me over the LinkedIn or any other prefer social media network,
            </span>
            
            <span id="chunk-627" class="transcript-chunks" onclick="console.log('00:41:16,781'); seek(2476.0)">
              or you can definitely get in touch with the Slack channel and other media.
            </span>
            
            <span id="chunk-628" class="transcript-chunks" onclick="console.log('00:41:20,251'); seek(2480.0)">
              I'd be happy to help you in optimizing whatever problems you may have with
            </span>
            
            <span id="chunk-629" class="transcript-chunks" onclick="console.log('00:41:25,181'); seek(2485.0)">
              pandas and discuss some kind of collaboration if you are interested in it.
            </span>
            
            <span id="chunk-630" class="transcript-chunks" onclick="console.log('00:41:30,691'); seek(2490.0)">
              Yes.
            </span>
            
            <span id="chunk-631" class="transcript-chunks" onclick="console.log('00:41:31,141'); seek(2491.0)">
              With that, I'm concluding my talk.
            </span>
            
            <span id="chunk-632" class="transcript-chunks" onclick="console.log('00:41:33,581'); seek(2493.0)">
              Thank you very much once again for listening to me till this.
            </span>
            
            <span id="chunk-633" class="transcript-chunks" onclick="console.log('00:41:37,551'); seek(2497.0)">
              till this end, I hope you enjoy rest of the presentation as well,
            </span>
            
            <span id="chunk-634" class="transcript-chunks" onclick="console.log('00:41:41,461'); seek(2501.0)">
              happy collaboration, happy learning.
            </span>
            
            <span id="chunk-635" class="transcript-chunks" onclick="console.log('00:41:43,511'); seek(2503.0)">
              Thank you so much.
            </span>
            
            </div>
          </div>
          
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Sourav%20Saha%20-%20Conf42%20Python%202025.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Sourav%20Saha%20-%20Conf42%20Python%202025.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #69811f;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/python2025" class="btn btn-sm btn-danger shadow lift" style="background-color: #69811f;">
                <i class="fe fe-grid me-2"></i>
                See all 53 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/Sourav%20Saha_python.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Sourav Saha
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Senior Research Engineer @ NEC Corporation
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/sourav-%E3%82%BD%E3%82%A6%E3%83%A9%E3%83%96-saha-%E3%82%B5%E3%83%8F-a5750259/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Sourav Saha's LinkedIn account" />
                  </a>
                  
                  
                  <a href="https://twitter.com/SouravSaha97589" target="_blank">
                    <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="Sourav Saha's twitter account" />
                  </a>
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by SouravSaha97589"
                  data-url="https://www.conf42.com/python2025"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/python2025"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>






    <!-- WELCOME -->
    <section class="pt-8 pt-md-11 pb-10 pb-md-15 bg-info" id="register">

      <!-- Shape -->
      <div class="shape shape-blur-3 text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>      </div>

      <!-- Content -->
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 col-md-10 col-lg-8 text-center">

            <!-- Heading -->
            <h1 class="display-2 text-white">
              Join the community!
            </h1>

            <!-- Text -->
            <p class="lead text-white text-opacity-80 mb-6 mb-md-8">
              Learn for free, join the best tech learning community 
              for a <a class="text-white" href="https://www.reddit.com/r/sanfrancisco/comments/1bz90f6/why_are_coffee_shops_in_sf_so_expensive/" target="_blank">price of a pumpkin latte</a>.
            </p>

            <!-- Form -->
            <form class="d-flex align-items-center justify-content-center mb-7 mb-md-9">

              <!-- Label -->
              <span class="text-white text-opacity-80">
                Annual
              </span>

              <!-- Switch -->
              <div class="form-check form-check-dark form-switch mx-3">
                <input class="form-check-input" type="checkbox" id="billingSwitch" data-toggle="price" data-target=".price">
              </div>

              <!-- Label -->
              <span class="text-white text-opacity-80">
                Monthly
              </span>

            </form>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->

    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- PRICING -->
    <section class="mt-n8 mt-md-n15">
      <div class="container">
        <div class="row gx-4">
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-1">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Newsletter</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="0" data-monthly="0">0</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Event notifications, weekly newsletter
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Delayed access</b> to all content
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Immediate access to Keynotes & Panels
                  </p>
                </div>
              
              
              </div>
            </div>

            <!-- Card -->
            <div class="card shadow-lg mb-6 border border-success">
              <div class="card-body">

                <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
</script>

<!-- Form -->
<link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
<p class="emailoctopus-success-message text-success"></p>
<p class="emailoctopus-error-message text-danger"></p>
<form
    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
    method="post"
    data-message-success="Thanks! Check your email for further directions!"
    data-message-missing-email-address="Your email address is required."
    data-message-invalid-email-address="Your email address looks incorrect, please try again."
    data-message-bot-submission-error="This doesn't look like a human submission."
    data-message-consent-required="Please check the checkbox to indicate your consent."
    data-message-invalid-parameters-error="This form has missing or invalid fields."
    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
    class="emailoctopus-form"
    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
>
<div class="form-floating emailoctopus-form-row">
    <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
    <label for="field_0">Email address</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
    <label for="field_1">First Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
    <label for="field_2">Last Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
    <label for="field_4">Company</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
    <label for="field_5">Job Title</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
    <label for="field_3">Phone Number</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
    oninput="updateCountry()"
    >
    <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
    </select>
    <label for="field_7">Country</label>
</div>
<input id="country-destination" name="field_7" type="hidden">
<input id="tz-country" name="field_8" type="hidden">

<input
    name="field_6"
    type="hidden"
    value="Python"
>

<div class="emailoctopus-form-row-consent">
    <input
    type="checkbox"
    id="consent"
    name="consent"
    >
    <label for="consent">
    I consent to the following terms:
    </label>
    <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
    Terms and Conditions
    </a>
    &amp;
    <a href="./code-of-conduct" target="_blank">
    Code of Conduct
    </a>
</div>
<div
    aria-hidden="true"
    class="emailoctopus-form-row-hp"
>
    <input
    type="text"
    name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
    tabindex="-1"
    autocomplete="nope"
    >
</div>
<div class="mt-6 emailoctopus-form-row-subscribe">
    <input
    type="hidden"
    name="successRedirectUrl"
    >
    <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
    Subscribe to free newsletter <i class="fe fe-arrow-right ms-3"></i>
    </button>
</div>
</form>

<!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
<script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

              </div>
            </div>
          </div>
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-0">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Community</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="8.34" data-monthly="10">8.34</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Access to <a href="https://conf42.circle.so/">Circle community platform</a>
                  </p>
                </div>

                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Immediate access</b> to all content
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <a href="https://conf42.circle.so/c/live-events/" target="_blank"><b>Live events!</b></a>
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <a href="https://conf42.circle.so/c/live-events/" target="_blank">Regular office hours, Q&As, CV reviews</a>
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Courses, quizes & certificates
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Community chats
                  </p>
                </div>
                

                <!-- Button -->
                <a href="https://conf42.circle.so/checkout/subscribe" class="btn w-100 btn-primary">
                  Join the community (7 day free trial)<i class="fe fe-arrow-right ms-3"></i>
                </a>

              </div>
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2025">
                  Site Reliability Engineering (SRE) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2025">
                  Machine Learning 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2025">
                  Observability 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2025">
                  Quantum Computing 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2025">
                  Rustlang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2025">
                  Platform Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2025">
                  MLOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2025">
                  Incident Management 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2025">
                  Kube Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2025">
                  JavaScript 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2025">
                  Prompt Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/robotics2025">
                  Robotics 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2025">
                  DevSecOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2025">
                  Internet of Things (IoT) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>