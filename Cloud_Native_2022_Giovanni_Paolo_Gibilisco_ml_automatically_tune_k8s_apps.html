<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: Cheap or Fast? How we got both by leveraging ML to automatically tune K8s apps</title>
    <meta name="description" content="Everything Cloud Native and Cloud Security. It came from the Cloud!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/cloud_giovanni_paolo_gibilisco.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Cheap or Fast? How we got both by leveraging ML to automatically tune K8s apps | Conf42"/>
    <meta property="og:description" content="After all these years, the task of tuning Kubernetes microservice applications is a daunting task even for experienced Performance Engineers and SREs, often resulting in companies facing reliability and performance issues, as well as unexpected costs.   In this session, we plan to first illustrate some less-known facts about Kubernetes key resource management and autoscaling mechanisms and show how properly setting pod resources and autoscaling policies is critical to avoid over-provisioning while ensuring services deliver the expected performance and resilience.   We then demonstrate how a new approach leveraging ML techniques makes it possible to automatically tune both pod and runtime configurations to ensure any specified optimization goal, such as minimizing Kubernetes cost or maximizing application throughput, while respecting any SLOs, such as max response time and error rates.  Results of real-world cases will be used to document how much this new approach can be effective to deliver higher operational efficiency tangible benefits. "/>
    <meta property="og:url" content="https://conf42.com/Cloud_Native_2022_Giovanni_Paolo_Gibilisco_ml_automatically_tune_k8s_apps"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/SRE2025_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Site Reliability Engineering (SRE) 2025
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2025-04-17
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/sre2025" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2025">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2025">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2025">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2025">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2025">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2025">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2025">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2025">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2025">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2025">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2025">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/robotics2025">
                            Robotics
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2025">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2025">
                            Internet of Things (IoT)
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="https://conf42.circle.so/">
                            <b>Community platform login</b>
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Join the community!
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #7B2726;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Cloud Native 2022 - Online
            </h1>

            <h2 class="text-white">
              
              <time datetime="2022-04-28">April 28 2022</time>
              
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Everything Cloud Native and Cloud Security. It came from the Cloud!
 -->
              <script>
                const event_date = new Date("2022-04-28T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2022-04-28T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              <a href="#register" class="btn btn-primary shadow lift me-1 mb-3">
                <i class="fe fe-user-check me-2"></i>
                Subscribe to watch
              </a>
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "31Gw8UoYVbU"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <a class="btn btn-info lift mb-3" data-bigpicture='{"ytSrc": "UoS8Ek1nzlQ"}' href="#">
                <i class="fe fe-eye me-2"></i>
                Watch Premiere
              </a>
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://youtube.com/playlist?list=PLIuxSyKxlQrDBftRbZcQJXCPJHuJVe_FN" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "This is Giovannijilisko and in the next 20 minutes or so I\u0027ll", "timestamp": "00:01:28,770", "timestamp_s": 88.0}, {"text": "share with you some of our experiences in tuning applications running", "timestamp": "00:01:32,418", "timestamp_s": 92.0}, {"text": "on kubernetes. These are the contents that", "timestamp": "00:01:36,060", "timestamp_s": 96.0}, {"text": "we will cover. We\u0027ll start by identifying some challenges", "timestamp": "00:01:39,308", "timestamp_s": 99.0}, {"text": "of modern applications for ensuring performance and reliability.", "timestamp": "00:01:43,050", "timestamp_s": 103.0}, {"text": "We\u0027ll then review how Kubernetes manages container", "timestamp": "00:01:47,418", "timestamp_s": 107.0}, {"text": "resources and the factors we need to be aware of if we want", "timestamp": "00:01:50,842", "timestamp_s": 110.0}, {"text": "to ensure high performance and cost efficiency.", "timestamp": "00:01:54,424", "timestamp_s": 114.0}, {"text": "We will introduce a new approach we implemented at Akamas,", "timestamp": "00:01:57,438", "timestamp_s": 117.0}, {"text": "which leverages machine learning to automate the optimization process,", "timestamp": "00:02:01,070", "timestamp_s": 121.0}, {"text": "and we will do that with a real world example.", "timestamp": "00:02:04,776", "timestamp_s": 124.0}, {"text": "Finally, we will conclude by sharing some takeaways.", "timestamp": "00:02:08,090", "timestamp_s": 128.0}, {"text": "Before proceeding, let me introduce myself. My name Giovanni Paolo", "timestamp": "00:02:11,770", "timestamp_s": 131.0}, {"text": "Gibilisco and I serve as head of engineering at Akamas.", "timestamp": "00:02:15,474", "timestamp_s": 135.0}, {"text": "Okay, let\u0027s start with a quick overview of some of the main challenges that", "timestamp": "00:02:19,010", "timestamp_s": 139.0}, {"text": "comes with the development of modern applications. The advent of", "timestamp": "00:02:23,232", "timestamp_s": 143.0}, {"text": "agile practices allowed developers to speed up the development cycle", "timestamp": "00:02:26,912", "timestamp_s": 146.0}, {"text": "with the goal of getting rapid feedback and iteratively", "timestamp": "00:02:31,018", "timestamp_s": 151.0}, {"text": "improve applications. Though increasing the release frequency,", "timestamp": "00:02:34,458", "timestamp_s": 154.0}, {"text": "it\u0027s now common to see applications, or part of them,", "timestamp": "00:02:38,410", "timestamp_s": 158.0}, {"text": "released to production weekly or even daily. At the same time,", "timestamp": "00:02:41,540", "timestamp_s": 161.0}, {"text": "the underlying frameworks and runtimes, such as the JVM", "timestamp": "00:02:45,496", "timestamp_s": 165.0}, {"text": "that are used to build those applications, have grown in complexity.", "timestamp": "00:02:49,454", "timestamp_s": 169.0}, {"text": "The emergence of architectural patterns such as microservices", "timestamp": "00:02:53,670", "timestamp_s": 173.0}, {"text": "have also brought an increase in the number of frameworks and technologies", "timestamp": "00:02:58,002", "timestamp_s": 178.0}, {"text": "used within a single application. It\u0027s now common to", "timestamp": "00:03:02,178", "timestamp_s": 182.0}, {"text": "see application composed by tens or even hundreds of services,", "timestamp": "00:03:05,548", "timestamp_s": 185.0}, {"text": "written in different languages and interacting with multiple", "timestamp": "00:03:09,184", "timestamp_s": 189.0}, {"text": "runtimes and databases. Kubernetes provides a", "timestamp": "00:03:13,142", "timestamp_s": 193.0}, {"text": "great platform to run such applications, but it has its", "timestamp": "00:03:16,368", "timestamp_s": 196.0}, {"text": "own complexities. These Kubernetes", "timestamp": "00:03:19,792", "timestamp_s": 199.0}, {"text": "failure stories is a website specifically created", "timestamp": "00:03:23,146", "timestamp_s": 203.0}, {"text": "to share incident reports in order to allow the community", "timestamp": "00:03:26,394", "timestamp_s": 206.0}, {"text": "to learn from failures and prevent them for further", "timestamp": "00:03:29,908", "timestamp_s": 209.0}, {"text": "happening. Many of these stories describe teams struggling with", "timestamp": "00:03:33,438", "timestamp_s": 213.0}, {"text": "Kubernetes application performance and stability issues such", "timestamp": "00:03:37,512", "timestamp_s": 217.0}, {"text": "as unexpected cpu\u0027s, loaddowns and even sudden container", "timestamp": "00:03:41,192", "timestamp_s": 221.0}, {"text": "terminations. Engineers at Airbnb even got", "timestamp": "00:03:45,118", "timestamp_s": 225.0}, {"text": "to the point of suggesting that Kubernetes may actually hurt the", "timestamp": "00:03:48,508", "timestamp_s": 228.0}, {"text": "performance of latency sensitive applications. But why", "timestamp": "00:03:52,508", "timestamp_s": 232.0}, {"text": "it\u0027s so difficult to manage application performance, stability and efficiency", "timestamp": "00:03:56,572", "timestamp_s": 236.0}, {"text": "on Kubernetes? The simple answer is that Kubernetes is a", "timestamp": "00:04:00,582", "timestamp_s": 240.0}, {"text": "glaze platform to run containerized applications, but it requires", "timestamp": "00:04:03,984", "timestamp_s": 243.0}, {"text": "applications to be carefully configured to ensure high performance", "timestamp": "00:04:07,942", "timestamp_s": 247.0}, {"text": "and stability, as we\u0027re going to see. To answer", "timestamp": "00:04:11,722", "timestamp_s": 251.0}, {"text": "this question, let\u0027s now get back to the fundamentals and see how Kubernetes", "timestamp": "00:04:15,396", "timestamp_s": 255.0}, {"text": "resource management works to better understand the", "timestamp": "00:04:19,530", "timestamp_s": 259.0}, {"text": "main parameters that impact Kubernetes application performance,", "timestamp": "00:04:23,272", "timestamp_s": 263.0}, {"text": "stability and cost efficiency. Let\u0027s go through", "timestamp": "00:04:26,654", "timestamp_s": 266.0}, {"text": "five main key aspects and their implications.", "timestamp": "00:04:29,880", "timestamp_s": 269.0}, {"text": "The first important concept is resource requests.", "timestamp": "00:04:33,430", "timestamp_s": 273.0}, {"text": "When a developer is defined pod, she has the possibility to", "timestamp": "00:04:37,442", "timestamp_s": 277.0}, {"text": "specify resource results. These are the amount of cpu", "timestamp": "00:04:40,972", "timestamp_s": 280.0}, {"text": "and memory the pod or better, a container within the pod", "timestamp": "00:04:44,962", "timestamp_s": 284.0}, {"text": "is guaranteed to get. Kubernetes will schedule", "timestamp": "00:04:48,950", "timestamp_s": 288.0}, {"text": "the pod on a node where the requested resources are", "timestamp": "00:04:52,758", "timestamp_s": 292.0}, {"text": "actually available. In this example,", "timestamp": "00:04:56,192", "timestamp_s": 296.0}, {"text": "pod a acquires two cpus and is scheduled on a", "timestamp": "00:04:58,864", "timestamp_s": 298.0}, {"text": "four cpu node. When a new pod b on the", "timestamp": "00:05:02,836", "timestamp_s": 302.0}, {"text": "same side is created, it can also be scheduled on", "timestamp": "00:05:05,924", "timestamp_s": 305.0}, {"text": "the same node. This node now has all of its four", "timestamp": "00:05:09,204", "timestamp_s": 309.0}, {"text": "cpus requested. If a pod c is created,", "timestamp": "00:05:13,172", "timestamp_s": 313.0}, {"text": "Kubernetes won\u0027t schedule it on the same node as its", "timestamp": "00:05:16,718", "timestamp_s": 316.0}, {"text": "capacity is full. This means that those numbers these developers", "timestamp": "00:05:20,568", "timestamp_s": 320.0}, {"text": "specify in the deployment yaml are directly affect the", "timestamp": "00:05:24,430", "timestamp_s": 324.0}, {"text": "cluster capacity. A strong difference with respect to virtualization", "timestamp": "00:05:28,268", "timestamp_s": 328.0}, {"text": "and hypervisors is that with Kubernetes there is", "timestamp": "00:05:32,482", "timestamp_s": 332.0}, {"text": "no overcommitment on the requests. You cannot request more", "timestamp": "00:05:36,092", "timestamp_s": 336.0}, {"text": "cpus than those available in the cluster.", "timestamp": "00:05:40,160", "timestamp_s": 340.0}, {"text": "Another important aspect is that resource requests are", "timestamp": "00:05:42,982", "timestamp_s": 342.0}, {"text": "not equal to utilization. If pod requests are", "timestamp": "00:05:46,832", "timestamp_s": 346.0}, {"text": "much higher than the actual resource usage, you might end up with these cluster", "timestamp": "00:05:50,832", "timestamp_s": 350.0}, {"text": "that is at full capacity even though its cpu utilization is", "timestamp": "00:05:54,538", "timestamp_s": 354.0}, {"text": "only 10%. So the takeaway", "timestamp": "00:05:58,212", "timestamp_s": 358.0}, {"text": "here is that setting proper pod request is", "timestamp": "00:06:01,642", "timestamp_s": 361.0}, {"text": "paramount to ensure Kubernetes cost efficiency. The second", "timestamp": "00:06:04,712", "timestamp_s": 364.0}, {"text": "important concept is resource limits.", "timestamp": "00:06:08,296", "timestamp_s": 368.0}, {"text": "Resource requests are guaranteed resources that", "timestamp": "00:06:12,230", "timestamp_s": 372.0}, {"text": "a container will get, but usage can be higher.", "timestamp": "00:06:15,624", "timestamp_s": 375.0}, {"text": "Resource limits is the mechanisms that allows you to define", "timestamp": "00:06:19,388", "timestamp_s": 379.0}, {"text": "the maximum amount of resources that a container can use,", "timestamp": "00:06:23,058", "timestamp_s": 383.0}, {"text": "like two cpus or 1gb of memory.", "timestamp": "00:06:26,860", "timestamp_s": 386.0}, {"text": "All this is great, but what happens when resource usage hits", "timestamp": "00:06:30,730", "timestamp_s": 390.0}, {"text": "the limit? Kubernetes treat cpu and memory", "timestamp": "00:06:34,982", "timestamp_s": 394.0}, {"text": "differently here. When a cpu usage approaches the limit,", "timestamp": "00:06:38,166", "timestamp_s": 398.0}, {"text": "the container gets throttled. This means that these cpu is artificially", "timestamp": "00:06:41,546", "timestamp_s": 401.0}, {"text": "restricted and this usually results in application performance", "timestamp": "00:06:45,610", "timestamp_s": 405.0}, {"text": "issues. Instead, when memory usage hits the limit,", "timestamp": "00:06:49,642", "timestamp_s": 409.0}, {"text": "the container gets terminated, so there is no application", "timestamp": "00:06:53,374", "timestamp_s": 413.0}, {"text": "slowdown due to paging or swapping as we had in traditional", "timestamp": "00:06:56,888", "timestamp_s": 416.0}, {"text": "operating systems. With the Kubernetes your pod will", "timestamp": "00:07:00,446", "timestamp_s": 420.0}, {"text": "simply disappear and you may face serious application stability", "timestamp": "00:07:04,008", "timestamp_s": 424.0}, {"text": "issues. The third fact is about an important and less", "timestamp": "00:07:08,274", "timestamp_s": 428.0}, {"text": "known effect that cpu limits have on application performance.", "timestamp": "00:07:12,076", "timestamp_s": 432.0}, {"text": "We have seen that cpu limits called throttling and you may think that", "timestamp": "00:07:16,450", "timestamp_s": 436.0}, {"text": "this happens only when cpu usage hits the limit.", "timestamp": "00:07:20,336", "timestamp_s": 440.0}, {"text": "Surprisingly, the reality is that cpu throttling starts", "timestamp": "00:07:23,990", "timestamp_s": 443.0}, {"text": "even when cpu usage is well below the limit. We did", "timestamp": "00:07:27,398", "timestamp_s": 447.0}, {"text": "quite a bit of research on this aspect in our labs and found", "timestamp": "00:07:31,232", "timestamp_s": 451.0}, {"text": "that cpu throttling start when cpu usage is as", "timestamp": "00:07:34,964", "timestamp_s": 454.0}, {"text": "low as 30% of the limit. This is due", "timestamp": "00:07:38,372", "timestamp_s": 458.0}, {"text": "to a particular way cpu limits are implemented at the Linux kernel level.", "timestamp": "00:07:41,914", "timestamp_s": 461.0}, {"text": "These aggressive cpu throttling has a huge impact on", "timestamp": "00:07:46,184", "timestamp_s": 466.0}, {"text": "service performance. You can get sudden latency spikes", "timestamp": "00:07:49,832", "timestamp_s": 469.0}, {"text": "that may breach your slos without any apparent reason,", "timestamp": "00:07:53,630", "timestamp_s": 473.0}, {"text": "even at low cpu usage. Now, some people,", "timestamp": "00:07:57,116", "timestamp_s": 477.0}, {"text": "including engineers at buffers, tried to remove cpu limits.", "timestamp": "00:08:00,764", "timestamp_s": 480.0}, {"text": "What these got was an impressive reduction of service latency.", "timestamp": "00:08:04,626", "timestamp_s": 484.0}, {"text": "So is it a good idea to get rid of cpu limits?", "timestamp": "00:08:08,578", "timestamp_s": 488.0}, {"text": "Apparently not. Cpu limits exist to", "timestamp": "00:08:13,310", "timestamp_s": 493.0}, {"text": "bound the amount of resources a container can consume.", "timestamp": "00:08:16,608", "timestamp_s": 496.0}, {"text": "This allows many containers to coexist without competing", "timestamp": "00:08:20,290", "timestamp_s": 500.0}, {"text": "for the same resources. So if cpu limits are", "timestamp": "00:08:23,898", "timestamp_s": 503.0}, {"text": "removed, a single Runway container can disrupt the performance", "timestamp": "00:08:27,268", "timestamp_s": 507.0}, {"text": "and availability of your most critical services.", "timestamp": "00:08:30,938", "timestamp_s": 510.0}, {"text": "It might also make the Kubelet service unresponsive and effectively", "timestamp": "00:08:34,392", "timestamp_s": 514.0}, {"text": "remove the entire node from the cluster using", "timestamp": "00:08:38,590", "timestamp_s": 518.0}, {"text": "cpu limits. Is these best practice also recommended by Google?", "timestamp": "00:08:41,896", "timestamp_s": 521.0}, {"text": "Properly setting your cpu requests and limits is critical", "timestamp": "00:08:45,884", "timestamp_s": 525.0}, {"text": "to ensuring your Kubernetes cluster remains stable and efficient", "timestamp": "00:08:49,426", "timestamp_s": 529.0}, {"text": "over time. To ease the management of", "timestamp": "00:08:52,802", "timestamp_s": 532.0}, {"text": "limits and requests for many services, Kubernetes comes with", "timestamp": "00:08:56,572", "timestamp_s": 536.0}, {"text": "autoscaling. Let\u0027s discuss built in autoscaling", "timestamp": "00:08:59,808", "timestamp_s": 539.0}, {"text": "capabilities that are often considered as a way to automate this", "timestamp": "00:09:03,558", "timestamp_s": 543.0}, {"text": "process. In particular, the vertical pod autoscaler", "timestamp": "00:09:06,992", "timestamp_s": 546.0}, {"text": "or VPA provides recommended cpu and memory requests", "timestamp": "00:09:10,854", "timestamp_s": 550.0}, {"text": "based on the observed pod resource usage.", "timestamp": "00:09:15,130", "timestamp_s": 555.0}, {"text": "However, our experience with a VPA is mixed.", "timestamp": "00:09:18,330", "timestamp_s": 558.0}, {"text": "In this example, a Kubernetes microservice is serving a typical", "timestamp": "00:09:21,994", "timestamp_s": 561.0}, {"text": "dernel traffic pattern. The top left chart shows the", "timestamp": "00:09:25,546", "timestamp_s": 565.0}, {"text": "latency of this service and its service level objective,", "timestamp": "00:09:29,064", "timestamp_s": 569.0}, {"text": "while below you can see the resource request, cpu and memory,", "timestamp": "00:09:32,814", "timestamp_s": 572.0}, {"text": "and the corresponding resource utilization.", "timestamp": "00:09:36,590", "timestamp_s": 576.0}, {"text": "We let this service run for a couple of days with some initial resource", "timestamp": "00:09:39,530", "timestamp_s": 579.0}, {"text": "sizing, then activated the VPA and let it applied the new", "timestamp": "00:09:43,282", "timestamp_s": 583.0}, {"text": "recommended setting to the pod.", "timestamp": "00:09:47,148", "timestamp_s": 587.0}, {"text": "It\u0027s interesting to see that the VPA immediately decided to", "timestamp": "00:09:50,030", "timestamp_s": 590.0}, {"text": "reduce these assigned resources. In particularly, it cut in", "timestamp": "00:09:53,648", "timestamp_s": 593.0}, {"text": "half the cpu requests. This is likely due", "timestamp": "00:09:56,928", "timestamp_s": 596.0}, {"text": "to some apparent overprovisioning of these service as the cpu", "timestamp": "00:10:00,438", "timestamp_s": 600.0}, {"text": "utilization was below 50%.", "timestamp": "00:10:03,914", "timestamp_s": 603.0}, {"text": "However, with the new settings suggested by the VPA,", "timestamp": "00:10:07,090", "timestamp_s": 607.0}, {"text": "the latency of the microservice skyrocketed, breaching our slos.", "timestamp": "00:10:10,714", "timestamp_s": 610.0}, {"text": "What is the lesson heard here? Kubernetes autoscaling and", "timestamp": "00:10:16,050", "timestamp_s": 616.0}, {"text": "the VPA in particular is based on resource usage and", "timestamp": "00:10:20,088", "timestamp_s": 620.0}, {"text": "does not consider application level metrics like response time.", "timestamp": "00:10:23,688", "timestamp_s": 623.0}, {"text": "We need to evaluate the effect of the recommended settings as they", "timestamp": "00:10:27,884", "timestamp_s": 627.0}, {"text": "might be somewhat aggressive and cause severe service performance", "timestamp": "00:10:31,708", "timestamp_s": 631.0}, {"text": "or reliability degradations as", "timestamp": "00:10:35,650", "timestamp_s": 635.0}, {"text": "we\u0027ve seen so far, optimizing microservice applications on Kubernetes", "timestamp": "00:10:40,352", "timestamp_s": 640.0}, {"text": "is quite tuning tasks for developers,", "timestamp": "00:10:44,790", "timestamp_s": 644.0}, {"text": "sres and performance engineers. Given the complexity of tuning", "timestamp": "00:10:47,414", "timestamp_s": 647.0}, {"text": "Kubernetes resources and the many moving facts we have", "timestamp": "00:10:51,350", "timestamp_s": 651.0}, {"text": "in modern applications, a new approach is required", "timestamp": "00:10:54,772", "timestamp_s": 654.0}, {"text": "to successfully solve this problem and this is where machine learning", "timestamp": "00:10:58,378", "timestamp_s": 658.0}, {"text": "can help. AI and machine learning have revolutionarized", "timestamp": "00:11:01,716", "timestamp_s": 661.0}, {"text": "entire industries and the good news is that ML can be", "timestamp": "00:11:05,886", "timestamp_s": 665.0}, {"text": "used also in the performance tuning process. ML can automate", "timestamp": "00:11:09,528", "timestamp_s": 669.0}, {"text": "the tuning of many parameters we have in the software stack with", "timestamp": "00:11:13,038", "timestamp_s": 673.0}, {"text": "the goal of optimized application performance, resiliency and cost.", "timestamp": "00:11:16,712", "timestamp_s": 676.0}, {"text": "In this section I would like to introduce you to this new methodology.", "timestamp": "00:11:20,380", "timestamp_s": 680.0}, {"text": "Real world case is about an european leader in accounting,", "timestamp": "00:11:24,810", "timestamp_s": 684.0}, {"text": "payroll and business management software. These Java cases microservice", "timestamp": "00:11:28,082", "timestamp_s": 688.0}, {"text": "applications are running either on Azure or AWS Kubernetes", "timestamp": "00:11:32,182", "timestamp_s": 692.0}, {"text": "services the target system of the optimization", "timestamp": "00:11:36,630", "timestamp_s": 696.0}, {"text": "is the b two b authorization service running on Azure. It\u0027s a", "timestamp": "00:11:39,942", "timestamp_s": 699.0}, {"text": "business critical service that interacts with all the applications powered", "timestamp": "00:11:43,844", "timestamp_s": 703.0}, {"text": "in the digital services provided by the company.", "timestamp": "00:11:47,434", "timestamp_s": 707.0}, {"text": "These challenge of the customer was to avoid overspending and", "timestamp": "00:11:50,210", "timestamp_s": 710.0}, {"text": "achieve the best cost efficiency possible by enabling development teams", "timestamp": "00:11:53,768", "timestamp_s": 713.0}, {"text": "to optimize their applications while keeping on releasing application", "timestamp": "00:11:57,918", "timestamp_s": 717.0}, {"text": "updates required to introduce new business functionalities and align", "timestamp": "00:12:01,528", "timestamp_s": 721.0}, {"text": "to new regulations. So what is the goal", "timestamp": "00:12:05,102", "timestamp_s": 725.0}, {"text": "of this optimization? In this scenario, the goal was to reduce", "timestamp": "00:12:08,350", "timestamp_s": 728.0}, {"text": "the cloud costs required to run the optic authentication service on Kubernetes.", "timestamp": "00:12:11,538", "timestamp_s": 731.0}, {"text": "At the same time, we also wanted to ensure that service would", "timestamp": "00:12:15,906", "timestamp_s": 735.0}, {"text": "always meet its reliability targets which are expressed as latency,", "timestamp": "00:12:19,392", "timestamp_s": 739.0}, {"text": "throughput and error rate slos. So how can we", "timestamp": "00:12:23,334", "timestamp_s": 743.0}, {"text": "leverage ML to achieve this high level business goal?", "timestamp": "00:12:27,408", "timestamp_s": 747.0}, {"text": "In our optimization methodology, DML changes", "timestamp": "00:12:31,310", "timestamp_s": 751.0}, {"text": "the parameters of the system to improve these metric that we have defined.", "timestamp": "00:12:34,436", "timestamp_s": 754.0}, {"text": "In this case, the goal is simply to optimize the application cost.", "timestamp": "00:12:38,762", "timestamp_s": 758.0}, {"text": "This is a metric that represents the cost we pay to run the application on", "timestamp": "00:12:43,010", "timestamp_s": 763.0}, {"text": "the cloud, which depends on these amount of cpu and memory resources", "timestamp": "00:12:46,824", "timestamp_s": 766.0}, {"text": "allocated to the containers. The ML power optimization", "timestamp": "00:12:51,374", "timestamp_s": 771.0}, {"text": "methodology also allows to set constraints to define", "timestamp": "00:12:55,470", "timestamp_s": 775.0}, {"text": "which configurations are acceptable. In this case, we state", "timestamp": "00:12:58,962", "timestamp_s": 778.0}, {"text": "that the system throughput, response times and error rate should", "timestamp": "00:13:02,940", "timestamp_s": 782.0}, {"text": "not degrade more than 10% with respect to the baseline.", "timestamp": "00:13:06,428", "timestamp_s": 786.0}, {"text": "Once we have defined the optimization goal, next step is", "timestamp": "00:13:11,950", "timestamp_s": 791.0}, {"text": "to define these parameters of these system that machine learning", "timestamp": "00:13:15,568", "timestamp_s": 795.0}, {"text": "can optimize to improve our goal. In these scenario,", "timestamp": "00:13:18,944", "timestamp_s": 798.0}, {"text": "nine tunable parameters were considered. In total, four parameters", "timestamp": "00:13:22,570", "timestamp_s": 802.0}, {"text": "are related to Kubernetes container sighting, cpu and memory request and", "timestamp": "00:13:27,194", "timestamp_s": 807.0}, {"text": "limits which play a big role in the overall service performance,", "timestamp": "00:13:31,332", "timestamp_s": 811.0}, {"text": "cost and reliability and five parameters are related", "timestamp": "00:13:35,066", "timestamp_s": 815.0}, {"text": "to these JVM, which is the runtime that runs within the container.", "timestamp": "00:13:38,878", "timestamp_s": 818.0}, {"text": "Here we included parameters like heap size, garbage collector,", "timestamp": "00:13:43,678", "timestamp_s": 823.0}, {"text": "the size of the regions of the heap, which are important options to improve the", "timestamp": "00:13:47,150", "timestamp_s": 827.0}, {"text": "performance of Java apps. It\u0027s worth noticing that", "timestamp": "00:13:51,132", "timestamp_s": 831.0}, {"text": "the ML optimizes the full stack by operating on all these", "timestamp": "00:13:54,988", "timestamp_s": 834.0}, {"text": "nine parameters at the same time, thereby ensuring that the", "timestamp": "00:13:59,056", "timestamp_s": 839.0}, {"text": "JVM is optimally configured to run within the", "timestamp": "00:14:02,608", "timestamp_s": 842.0}, {"text": "chosen container. Resource sightseeing let\u0027s now", "timestamp": "00:14:05,728", "timestamp_s": 845.0}, {"text": "see how the ML Tower optimization methodology works. In practice.", "timestamp": "00:14:09,712", "timestamp_s": 849.0}, {"text": "The process is fully automated and works in five", "timestamp": "00:14:13,994", "timestamp_s": 853.0}, {"text": "sres. The first step is to apply the new configurations suggested", "timestamp": "00:14:17,220", "timestamp_s": 857.0}, {"text": "by the ML algorithms to our target system.", "timestamp": "00:14:21,098", "timestamp_s": 861.0}, {"text": "This is typically done leveraging Kubernetes APIs to", "timestamp": "00:14:24,068", "timestamp_s": 864.0}, {"text": "set the new value to the parameters, for example the CPU request.", "timestamp": "00:14:27,528", "timestamp_s": 867.0}, {"text": "The second step is to apply a workload to the target system", "timestamp": "00:14:31,910", "timestamp_s": 871.0}, {"text": "in order to assess the performance of the new configuration.", "timestamp": "00:14:35,304", "timestamp_s": 875.0}, {"text": "This is usually done by leveraging performance testing tools.", "timestamp": "00:14:38,970", "timestamp_s": 878.0}, {"text": "In this case, we use a geneter test that was already available to", "timestamp": "00:14:42,434", "timestamp_s": 882.0}, {"text": "stress the application with a realistic workload.", "timestamp": "00:14:46,012", "timestamp_s": 886.0}, {"text": "The first step is to collect KPIs related to the target", "timestamp": "00:14:49,550", "timestamp_s": 889.0}, {"text": "system. The typical approach here is to leverage observability", "timestamp": "00:14:53,382", "timestamp_s": 893.0}, {"text": "tools. In this case, we integrated elastic APM,", "timestamp": "00:14:57,414", "timestamp_s": 897.0}, {"text": "which is the monitoring solution used by these customer.", "timestamp": "00:15:00,774", "timestamp_s": 900.0}, {"text": "The fourth step is to analyze the result of the performance test", "timestamp": "00:15:03,730", "timestamp_s": 903.0}, {"text": "and assign a score based on the specific goal that you have defined.", "timestamp": "00:15:07,444", "timestamp_s": 907.0}, {"text": "In this case, the score is simply the cost of running the application", "timestamp": "00:15:11,386", "timestamp_s": 911.0}, {"text": "containers. Considering the prices of azure cloud.", "timestamp": "00:15:14,968", "timestamp_s": 914.0}, {"text": "The last step is where the machine learning kicks in by taking", "timestamp": "00:15:18,550", "timestamp_s": 918.0}, {"text": "the score of the tested configurations as input and producing as", "timestamp": "00:15:22,216", "timestamp_s": 922.0}, {"text": "an output the most promising configuration to be tested in the", "timestamp": "00:15:26,008", "timestamp_s": 926.0}, {"text": "next iteration. In a relatively short amount of", "timestamp": "00:15:29,308", "timestamp_s": 929.0}, {"text": "time, the ML algorithm learns the dependencies between the configuration", "timestamp": "00:15:32,828", "timestamp_s": 932.0}, {"text": "parameters and the system behavior. Though identifying better and", "timestamp": "00:15:36,642", "timestamp_s": 936.0}, {"text": "better configurations. It\u0027s worth noticing that the whole optimization", "timestamp": "00:15:40,752", "timestamp_s": 940.0}, {"text": "process becomes completely automated.", "timestamp": "00:15:44,710", "timestamp_s": 944.0}, {"text": "So what are we getting as an output of the MLbase optimization?", "timestamp": "00:15:49,070", "timestamp_s": 949.0}, {"text": "The main result is the best configuration of the software stack parameters", "timestamp": "00:15:53,970", "timestamp_s": 953.0}, {"text": "that maximizing or minimize the goal we have defined.", "timestamp": "00:15:57,866", "timestamp_s": 957.0}, {"text": "These parameters can be then applied in production environments,", "timestamp": "00:16:01,530", "timestamp_s": 961.0}, {"text": "but the value this methodology can bring is actually much", "timestamp": "00:16:05,830", "timestamp_s": 965.0}, {"text": "higher. Amal will evaluate many different configurations", "timestamp": "00:16:09,576", "timestamp_s": 969.0}, {"text": "of the system, which can reveal important insights about the overall", "timestamp": "00:16:13,262", "timestamp_s": 973.0}, {"text": "system behavior in terms of other KPIs like cost, performance or", "timestamp": "00:16:17,266", "timestamp_s": 977.0}, {"text": "resiliency. These supports performance engineers and", "timestamp": "00:16:21,452", "timestamp_s": 981.0}, {"text": "developers in their decision on how to best configure these application to", "timestamp": "00:16:25,228", "timestamp_s": 985.0}, {"text": "maximizing the specific goals. So,", "timestamp": "00:16:29,152", "timestamp_s": 989.0}, {"text": "to assess the performance and cost efficiency of a new configuration suggested", "timestamp": "00:16:32,592", "timestamp_s": 992.0}, {"text": "by the ML optimizer. We stress the system with these load", "timestamp": "00:16:36,358", "timestamp_s": 996.0}, {"text": "test here you can see the load test scenario that we use just", "timestamp": "00:16:39,542", "timestamp_s": 999.0}, {"text": "designed according to the performance engineering best practices.", "timestamp": "00:16:43,488", "timestamp_s": 1003.0}, {"text": "The traffic pattern mimicked the behavior seen in production,", "timestamp": "00:16:46,730", "timestamp_s": 1006.0}, {"text": "including API call distribution and sync times.", "timestamp": "00:16:50,298", "timestamp_s": 1010.0}, {"text": "Before looking at the results, it\u0027s worth commenting on the application", "timestamp": "00:16:54,470", "timestamp_s": 1014.0}, {"text": "on how the application was initially configured by the customer.", "timestamp": "00:16:58,472", "timestamp_s": 1018.0}, {"text": "We call this these baseline configuration. Let\u0027s look", "timestamp": "00:17:02,168", "timestamp_s": 1022.0}, {"text": "at the Kubernetes settings first. The container powering these", "timestamp": "00:17:06,268", "timestamp_s": 1026.0}, {"text": "application was configured with resource requests of 1.5 cpus", "timestamp": "00:17:10,172", "timestamp_s": 1030.0}, {"text": "and 3.42gb of memory. The team also", "timestamp": "00:17:14,498", "timestamp_s": 1034.0}, {"text": "specified resource limits of two cpus and", "timestamp": "00:17:18,140", "timestamp_s": 1038.0}, {"text": "4.39gb of memory. Remember,", "timestamp": "00:17:21,696", "timestamp_s": 1041.0}, {"text": "the requests are the guaranteed resource that kubernetes", "timestamp": "00:17:25,328", "timestamp_s": 1045.0}, {"text": "will use for scheduling and capacity management of the cluster.", "timestamp": "00:17:28,838", "timestamp_s": 1048.0}, {"text": "In this case, requests are lower than the limit.", "timestamp": "00:17:32,690", "timestamp_s": 1052.0}, {"text": "This is a common approach to guarantee resources for the application", "timestamp": "00:17:36,170", "timestamp_s": 1056.0}, {"text": "to run properly, but at the same time allow for some room", "timestamp": "00:17:39,380", "timestamp_s": 1059.0}, {"text": "for unexpected growth.", "timestamp": "00:17:43,544", "timestamp_s": 1063.0}, {"text": "Besides looking at the container settings, it\u0027s important to also see", "timestamp": "00:17:46,710", "timestamp_s": 1066.0}, {"text": "how the application runtime is configured. The runtime is", "timestamp": "00:17:50,344", "timestamp_s": 1070.0}, {"text": "what ultimately powers our application, and for Java apps", "timestamp": "00:17:53,848", "timestamp_s": 1073.0}, {"text": "we know that JVM settings play a big role in app", "timestamp": "00:17:57,650", "timestamp_s": 1077.0}, {"text": "performance, but the same happens for goaling applications.", "timestamp": "00:18:01,356", "timestamp_s": 1081.0}, {"text": "For example, the JVM was configured with a minimum", "timestamp": "00:18:04,962", "timestamp_s": 1084.0}, {"text": "cheap of half a gig and a max heap of 4gb.", "timestamp": "00:18:08,578", "timestamp_s": 1088.0}, {"text": "Notice that the max heap is higher than the memory results,", "timestamp": "00:18:12,678", "timestamp_s": 1092.0}, {"text": "which means that the JVM can use more memory than the amount", "timestamp": "00:18:16,454", "timestamp_s": 1096.0}, {"text": "requested. As we\u0027re going to see, this configuration will have", "timestamp": "00:18:20,016", "timestamp_s": 1100.0}, {"text": "an impact on how the application behaves under load and the associated", "timestamp": "00:18:23,828", "timestamp_s": 1103.0}, {"text": "resiliency and costs.", "timestamp": "00:18:27,722", "timestamp_s": 1107.0}, {"text": "It\u0027s worth noting that these customer also defined autoscaling", "timestamp": "00:18:31,410", "timestamp_s": 1111.0}, {"text": "policies for this application, leveraging the Ka autoscaling", "timestamp": "00:18:34,938", "timestamp_s": 1114.0}, {"text": "project for kubernetes in their environment,", "timestamp": "00:18:38,478", "timestamp_s": 1118.0}, {"text": "both cpu and memory were defined as scalers with", "timestamp": "00:18:42,286", "timestamp_s": 1122.0}, {"text": "a triggering threshold of 70% and 90% utilization,", "timestamp": "00:18:46,168", "timestamp_s": 1126.0}, {"text": "respectively. What is important to keep in mind is", "timestamp": "00:18:50,002", "timestamp_s": 1130.0}, {"text": "that such utilization percentage are related to the resource request,", "timestamp": "00:18:53,228", "timestamp_s": 1133.0}, {"text": "not limits. So as you can see in the diagram on", "timestamp": "00:18:57,010", "timestamp_s": 1137.0}, {"text": "the right can action to scale out the application will happen,", "timestamp": "00:19:00,368", "timestamp_s": 1140.0}, {"text": "for example when the cpu usage will got above one", "timestamp": "00:19:03,840", "timestamp_s": 1143.0}, {"text": "core. Okay, we\u0027ve covered how the", "timestamp": "00:19:07,296", "timestamp_s": 1147.0}, {"text": "application is configured. Let\u0027s now look at the behavior of the application when", "timestamp": "00:19:10,672", "timestamp_s": 1150.0}, {"text": "subject to the load test we\u0027ve shown before with the baseline configuration.", "timestamp": "00:19:14,996", "timestamp_s": 1154.0}, {"text": "In this chart you can see the application throughput response time and the", "timestamp": "00:19:19,578", "timestamp_s": 1159.0}, {"text": "number of replicas that were created by the autoscaling.", "timestamp": "00:19:23,268", "timestamp_s": 1163.0}, {"text": "Two facts are important to notice. When the load increases, the autoscaling", "timestamp": "00:19:26,870", "timestamp_s": 1166.0}, {"text": "triggers a scaleout event which creates a new replica.", "timestamp": "00:19:31,438", "timestamp_s": 1171.0}, {"text": "This event causes a big spike on response time which impacts", "timestamp": "00:19:35,118", "timestamp_s": 1175.0}, {"text": "service reliability and performance. This is due to the", "timestamp": "00:19:38,882", "timestamp_s": 1178.0}, {"text": "high cpu usage and throttling during the JVM startup.", "timestamp": "00:19:42,348", "timestamp_s": 1182.0}, {"text": "When the load drops, the number of replicas does not scale down.", "timestamp": "00:19:47,130", "timestamp_s": 1187.0}, {"text": "Despite these, container cpu usage is idle.", "timestamp": "00:19:50,896", "timestamp_s": 1190.0}, {"text": "It\u0027s interesting to understand why this is happening. This is", "timestamp": "00:19:54,830", "timestamp_s": 1194.0}, {"text": "caused by the configuration of the container resource, the JVM", "timestamp": "00:19:58,912", "timestamp_s": 1198.0}, {"text": "tuning inside, and these autoscaler policies in particular for the", "timestamp": "00:20:02,378", "timestamp_s": 1202.0}, {"text": "memory resources. The autoscaler in this case", "timestamp": "00:20:06,228", "timestamp_s": 1206.0}, {"text": "is not scaling down because the memory usage of the container is", "timestamp": "00:20:09,972", "timestamp_s": 1209.0}, {"text": "higher than these configured threshold of 70% usage with", "timestamp": "00:20:14,020", "timestamp_s": 1214.0}, {"text": "respect to the memory requests. These might be due to the JDM", "timestamp": "00:20:17,832", "timestamp_s": 1217.0}, {"text": "Max heap being higher than the memory request we\u0027ve seen", "timestamp": "00:20:21,502", "timestamp_s": 1221.0}, {"text": "before, but it max also be due to a", "timestamp": "00:20:24,696", "timestamp_s": 1224.0}, {"text": "change in the application memory footprint, for example due to a new", "timestamp": "00:20:27,804", "timestamp_s": 1227.0}, {"text": "application release. This effect clearly impacts the", "timestamp": "00:20:31,132", "timestamp_s": 1231.0}, {"text": "cloud build as more instances are up and running than", "timestamp": "00:20:34,748", "timestamp_s": 1234.0}, {"text": "required. But slos that configuring Kubernetes apps", "timestamp": "00:20:38,336", "timestamp_s": 1238.0}, {"text": "for reliability and cost efficiency is actually a tricky process.", "timestamp": "00:20:42,294", "timestamp_s": 1242.0}, {"text": "Let\u0027s now have a look at the best configuration identified by ML", "timestamp": "00:20:46,670", "timestamp_s": 1246.0}, {"text": "with respect to the defined cost efficiency goal.", "timestamp": "00:20:50,486", "timestamp_s": 1250.0}, {"text": "This was found at experiment number 34 after", "timestamp": "00:20:53,658", "timestamp_s": 1253.0}, {"text": "about 19 hours and almost half the cost of", "timestamp": "00:20:56,916", "timestamp_s": 1256.0}, {"text": "running the application with respect to the baseline.", "timestamp": "00:21:00,692", "timestamp_s": 1260.0}, {"text": "First of all, it\u0027s interesting to notice how our", "timestamp": "00:21:03,910", "timestamp_s": 1263.0}, {"text": "MLbase optimization increased both memory and cpu", "timestamp": "00:21:07,064", "timestamp_s": 1267.0}, {"text": "results and limits, which is not at all obvious and", "timestamp": "00:21:10,782", "timestamp_s": 1270.0}, {"text": "may seem at first counterintuitive, especially as Kubernetes is", "timestamp": "00:21:14,312", "timestamp_s": 1274.0}, {"text": "often considered well suited for small and highly scalable", "timestamp": "00:21:18,188", "timestamp_s": 1278.0}, {"text": "applications. The other notable changes are related to the", "timestamp": "00:21:21,602", "timestamp_s": 1281.0}, {"text": "JVM options. The max cheap size was increased by 20% and is", "timestamp": "00:21:25,388", "timestamp_s": 1285.0}, {"text": "now well within the container memory request, which was increased", "timestamp": "00:21:29,228", "timestamp_s": 1289.0}, {"text": "to five gigabyte. The min heap size has also", "timestamp": "00:21:32,358", "timestamp_s": 1292.0}, {"text": "been adjusted to be almost equal to the max cheap, which is a configuration", "timestamp": "00:21:35,712", "timestamp_s": 1295.0}, {"text": "that can avoid garbage collection cycles, especially in the startup", "timestamp": "00:21:39,638", "timestamp_s": 1299.0}, {"text": "phase of JVM. So let\u0027s now see how", "timestamp": "00:21:43,322", "timestamp_s": 1303.0}, {"text": "the application performs with the new configuration identified by ML", "timestamp": "00:21:46,948", "timestamp_s": 1306.0}, {"text": "and how it compares with respect to the baseline. There are two important differences", "timestamp": "00:21:50,906", "timestamp_s": 1310.0}, {"text": "here. Results time always remain within the Hasselo", "timestamp": "00:21:55,370", "timestamp_s": 1315.0}, {"text": "and there are no more picks. So these configuration got only improves", "timestamp": "00:21:59,450", "timestamp_s": 1319.0}, {"text": "on cost, but it\u0027s also beneficial in terms of performance", "timestamp": "00:22:03,422", "timestamp_s": 1323.0}, {"text": "and resilience. Autoscaling is not triggering these", "timestamp": "00:22:07,026", "timestamp_s": 1327.0}, {"text": "configuration as the full load is sustained by just one pod.", "timestamp": "00:22:10,652", "timestamp_s": 1330.0}, {"text": "These is clearly beneficial in terms of costs.", "timestamp": "00:22:14,642", "timestamp_s": 1334.0}, {"text": "Let\u0027s also compare in detail the best configuration with respect to", "timestamp": "00:22:18,018", "timestamp_s": 1338.0}, {"text": "the baseline. These we can notice that the pod is significantly", "timestamp": "00:22:21,728", "timestamp_s": 1341.0}, {"text": "larger in terms of both cpu and memory, especially for", "timestamp": "00:22:25,814", "timestamp_s": 1345.0}, {"text": "the requests. This configuration has the effect of triggering the auto", "timestamp": "00:22:29,248", "timestamp_s": 1349.0}, {"text": "scaler less often, as we have seen, but interestingly and", "timestamp": "00:22:33,178", "timestamp_s": 1353.0}, {"text": "somewhat counterintuitively, while this implies a kind of a", "timestamp": "00:22:37,396", "timestamp_s": 1357.0}, {"text": "fixed cost considering the prices of the container resource,", "timestamp": "00:22:40,564", "timestamp_s": 1360.0}, {"text": "it turns out being much cheap than a configuration where autoscaling", "timestamp": "00:22:44,870", "timestamp_s": 1364.0}, {"text": "is triggered, and this also avoids performance issues.", "timestamp": "00:22:49,038", "timestamp_s": 1369.0}, {"text": "The container and runtime configuration are now better aligned.", "timestamp": "00:22:52,696", "timestamp_s": 1372.0}, {"text": "The JVM max is now below the memory request and", "timestamp": "00:22:56,654", "timestamp_s": 1376.0}, {"text": "has a beneficial effect as it also enables the scaled down", "timestamp": "00:23:00,092", "timestamp_s": 1380.0}, {"text": "of the application should the scaling be triggered by higher loads.", "timestamp": "00:23:03,708", "timestamp_s": 1383.0}, {"text": "Let\u0027s now have a look at another configuration found by ML", "timestamp": "00:23:08,034", "timestamp_s": 1388.0}, {"text": "at experiment number 14. After about 8 hours", "timestamp": "00:23:12,230", "timestamp_s": 1392.0}, {"text": "of automated optimization, we leveled this configuration high", "timestamp": "00:23:16,000", "timestamp_s": 1396.0}, {"text": "reliability for a reason that we will be clear in a minute.", "timestamp": "00:23:20,096", "timestamp_s": 1400.0}, {"text": "The score for this configuration, while not as good as the best configurations,", "timestamp": "00:23:24,370", "timestamp_s": 1404.0}, {"text": "also provided about 60% cost reduction.", "timestamp": "00:23:28,858", "timestamp_s": 1408.0}, {"text": "So this can be considered also an interesting configuration with", "timestamp": "00:23:31,818", "timestamp_s": 1411.0}, {"text": "respect to the cost efficiency goal as regards to the parameters.", "timestamp": "00:23:34,948", "timestamp_s": 1414.0}, {"text": "What is worth noticing is that this time ML picked", "timestamp": "00:23:39,230", "timestamp_s": 1419.0}, {"text": "settings that significantly change the shape of the container.", "timestamp": "00:23:42,478", "timestamp_s": 1422.0}, {"text": "It now has a much smaller cpu request with respect to the", "timestamp": "00:23:46,366", "timestamp_s": 1426.0}, {"text": "baseline, but the memory is still pretty large, which is", "timestamp": "00:23:49,644", "timestamp_s": 1429.0}, {"text": "pretty interesting. The JVM options were", "timestamp": "00:23:53,388", "timestamp_s": 1433.0}, {"text": "also changed. In particular, the Galbridge collector was", "timestamp": "00:23:56,732", "timestamp_s": 1436.0}, {"text": "switched to parallel, which is a collector that can be much", "timestamp": "00:24:00,288", "timestamp_s": 1440.0}, {"text": "more efficient on the use of cpu and memory.", "timestamp": "00:24:03,696", "timestamp_s": 1443.0}, {"text": "Let\u0027s compare the behavior of this configuration with respect to the baseline.", "timestamp": "00:24:07,870", "timestamp_s": 1447.0}, {"text": "There are two important differences here. The peak on the response", "timestamp": "00:24:11,862", "timestamp_s": 1451.0}, {"text": "time upon the scaling out is significantly lower. It\u0027s still", "timestamp": "00:24:15,258", "timestamp_s": 1455.0}, {"text": "higher than the response time slo. However, the peak is", "timestamp": "00:24:19,092", "timestamp_s": 1459.0}, {"text": "less than half the value of the baseline configuration.", "timestamp": "00:24:22,532", "timestamp_s": 1462.0}, {"text": "This clearly improves the service resilience.", "timestamp": "00:24:25,710", "timestamp_s": 1465.0}, {"text": "Autoscaling works properly after the high load phase", "timestamp": "00:24:28,790", "timestamp_s": 1468.0}, {"text": "replicarves are scaled back to one. Its behavior is what we expect from", "timestamp": "00:24:32,526", "timestamp_s": 1472.0}, {"text": "an autoscaling system that works properly. Notice the response time", "timestamp": "00:24:36,568", "timestamp_s": 1476.0}, {"text": "picks could also be further reduced. It would simply", "timestamp": "00:24:40,252", "timestamp_s": 1480.0}, {"text": "be a matter of creating a new optimization with the goal of minimizing", "timestamp": "00:24:44,082", "timestamp_s": 1484.0}, {"text": "these response time matrix instead of the application cost.", "timestamp": "00:24:47,778", "timestamp_s": 1487.0}, {"text": "Let\u0027s now also companies in detail the high resilience configuration", "timestamp": "00:24:51,152", "timestamp_s": 1491.0}, {"text": "with respect to the baseline. Quite interestingly,", "timestamp": "00:24:55,126", "timestamp_s": 1495.0}, {"text": "these configuration has a higher memory request and lower cpu results,", "timestamp": "00:24:58,006", "timestamp_s": 1498.0}, {"text": "but higher limits than the baseline. As you may remember,", "timestamp": "00:25:02,250", "timestamp_s": 1502.0}, {"text": "the lowest cost configuration instead had a higher cpu request than", "timestamp": "00:25:05,924", "timestamp_s": 1505.0}, {"text": "the baseline. Without getting into much details in the analysis", "timestamp": "00:25:09,748", "timestamp_s": 1509.0}, {"text": "of this specific configuration, what these facts show is", "timestamp": "00:25:13,802", "timestamp_s": 1513.0}, {"text": "that as the optimization goal changes, cpu and memory", "timestamp": "00:25:17,412", "timestamp_s": 1517.0}, {"text": "results and limits may need to be increased or decreased.", "timestamp": "00:25:21,198", "timestamp_s": 1521.0}, {"text": "That multiple parameters at Kubernetes and JVM", "timestamp": "00:25:24,782", "timestamp_s": 1524.0}, {"text": "levels also need to be tune accordingly.", "timestamp": "00:25:28,386", "timestamp_s": 1528.0}, {"text": "This is a clear confirmation of the perceived complexity of", "timestamp": "00:25:31,458", "timestamp_s": 1531.0}, {"text": "tuning Kubernetes microservices application,", "timestamp": "00:25:35,052", "timestamp_s": 1535.0}, {"text": "as here we are just discussing one microservice out of hundreds", "timestamp": "00:25:38,090", "timestamp_s": 1538.0}, {"text": "or more of today applications. There are many other interesting", "timestamp": "00:25:42,226", "timestamp_s": 1542.0}, {"text": "configurations found by ML that we would like to discuss,", "timestamp": "00:25:46,464", "timestamp_s": 1546.0}, {"text": "but I think it\u0027s time to conclude with our takeaways.", "timestamp": "00:25:50,240", "timestamp_s": 1550.0}, {"text": "Our first takeaway is that when tuning the modern applications,", "timestamp": "00:25:53,730", "timestamp_s": 1553.0}, {"text": "the interplay between different application layers and technologies require", "timestamp": "00:25:57,306", "timestamp_s": 1557.0}, {"text": "tuning the full stack configuration to make sure", "timestamp": "00:26:01,722", "timestamp_s": 1561.0}, {"text": "that both the optimization goal and slos are", "timestamp": "00:26:05,096", "timestamp_s": 1565.0}, {"text": "matched, as we\u0027ve seen in our real world example. A second takeaway", "timestamp": "00:26:08,312", "timestamp_s": 1568.0}, {"text": "is that the complexity of this application under varied workloads and", "timestamp": "00:26:12,590", "timestamp_s": 1572.0}, {"text": "in a context of frequent releases with agile practices", "timestamp": "00:26:16,492", "timestamp_s": 1576.0}, {"text": "requires a continuous performance tuning process. Developers cannot", "timestamp": "00:26:19,906", "timestamp_s": 1579.0}, {"text": "simply rely on manual tuning or utilization based autoscaling", "timestamp": "00:26:23,842", "timestamp_s": 1583.0}, {"text": "mechanisms. Finally, in order to explore", "timestamp": "00:26:27,602", "timestamp_s": 1587.0}, {"text": "the vastness of the space of possible configuration in a cost", "timestamp": "00:26:30,914", "timestamp_s": 1590.0}, {"text": "and time efficient way, it\u0027s mandatory to leverage Mlbased methods", "timestamp": "00:26:34,732", "timestamp_s": 1594.0}, {"text": "that can automatically converge to optimal configuration within hours", "timestamp": "00:26:39,026", "timestamp_s": 1599.0}, {"text": "without requiring deep knowledge of all the underlying technologies.", "timestamp": "00:26:43,428", "timestamp_s": 1603.0}, {"text": "Many thanks for your time. I hope you enjoyed the talk. Please reach", "timestamp": "00:26:47,450", "timestamp_s": 1607.0}, {"text": "out to me if you have found this talk interesting. I would love to share", "timestamp": "00:26:51,012", "timestamp_s": 1611.0}, {"text": "more details and hear your Kubernetes challenges.", "timestamp": "00:26:54,292", "timestamp_s": 1614.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: '31Gw8UoYVbU',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              Cheap or Fast? How we got both by leveraging ML to automatically tune K8s apps
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>After all these years, the task of tuning Kubernetes microservice applications is a daunting task even for experienced Performance Engineers and SREs, often resulting in companies facing reliability and performance issues, as well as unexpected costs. </p>
<p>In this session, we plan to first illustrate some less-known facts about Kubernetes key resource management and autoscaling mechanisms and show how properly setting pod resources and autoscaling policies is critical to avoid over-provisioning while ensuring services deliver the expected performance and resilience. </p>
<p>We then demonstrate how a new approach leveraging ML techniques makes it possible to automatically tune both pod and runtime configurations to ensure any specified optimization goal, such as minimizing Kubernetes cost or maximizing application throughput, while respecting any SLOs, such as max response time and error rates. 
Results of real-world cases will be used to document how much this new approach can be effective to deliver higher operational efficiency tangible benefits.</p>
<!-- End Text -->
          </div>

          
          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
              <li>
                In the next 20 minutes or so I'll share with you some of our experiences in tuning applications running on kubernetes. We'll start by identifying some challenges of modern applications for ensuring performance and reliability. Finally, we will conclude by sharing some takeaways.

              </li>
              
              <li>
                Giovanni Paolo Gibilisco is head of engineering at Akamas. Many teams struggle with Kubernetes application performance and stability. Why is it so difficult to manage application performance, stability and efficiency on Kuber netes?

              </li>
              
              <li>
                Kubernetes resource management works to better understand the main parameters that impact Kubernetes application performance, stability and cost efficiency. Let's go through five main key aspects and their implications.

              </li>
              
              <li>
                Cpu limits exist to bound the amount of resources a container can consume. These aggressive cpu throttling has a huge impact on service performance. Properly setting your cpu requests and limits is critical to ensuring your Kubernetes cluster remains stable and efficient over time. A new approach is required to successfully solve this problem using machine learning.

              </li>
              
              <li>
                The ML Tower optimization process is fully automated and works in five sres. The first step is to apply the new configurations suggested by the ML algorithms to our target system. The main result is the best configuration of the software stack parameters that maximizing or minimize the goal we have defined.

              </li>
              
              <li>
                Another configuration found by ML at experiment number 14. This time ML picked settings that significantly change the shape of the container. The peak on the response time upon the scaling out is significantly lower. This clearly improves the service resilience. As the optimization goal changes, results and limits may need to be increased or decreased.

              </li>
              
              <li>
                When tuning the modern applications, the interplay between different application layers and technologies require tuning the full stack configuration. Developers cannot simply rely on manual tuning or utilization based autoscaling mechanisms. Mlbased methods can automatically converge to optimal configuration within hours.
              </li>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./assemblyai/31Gw8UoYVbU.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:01:28,770'); seek(88.0)">
              This is Giovannijilisko and in the next 20 minutes or so I'll
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:01:32,418'); seek(92.0)">
              share with you some of our experiences in tuning applications running
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:01:36,060'); seek(96.0)">
              on kubernetes. These are the contents that
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:01:39,308'); seek(99.0)">
              we will cover. We'll start by identifying some challenges
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:01:43,050'); seek(103.0)">
              of modern applications for ensuring performance and reliability.
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:01:47,418'); seek(107.0)">
              We'll then review how Kubernetes manages container
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:01:50,842'); seek(110.0)">
              resources and the factors we need to be aware of if we want
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:01:54,424'); seek(114.0)">
              to ensure high performance and cost efficiency.
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:01:57,438'); seek(117.0)">
              We will introduce a new approach we implemented at Akamas,
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:02:01,070'); seek(121.0)">
              which leverages machine learning to automate the optimization process,
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:02:04,776'); seek(124.0)">
              and we will do that with a real world example.
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:02:08,090'); seek(128.0)">
              Finally, we will conclude by sharing some takeaways.
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:02:11,770'); seek(131.0)">
              Before proceeding, let me introduce myself. My name Giovanni Paolo
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:02:15,474'); seek(135.0)">
              Gibilisco and I serve as head of engineering at Akamas.
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:02:19,010'); seek(139.0)">
              Okay, let's start with a quick overview of some of the main challenges that
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:02:23,232'); seek(143.0)">
              comes with the development of modern applications. The advent of
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:02:26,912'); seek(146.0)">
              agile practices allowed developers to speed up the development cycle
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:02:31,018'); seek(151.0)">
              with the goal of getting rapid feedback and iteratively
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:02:34,458'); seek(154.0)">
              improve applications. Though increasing the release frequency,
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:02:38,410'); seek(158.0)">
              it's now common to see applications, or part of them,
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:02:41,540'); seek(161.0)">
              released to production weekly or even daily. At the same time,
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:02:45,496'); seek(165.0)">
              the underlying frameworks and runtimes, such as the JVM
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:02:49,454'); seek(169.0)">
              that are used to build those applications, have grown in complexity.
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:02:53,670'); seek(173.0)">
              The emergence of architectural patterns such as microservices
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:02:58,002'); seek(178.0)">
              have also brought an increase in the number of frameworks and technologies
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:03:02,178'); seek(182.0)">
              used within a single application. It's now common to
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:03:05,548'); seek(185.0)">
              see application composed by tens or even hundreds of services,
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:03:09,184'); seek(189.0)">
              written in different languages and interacting with multiple
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:03:13,142'); seek(193.0)">
              runtimes and databases. Kubernetes provides a
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:03:16,368'); seek(196.0)">
              great platform to run such applications, but it has its
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:03:19,792'); seek(199.0)">
              own complexities. These Kubernetes
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:03:23,146'); seek(203.0)">
              failure stories is a website specifically created
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:03:26,394'); seek(206.0)">
              to share incident reports in order to allow the community
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:03:29,908'); seek(209.0)">
              to learn from failures and prevent them for further
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:03:33,438'); seek(213.0)">
              happening. Many of these stories describe teams struggling with
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:03:37,512'); seek(217.0)">
              Kubernetes application performance and stability issues such
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:03:41,192'); seek(221.0)">
              as unexpected cpu's, loaddowns and even sudden container
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:03:45,118'); seek(225.0)">
              terminations. Engineers at Airbnb even got
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:03:48,508'); seek(228.0)">
              to the point of suggesting that Kubernetes may actually hurt the
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:03:52,508'); seek(232.0)">
              performance of latency sensitive applications. But why
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:03:56,572'); seek(236.0)">
              it's so difficult to manage application performance, stability and efficiency
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:04:00,582'); seek(240.0)">
              on Kubernetes? The simple answer is that Kubernetes is a
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:04:03,984'); seek(243.0)">
              glaze platform to run containerized applications, but it requires
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:04:07,942'); seek(247.0)">
              applications to be carefully configured to ensure high performance
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:04:11,722'); seek(251.0)">
              and stability, as we're going to see. To answer
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:04:15,396'); seek(255.0)">
              this question, let's now get back to the fundamentals and see how Kubernetes
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:04:19,530'); seek(259.0)">
              resource management works to better understand the
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:04:23,272'); seek(263.0)">
              main parameters that impact Kubernetes application performance,
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:04:26,654'); seek(266.0)">
              stability and cost efficiency. Let's go through
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:04:29,880'); seek(269.0)">
              five main key aspects and their implications.
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:04:33,430'); seek(273.0)">
              The first important concept is resource requests.
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:04:37,442'); seek(277.0)">
              When a developer is defined pod, she has the possibility to
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:04:40,972'); seek(280.0)">
              specify resource results. These are the amount of cpu
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:04:44,962'); seek(284.0)">
              and memory the pod or better, a container within the pod
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:04:48,950'); seek(288.0)">
              is guaranteed to get. Kubernetes will schedule
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:04:52,758'); seek(292.0)">
              the pod on a node where the requested resources are
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:04:56,192'); seek(296.0)">
              actually available. In this example,
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:04:58,864'); seek(298.0)">
              pod a acquires two cpus and is scheduled on a
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:05:02,836'); seek(302.0)">
              four cpu node. When a new pod b on the
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:05:05,924'); seek(305.0)">
              same side is created, it can also be scheduled on
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:05:09,204'); seek(309.0)">
              the same node. This node now has all of its four
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:05:13,172'); seek(313.0)">
              cpus requested. If a pod c is created,
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:05:16,718'); seek(316.0)">
              Kubernetes won't schedule it on the same node as its
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:05:20,568'); seek(320.0)">
              capacity is full. This means that those numbers these developers
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:05:24,430'); seek(324.0)">
              specify in the deployment yaml are directly affect the
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:05:28,268'); seek(328.0)">
              cluster capacity. A strong difference with respect to virtualization
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:05:32,482'); seek(332.0)">
              and hypervisors is that with Kubernetes there is
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:05:36,092'); seek(336.0)">
              no overcommitment on the requests. You cannot request more
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:05:40,160'); seek(340.0)">
              cpus than those available in the cluster.
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:05:42,982'); seek(342.0)">
              Another important aspect is that resource requests are
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:05:46,832'); seek(346.0)">
              not equal to utilization. If pod requests are
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:05:50,832'); seek(350.0)">
              much higher than the actual resource usage, you might end up with these cluster
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:05:54,538'); seek(354.0)">
              that is at full capacity even though its cpu utilization is
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:05:58,212'); seek(358.0)">
              only 10%. So the takeaway
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:06:01,642'); seek(361.0)">
              here is that setting proper pod request is
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:06:04,712'); seek(364.0)">
              paramount to ensure Kubernetes cost efficiency. The second
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:06:08,296'); seek(368.0)">
              important concept is resource limits.
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:06:12,230'); seek(372.0)">
              Resource requests are guaranteed resources that
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:06:15,624'); seek(375.0)">
              a container will get, but usage can be higher.
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:06:19,388'); seek(379.0)">
              Resource limits is the mechanisms that allows you to define
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:06:23,058'); seek(383.0)">
              the maximum amount of resources that a container can use,
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:06:26,860'); seek(386.0)">
              like two cpus or 1gb of memory.
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:06:30,730'); seek(390.0)">
              All this is great, but what happens when resource usage hits
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:06:34,982'); seek(394.0)">
              the limit? Kubernetes treat cpu and memory
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:06:38,166'); seek(398.0)">
              differently here. When a cpu usage approaches the limit,
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:06:41,546'); seek(401.0)">
              the container gets throttled. This means that these cpu is artificially
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:06:45,610'); seek(405.0)">
              restricted and this usually results in application performance
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:06:49,642'); seek(409.0)">
              issues. Instead, when memory usage hits the limit,
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:06:53,374'); seek(413.0)">
              the container gets terminated, so there is no application
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:06:56,888'); seek(416.0)">
              slowdown due to paging or swapping as we had in traditional
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:07:00,446'); seek(420.0)">
              operating systems. With the Kubernetes your pod will
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:07:04,008'); seek(424.0)">
              simply disappear and you may face serious application stability
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:07:08,274'); seek(428.0)">
              issues. The third fact is about an important and less
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:07:12,076'); seek(432.0)">
              known effect that cpu limits have on application performance.
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:07:16,450'); seek(436.0)">
              We have seen that cpu limits called throttling and you may think that
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:07:20,336'); seek(440.0)">
              this happens only when cpu usage hits the limit.
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:07:23,990'); seek(443.0)">
              Surprisingly, the reality is that cpu throttling starts
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:07:27,398'); seek(447.0)">
              even when cpu usage is well below the limit. We did
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:07:31,232'); seek(451.0)">
              quite a bit of research on this aspect in our labs and found
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:07:34,964'); seek(454.0)">
              that cpu throttling start when cpu usage is as
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:07:38,372'); seek(458.0)">
              low as 30% of the limit. This is due
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:07:41,914'); seek(461.0)">
              to a particular way cpu limits are implemented at the Linux kernel level.
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:07:46,184'); seek(466.0)">
              These aggressive cpu throttling has a huge impact on
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:07:49,832'); seek(469.0)">
              service performance. You can get sudden latency spikes
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:07:53,630'); seek(473.0)">
              that may breach your slos without any apparent reason,
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:07:57,116'); seek(477.0)">
              even at low cpu usage. Now, some people,
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:08:00,764'); seek(480.0)">
              including engineers at buffers, tried to remove cpu limits.
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:08:04,626'); seek(484.0)">
              What these got was an impressive reduction of service latency.
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:08:08,578'); seek(488.0)">
              So is it a good idea to get rid of cpu limits?
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:08:13,310'); seek(493.0)">
              Apparently not. Cpu limits exist to
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:08:16,608'); seek(496.0)">
              bound the amount of resources a container can consume.
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:08:20,290'); seek(500.0)">
              This allows many containers to coexist without competing
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:08:23,898'); seek(503.0)">
              for the same resources. So if cpu limits are
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:08:27,268'); seek(507.0)">
              removed, a single Runway container can disrupt the performance
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:08:30,938'); seek(510.0)">
              and availability of your most critical services.
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:08:34,392'); seek(514.0)">
              It might also make the Kubelet service unresponsive and effectively
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:08:38,590'); seek(518.0)">
              remove the entire node from the cluster using
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:08:41,896'); seek(521.0)">
              cpu limits. Is these best practice also recommended by Google?
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:08:45,884'); seek(525.0)">
              Properly setting your cpu requests and limits is critical
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:08:49,426'); seek(529.0)">
              to ensuring your Kubernetes cluster remains stable and efficient
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:08:52,802'); seek(532.0)">
              over time. To ease the management of
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:08:56,572'); seek(536.0)">
              limits and requests for many services, Kubernetes comes with
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:08:59,808'); seek(539.0)">
              autoscaling. Let's discuss built in autoscaling
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:09:03,558'); seek(543.0)">
              capabilities that are often considered as a way to automate this
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:09:06,992'); seek(546.0)">
              process. In particular, the vertical pod autoscaler
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:09:10,854'); seek(550.0)">
              or VPA provides recommended cpu and memory requests
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:09:15,130'); seek(555.0)">
              based on the observed pod resource usage.
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:09:18,330'); seek(558.0)">
              However, our experience with a VPA is mixed.
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:09:21,994'); seek(561.0)">
              In this example, a Kubernetes microservice is serving a typical
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:09:25,546'); seek(565.0)">
              dernel traffic pattern. The top left chart shows the
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:09:29,064'); seek(569.0)">
              latency of this service and its service level objective,
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:09:32,814'); seek(572.0)">
              while below you can see the resource request, cpu and memory,
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:09:36,590'); seek(576.0)">
              and the corresponding resource utilization.
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:09:39,530'); seek(579.0)">
              We let this service run for a couple of days with some initial resource
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:09:43,282'); seek(583.0)">
              sizing, then activated the VPA and let it applied the new
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:09:47,148'); seek(587.0)">
              recommended setting to the pod.
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:09:50,030'); seek(590.0)">
              It's interesting to see that the VPA immediately decided to
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:09:53,648'); seek(593.0)">
              reduce these assigned resources. In particularly, it cut in
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:09:56,928'); seek(596.0)">
              half the cpu requests. This is likely due
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:10:00,438'); seek(600.0)">
              to some apparent overprovisioning of these service as the cpu
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:10:03,914'); seek(603.0)">
              utilization was below 50%.
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:10:07,090'); seek(607.0)">
              However, with the new settings suggested by the VPA,
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:10:10,714'); seek(610.0)">
              the latency of the microservice skyrocketed, breaching our slos.
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:10:16,050'); seek(616.0)">
              What is the lesson heard here? Kubernetes autoscaling and
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:10:20,088'); seek(620.0)">
              the VPA in particular is based on resource usage and
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:10:23,688'); seek(623.0)">
              does not consider application level metrics like response time.
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:10:27,884'); seek(627.0)">
              We need to evaluate the effect of the recommended settings as they
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:10:31,708'); seek(631.0)">
              might be somewhat aggressive and cause severe service performance
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:10:35,650'); seek(635.0)">
              or reliability degradations as
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:10:40,352'); seek(640.0)">
              we've seen so far, optimizing microservice applications on Kubernetes
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:10:44,790'); seek(644.0)">
              is quite tuning tasks for developers,
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:10:47,414'); seek(647.0)">
              sres and performance engineers. Given the complexity of tuning
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:10:51,350'); seek(651.0)">
              Kubernetes resources and the many moving facts we have
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:10:54,772'); seek(654.0)">
              in modern applications, a new approach is required
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:10:58,378'); seek(658.0)">
              to successfully solve this problem and this is where machine learning
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:11:01,716'); seek(661.0)">
              can help. AI and machine learning have revolutionarized
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:11:05,886'); seek(665.0)">
              entire industries and the good news is that ML can be
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:11:09,528'); seek(669.0)">
              used also in the performance tuning process. ML can automate
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:11:13,038'); seek(673.0)">
              the tuning of many parameters we have in the software stack with
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:11:16,712'); seek(676.0)">
              the goal of optimized application performance, resiliency and cost.
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:11:20,380'); seek(680.0)">
              In this section I would like to introduce you to this new methodology.
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:11:24,810'); seek(684.0)">
              Real world case is about an european leader in accounting,
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:11:28,082'); seek(688.0)">
              payroll and business management software. These Java cases microservice
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:11:32,182'); seek(692.0)">
              applications are running either on Azure or AWS Kubernetes
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:11:36,630'); seek(696.0)">
              services the target system of the optimization
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:11:39,942'); seek(699.0)">
              is the b two b authorization service running on Azure. It's a
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:11:43,844'); seek(703.0)">
              business critical service that interacts with all the applications powered
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:11:47,434'); seek(707.0)">
              in the digital services provided by the company.
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:11:50,210'); seek(710.0)">
              These challenge of the customer was to avoid overspending and
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:11:53,768'); seek(713.0)">
              achieve the best cost efficiency possible by enabling development teams
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:11:57,918'); seek(717.0)">
              to optimize their applications while keeping on releasing application
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:12:01,528'); seek(721.0)">
              updates required to introduce new business functionalities and align
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:12:05,102'); seek(725.0)">
              to new regulations. So what is the goal
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:12:08,350'); seek(728.0)">
              of this optimization? In this scenario, the goal was to reduce
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:12:11,538'); seek(731.0)">
              the cloud costs required to run the optic authentication service on Kubernetes.
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:12:15,906'); seek(735.0)">
              At the same time, we also wanted to ensure that service would
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:12:19,392'); seek(739.0)">
              always meet its reliability targets which are expressed as latency,
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:12:23,334'); seek(743.0)">
              throughput and error rate slos. So how can we
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:12:27,408'); seek(747.0)">
              leverage ML to achieve this high level business goal?
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:12:31,310'); seek(751.0)">
              In our optimization methodology, DML changes
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:12:34,436'); seek(754.0)">
              the parameters of the system to improve these metric that we have defined.
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:12:38,762'); seek(758.0)">
              In this case, the goal is simply to optimize the application cost.
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:12:43,010'); seek(763.0)">
              This is a metric that represents the cost we pay to run the application on
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:12:46,824'); seek(766.0)">
              the cloud, which depends on these amount of cpu and memory resources
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:12:51,374'); seek(771.0)">
              allocated to the containers. The ML power optimization
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:12:55,470'); seek(775.0)">
              methodology also allows to set constraints to define
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:12:58,962'); seek(778.0)">
              which configurations are acceptable. In this case, we state
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:13:02,940'); seek(782.0)">
              that the system throughput, response times and error rate should
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:13:06,428'); seek(786.0)">
              not degrade more than 10% with respect to the baseline.
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:13:11,950'); seek(791.0)">
              Once we have defined the optimization goal, next step is
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:13:15,568'); seek(795.0)">
              to define these parameters of these system that machine learning
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:13:18,944'); seek(798.0)">
              can optimize to improve our goal. In these scenario,
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:13:22,570'); seek(802.0)">
              nine tunable parameters were considered. In total, four parameters
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:13:27,194'); seek(807.0)">
              are related to Kubernetes container sighting, cpu and memory request and
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:13:31,332'); seek(811.0)">
              limits which play a big role in the overall service performance,
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:13:35,066'); seek(815.0)">
              cost and reliability and five parameters are related
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:13:38,878'); seek(818.0)">
              to these JVM, which is the runtime that runs within the container.
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:13:43,678'); seek(823.0)">
              Here we included parameters like heap size, garbage collector,
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:13:47,150'); seek(827.0)">
              the size of the regions of the heap, which are important options to improve the
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:13:51,132'); seek(831.0)">
              performance of Java apps. It's worth noticing that
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:13:54,988'); seek(834.0)">
              the ML optimizes the full stack by operating on all these
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:13:59,056'); seek(839.0)">
              nine parameters at the same time, thereby ensuring that the
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:14:02,608'); seek(842.0)">
              JVM is optimally configured to run within the
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:14:05,728'); seek(845.0)">
              chosen container. Resource sightseeing let's now
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:14:09,712'); seek(849.0)">
              see how the ML Tower optimization methodology works. In practice.
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:14:13,994'); seek(853.0)">
              The process is fully automated and works in five
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:14:17,220'); seek(857.0)">
              sres. The first step is to apply the new configurations suggested
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:14:21,098'); seek(861.0)">
              by the ML algorithms to our target system.
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:14:24,068'); seek(864.0)">
              This is typically done leveraging Kubernetes APIs to
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:14:27,528'); seek(867.0)">
              set the new value to the parameters, for example the CPU request.
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:14:31,910'); seek(871.0)">
              The second step is to apply a workload to the target system
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:14:35,304'); seek(875.0)">
              in order to assess the performance of the new configuration.
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:14:38,970'); seek(878.0)">
              This is usually done by leveraging performance testing tools.
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:14:42,434'); seek(882.0)">
              In this case, we use a geneter test that was already available to
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:14:46,012'); seek(886.0)">
              stress the application with a realistic workload.
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:14:49,550'); seek(889.0)">
              The first step is to collect KPIs related to the target
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:14:53,382'); seek(893.0)">
              system. The typical approach here is to leverage observability
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:14:57,414'); seek(897.0)">
              tools. In this case, we integrated elastic APM,
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:15:00,774'); seek(900.0)">
              which is the monitoring solution used by these customer.
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:15:03,730'); seek(903.0)">
              The fourth step is to analyze the result of the performance test
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:15:07,444'); seek(907.0)">
              and assign a score based on the specific goal that you have defined.
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:15:11,386'); seek(911.0)">
              In this case, the score is simply the cost of running the application
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:15:14,968'); seek(914.0)">
              containers. Considering the prices of azure cloud.
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:15:18,550'); seek(918.0)">
              The last step is where the machine learning kicks in by taking
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:15:22,216'); seek(922.0)">
              the score of the tested configurations as input and producing as
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:15:26,008'); seek(926.0)">
              an output the most promising configuration to be tested in the
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:15:29,308'); seek(929.0)">
              next iteration. In a relatively short amount of
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:15:32,828'); seek(932.0)">
              time, the ML algorithm learns the dependencies between the configuration
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:15:36,642'); seek(936.0)">
              parameters and the system behavior. Though identifying better and
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:15:40,752'); seek(940.0)">
              better configurations. It's worth noticing that the whole optimization
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:15:44,710'); seek(944.0)">
              process becomes completely automated.
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:15:49,070'); seek(949.0)">
              So what are we getting as an output of the MLbase optimization?
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:15:53,970'); seek(953.0)">
              The main result is the best configuration of the software stack parameters
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:15:57,866'); seek(957.0)">
              that maximizing or minimize the goal we have defined.
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:16:01,530'); seek(961.0)">
              These parameters can be then applied in production environments,
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:16:05,830'); seek(965.0)">
              but the value this methodology can bring is actually much
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:16:09,576'); seek(969.0)">
              higher. Amal will evaluate many different configurations
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:16:13,262'); seek(973.0)">
              of the system, which can reveal important insights about the overall
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:16:17,266'); seek(977.0)">
              system behavior in terms of other KPIs like cost, performance or
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:16:21,452'); seek(981.0)">
              resiliency. These supports performance engineers and
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:16:25,228'); seek(985.0)">
              developers in their decision on how to best configure these application to
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:16:29,152'); seek(989.0)">
              maximizing the specific goals. So,
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:16:32,592'); seek(992.0)">
              to assess the performance and cost efficiency of a new configuration suggested
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:16:36,358'); seek(996.0)">
              by the ML optimizer. We stress the system with these load
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:16:39,542'); seek(999.0)">
              test here you can see the load test scenario that we use just
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:16:43,488'); seek(1003.0)">
              designed according to the performance engineering best practices.
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:16:46,730'); seek(1006.0)">
              The traffic pattern mimicked the behavior seen in production,
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:16:50,298'); seek(1010.0)">
              including API call distribution and sync times.
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:16:54,470'); seek(1014.0)">
              Before looking at the results, it's worth commenting on the application
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:16:58,472'); seek(1018.0)">
              on how the application was initially configured by the customer.
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:17:02,168'); seek(1022.0)">
              We call this these baseline configuration. Let's look
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:17:06,268'); seek(1026.0)">
              at the Kubernetes settings first. The container powering these
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:17:10,172'); seek(1030.0)">
              application was configured with resource requests of 1.5 cpus
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:17:14,498'); seek(1034.0)">
              and 3.42gb of memory. The team also
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:17:18,140'); seek(1038.0)">
              specified resource limits of two cpus and
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:17:21,696'); seek(1041.0)">
              4.39gb of memory. Remember,
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:17:25,328'); seek(1045.0)">
              the requests are the guaranteed resource that kubernetes
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:17:28,838'); seek(1048.0)">
              will use for scheduling and capacity management of the cluster.
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:17:32,690'); seek(1052.0)">
              In this case, requests are lower than the limit.
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:17:36,170'); seek(1056.0)">
              This is a common approach to guarantee resources for the application
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:17:39,380'); seek(1059.0)">
              to run properly, but at the same time allow for some room
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:17:43,544'); seek(1063.0)">
              for unexpected growth.
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:17:46,710'); seek(1066.0)">
              Besides looking at the container settings, it's important to also see
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:17:50,344'); seek(1070.0)">
              how the application runtime is configured. The runtime is
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:17:53,848'); seek(1073.0)">
              what ultimately powers our application, and for Java apps
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:17:57,650'); seek(1077.0)">
              we know that JVM settings play a big role in app
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:18:01,356'); seek(1081.0)">
              performance, but the same happens for goaling applications.
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:18:04,962'); seek(1084.0)">
              For example, the JVM was configured with a minimum
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:18:08,578'); seek(1088.0)">
              cheap of half a gig and a max heap of 4gb.
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:18:12,678'); seek(1092.0)">
              Notice that the max heap is higher than the memory results,
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:18:16,454'); seek(1096.0)">
              which means that the JVM can use more memory than the amount
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:18:20,016'); seek(1100.0)">
              requested. As we're going to see, this configuration will have
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:18:23,828'); seek(1103.0)">
              an impact on how the application behaves under load and the associated
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:18:27,722'); seek(1107.0)">
              resiliency and costs.
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:18:31,410'); seek(1111.0)">
              It's worth noting that these customer also defined autoscaling
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:18:34,938'); seek(1114.0)">
              policies for this application, leveraging the Ka autoscaling
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:18:38,478'); seek(1118.0)">
              project for kubernetes in their environment,
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:18:42,286'); seek(1122.0)">
              both cpu and memory were defined as scalers with
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:18:46,168'); seek(1126.0)">
              a triggering threshold of 70% and 90% utilization,
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:18:50,002'); seek(1130.0)">
              respectively. What is important to keep in mind is
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:18:53,228'); seek(1133.0)">
              that such utilization percentage are related to the resource request,
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:18:57,010'); seek(1137.0)">
              not limits. So as you can see in the diagram on
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:19:00,368'); seek(1140.0)">
              the right can action to scale out the application will happen,
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:19:03,840'); seek(1143.0)">
              for example when the cpu usage will got above one
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:19:07,296'); seek(1147.0)">
              core. Okay, we've covered how the
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:19:10,672'); seek(1150.0)">
              application is configured. Let's now look at the behavior of the application when
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:19:14,996'); seek(1154.0)">
              subject to the load test we've shown before with the baseline configuration.
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:19:19,578'); seek(1159.0)">
              In this chart you can see the application throughput response time and the
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:19:23,268'); seek(1163.0)">
              number of replicas that were created by the autoscaling.
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:19:26,870'); seek(1166.0)">
              Two facts are important to notice. When the load increases, the autoscaling
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:19:31,438'); seek(1171.0)">
              triggers a scaleout event which creates a new replica.
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:19:35,118'); seek(1175.0)">
              This event causes a big spike on response time which impacts
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:19:38,882'); seek(1178.0)">
              service reliability and performance. This is due to the
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:19:42,348'); seek(1182.0)">
              high cpu usage and throttling during the JVM startup.
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:19:47,130'); seek(1187.0)">
              When the load drops, the number of replicas does not scale down.
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:19:50,896'); seek(1190.0)">
              Despite these, container cpu usage is idle.
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:19:54,830'); seek(1194.0)">
              It's interesting to understand why this is happening. This is
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:19:58,912'); seek(1198.0)">
              caused by the configuration of the container resource, the JVM
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:20:02,378'); seek(1202.0)">
              tuning inside, and these autoscaler policies in particular for the
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:20:06,228'); seek(1206.0)">
              memory resources. The autoscaler in this case
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:20:09,972'); seek(1209.0)">
              is not scaling down because the memory usage of the container is
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:20:14,020'); seek(1214.0)">
              higher than these configured threshold of 70% usage with
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:20:17,832'); seek(1217.0)">
              respect to the memory requests. These might be due to the JDM
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:20:21,502'); seek(1221.0)">
              Max heap being higher than the memory request we've seen
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:20:24,696'); seek(1224.0)">
              before, but it max also be due to a
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:20:27,804'); seek(1227.0)">
              change in the application memory footprint, for example due to a new
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:20:31,132'); seek(1231.0)">
              application release. This effect clearly impacts the
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:20:34,748'); seek(1234.0)">
              cloud build as more instances are up and running than
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:20:38,336'); seek(1238.0)">
              required. But slos that configuring Kubernetes apps
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:20:42,294'); seek(1242.0)">
              for reliability and cost efficiency is actually a tricky process.
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:20:46,670'); seek(1246.0)">
              Let's now have a look at the best configuration identified by ML
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:20:50,486'); seek(1250.0)">
              with respect to the defined cost efficiency goal.
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:20:53,658'); seek(1253.0)">
              This was found at experiment number 34 after
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:20:56,916'); seek(1256.0)">
              about 19 hours and almost half the cost of
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:21:00,692'); seek(1260.0)">
              running the application with respect to the baseline.
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:21:03,910'); seek(1263.0)">
              First of all, it's interesting to notice how our
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:21:07,064'); seek(1267.0)">
              MLbase optimization increased both memory and cpu
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:21:10,782'); seek(1270.0)">
              results and limits, which is not at all obvious and
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:21:14,312'); seek(1274.0)">
              may seem at first counterintuitive, especially as Kubernetes is
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:21:18,188'); seek(1278.0)">
              often considered well suited for small and highly scalable
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:21:21,602'); seek(1281.0)">
              applications. The other notable changes are related to the
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:21:25,388'); seek(1285.0)">
              JVM options. The max cheap size was increased by 20% and is
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:21:29,228'); seek(1289.0)">
              now well within the container memory request, which was increased
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:21:32,358'); seek(1292.0)">
              to five gigabyte. The min heap size has also
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:21:35,712'); seek(1295.0)">
              been adjusted to be almost equal to the max cheap, which is a configuration
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:21:39,638'); seek(1299.0)">
              that can avoid garbage collection cycles, especially in the startup
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:21:43,322'); seek(1303.0)">
              phase of JVM. So let's now see how
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:21:46,948'); seek(1306.0)">
              the application performs with the new configuration identified by ML
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:21:50,906'); seek(1310.0)">
              and how it compares with respect to the baseline. There are two important differences
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:21:55,370'); seek(1315.0)">
              here. Results time always remain within the Hasselo
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:21:59,450'); seek(1319.0)">
              and there are no more picks. So these configuration got only improves
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:22:03,422'); seek(1323.0)">
              on cost, but it's also beneficial in terms of performance
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:22:07,026'); seek(1327.0)">
              and resilience. Autoscaling is not triggering these
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:22:10,652'); seek(1330.0)">
              configuration as the full load is sustained by just one pod.
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:22:14,642'); seek(1334.0)">
              These is clearly beneficial in terms of costs.
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:22:18,018'); seek(1338.0)">
              Let's also compare in detail the best configuration with respect to
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:22:21,728'); seek(1341.0)">
              the baseline. These we can notice that the pod is significantly
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:22:25,814'); seek(1345.0)">
              larger in terms of both cpu and memory, especially for
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:22:29,248'); seek(1349.0)">
              the requests. This configuration has the effect of triggering the auto
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:22:33,178'); seek(1353.0)">
              scaler less often, as we have seen, but interestingly and
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:22:37,396'); seek(1357.0)">
              somewhat counterintuitively, while this implies a kind of a
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:22:40,564'); seek(1360.0)">
              fixed cost considering the prices of the container resource,
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:22:44,870'); seek(1364.0)">
              it turns out being much cheap than a configuration where autoscaling
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:22:49,038'); seek(1369.0)">
              is triggered, and this also avoids performance issues.
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:22:52,696'); seek(1372.0)">
              The container and runtime configuration are now better aligned.
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:22:56,654'); seek(1376.0)">
              The JVM max is now below the memory request and
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:23:00,092'); seek(1380.0)">
              has a beneficial effect as it also enables the scaled down
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:23:03,708'); seek(1383.0)">
              of the application should the scaling be triggered by higher loads.
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:23:08,034'); seek(1388.0)">
              Let's now have a look at another configuration found by ML
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:23:12,230'); seek(1392.0)">
              at experiment number 14. After about 8 hours
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:23:16,000'); seek(1396.0)">
              of automated optimization, we leveled this configuration high
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:23:20,096'); seek(1400.0)">
              reliability for a reason that we will be clear in a minute.
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:23:24,370'); seek(1404.0)">
              The score for this configuration, while not as good as the best configurations,
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:23:28,858'); seek(1408.0)">
              also provided about 60% cost reduction.
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:23:31,818'); seek(1411.0)">
              So this can be considered also an interesting configuration with
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:23:34,948'); seek(1414.0)">
              respect to the cost efficiency goal as regards to the parameters.
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:23:39,230'); seek(1419.0)">
              What is worth noticing is that this time ML picked
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:23:42,478'); seek(1422.0)">
              settings that significantly change the shape of the container.
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:23:46,366'); seek(1426.0)">
              It now has a much smaller cpu request with respect to the
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:23:49,644'); seek(1429.0)">
              baseline, but the memory is still pretty large, which is
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:23:53,388'); seek(1433.0)">
              pretty interesting. The JVM options were
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:23:56,732'); seek(1436.0)">
              also changed. In particular, the Galbridge collector was
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:24:00,288'); seek(1440.0)">
              switched to parallel, which is a collector that can be much
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:24:03,696'); seek(1443.0)">
              more efficient on the use of cpu and memory.
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:24:07,870'); seek(1447.0)">
              Let's compare the behavior of this configuration with respect to the baseline.
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:24:11,862'); seek(1451.0)">
              There are two important differences here. The peak on the response
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:24:15,258'); seek(1455.0)">
              time upon the scaling out is significantly lower. It's still
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:24:19,092'); seek(1459.0)">
              higher than the response time slo. However, the peak is
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:24:22,532'); seek(1462.0)">
              less than half the value of the baseline configuration.
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:24:25,710'); seek(1465.0)">
              This clearly improves the service resilience.
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:24:28,790'); seek(1468.0)">
              Autoscaling works properly after the high load phase
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:24:32,526'); seek(1472.0)">
              replicarves are scaled back to one. Its behavior is what we expect from
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:24:36,568'); seek(1476.0)">
              an autoscaling system that works properly. Notice the response time
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:24:40,252'); seek(1480.0)">
              picks could also be further reduced. It would simply
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:24:44,082'); seek(1484.0)">
              be a matter of creating a new optimization with the goal of minimizing
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:24:47,778'); seek(1487.0)">
              these response time matrix instead of the application cost.
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:24:51,152'); seek(1491.0)">
              Let's now also companies in detail the high resilience configuration
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:24:55,126'); seek(1495.0)">
              with respect to the baseline. Quite interestingly,
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:24:58,006'); seek(1498.0)">
              these configuration has a higher memory request and lower cpu results,
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:25:02,250'); seek(1502.0)">
              but higher limits than the baseline. As you may remember,
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:25:05,924'); seek(1505.0)">
              the lowest cost configuration instead had a higher cpu request than
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:25:09,748'); seek(1509.0)">
              the baseline. Without getting into much details in the analysis
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:25:13,802'); seek(1513.0)">
              of this specific configuration, what these facts show is
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:25:17,412'); seek(1517.0)">
              that as the optimization goal changes, cpu and memory
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:25:21,198'); seek(1521.0)">
              results and limits may need to be increased or decreased.
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:25:24,782'); seek(1524.0)">
              That multiple parameters at Kubernetes and JVM
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:25:28,386'); seek(1528.0)">
              levels also need to be tune accordingly.
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:25:31,458'); seek(1531.0)">
              This is a clear confirmation of the perceived complexity of
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:25:35,052'); seek(1535.0)">
              tuning Kubernetes microservices application,
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:25:38,090'); seek(1538.0)">
              as here we are just discussing one microservice out of hundreds
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:25:42,226'); seek(1542.0)">
              or more of today applications. There are many other interesting
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:25:46,464'); seek(1546.0)">
              configurations found by ML that we would like to discuss,
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:25:50,240'); seek(1550.0)">
              but I think it's time to conclude with our takeaways.
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:25:53,730'); seek(1553.0)">
              Our first takeaway is that when tuning the modern applications,
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:25:57,306'); seek(1557.0)">
              the interplay between different application layers and technologies require
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:26:01,722'); seek(1561.0)">
              tuning the full stack configuration to make sure
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:26:05,096'); seek(1565.0)">
              that both the optimization goal and slos are
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:26:08,312'); seek(1568.0)">
              matched, as we've seen in our real world example. A second takeaway
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:26:12,590'); seek(1572.0)">
              is that the complexity of this application under varied workloads and
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:26:16,492'); seek(1576.0)">
              in a context of frequent releases with agile practices
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:26:19,906'); seek(1579.0)">
              requires a continuous performance tuning process. Developers cannot
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:26:23,842'); seek(1583.0)">
              simply rely on manual tuning or utilization based autoscaling
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:26:27,602'); seek(1587.0)">
              mechanisms. Finally, in order to explore
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:26:30,914'); seek(1590.0)">
              the vastness of the space of possible configuration in a cost
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:26:34,732'); seek(1594.0)">
              and time efficient way, it's mandatory to leverage Mlbased methods
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:26:39,026'); seek(1599.0)">
              that can automatically converge to optimal configuration within hours
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:26:43,428'); seek(1603.0)">
              without requiring deep knowledge of all the underlying technologies.
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:26:47,450'); seek(1607.0)">
              Many thanks for your time. I hope you enjoyed the talk. Please reach
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:26:51,012'); seek(1611.0)">
              out to me if you have found this talk interesting. I would love to share
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:26:54,292'); seek(1614.0)">
              more details and hear your Kubernetes challenges.
            </span>
            
            </div>
          </div>
          
          

          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/cloud2022" class="btn btn-sm btn-danger shadow lift" style="background-color: #7B2726;">
                <i class="fe fe-grid me-2"></i>
                See all 50 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/cloud_giovanni_paolo_gibilisco.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Giovanni Paolo Gibilisco
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Head of Engineering @ Akamas
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/giovanni-paolo-gibilisco-b59ab329/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Giovanni Paolo Gibilisco's LinkedIn account" />
                  </a>
                  
                  
                  <a href="https://twitter.com/@gibbone87" target="_blank">
                    <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="Giovanni Paolo Gibilisco's twitter account" />
                  </a>
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by @gibbone87"
                  data-url="https://www.conf42.com/cloud2022"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/cloud2022"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>






    <!-- WELCOME -->
    <section class="pt-8 pt-md-11 pb-10 pb-md-15 bg-info" id="register">

      <!-- Shape -->
      <div class="shape shape-blur-3 text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>      </div>

      <!-- Content -->
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 col-md-10 col-lg-8 text-center">

            <!-- Heading -->
            <h1 class="display-2 text-white">
              Join the community!
            </h1>

            <!-- Text -->
            <p class="lead text-white text-opacity-80 mb-6 mb-md-8">
              Learn for free, join the best tech learning community 
              for a <a class="text-white" href="https://www.reddit.com/r/sanfrancisco/comments/1bz90f6/why_are_coffee_shops_in_sf_so_expensive/" target="_blank">price of a pumpkin latte</a>.
            </p>

            <!-- Form -->
            <form class="d-flex align-items-center justify-content-center mb-7 mb-md-9">

              <!-- Label -->
              <span class="text-white text-opacity-80">
                Annual
              </span>

              <!-- Switch -->
              <div class="form-check form-check-dark form-switch mx-3">
                <input class="form-check-input" type="checkbox" id="billingSwitch" data-toggle="price" data-target=".price">
              </div>

              <!-- Label -->
              <span class="text-white text-opacity-80">
                Monthly
              </span>

            </form>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->

    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- PRICING -->
    <section class="mt-n8 mt-md-n15">
      <div class="container">
        <div class="row gx-4">
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-1">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Newsletter</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="0" data-monthly="0">0</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Event notifications, weekly newsletter
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Delayed access</b> to all content
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Immediate access to Keynotes & Panels
                  </p>
                </div>
              
              
              </div>
            </div>

            <!-- Card -->
            <div class="card shadow-lg mb-6 border border-success">
              <div class="card-body">

                <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
</script>

<!-- Form -->
<link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
<p class="emailoctopus-success-message text-success"></p>
<p class="emailoctopus-error-message text-danger"></p>
<form
    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
    method="post"
    data-message-success="Thanks! Check your email for further directions!"
    data-message-missing-email-address="Your email address is required."
    data-message-invalid-email-address="Your email address looks incorrect, please try again."
    data-message-bot-submission-error="This doesn't look like a human submission."
    data-message-consent-required="Please check the checkbox to indicate your consent."
    data-message-invalid-parameters-error="This form has missing or invalid fields."
    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
    class="emailoctopus-form"
    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
>
<div class="form-floating emailoctopus-form-row">
    <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
    <label for="field_0">Email address</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
    <label for="field_1">First Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
    <label for="field_2">Last Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
    <label for="field_4">Company</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
    <label for="field_5">Job Title</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
    <label for="field_3">Phone Number</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
    oninput="updateCountry()"
    >
    <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
    </select>
    <label for="field_7">Country</label>
</div>
<input id="country-destination" name="field_7" type="hidden">
<input id="tz-country" name="field_8" type="hidden">

<input
    name="field_6"
    type="hidden"
    value="Cloud Native"
>

<div class="emailoctopus-form-row-consent">
    <input
    type="checkbox"
    id="consent"
    name="consent"
    >
    <label for="consent">
    I consent to the following terms:
    </label>
    <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
    Terms and Conditions
    </a>
    &amp;
    <a href="./code-of-conduct" target="_blank">
    Code of Conduct
    </a>
</div>
<div
    aria-hidden="true"
    class="emailoctopus-form-row-hp"
>
    <input
    type="text"
    name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
    tabindex="-1"
    autocomplete="nope"
    >
</div>
<div class="mt-6 emailoctopus-form-row-subscribe">
    <input
    type="hidden"
    name="successRedirectUrl"
    >
    <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
    Subscribe to free newsletter <i class="fe fe-arrow-right ms-3"></i>
    </button>
</div>
</form>

<!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
<script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

              </div>
            </div>
          </div>
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-0">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Community</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="8.34" data-monthly="10">8.34</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Access to <a href="https://conf42.circle.so/">Circle community platform</a>
                  </p>
                </div>

                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Immediate access</b> to all content
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <a href="https://conf42.circle.so/c/live-events/" target="_blank"><b>Live events!</b></a>
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <a href="https://conf42.circle.so/c/live-events/" target="_blank">Regular office hours, Q&As, CV reviews</a>
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Courses, quizes & certificates
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Community chats
                  </p>
                </div>
                

                <!-- Button -->
                <a href="https://conf42.circle.so/checkout/subscribe" class="btn w-100 btn-primary">
                  Join the community (7 day free trial)<i class="fe fe-arrow-right ms-3"></i>
                </a>

              </div>
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2025">
                  Site Reliability Engineering (SRE) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2025">
                  Machine Learning 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2025">
                  Observability 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2025">
                  Quantum Computing 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2025">
                  Rustlang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2025">
                  Platform Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2025">
                  MLOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2025">
                  Incident Management 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2025">
                  Kube Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2025">
                  JavaScript 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2025">
                  Prompt Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/robotics2025">
                  Robotics 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2025">
                  DevSecOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2025">
                  Internet of Things (IoT) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>