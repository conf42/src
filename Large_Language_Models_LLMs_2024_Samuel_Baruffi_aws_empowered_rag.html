<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: Vectoring Into The Future: AWS Empowered RAG Systems for LLMs</title>
    <meta name="description" content="One model, extra large, please!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/Samuel%20Baruffi_llm.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Vectoring Into The Future: AWS Empowered RAG Systems for LLMs | Conf42"/>
    <meta property="og:description" content="Dive into AWS' innovative toolkit for Retrieval Augmented Generation (RAG) systems. Harness the power of vector databases, SageMaker JumpStart, and/or BedRock to supercharge your Large Language Models (LLMs) and reshape your GenAI landscape!"/>
    <meta property="og:url" content="https://conf42.com/Large_Language_Models_LLMs_2024_Samuel_Baruffi_aws_empowered_rag"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/CE2025_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Chaos Engineering 2025
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2025-02-20
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/ce2025" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2025">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2025">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2025">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2025">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2025">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2025">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2025">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2025">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2025">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2025">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2025">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/robotics2025">
                            Robotics
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2025">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2025">
                            Internet of Things (IoT)
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="https://conf42.circle.so/">
                            <b>Community platform login</b>
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Join the community!
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #CCB87B;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Large Language Models (LLMs) 2024 - Online
            </h1>

            <h2 class="text-white">
              
              <time datetime="2024-04-11">April 11 2024</time>
              
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- One model, extra large, please!
 -->
              <script>
                const event_date = new Date("2024-04-11T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2024-04-11T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              <a href="#register" class="btn btn-primary shadow lift me-1 mb-3">
                <i class="fe fe-user-check me-2"></i>
                Subscribe to watch
              </a>
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "2xhalsIDYco"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <a class="btn btn-info lift mb-3" data-bigpicture='{"ytSrc": "TQwxk0c4sh0"}' href="#">
                <i class="fe fe-eye me-2"></i>
                Watch Premiere
              </a>
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://www.youtube.com/playlist?list=PLIuxSyKxlQrBjR6ZR0g0LRq9Fp8c_4HrI" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Thanks for joining my session. My name is Samuel Baruffi. I am a", "timestamp": "00:00:20,760", "timestamp_s": 20.0}, {"text": "solutions architect with AWS and I\u0027m very excited", "timestamp": "00:00:24,662", "timestamp_s": 24.0}, {"text": "to talk about vectorizing into the future", "timestamp": "00:00:27,968", "timestamp_s": 27.0}, {"text": "AWS retrieval augmented generation systems using", "timestamp": "00:00:32,104", "timestamp_s": 32.0}, {"text": "large language models. So a quick agenda", "timestamp": "00:00:36,320", "timestamp_s": 36.0}, {"text": "for today will be the following.", "timestamp": "00:00:39,632", "timestamp_s": 39.0}, {"text": "We\u0027re going to quickly talk about what are foundational", "timestamp": "00:00:43,384", "timestamp_s": 43.0}, {"text": "models, large language models. Then we\u0027re going", "timestamp": "00:00:46,776", "timestamp_s": 46.0}, {"text": "to talk about some of the capabilities that are very easy", "timestamp": "00:00:51,004", "timestamp_s": 51.0}, {"text": "and important to use when it comes to generative AI.", "timestamp": "00:00:56,334", "timestamp_s": 56.0}, {"text": "Then we\u0027re going to talk about some limitations of those foundational models.", "timestamp": "00:01:00,614", "timestamp_s": 60.0}, {"text": "Those models are amazing. It has revolutionized", "timestamp": "00:01:04,958", "timestamp_s": 64.0}, {"text": "and it\u0027s still revolutionizing many, many industries across", "timestamp": "00:01:08,566", "timestamp_s": 68.0}, {"text": "the world, but they have limitations. So we\u0027re", "timestamp": "00:01:12,630", "timestamp_s": 72.0}, {"text": "going to talk about what are those limitations, and we\u0027re going to talk about potential", "timestamp": "00:01:16,190", "timestamp_s": 76.0}, {"text": "solutions, especially using retrieval augmented generations,", "timestamp": "00:01:19,630", "timestamp_s": 79.0}, {"text": "which Reg is short for. Then we\u0027re", "timestamp": "00:01:24,904", "timestamp_s": 84.0}, {"text": "going to talk about what type of databases", "timestamp": "00:01:28,352", "timestamp_s": 88.0}, {"text": "can help us, you know, improve those", "timestamp": "00:01:32,400", "timestamp_s": 92.0}, {"text": "foundational models with Reg. So we\u0027re going to go through", "timestamp": "00:01:35,816", "timestamp_s": 95.0}, {"text": "the list of currently supported databases offerings on", "timestamp": "00:01:39,688", "timestamp_s": 99.0}, {"text": "AWS for vector. We\u0027re going to explain, explain at", "timestamp": "00:01:43,424", "timestamp_s": 103.0}, {"text": "a high level the capabilities", "timestamp": "00:01:47,530", "timestamp_s": 107.0}, {"text": "and the differentiations across those offerings.", "timestamp": "00:01:51,018", "timestamp_s": 111.0}, {"text": "And then after that we\u0027re going to talk about Amazon Bedrock, which is a", "timestamp": "00:01:54,994", "timestamp_s": 114.0}, {"text": "generative AI managed service", "timestamp": "00:01:58,810", "timestamp_s": 118.0}, {"text": "on AWS that allows you to very easily consume", "timestamp": "00:02:02,306", "timestamp_s": 122.0}, {"text": "different foundational models, both image generation", "timestamp": "00:02:06,162", "timestamp_s": 126.0}, {"text": "text to text, and also embeddings. And then", "timestamp": "00:02:09,498", "timestamp_s": 129.0}, {"text": "we\u0027re going to talk about Amazon Bedrock knowledge base,", "timestamp": "00:02:12,974", "timestamp_s": 132.0}, {"text": "which combines the powerful rack", "timestamp": "00:02:16,542", "timestamp_s": 136.0}, {"text": "systems into the bedrock ecosystem", "timestamp": "00:02:21,238", "timestamp_s": 141.0}, {"text": "and it allows users to very easily configure", "timestamp": "00:02:24,766", "timestamp_s": 144.0}, {"text": "retrieval augmented generation systems using", "timestamp": "00:02:29,334", "timestamp_s": 149.0}, {"text": "bedrock foundational models and also using AWS", "timestamp": "00:02:32,710", "timestamp_s": 152.0}, {"text": "vector databases that are managed. So we\u0027re", "timestamp": "00:02:36,630", "timestamp_s": 156.0}, {"text": "going to talk about how those two words can come together", "timestamp": "00:02:40,260", "timestamp_s": 160.0}, {"text": "to really empower a lot of companies and users", "timestamp": "00:02:43,748", "timestamp_s": 163.0}, {"text": "to create very powerful generative AI solutions.", "timestamp": "00:02:47,316", "timestamp_s": 167.0}, {"text": "And then in the end, we\u0027re going to do a quick demo just showcasing", "timestamp": "00:02:51,484", "timestamp_s": 171.0}, {"text": "the capabilities of bedrock and open search.", "timestamp": "00:02:54,820", "timestamp_s": 174.0}, {"text": "So without further ado, let\u0027s get started. So WiFi", "timestamp": "00:02:58,812", "timestamp_s": 178.0}, {"text": "national models, right in a before transformers", "timestamp": "00:03:02,732", "timestamp_s": 182.0}, {"text": "and generative AI was really powerful in", "timestamp": "00:03:08,160", "timestamp_s": 188.0}, {"text": "the past, traditional machine learning models", "timestamp": "00:03:11,856", "timestamp_s": 191.0}, {"text": "were really trained and deployed for specific", "timestamp": "00:03:15,144", "timestamp_s": 195.0}, {"text": "tasks. So you might have some models that were for specific task", "timestamp": "00:03:18,912", "timestamp_s": 198.0}, {"text": "generation, some models that were really able to do Q", "timestamp": "00:03:22,416", "timestamp_s": 202.0}, {"text": "and a, some bots, some models that maybe were able to do some type", "timestamp": "00:03:25,856", "timestamp_s": 205.0}, {"text": "of predictions. So they\u0027re really specific", "timestamp": "00:03:29,920", "timestamp_s": 209.0}, {"text": "models, but you need to deploy all these different models to potentially achieve", "timestamp": "00:03:34,666", "timestamp_s": 214.0}, {"text": "the combination or the collection of different tasks", "timestamp": "00:03:40,674", "timestamp_s": 220.0}, {"text": "with generative AI and transformers,", "timestamp": "00:03:45,034", "timestamp_s": 225.0}, {"text": "the foundational models, if you think about quickly on", "timestamp": "00:03:48,354", "timestamp_s": 228.0}, {"text": "the traditional machine learning models, you\u0027d have a lot of label", "timestamp": "00:03:52,106", "timestamp_s": 232.0}, {"text": "data, and you train those models to that specific label", "timestamp": "00:03:55,746", "timestamp_s": 235.0}, {"text": "data. Right? What foundational models?", "timestamp": "00:03:58,954", "timestamp_s": 238.0}, {"text": "Using transformers enables users", "timestamp": "00:04:03,192", "timestamp_s": 243.0}, {"text": "to actually do all of those tasks within a", "timestamp": "00:04:07,568", "timestamp_s": 247.0}, {"text": "simple, not simple, but within a single model", "timestamp": "00:04:11,320", "timestamp_s": 251.0}, {"text": "that has been trained with unlabeled data. So foundational", "timestamp": "00:04:15,320", "timestamp_s": 255.0}, {"text": "models sometimes are also referred to as general models", "timestamp": "00:04:19,520", "timestamp_s": 259.0}, {"text": "that have good word representations and", "timestamp": "00:04:23,424", "timestamp_s": 263.0}, {"text": "can do a lot of different tasks that in the", "timestamp": "00:04:26,664", "timestamp_s": 266.0}, {"text": "past, you need to select the different models.", "timestamp": "00:04:30,532", "timestamp_s": 270.0}, {"text": "It is very powerful because with a single model now", "timestamp": "00:04:33,804", "timestamp_s": 273.0}, {"text": "you can perform a combination of different", "timestamp": "00:04:37,748", "timestamp_s": 277.0}, {"text": "tasks that in the past wouldn\u0027t have been possible.", "timestamp": "00:04:41,300", "timestamp_s": 281.0}, {"text": "So generative AI, you can use for", "timestamp": "00:04:45,284", "timestamp_s": 285.0}, {"text": "many, many different use cases. Here, it\u0027s just", "timestamp": "00:04:49,220", "timestamp_s": 289.0}, {"text": "demonstrating into four different categories,", "timestamp": "00:04:53,204", "timestamp_s": 293.0}, {"text": "the capabilities of generative AI. So you", "timestamp": "00:04:57,334", "timestamp_s": 297.0}, {"text": "can enhance customer experience by having, you know, agent assistance", "timestamp": "00:05:01,166", "timestamp_s": 301.0}, {"text": "or, you know, personalizations or chat bots that will", "timestamp": "00:05:05,142", "timestamp_s": 305.0}, {"text": "help enhance your customer experience. You can", "timestamp": "00:05:08,374", "timestamp_s": 308.0}, {"text": "also have boost, you can also help boost employee productivity", "timestamp": "00:05:11,430", "timestamp_s": 311.0}, {"text": "with conversational search. Let\u0027s say you", "timestamp": "00:05:15,542", "timestamp_s": 315.0}, {"text": "have vast amount of internal data and", "timestamp": "00:05:19,030", "timestamp_s": 319.0}, {"text": "you want to make very easy for users internally to consume", "timestamp": "00:05:22,358", "timestamp_s": 322.0}, {"text": "the data to improve the productivity. Foundational models can", "timestamp": "00:05:26,030", "timestamp_s": 326.0}, {"text": "help solve that problem and a very good solution. You can", "timestamp": "00:05:30,062", "timestamp_s": 330.0}, {"text": "also improve business operation. So if you\u0027re doing a lot of document", "timestamp": "00:05:33,702", "timestamp_s": 333.0}, {"text": "processing that maybe before was done by manual labor,", "timestamp": "00:05:37,446", "timestamp_s": 337.0}, {"text": "you can use those foundational models to potentially process,", "timestamp": "00:05:41,326", "timestamp_s": 341.0}, {"text": "you know, some entity extraction or maybe document", "timestamp": "00:05:44,726", "timestamp_s": 344.0}, {"text": "processing or maybe generation of documents. You can use generative", "timestamp": "00:05:48,238", "timestamp_s": 348.0}, {"text": "AI, and then of course, creativity.", "timestamp": "00:05:52,016", "timestamp_s": 352.0}, {"text": "With a stable diffusion models, you can create many different", "timestamp": "00:05:55,072", "timestamp_s": 355.0}, {"text": "images. You can do video enhancements, you can create music.", "timestamp": "00:05:59,120", "timestamp_s": 359.0}, {"text": "So those generative AI models are not only text generations,", "timestamp": "00:06:03,080", "timestamp_s": 363.0}, {"text": "but you can generate images, videos. And this is a very", "timestamp": "00:06:07,464", "timestamp_s": 367.0}, {"text": "fast paced, evolving technology.", "timestamp": "00:06:11,464", "timestamp_s": 371.0}, {"text": "So what is capable today might", "timestamp": "00:06:14,624", "timestamp_s": 374.0}, {"text": "very quickly advance in the near future. The text", "timestamp": "00:06:18,188", "timestamp_s": 378.0}, {"text": "to text models are really, really powerful today. Images have", "timestamp": "00:06:21,332", "timestamp_s": 381.0}, {"text": "become very powerful. And now we can see that video generations are", "timestamp": "00:06:24,620", "timestamp_s": 384.0}, {"text": "just starting to get more powerful than ever.", "timestamp": "00:06:28,532", "timestamp_s": 388.0}, {"text": "So what does aws in", "timestamp": "00:06:31,564", "timestamp_s": 391.0}, {"text": "terms of generative AI? Right, so AWS", "timestamp": "00:06:35,620", "timestamp_s": 395.0}, {"text": "is very quickly growing", "timestamp": "00:06:40,508", "timestamp_s": 400.0}, {"text": "the list of services and capabilities that support customers. To use", "timestamp": "00:06:44,402", "timestamp_s": 404.0}, {"text": "generative AI, we can, we have Amazon Sagemaker,", "timestamp": "00:06:48,346", "timestamp_s": 408.0}, {"text": "which is the platform for any machine", "timestamp": "00:06:52,338", "timestamp_s": 412.0}, {"text": "learning AI requirements, training,", "timestamp": "00:06:56,826", "timestamp_s": 416.0}, {"text": "inference, evaluation, you know, data ingestion,", "timestamp": "00:06:59,970", "timestamp_s": 419.0}, {"text": "data cleaning, you can name it. But when it comes to generative", "timestamp": "00:07:03,730", "timestamp_s": 423.0}, {"text": "AI, Amazon Sagemaker has a, a foundational hub", "timestamp": "00:07:07,818", "timestamp_s": 427.0}, {"text": "called Jumpstart, where you can actually deploy many, many different", "timestamp": "00:07:11,486", "timestamp_s": 431.0}, {"text": "foundational models that are going to be,", "timestamp": "00:07:15,198", "timestamp_s": 435.0}, {"text": "that you\u0027re going to deploy within Sagemaker. Sagemaker is going to deploy the", "timestamp": "00:07:18,214", "timestamp_s": 438.0}, {"text": "infrastructure for you and it\u0027s going to match that infrastructure.", "timestamp": "00:07:21,598", "timestamp_s": 441.0}, {"text": "But then we also have Amazon bedrock, which is a", "timestamp": "00:07:25,334", "timestamp_s": 445.0}, {"text": "completely managed service with pay as you go approach, that you", "timestamp": "00:07:28,750", "timestamp_s": 448.0}, {"text": "can select a variety of different model providers", "timestamp": "00:07:32,438", "timestamp_s": 452.0}, {"text": "and models within those model providers. We\u0027re going to talk in", "timestamp": "00:07:36,558", "timestamp_s": 456.0}, {"text": "a couple of slides into the future of this", "timestamp": "00:07:40,130", "timestamp_s": 460.0}, {"text": "presentation that are going to present some of the models that are capable.", "timestamp": "00:07:43,362", "timestamp_s": 463.0}, {"text": "And Amazon has also done a lot of", "timestamp": "00:07:47,210", "timestamp_s": 467.0}, {"text": "innovation at the hardware level. So you can see with Amazon", "timestamp": "00:07:50,978", "timestamp_s": 470.0}, {"text": "EC two, TRN one, which is", "timestamp": "00:07:55,066", "timestamp_s": 475.0}, {"text": "training instances, which are instances that", "timestamp": "00:07:58,922", "timestamp_s": 478.0}, {"text": "have proprietary innovative accelerators", "timestamp": "00:08:02,802", "timestamp_s": 482.0}, {"text": "for machine learning training from Amazon that really optimizes the cost", "timestamp": "00:08:07,966", "timestamp_s": 487.0}, {"text": "performance for companies that wants to train their own model.", "timestamp": "00:08:12,070", "timestamp_s": 492.0}, {"text": "Those could be foundational models or could be traditional", "timestamp": "00:08:15,910", "timestamp_s": 495.0}, {"text": "machine learning models. But we also have Amazon EC", "timestamp": "00:08:19,902", "timestamp_s": 499.0}, {"text": "two, InF two, which is short for inferential", "timestamp": "00:08:23,966", "timestamp_s": 503.0}, {"text": "two, which is a chip that is optimized for accelerating", "timestamp": "00:08:27,998", "timestamp_s": 507.0}, {"text": "inferential inference from your machine", "timestamp": "00:08:32,558", "timestamp_s": 512.0}, {"text": "learning models. Those could be foundational models or any other type of model.", "timestamp": "00:08:36,154", "timestamp_s": 516.0}, {"text": "And then last but not least, Amazon Codewisper,", "timestamp": "00:08:40,354", "timestamp_s": 520.0}, {"text": "which is a generative AI power coding assistant that", "timestamp": "00:08:44,882", "timestamp_s": 524.0}, {"text": "helps developers with code completion security scams.", "timestamp": "00:08:49,034", "timestamp_s": 529.0}, {"text": "You know, chat, you can chat with your code", "timestamp": "00:08:52,834", "timestamp_s": 532.0}, {"text": "and receive recommendations and different helps", "timestamp": "00:08:56,274", "timestamp_s": 536.0}, {"text": "in terms of fixing bugs and so forth. So those are", "timestamp": "00:09:00,470", "timestamp_s": 540.0}, {"text": "the things that AWS offers for generative AI capabilities.", "timestamp": "00:09:03,598", "timestamp_s": 543.0}, {"text": "And, you know, there are a lot more that goes within those services in", "timestamp": "00:09:07,862", "timestamp_s": 547.0}, {"text": "terms of functionality and features as", "timestamp": "00:09:11,550", "timestamp_s": 551.0}, {"text": "much as those models. Foundational models are really, really powerful.", "timestamp": "00:09:15,694", "timestamp_s": 555.0}, {"text": "There are limitations of large language models and, you know,", "timestamp": "00:09:20,014", "timestamp_s": 560.0}, {"text": "large language models and foundational models sometimes just use together.", "timestamp": "00:09:23,174", "timestamp_s": 563.0}, {"text": "But you know, large language models are just models that", "timestamp": "00:09:28,444", "timestamp_s": 568.0}, {"text": "can generate text or embeddings that really made", "timestamp": "00:09:31,820", "timestamp_s": 571.0}, {"text": "it possible to use generative AI as", "timestamp": "00:09:36,964", "timestamp_s": 576.0}, {"text": "we know today. But what are some of those limitations that we", "timestamp": "00:09:40,820", "timestamp_s": 580.0}, {"text": "know? So first of all, there is really limited contextual", "timestamp": "00:09:44,420", "timestamp_s": 584.0}, {"text": "understanding. So the model, because it has", "timestamp": "00:09:48,300", "timestamp_s": 588.0}, {"text": "been pre trained, he only knows information", "timestamp": "00:09:51,788", "timestamp_s": 591.0}, {"text": "to the date and is not going to know proprietary,", "timestamp": "00:09:56,106", "timestamp_s": 596.0}, {"text": "you know, private information. So he has limited contextual understanding", "timestamp": "00:10:00,058", "timestamp_s": 600.0}, {"text": "of what you are asking. You might be asking some", "timestamp": "00:10:04,410", "timestamp_s": 604.0}, {"text": "question that is ambiguous and it might have, you know, a contextual", "timestamp": "00:10:07,946", "timestamp_s": 607.0}, {"text": "limitation. In that sense, he also", "timestamp": "00:10:12,306", "timestamp_s": 612.0}, {"text": "has lack of domain specific knowledge. So if you, if you work for", "timestamp": "00:10:16,226", "timestamp_s": 616.0}, {"text": "company a and company a has a lot of private documentation that", "timestamp": "00:10:19,622", "timestamp_s": 619.0}, {"text": "it was not on the Internet, or even if it was in", "timestamp": "00:10:23,478", "timestamp_s": 623.0}, {"text": "the Internet, it might not be an expert on that domain specific.", "timestamp": "00:10:26,766", "timestamp_s": 626.0}, {"text": "So they are known to not be super good in", "timestamp": "00:10:30,526", "timestamp_s": 630.0}, {"text": "specific domains, especially if those domains don\u0027t have a lot", "timestamp": "00:10:33,998", "timestamp_s": 633.0}, {"text": "of data on the Internet. Which most of those models", "timestamp": "00:10:37,358", "timestamp_s": 637.0}, {"text": "get trained on top of it.", "timestamp": "00:10:41,190", "timestamp_s": 641.0}, {"text": "So this is a big one, lacks explainability of interval", "timestamp": "00:10:45,144", "timestamp_s": 645.0}, {"text": "ability. So it\u0027s very common that those large language", "timestamp": "00:10:48,672", "timestamp_s": 648.0}, {"text": "models might hallucinate. And hallucinate is it", "timestamp": "00:10:52,304", "timestamp_s": 652.0}, {"text": "just means when a response, an output from", "timestamp": "00:10:55,648", "timestamp_s": 655.0}, {"text": "one of those models are generated is stating", "timestamp": "00:10:59,536", "timestamp_s": 659.0}, {"text": "a inaccurate and not factual correct", "timestamp": "00:11:03,112", "timestamp_s": 663.0}, {"text": "information, right. So there is very little explainability of", "timestamp": "00:11:06,552", "timestamp_s": 666.0}, {"text": "why that information began to be. The way those models works is", "timestamp": "00:11:10,552", "timestamp_s": 670.0}, {"text": "just predicting the next word and they might just spit", "timestamp": "00:11:14,258", "timestamp_s": 674.0}, {"text": "it out. A lot of not factual,", "timestamp": "00:11:17,690", "timestamp_s": 677.0}, {"text": "accurate data. And it\u0027s really hard to know why", "timestamp": "00:11:20,290", "timestamp_s": 680.0}, {"text": "they have done that. So they lack explainability and interpretability.", "timestamp": "00:11:23,658", "timestamp_s": 683.0}, {"text": "And again, inaccurate information. It\u0027s what", "timestamp": "00:11:27,994", "timestamp_s": 687.0}, {"text": "we just described, which you might ask a question, the model", "timestamp": "00:11:31,498", "timestamp_s": 691.0}, {"text": "might give you an answer that sounds very, very confident", "timestamp": "00:11:35,322", "timestamp_s": 695.0}, {"text": "that answer is correct, but in fact, it\u0027s just a made up answer and", "timestamp": "00:11:39,640", "timestamp_s": 699.0}, {"text": "is not accurate, not neither factual,", "timestamp": "00:11:43,400", "timestamp_s": 703.0}, {"text": "accurate. So with that said,", "timestamp": "00:11:46,400", "timestamp_s": 706.0}, {"text": "with the limitations that we know, how can we potentially,", "timestamp": "00:11:50,256", "timestamp_s": 710.0}, {"text": "what are the solutions that we can put in place to help solve", "timestamp": "00:11:53,976", "timestamp_s": 713.0}, {"text": "this problem? So there is something called vector embeddings.", "timestamp": "00:11:57,840", "timestamp_s": 717.0}, {"text": "And what are vector embeddings? So vector embeddings", "timestamp": "00:12:01,624", "timestamp_s": 721.0}, {"text": "are using these foundational models.", "timestamp": "00:12:05,328", "timestamp_s": 725.0}, {"text": "Embeddings are semantic representations of", "timestamp": "00:12:08,464", "timestamp_s": 728.0}, {"text": "words by translating", "timestamp": "00:12:12,696", "timestamp_s": 732.0}, {"text": "into vector, mathematical vectors, float vector", "timestamp": "00:12:15,936", "timestamp_s": 735.0}, {"text": "vectors. So you can think about if a user inputs,", "timestamp": "00:12:19,928", "timestamp_s": 739.0}, {"text": "you know, New York and it runs into an embedded model,", "timestamp": "00:12:23,152", "timestamp_s": 743.0}, {"text": "and an embedded model is just a large language model that is able to", "timestamp": "00:12:26,776", "timestamp_s": 746.0}, {"text": "convert text into a array", "timestamp": "00:12:30,624", "timestamp_s": 750.0}, {"text": "of float numbers in a vector.", "timestamp": "00:12:34,152", "timestamp_s": 754.0}, {"text": "So you can see New York might be the", "timestamp": "00:12:37,480", "timestamp_s": 757.0}, {"text": "vector representation of New York, might be the one you see here.", "timestamp": "00:12:41,792", "timestamp_s": 761.0}, {"text": "There are different dimensions on vectors embeddings.", "timestamp": "00:12:45,656", "timestamp_s": 765.0}, {"text": "The bigger the dimensions, the more data and the more float numbers", "timestamp": "00:12:49,056", "timestamp_s": 769.0}, {"text": "you\u0027re going to have on the vector array.", "timestamp": "00:12:52,872", "timestamp_s": 772.0}, {"text": "And why are vectors embedding?", "timestamp": "00:12:55,664", "timestamp_s": 775.0}, {"text": "Is important because they carry", "timestamp": "00:12:59,320", "timestamp_s": 779.0}, {"text": "with those numbers, with these mathematical arrays", "timestamp": "00:13:02,936", "timestamp_s": 782.0}, {"text": "of flow numbers, they carry the semantic understanding", "timestamp": "00:13:06,824", "timestamp_s": 786.0}, {"text": "behind the text that you are embedding.", "timestamp": "00:13:11,296", "timestamp_s": 791.0}, {"text": "So, and we\u0027re going to talk in a moment why they are important.", "timestamp": "00:13:14,176", "timestamp_s": 794.0}, {"text": "But it\u0027s really important that if you have, you know,", "timestamp": "00:13:18,264", "timestamp_s": 798.0}, {"text": "terabytes of data that you want to store and you want to", "timestamp": "00:13:21,552", "timestamp_s": 801.0}, {"text": "very easily retrieve that data based on semantic understanding.", "timestamp": "00:13:25,110", "timestamp_s": 805.0}, {"text": "So you\u0027re not doing just an exactly match search, you\u0027re asking", "timestamp": "00:13:29,094", "timestamp_s": 809.0}, {"text": "a question. And that question might be related", "timestamp": "00:13:33,366", "timestamp_s": 813.0}, {"text": "to some of those, the context in your text that is also", "timestamp": "00:13:36,678", "timestamp_s": 816.0}, {"text": "known as semantic search. So the numbers will carry", "timestamp": "00:13:40,830", "timestamp_s": 820.0}, {"text": "a representation of the text in", "timestamp": "00:13:44,286", "timestamp_s": 824.0}, {"text": "itself. So now that", "timestamp": "00:13:47,710", "timestamp_s": 827.0}, {"text": "we might have generated. So it\u0027s very common on,", "timestamp": "00:13:51,626", "timestamp_s": 831.0}, {"text": "when you have those type of limitations into large", "timestamp": "00:13:55,810", "timestamp_s": 835.0}, {"text": "language models that we just described. One of the common", "timestamp": "00:13:59,506", "timestamp_s": 839.0}, {"text": "and best approaches to solve that is to add", "timestamp": "00:14:03,202", "timestamp_s": 843.0}, {"text": "an ability to retrieve the context from", "timestamp": "00:14:06,698", "timestamp_s": 846.0}, {"text": "your vector space and add the vector,", "timestamp": "00:14:10,386", "timestamp_s": 850.0}, {"text": "the text chunks that will be converted back from numbers", "timestamp": "00:14:14,474", "timestamp_s": 854.0}, {"text": "into text as context to your large language models.", "timestamp": "00:14:17,898", "timestamp_s": 857.0}, {"text": "But one of the challenges that you have once you create", "timestamp": "00:14:21,990", "timestamp_s": 861.0}, {"text": "all these embeddings, let\u0027s say you have multiple documents internally", "timestamp": "00:14:26,086", "timestamp_s": 866.0}, {"text": "and you want to translate all those documents, maybe PDF,", "timestamp": "00:14:30,174", "timestamp_s": 870.0}, {"text": "into vectors, what do you do with those vectors?", "timestamp": "00:14:33,518", "timestamp_s": 873.0}, {"text": "And here where vector databases play a big role.", "timestamp": "00:14:37,974", "timestamp_s": 877.0}, {"text": "So you want to make sure you can store those vectors representations,", "timestamp": "00:14:41,750", "timestamp_s": 881.0}, {"text": "those vector embeddings in a database. And then", "timestamp": "00:14:45,694", "timestamp_s": 885.0}, {"text": "after you restore there in the database, you have the ability to retrieve", "timestamp": "00:14:49,794", "timestamp_s": 889.0}, {"text": "by doing semantic search chunks of text that", "timestamp": "00:14:53,578", "timestamp_s": 893.0}, {"text": "are similar to the question or topic you", "timestamp": "00:14:57,610", "timestamp_s": 897.0}, {"text": "are trying to retrieve from. So how does vector", "timestamp": "00:15:01,138", "timestamp_s": 901.0}, {"text": "database works or this vector embedding system?", "timestamp": "00:15:04,442", "timestamp_s": 904.0}, {"text": "So if you think about in this diagram, you\u0027re going to have some raw data.", "timestamp": "00:15:07,962", "timestamp_s": 907.0}, {"text": "You know, it could be images, it could be documents, it could be audio.", "timestamp": "00:15:11,738", "timestamp_s": 911.0}, {"text": "For the sake of simplicity, for today\u0027s presentation, let\u0027s just focus on", "timestamp": "00:15:15,130", "timestamp_s": 915.0}, {"text": "text. So let\u0027s say you have a word document and you", "timestamp": "00:15:18,722", "timestamp_s": 918.0}, {"text": "want to create embeddings that behind the", "timestamp": "00:15:22,122", "timestamp_s": 922.0}, {"text": "scenes are going to create vectors, the arrays of vectors", "timestamp": "00:15:26,178", "timestamp_s": 926.0}, {"text": "for you. So what do you do? You create, you chunk that document", "timestamp": "00:15:29,826", "timestamp_s": 929.0}, {"text": "into different pieces, because there are limitations of", "timestamp": "00:15:33,930", "timestamp_s": 933.0}, {"text": "how many words you can create a vector.", "timestamp": "00:15:37,794", "timestamp_s": 937.0}, {"text": "And it is of course very depending on the embedding model, the foundation embedding", "timestamp": "00:15:41,914", "timestamp_s": 941.0}, {"text": "model that you use. But then once you have created", "timestamp": "00:15:46,202", "timestamp_s": 946.0}, {"text": "the chunks, you go through the model and you say, hey, here is the chunk", "timestamp": "00:15:49,410", "timestamp_s": 949.0}, {"text": "of text. Can you create a dense vector encoding for", "timestamp": "00:15:52,898", "timestamp_s": 952.0}, {"text": "me? So that is where it creates the vector embedding space", "timestamp": "00:15:56,610", "timestamp_s": 956.0}, {"text": "which will return an array of flow numbers for you that you", "timestamp": "00:16:00,058", "timestamp_s": 960.0}, {"text": "create your vector embeddings.", "timestamp": "00:16:03,290", "timestamp_s": 963.0}, {"text": "You can also create sparse vectors encoding, which is", "timestamp": "00:16:06,614", "timestamp_s": 966.0}, {"text": "a different way to perform and being more optimized when doing", "timestamp": "00:16:10,494", "timestamp_s": 970.0}, {"text": "the retrieval. Once you have those vectors, then you can", "timestamp": "00:16:14,502", "timestamp_s": 974.0}, {"text": "stores those vectors in a database. And we\u0027re going to talk about some", "timestamp": "00:16:18,158", "timestamp_s": 978.0}, {"text": "databases that AWS offers with the ability to", "timestamp": "00:16:21,766", "timestamp_s": 981.0}, {"text": "store those vector databases. And then after,", "timestamp": "00:16:25,326", "timestamp_s": 985.0}, {"text": "finally you can build applications that are able to", "timestamp": "00:16:28,598", "timestamp_s": 988.0}, {"text": "retrieve query your database using semantic understanding", "timestamp": "00:16:32,014", "timestamp_s": 992.0}, {"text": "and using different techniques like KNN", "timestamp": "00:16:37,184", "timestamp_s": 997.0}, {"text": "and few other ones that you can just ask a question", "timestamp": "00:16:41,224", "timestamp_s": 1001.0}, {"text": "and you find the close similarities,", "timestamp": "00:16:44,408", "timestamp_s": 1004.0}, {"text": "vectors from the probe and query that you\u0027ve provided.", "timestamp": "00:16:47,384", "timestamp_s": 1007.0}, {"text": "And after that you just, you copied", "timestamp": "00:16:51,360", "timestamp_s": 1011.0}, {"text": "the vectors from your database. You run again in the embedding", "timestamp": "00:16:54,864", "timestamp_s": 1014.0}, {"text": "model though that embedding model, just convert the vectors into", "timestamp": "00:16:58,384", "timestamp_s": 1018.0}, {"text": "text and then you can consume the text into", "timestamp": "00:17:03,284", "timestamp_s": 1023.0}, {"text": "the foundational models as texture text models that you", "timestamp": "00:17:06,524", "timestamp_s": 1026.0}, {"text": "might have available. Now let\u0027s just talk", "timestamp": "00:17:10,388", "timestamp_s": 1030.0}, {"text": "about the capabilities and databases that AWS offers", "timestamp": "00:17:13,700", "timestamp_s": 1033.0}, {"text": "you into storing those vectors.", "timestamp": "00:17:17,484", "timestamp_s": 1037.0}, {"text": "So there are a wide array of", "timestamp": "00:17:21,508", "timestamp_s": 1041.0}, {"text": "databases that AWS provides.", "timestamp": "00:17:25,476", "timestamp_s": 1045.0}, {"text": "They have vector capabilities you", "timestamp": "00:17:29,034", "timestamp_s": 1049.0}, {"text": "can see here on the list. We are going to go through most of them", "timestamp": "00:17:32,178", "timestamp_s": 1052.0}, {"text": "and I\u0027m just going to talk to you about a high level why", "timestamp": "00:17:35,370", "timestamp_s": 1055.0}, {"text": "and how they are different from each other. So we\u0027re going to have search engines", "timestamp": "00:17:41,178", "timestamp_s": 1061.0}, {"text": "like open search. We\u0027re going to have relational databases like", "timestamp": "00:17:45,026", "timestamp_s": 1065.0}, {"text": "Postgres Aurora Postgres and RDS postgres.", "timestamp": "00:17:48,850", "timestamp_s": 1068.0}, {"text": "You\u0027re going to have document databases like document DB.", "timestamp": "00:17:52,866", "timestamp_s": 1072.0}, {"text": "You\u0027re going to have memory ink in memory", "timestamp": "00:17:56,160", "timestamp_s": 1076.0}, {"text": "databases like memory DB, and graph", "timestamp": "00:17:59,912", "timestamp_s": 1079.0}, {"text": "databases like Neptune. And all of those databases", "timestamp": "00:18:03,184", "timestamp_s": 1083.0}, {"text": "now have capabilities to run and store vector", "timestamp": "00:18:06,584", "timestamp_s": 1086.0}, {"text": "functionality. So let\u0027s just start with our first", "timestamp": "00:18:11,144", "timestamp_s": 1091.0}, {"text": "database. Amazon Zarora is", "timestamp": "00:18:14,968", "timestamp_s": 1094.0}, {"text": "a relational database that is a managed database on AWS.", "timestamp": "00:18:18,456", "timestamp_s": 1098.0}, {"text": "So Amazon Aurora Postgres flavor now has", "timestamp": "00:18:22,834", "timestamp_s": 1102.0}, {"text": "the capability to run vectors", "timestamp": "00:18:26,890", "timestamp_s": 1106.0}, {"text": "using a extension called, which is an", "timestamp": "00:18:30,778", "timestamp_s": 1110.0}, {"text": "open source extension called PG Vector. What it allows", "timestamp": "00:18:34,106", "timestamp_s": 1114.0}, {"text": "you to do is to have vector embeddings", "timestamp": "00:18:37,962", "timestamp_s": 1117.0}, {"text": "stored on your relation database. So if you\u0027re already storing", "timestamp": "00:18:42,434", "timestamp_s": 1122.0}, {"text": "your data using a relational approach and you just want to store", "timestamp": "00:18:46,194", "timestamp_s": 1126.0}, {"text": "an additional vector representation", "timestamp": "00:18:50,090", "timestamp_s": 1130.0}, {"text": "of the data, you can install PG vector both on Amazon Aurora", "timestamp": "00:18:53,502", "timestamp_s": 1133.0}, {"text": "and RDS postgres flavor.", "timestamp": "00:18:57,646", "timestamp_s": 1137.0}, {"text": "And once you restore those embeddings, you can", "timestamp": "00:19:00,630", "timestamp_s": 1140.0}, {"text": "support different algorithms such as KNN ANN", "timestamp": "00:19:04,510", "timestamp_s": 1144.0}, {"text": "H and SW and IV flat. Those are", "timestamp": "00:19:08,838", "timestamp_s": 1148.0}, {"text": "just different approaches and solutions on", "timestamp": "00:19:12,190", "timestamp_s": 1152.0}, {"text": "how to retrieve close similarities and chunks of embeddings", "timestamp": "00:19:15,862", "timestamp_s": 1155.0}, {"text": "and text for you. And you know, for postgres apps,", "timestamp": "00:19:20,196", "timestamp_s": 1160.0}, {"text": "the good thing is you don\u0027t need to make any driver", "timestamp": "00:19:23,932", "timestamp_s": 1163.0}, {"text": "change. You can just literally use install the extension on Amazon Aurora", "timestamp": "00:19:28,332", "timestamp_s": 1168.0}, {"text": "or RDS Aurora and continue to use your database.", "timestamp": "00:19:32,196", "timestamp_s": 1172.0}, {"text": "So this solution is a very good solution for existing", "timestamp": "00:19:36,036", "timestamp_s": 1176.0}, {"text": "postgres SQL users or any users", "timestamp": "00:19:40,252", "timestamp_s": 1180.0}, {"text": "that prefer relation database. You can actually use them.", "timestamp": "00:19:43,332", "timestamp_s": 1183.0}, {"text": "That right? So it\u0027s really powerful. There are a lot", "timestamp": "00:19:46,716", "timestamp_s": 1186.0}, {"text": "of integration. So if you have ML", "timestamp": "00:19:50,198", "timestamp_s": 1190.0}, {"text": "background but you are focused on relation database you,", "timestamp": "00:19:54,574", "timestamp_s": 1194.0}, {"text": "I would recommend you taking a look at Amazon Aurora with PG Vector", "timestamp": "00:19:58,958", "timestamp_s": 1198.0}, {"text": "and talking about PG Vector. PG Vector is an open source postgres", "timestamp": "00:20:04,038", "timestamp_s": 1204.0}, {"text": "SQL extension that is designed for efficient vector", "timestamp": "00:20:07,958", "timestamp_s": 1207.0}, {"text": "similarity search and perfect for levering machine learning with", "timestamp": "00:20:11,598", "timestamp_s": 1211.0}, {"text": "your databases. So it supports storing data", "timestamp": "00:20:15,484", "timestamp_s": 1215.0}, {"text": "along with your traditional data types while maintaining", "timestamp": "00:20:19,076", "timestamp_s": 1219.0}, {"text": "postgres robustness features such as acid compliant", "timestamp": "00:20:22,604", "timestamp_s": 1222.0}, {"text": "point in time recover and PG vector handles", "timestamp": "00:20:27,484", "timestamp_s": 1227.0}, {"text": "exactly an approximate nearest neighbor. Search accommodates in", "timestamp": "00:20:31,316", "timestamp_s": 1231.0}, {"text": "various distance measures like l two indian product", "timestamp": "00:20:35,364", "timestamp_s": 1235.0}, {"text": "and cosine distance. Those are just different mathematical expressions", "timestamp": "00:20:38,924", "timestamp_s": 1238.0}, {"text": "that are going to retrieve the similarity semantic", "timestamp": "00:20:43,466", "timestamp_s": 1243.0}, {"text": "search for you as you can see here, PG vector", "timestamp": "00:20:47,226", "timestamp_s": 1247.0}, {"text": "and with Aurora and RDS, sorry with Aurora are", "timestamp": "00:20:50,722", "timestamp_s": 1250.0}, {"text": "also integrated with Amazon bedrock knowledge base. We\u0027re going to talk about", "timestamp": "00:20:54,434", "timestamp_s": 1254.0}, {"text": "that in a moment. You have configurable require rate using", "timestamp": "00:20:58,242", "timestamp_s": 1258.0}, {"text": "these different approaches like HM and SW", "timestamp": "00:21:02,178", "timestamp_s": 1262.0}, {"text": "EF underscore search and IV IVF flat", "timestamp": "00:21:05,856", "timestamp_s": 1265.0}, {"text": "probes. The good thing about PG vector, it can", "timestamp": "00:21:09,960", "timestamp_s": 1269.0}, {"text": "scale to support over 1 billion vectors and the", "timestamp": "00:21:13,448", "timestamp_s": 1273.0}, {"text": "dimension it can support vectors with a 16 up to", "timestamp": "00:21:16,760", "timestamp_s": 1276.0}, {"text": "16,000 dimension. So that is a very good", "timestamp": "00:21:20,024", "timestamp_s": 1280.0}, {"text": "way if you have relational databases and you want to store vectors and", "timestamp": "00:21:23,576", "timestamp_s": 1283.0}, {"text": "this could be the place you you go.", "timestamp": "00:21:27,072", "timestamp_s": 1287.0}, {"text": "Second, we nietzsche talked about a very powerful", "timestamp": "00:21:30,184", "timestamp_s": 1290.0}, {"text": "service which is Amazon open search. So Amazon", "timestamp": "00:21:34,652", "timestamp_s": 1294.0}, {"text": "Open Search is a NoSQL database that is", "timestamp": "00:21:38,196", "timestamp_s": 1298.0}, {"text": "has been built from the beginning with scalability", "timestamp": "00:21:42,684", "timestamp_s": 1302.0}, {"text": "and as a distributed database for", "timestamp": "00:21:46,668", "timestamp_s": 1306.0}, {"text": "search. So you can use search and analytics engine", "timestamp": "00:21:50,028", "timestamp_s": 1310.0}, {"text": "on top of open search. You have different", "timestamp": "00:21:54,156", "timestamp_s": 1314.0}, {"text": "types of deployment for open source. So you can have a managed service that you", "timestamp": "00:21:57,252", "timestamp_s": 1317.0}, {"text": "manage different instance behind the scene for you. But it\u0027s also", "timestamp": "00:22:00,956", "timestamp_s": 1320.0}, {"text": "have the capability to deploy a serverless open search", "timestamp": "00:22:04,822", "timestamp_s": 1324.0}, {"text": "where you don\u0027t need to manage, you know, even the service doesn\u0027t need to", "timestamp": "00:22:08,478", "timestamp_s": 1328.0}, {"text": "manage any server for you. It doesn\u0027t abstract abstracts that", "timestamp": "00:22:11,982", "timestamp_s": 1331.0}, {"text": "away from you. Open search has also the", "timestamp": "00:22:15,702", "timestamp_s": 1335.0}, {"text": "capability restore vector using the KNN plugin.", "timestamp": "00:22:18,942", "timestamp_s": 1338.0}, {"text": "It also supports different algorithms such", "timestamp": "00:22:22,630", "timestamp_s": 1342.0}, {"text": "as KNN, AM, HMSW and IV", "timestamp": "00:22:26,710", "timestamp_s": 1346.0}, {"text": "flat. IVF flat. So you can see that similar", "timestamp": "00:22:30,422", "timestamp_s": 1350.0}, {"text": "to the Aurora postgres, Opensearch has", "timestamp": "00:22:34,506", "timestamp_s": 1354.0}, {"text": "similar algorithm capability.", "timestamp": "00:22:38,186", "timestamp_s": 1358.0}, {"text": "And if you have DynoDB tables, you can actually use zero ETL", "timestamp": "00:22:41,074", "timestamp_s": 1361.0}, {"text": "from dynoDB to move the data into open source service", "timestamp": "00:22:44,666", "timestamp_s": 1364.0}, {"text": "and you can vectorize those as well. So who are", "timestamp": "00:22:49,202", "timestamp_s": 1369.0}, {"text": "open source service? Very. It\u0027s a good fit.", "timestamp": "00:22:53,226", "timestamp_s": 1373.0}, {"text": "So if you are already an open source user or if you prefer NoSQL and", "timestamp": "00:22:57,162", "timestamp_s": 1377.0}, {"text": "you want to do hybrid search as well. So let\u0027s say you have a piece", "timestamp": "00:23:01,056", "timestamp_s": 1381.0}, {"text": "of text and you want to search both maybe search or", "timestamp": "00:23:04,192", "timestamp_s": 1384.0}, {"text": "field from the text, but also using the vector semantic capability,", "timestamp": "00:23:07,720", "timestamp_s": 1387.0}, {"text": "open search support that capability for you.", "timestamp": "00:23:12,184", "timestamp_s": 1392.0}, {"text": "And with open search service", "timestamp": "00:23:15,984", "timestamp_s": 1395.0}, {"text": "on AWS for vector it supports.", "timestamp": "00:23:19,968", "timestamp_s": 1399.0}, {"text": "I really like the open search and we\u0027ll do a demo later on because you", "timestamp": "00:23:23,808", "timestamp_s": 1403.0}, {"text": "can very easily and cost efficient deploy an open search serverless", "timestamp": "00:23:28,000", "timestamp_s": 1408.0}, {"text": "vector database that will behind the scenes manage all the", "timestamp": "00:23:32,258", "timestamp_s": 1412.0}, {"text": "index shared and manipulation of the data for you", "timestamp": "00:23:36,386", "timestamp_s": 1416.0}, {"text": "and it can scale for over a billion vectors with very high performance", "timestamp": "00:23:40,178", "timestamp_s": 1420.0}, {"text": "with the same dimensionality as Aurora. You can also", "timestamp": "00:23:44,546", "timestamp_s": 1424.0}, {"text": "have configurable recall rates via different segments and EF", "timestamp": "00:23:48,586", "timestamp_s": 1428.0}, {"text": "search. And similar to Amazon Aurora,", "timestamp": "00:23:52,418", "timestamp_s": 1432.0}, {"text": "OpenSearch is one of the main vector databases on AWS", "timestamp": "00:23:56,354", "timestamp_s": 1436.0}, {"text": "and integrates very well with knowledge base", "timestamp": "00:24:00,742", "timestamp_s": 1440.0}, {"text": "on bedrock. But also open search has", "timestamp": "00:24:04,774", "timestamp_s": 1444.0}, {"text": "a plugin called Neuro search that it can provide a", "timestamp": "00:24:07,982", "timestamp_s": 1447.0}, {"text": "very seamless integration between your text ingestion", "timestamp": "00:24:11,670", "timestamp_s": 1451.0}, {"text": "and the vector embedding creation. It can talk to Bedrock,", "timestamp": "00:24:16,350", "timestamp_s": 1456.0}, {"text": "you can talk to OpenAI, you can talk with cohere.", "timestamp": "00:24:20,142", "timestamp_s": 1460.0}, {"text": "By using this neural search it can automatically do all the", "timestamp": "00:24:23,388", "timestamp_s": 1463.0}, {"text": "retrieval generation of the battings for you continuing", "timestamp": "00:24:27,132", "timestamp_s": 1467.0}, {"text": "the segment. Vector support on AWS is", "timestamp": "00:24:32,252", "timestamp_s": 1472.0}, {"text": "also made available through document DB. So document DB is", "timestamp": "00:24:36,396", "timestamp_s": 1476.0}, {"text": "a very fast cloud native document database.", "timestamp": "00:24:39,988", "timestamp_s": 1479.0}, {"text": "So again it\u0027s a NoSQL database that has MongoDB API", "timestamp": "00:24:43,420", "timestamp_s": 1483.0}, {"text": "compatibility. You have different provision deployment", "timestamp": "00:24:47,476", "timestamp_s": 1487.0}, {"text": "options that it\u0027s a managed service. It also supports", "timestamp": "00:24:51,282", "timestamp_s": 1491.0}, {"text": "the same algorithms that I mentioned before,", "timestamp": "00:24:56,114", "timestamp_s": 1496.0}, {"text": "KNN Am IVF flat.", "timestamp": "00:24:59,314", "timestamp_s": 1499.0}, {"text": "By using MongoDB you can just elevate", "timestamp": "00:25:03,434", "timestamp_s": 1503.0}, {"text": "the capability of your vector search if you\u0027re already using documentDB", "timestamp": "00:25:09,002", "timestamp_s": 1509.0}, {"text": "or MongoDB. And what we", "timestamp": "00:25:12,722", "timestamp_s": 1512.0}, {"text": "see here is the good thing about documentDB if", "timestamp": "00:25:15,910", "timestamp_s": 1515.0}, {"text": "you\u0027re very familiar with document databases specific", "timestamp": "00:25:19,158", "timestamp_s": 1519.0}, {"text": "JSON usage because document database are really powerful", "timestamp": "00:25:23,750", "timestamp_s": 1523.0}, {"text": "with JSON, if you want to vectorize that information", "timestamp": "00:25:27,062", "timestamp_s": 1527.0}, {"text": "by just enabling vector capabilities", "timestamp": "00:25:30,214", "timestamp_s": 1530.0}, {"text": "on your document DB, it becomes very very powerful", "timestamp": "00:25:33,526", "timestamp_s": 1533.0}, {"text": "and continue. This is a very interesting service.", "timestamp": "00:25:37,814", "timestamp_s": 1537.0}, {"text": "Amazon Memory DB for Redis now also", "timestamp": "00:25:41,594", "timestamp_s": 1541.0}, {"text": "have a feature that is currently in preview and hopefully very soon is", "timestamp": "00:25:45,450", "timestamp_s": 1545.0}, {"text": "going to become GA general available that adds the ability", "timestamp": "00:25:48,810", "timestamp_s": 1548.0}, {"text": "for memory DB, which is already a very popular and", "timestamp": "00:25:52,394", "timestamp_s": 1552.0}, {"text": "performant database to have multi zero", "timestamp": "00:25:58,074", "timestamp_s": 1558.0}, {"text": "ability to handle vector storage, index and", "timestamp": "00:26:02,026", "timestamp_s": 1562.0}, {"text": "search capabilities. So memory DB,", "timestamp": "00:26:05,922", "timestamp_s": 1565.0}, {"text": "like the name says, is a database that stores all the data in", "timestamp": "00:26:09,438", "timestamp_s": 1569.0}, {"text": "memory and is ready\u0027s API compatible. It\u0027s a fully", "timestamp": "00:26:12,822", "timestamp_s": 1572.0}, {"text": "managed service. You can see it supports different word vector", "timestamp": "00:26:16,758", "timestamp_s": 1576.0}, {"text": "searches, algorithms that we mentioned. It has", "timestamp": "00:26:21,038", "timestamp_s": 1581.0}, {"text": "abilities to support up to 32,000 dimensions", "timestamp": "00:26:24,534", "timestamp_s": 1584.0}, {"text": "of vectors. And this is ideal if you really have a workflow", "timestamp": "00:26:28,718", "timestamp_s": 1588.0}, {"text": "that requires single digit millisecond", "timestamp": "00:26:32,622", "timestamp_s": 1592.0}, {"text": "latencies and throughput for your vector.", "timestamp": "00:26:36,054", "timestamp_s": 1596.0}, {"text": "So let\u0027s say you are building a chatbot that should be really quickly or trying", "timestamp": "00:26:39,534", "timestamp_s": 1599.0}, {"text": "to do retrieval augmented generation. That is super powerful.", "timestamp": "00:26:43,094", "timestamp_s": 1603.0}, {"text": "Memory DB might be the best place to look for because", "timestamp": "00:26:47,054", "timestamp_s": 1607.0}, {"text": "that very powerful capability and", "timestamp": "00:26:50,318", "timestamp_s": 1610.0}, {"text": "then fine. Last but not least, you also have Amazon", "timestamp": "00:26:54,030", "timestamp_s": 1614.0}, {"text": "Neptune analytics. So Amazon Neptune is the", "timestamp": "00:26:57,174", "timestamp_s": 1617.0}, {"text": "Amazon graph database. It allows you", "timestamp": "00:27:00,518", "timestamp_s": 1620.0}, {"text": "with the Amazon Neptune analytics allows you to have analytic", "timestamp": "00:27:04,214", "timestamp_s": 1624.0}, {"text": "memory optimized graph database engines. You have", "timestamp": "00:27:07,590", "timestamp_s": 1627.0}, {"text": "different discrete capacity deployments to deploy this database.", "timestamp": "00:27:11,126", "timestamp_s": 1631.0}, {"text": "It supports agents w similarity algorithm.", "timestamp": "00:27:14,942", "timestamp_s": 1634.0}, {"text": "You can see the dimension of that. This database for vectors are", "timestamp": "00:27:19,102", "timestamp_s": 1639.0}, {"text": "much bigger with up to 65,000 and it complements.", "timestamp": "00:27:22,782", "timestamp_s": 1642.0}, {"text": "So it\u0027s an addition plugin on top of your Amazon Neptune database.", "timestamp": "00:27:26,478", "timestamp_s": 1646.0}, {"text": "And if you why would you use Neptune", "timestamp": "00:27:30,702", "timestamp_s": 1650.0}, {"text": "analytics for your vector database? So if you\u0027re using neural networks, use cases", "timestamp": "00:27:34,790", "timestamp_s": 1654.0}, {"text": "where you need to do vector search graph traversals.", "timestamp": "00:27:39,014", "timestamp_s": 1659.0}, {"text": "This would be a very good approach. You can", "timestamp": "00:27:42,990", "timestamp_s": 1662.0}, {"text": "also use Neptune database with serverless deployment,", "timestamp": "00:27:46,262", "timestamp_s": 1666.0}, {"text": "but Neptune analytics only supports discrete capacity levels", "timestamp": "00:27:50,654", "timestamp_s": 1670.0}, {"text": "at this time. So if you\u0027re curious to", "timestamp": "00:27:54,934", "timestamp_s": 1674.0}, {"text": "learn more, I know I just covered very quickly these databases. I would", "timestamp": "00:27:58,490", "timestamp_s": 1678.0}, {"text": "highly recommend that you just do a quick Google and search", "timestamp": "00:28:01,898", "timestamp_s": 1681.0}, {"text": "our AWS documentation about how they work.", "timestamp": "00:28:05,842", "timestamp_s": 1685.0}, {"text": "But now I want to talk about Amazon Bedrock.", "timestamp": "00:28:09,194", "timestamp_s": 1689.0}, {"text": "I mentioned before in the beginning of my presentation that Amazon Bedrock", "timestamp": "00:28:12,994", "timestamp_s": 1692.0}, {"text": "is the easiest way for you to build generative AI applications", "timestamp": "00:28:17,242", "timestamp_s": 1697.0}, {"text": "on AWS. And the amazing thing about Bedrock", "timestamp": "00:28:21,162", "timestamp_s": 1701.0}, {"text": "is a completely managed service for Genai models. So you", "timestamp": "00:28:24,400", "timestamp_s": 1704.0}, {"text": "have a choice of multiple models with industry leading", "timestamp": "00:28:28,520", "timestamp_s": 1708.0}, {"text": "foundational model providers that are available with a single API", "timestamp": "00:28:32,912", "timestamp_s": 1712.0}, {"text": "call if you want. You can also customize and", "timestamp": "00:28:36,264", "timestamp_s": 1716.0}, {"text": "fine tune your models using your own organization data.", "timestamp": "00:28:39,520", "timestamp_s": 1719.0}, {"text": "And Bedrock has taken security", "timestamp": "00:28:42,688", "timestamp_s": 1722.0}, {"text": "as job number zero and it has all", "timestamp": "00:28:46,040", "timestamp_s": 1726.0}, {"text": "the encryption capabilities, privacy capabilities,", "timestamp": "00:28:49,824", "timestamp_s": 1729.0}, {"text": "not using your data to train any of those models. So it\u0027s an enterprise", "timestamp": "00:28:53,240", "timestamp_s": 1733.0}, {"text": "grade security and private service. With Amazon Bedrock", "timestamp": "00:28:57,296", "timestamp_s": 1737.0}, {"text": "you have a broad choice of models, as you can see here. This list", "timestamp": "00:29:01,432", "timestamp_s": 1741.0}, {"text": "is just as of today in March 30", "timestamp": "00:29:04,760", "timestamp_s": 1744.0}, {"text": "as I\u0027m recording this session 2024. Right now there", "timestamp": "00:29:08,760", "timestamp_s": 1748.0}, {"text": "are seven different model providers,", "timestamp": "00:29:12,320", "timestamp_s": 1752.0}, {"text": "AI 21, Amazon and tropic cohere,", "timestamp": "00:29:15,712", "timestamp_s": 1755.0}, {"text": "meta nest row and stability.", "timestamp": "00:29:19,398", "timestamp_s": 1759.0}, {"text": "Those models have different capabilities. So you\u0027re going to", "timestamp": "00:29:22,454", "timestamp_s": 1762.0}, {"text": "have a text to text model where it\u0027s just a foundational model that you send", "timestamp": "00:29:25,870", "timestamp_s": 1765.0}, {"text": "text and it returns text back by predicting the next", "timestamp": "00:29:29,742", "timestamp_s": 1769.0}, {"text": "word. But you also have embedded models such as Amazon", "timestamp": "00:29:33,070", "timestamp_s": 1773.0}, {"text": "text embeddings and Amazon Titan multi model embeddings.", "timestamp": "00:29:37,086", "timestamp_s": 1777.0}, {"text": "But you also have an embeddings with cohere, which is the coherent", "timestamp": "00:29:41,406", "timestamp_s": 1781.0}, {"text": "embedding multilingual. And on top of that,", "timestamp": "00:29:45,286", "timestamp_s": 1785.0}, {"text": "you also have the ability to use bedrock to generate images with", "timestamp": "00:29:48,818", "timestamp_s": 1788.0}, {"text": "stability, AI stable diffusion Excel 1.0,", "timestamp": "00:29:52,938", "timestamp_s": 1792.0}, {"text": "but also with Titan image generator,", "timestamp": "00:29:57,378", "timestamp_s": 1797.0}, {"text": "it\u0027s pay as you go. You pay per token that you consume and", "timestamp": "00:30:01,834", "timestamp_s": 1801.0}, {"text": "you can choose the model that you\u0027re going to have access. In my demo I\u0027m", "timestamp": "00:30:05,890", "timestamp_s": 1805.0}, {"text": "going to show you actually in the demo, the demo that we\u0027re going to show", "timestamp": "00:30:09,530", "timestamp_s": 1809.0}, {"text": "to you today is knowledge base for Amazon", "timestamp": "00:30:12,974", "timestamp_s": 1812.0}, {"text": "bedrock. And this is where I\u0027m trying to bring all my", "timestamp": "00:30:16,254", "timestamp_s": 1816.0}, {"text": "presentation into a single place. Knowing the limitations of large language", "timestamp": "00:30:19,942", "timestamp_s": 1819.0}, {"text": "models that I\u0027ve discussed in the beginning, one of the ways", "timestamp": "00:30:24,254", "timestamp_s": 1824.0}, {"text": "that you can work around the limitation is by creating a", "timestamp": "00:30:27,822", "timestamp_s": 1827.0}, {"text": "rack system, a retrieval augmented generation. What is a", "timestamp": "00:30:32,118", "timestamp_s": 1832.0}, {"text": "retrieval generation augmented is to bring pieces", "timestamp": "00:30:35,550", "timestamp_s": 1835.0}, {"text": "of data on text into your", "timestamp": "00:30:40,378", "timestamp_s": 1840.0}, {"text": "context before sending to a foundational model.", "timestamp": "00:30:43,866", "timestamp_s": 1843.0}, {"text": "And the ability that you do that, the first thing you need to do is", "timestamp": "00:30:47,210", "timestamp_s": 1847.0}, {"text": "to have a vector database where you can store all the vector embeddings", "timestamp": "00:30:50,450", "timestamp_s": 1850.0}, {"text": "from your specific domain data.", "timestamp": "00:30:55,090", "timestamp_s": 1855.0}, {"text": "You can retrieve the data at the query time. That data", "timestamp": "00:30:59,354", "timestamp_s": 1859.0}, {"text": "is going to be converted from vectors to text and", "timestamp": "00:31:03,384", "timestamp_s": 1863.0}, {"text": "then that data is going to be put it as the context of", "timestamp": "00:31:06,720", "timestamp_s": 1866.0}, {"text": "your query to the foundational model. It\u0027s,", "timestamp": "00:31:10,064", "timestamp_s": 1870.0}, {"text": "it can be very cumbersome to build this completely", "timestamp": "00:31:13,592", "timestamp_s": 1873.0}, {"text": "rag solution. So what knowledge basis for Amazon bedrock", "timestamp": "00:31:17,072", "timestamp_s": 1877.0}, {"text": "achieves is to automatically automate", "timestamp": "00:31:21,384", "timestamp_s": 1881.0}, {"text": "all the ingestion and retrieval for", "timestamp": "00:31:26,384", "timestamp_s": 1886.0}, {"text": "you on this reg system. So you connect", "timestamp": "00:31:29,736", "timestamp_s": 1889.0}, {"text": "your knowledge base with a database, you there", "timestamp": "00:31:33,792", "timestamp_s": 1893.0}, {"text": "are currently different supports for databases that are going to show in a moment for", "timestamp": "00:31:38,032", "timestamp_s": 1898.0}, {"text": "vector databases. Then you select an embedding", "timestamp": "00:31:41,600", "timestamp_s": 1901.0}, {"text": "model. Then you put your data on s", "timestamp": "00:31:45,296", "timestamp_s": 1905.0}, {"text": "three simple storage service and", "timestamp": "00:31:48,864", "timestamp_s": 1908.0}, {"text": "as soon as the data hits on that", "timestamp": "00:31:52,704", "timestamp_s": 1912.0}, {"text": "s three you can sync knowledge base which", "timestamp": "00:31:56,224", "timestamp_s": 1916.0}, {"text": "behind the scenes is going to create the embeddings, start embedding in", "timestamp": "00:31:59,752", "timestamp_s": 1919.0}, {"text": "the database and then when you make a call to", "timestamp": "00:32:03,088", "timestamp_s": 1923.0}, {"text": "knowledgebase for bedrock, that call you can decide", "timestamp": "00:32:07,120", "timestamp_s": 1927.0}, {"text": "if that call just retrieved the data from your database", "timestamp": "00:32:11,144", "timestamp_s": 1931.0}, {"text": "or if you want to do retrieve and generation, which means", "timestamp": "00:32:14,568", "timestamp_s": 1934.0}, {"text": "just retrieve the data from Myvector database, send to the", "timestamp": "00:32:18,288", "timestamp_s": 1938.0}, {"text": "foundation model, generate a response with my contacts,", "timestamp": "00:32:21,888", "timestamp_s": 1941.0}, {"text": "awareness information and then give the answer back to the customer.", "timestamp": "00:32:24,914", "timestamp_s": 1944.0}, {"text": "And you can select the model that you want to be used as the foundational", "timestamp": "00:32:28,914", "timestamp_s": 1948.0}, {"text": "model and also the embedding as well.", "timestamp": "00:32:32,370", "timestamp_s": 1952.0}, {"text": "So knowledge base on Bedrock has support for", "timestamp": "00:32:35,274", "timestamp_s": 1955.0}, {"text": "currently different databases. So right now it supports vector engine", "timestamp": "00:32:38,882", "timestamp_s": 1958.0}, {"text": "for open source serverless, redis, enterprise, cloud,", "timestamp": "00:32:42,602", "timestamp_s": 1962.0}, {"text": "Pinecone and Amazon Aurora. There are more capabilities coming soon.", "timestamp": "00:32:45,714", "timestamp_s": 1965.0}, {"text": "For example Mongodb. It\u0027s coming to be one of the vector", "timestamp": "00:32:49,970", "timestamp_s": 1969.0}, {"text": "databases support on Amazon Bedrock and hopefully in the future more", "timestamp": "00:32:53,892", "timestamp_s": 1973.0}, {"text": "of the databases that I talked today are also going to be available on", "timestamp": "00:32:57,460", "timestamp_s": 1977.0}, {"text": "bedrock. And the last thing I want to show is with knowledge", "timestamp": "00:33:01,020", "timestamp_s": 1981.0}, {"text": "base for bedrock you can use a single API call to do", "timestamp": "00:33:05,396", "timestamp_s": 1985.0}, {"text": "the retrieval and generation. So if you look at this diagram", "timestamp": "00:33:08,868", "timestamp_s": 1988.0}, {"text": "with a single API call on number one you can think about", "timestamp": "00:33:12,524", "timestamp_s": 1992.0}, {"text": "a search query. So you can say,", "timestamp": "00:33:16,260", "timestamp_s": 1996.0}, {"text": "let\u0027s just give an example. You are asking about a", "timestamp": "00:33:19,384", "timestamp_s": 1999.0}, {"text": "proprietary question of your company,", "timestamp": "00:33:22,648", "timestamp_s": 2002.0}, {"text": "right? And you know the foundation model doesn\u0027t know the answer.", "timestamp": "00:33:26,368", "timestamp_s": 2006.0}, {"text": "So you can do a search query what bedrock", "timestamp": "00:33:29,616", "timestamp_s": 2009.0}, {"text": "knowledge base you do, realizing that you need to do a retrieval on", "timestamp": "00:33:33,104", "timestamp_s": 2013.0}, {"text": "your vector database. So number two is going to go there, do the retrieval,", "timestamp": "00:33:36,600", "timestamp_s": 2016.0}, {"text": "then behind the scenes going to call your vector", "timestamp": "00:33:40,720", "timestamp_s": 2020.0}, {"text": "database is going to retrieve that", "timestamp": "00:33:44,064", "timestamp_s": 2024.0}, {"text": "embedding. The vector embedding is going to then convert", "timestamp": "00:33:48,322", "timestamp_s": 2028.0}, {"text": "the vector into text. And then on four", "timestamp": "00:33:52,946", "timestamp_s": 2032.0}, {"text": "it\u0027s going to send that text as context into your", "timestamp": "00:33:56,186", "timestamp_s": 2036.0}, {"text": "bedrock foundational model, texture text generation.", "timestamp": "00:34:00,658", "timestamp_s": 2040.0}, {"text": "And then finally it\u0027s going to send back the generation", "timestamp": "00:34:04,074", "timestamp_s": 2044.0}, {"text": "of answer that it chose. And you can see here soon,", "timestamp": "00:34:07,826", "timestamp_s": 2047.0}, {"text": "you know it\u0027s also going to support s three.", "timestamp": "00:34:11,956", "timestamp_s": 2051.0}, {"text": "And now let\u0027s jump in to do a", "timestamp": "00:34:15,404", "timestamp_s": 2055.0}, {"text": "quick demo of knowledge base for bedrock.", "timestamp": "00:34:18,652", "timestamp_s": 2058.0}, {"text": "Awesome. So let\u0027s just jump into the demo.", "timestamp": "00:34:28,844", "timestamp_s": 2068.0}, {"text": "The demo will be a very straightforward.", "timestamp": "00:34:32,356", "timestamp_s": 2072.0}, {"text": "I have downloaded some files", "timestamp": "00:34:35,884", "timestamp_s": 2075.0}, {"text": "from Amazon shareholder ladder.", "timestamp": "00:34:40,064", "timestamp_s": 2080.0}, {"text": "So you can see here I have the 2019,", "timestamp": "00:34:44,552", "timestamp_s": 2084.0}, {"text": "the 2020, the 2021 and the", "timestamp": "00:34:48,608", "timestamp_s": 2088.0}, {"text": "2022 Amazon shareholder.", "timestamp": "00:34:51,712", "timestamp_s": 2091.0}, {"text": "What I want to show is I have already created a", "timestamp": "00:34:55,352", "timestamp_s": 2095.0}, {"text": "open search database and I have then linked", "timestamp": "00:34:58,992", "timestamp_s": 2098.0}, {"text": "that database into bedrock knowledge base", "timestamp": "00:35:04,044", "timestamp_s": 2104.0}, {"text": "and I want to show you that it created the vectors automatically", "timestamp": "00:35:07,900", "timestamp_s": 2107.0}, {"text": "from s three. So just first let me show you.", "timestamp": "00:35:11,316", "timestamp_s": 2111.0}, {"text": "I have an s three here. So I created an s three", "timestamp": "00:35:14,636", "timestamp_s": 2114.0}, {"text": "bucket on that s three bucket. I just true", "timestamp": "00:35:18,044", "timestamp_s": 2118.0}, {"text": "those four files. I could have as many files as, you know,", "timestamp": "00:35:22,364", "timestamp_s": 2122.0}, {"text": "I wanted here. And what I\u0027ve done then of", "timestamp": "00:35:26,852", "timestamp_s": 2126.0}, {"text": "course I\u0027ve created an open search database. So this open", "timestamp": "00:35:31,034", "timestamp_s": 2131.0}, {"text": "search database you can see here, it\u0027s an open search serverless database.", "timestamp": "00:35:34,426", "timestamp_s": 2134.0}, {"text": "I have a collection. So let me just close these ones.", "timestamp": "00:35:38,202", "timestamp_s": 2138.0}, {"text": "I have a collection here I call bedrock sample.", "timestamp": "00:35:41,242", "timestamp_s": 2141.0}, {"text": "So I created this database. There is a dashboard also created for", "timestamp": "00:35:44,930", "timestamp_s": 2144.0}, {"text": "this database that I\u0027m going to show in a moment. But the interesting part here", "timestamp": "00:35:48,242", "timestamp_s": 2148.0}, {"text": "is if I go on bedrock, which bedrock is the service that,", "timestamp": "00:35:51,898", "timestamp_s": 2151.0}, {"text": "that allows a no easy and scalable", "timestamp": "00:35:55,394", "timestamp_s": 2155.0}, {"text": "way to create generative AI on bedrock.", "timestamp": "00:35:59,248", "timestamp_s": 2159.0}, {"text": "The first thing we\u0027re going to do is let\u0027s just ask", "timestamp": "00:36:03,584", "timestamp_s": 2163.0}, {"text": "a very specific question to a foundational model", "timestamp": "00:36:06,912", "timestamp_s": 2166.0}, {"text": "without a reg system. So without using knowledge", "timestamp": "00:36:10,504", "timestamp_s": 2170.0}, {"text": "base. So you can go here on text we can first", "timestamp": "00:36:14,016", "timestamp_s": 2174.0}, {"text": "let\u0027s just look for a very specific, I think on the 2020.", "timestamp": "00:36:17,888", "timestamp_s": 2177.0}, {"text": "There is a mention. Let me", "timestamp": "00:36:22,694", "timestamp_s": 2182.0}, {"text": "just find the mention. There is a mention of 3000. Just bear", "timestamp": "00:36:26,278", "timestamp_s": 2186.0}, {"text": "with me. Let me see if I can find on the document.", "timestamp": "00:36:30,230", "timestamp_s": 2190.0}, {"text": "There is a mention somewhere here. I just need to find", "timestamp": "00:36:33,806", "timestamp_s": 2193.0}, {"text": "that AWS has released over 3000", "timestamp": "00:36:37,574", "timestamp_s": 2197.0}, {"text": "features,", "timestamp": "00:36:42,102", "timestamp_s": 2202.0}, {"text": "3000 features and services. I don\u0027t think", "timestamp": "00:36:45,374", "timestamp_s": 2205.0}, {"text": "it\u0027s highlighting here. So just bear with me.", "timestamp": "00:36:48,698", "timestamp_s": 2208.0}, {"text": "Let me just, let me download this file. So what we\u0027re gonna do, we\u0027re gonna", "timestamp": "00:36:52,514", "timestamp_s": 2212.0}, {"text": "download the file. Let me just download the file.", "timestamp": "00:36:55,762", "timestamp_s": 2215.0}, {"text": "Let me open the file here. And I think if I search now here", "timestamp": "00:36:59,706", "timestamp_s": 2219.0}, {"text": "features here. So 33 times I was", "timestamp": "00:37:06,234", "timestamp_s": 2226.0}, {"text": "searching wrong. You can see here AWS continues", "timestamp": "00:37:09,954", "timestamp_s": 2229.0}, {"text": "to deliver new capability over 3300", "timestamp": "00:37:13,538", "timestamp_s": 2233.0}, {"text": "new features and services launch in 2022.", "timestamp": "00:37:17,122", "timestamp_s": 2237.0}, {"text": "So what you\u0027re going to ask the foundational model without rag is", "timestamp": "00:37:20,330", "timestamp_s": 2240.0}, {"text": "this. Let\u0027s go here. Let\u0027s go on bedrock.", "timestamp": "00:37:24,754", "timestamp_s": 2244.0}, {"text": "Let\u0027s just choose one of the better models in tropic.", "timestamp": "00:37:28,418", "timestamp_s": 2248.0}, {"text": "Let\u0027s just go with instant because I know this is just a fast", "timestamp": "00:37:31,386", "timestamp_s": 2251.0}, {"text": "model and say how.", "timestamp": "00:37:35,130", "timestamp_s": 2255.0}, {"text": "So let\u0027s ask the model how many new features and services", "timestamp": "00:37:38,634", "timestamp_s": 2258.0}, {"text": "did AWS services", "timestamp": "00:37:43,684", "timestamp_s": 2263.0}, {"text": "did AWS launch in", "timestamp": "00:37:48,364", "timestamp_s": 2268.0}, {"text": "2022? So there is going to be the question.", "timestamp": "00:37:51,772", "timestamp_s": 2271.0}, {"text": "You can see I\u0027m going to go in the model you\u0027re going to ask and", "timestamp": "00:37:55,196", "timestamp_s": 2275.0}, {"text": "the model says I don\u0027t have exact, I do not have.", "timestamp": "00:37:58,108", "timestamp_s": 2278.0}, {"text": "Let\u0027s just wait the finish. And it says I", "timestamp": "00:38:01,804", "timestamp_s": 2281.0}, {"text": "do not have the exact count of numbers or new features services", "timestamp": "00:38:05,060", "timestamp_s": 2285.0}, {"text": "like launch 2022. So what this means in this place", "timestamp": "00:38:09,092", "timestamp_s": 2289.0}, {"text": "here is that the foundational model itself doesn\u0027t have", "timestamp": "00:38:12,714", "timestamp_s": 2292.0}, {"text": "that information, right? Exactly. But the document", "timestamp": "00:38:16,634", "timestamp_s": 2296.0}, {"text": "that we have knows. So how do you put these two pieces together?", "timestamp": "00:38:20,666", "timestamp_s": 2300.0}, {"text": "Well, the first thing we can do is if we go on", "timestamp": "00:38:24,706", "timestamp_s": 2304.0}, {"text": "the knowledge base. So let me show you how I\u0027ve created a knowledge base.", "timestamp": "00:38:28,898", "timestamp_s": 2308.0}, {"text": "So I\u0027ve already created a knowledge base on dialog.", "timestamp": "00:38:32,218", "timestamp_s": 2312.0}, {"text": "And let me show you how the knowledge base works. So let me just scroll.", "timestamp": "00:38:36,026", "timestamp_s": 2316.0}, {"text": "So you create a knowledge base. Then you choose a", "timestamp": "00:38:40,216", "timestamp_s": 2320.0}, {"text": "data source. So in this case the data source is s", "timestamp": "00:38:43,944", "timestamp_s": 2323.0}, {"text": "three. So you can see that is the s three I showed you. If I", "timestamp": "00:38:47,384", "timestamp_s": 2327.0}, {"text": "go here and I show you can see this, we have these files.", "timestamp": "00:38:51,144", "timestamp_s": 2331.0}, {"text": "So you put, you choose the data source first, which is just an s", "timestamp": "00:38:55,264", "timestamp_s": 2335.0}, {"text": "three bucket. Then you choose the model that you want, bedrock knowledge", "timestamp": "00:38:58,528", "timestamp_s": 2338.0}, {"text": "base to create the vectors for you. So we are using a", "timestamp": "00:39:02,696", "timestamp_s": 2342.0}, {"text": "model that is offered within bedrock, which is the title", "timestamp": "00:39:06,608", "timestamp_s": 2346.0}, {"text": "embedding model version 1.2. Then after that", "timestamp": "00:39:10,480", "timestamp_s": 2350.0}, {"text": "you choose a database that you want to store those", "timestamp": "00:39:14,592", "timestamp_s": 2354.0}, {"text": "vectors. Right? So you want to have a database where the", "timestamp": "00:39:17,768", "timestamp_s": 2357.0}, {"text": "vectors can be stored and then you can retrieve that after the fact.", "timestamp": "00:39:21,280", "timestamp_s": 2361.0}, {"text": "So if you look here we have a vector database. We\u0027re using", "timestamp": "00:39:25,152", "timestamp_s": 2365.0}, {"text": "vector engine Amazon open search serverless.", "timestamp": "00:39:28,336", "timestamp_s": 2368.0}, {"text": "We have created the index name. So open search works with multiple", "timestamp": "00:39:31,514", "timestamp_s": 2371.0}, {"text": "index and within those indexes you can have a combination", "timestamp": "00:39:35,474", "timestamp_s": 2375.0}, {"text": "of items and documents. So, and we said when", "timestamp": "00:39:38,914", "timestamp_s": 2378.0}, {"text": "you create new vectors please add the,", "timestamp": "00:39:42,674", "timestamp_s": 2382.0}, {"text": "add the vector into the vector field on that", "timestamp": "00:39:46,954", "timestamp_s": 2386.0}, {"text": "item, on that document and add the text, the text itself", "timestamp": "00:39:50,626", "timestamp_s": 2390.0}, {"text": "into the text field. Because remember open search can do hybrid. So search", "timestamp": "00:39:54,938", "timestamp_s": 2394.0}, {"text": "in this case we\u0027re just going to do semantic search which is", "timestamp": "00:39:59,316", "timestamp_s": 2399.0}, {"text": "doing a similarity algorithm on top of your vector.", "timestamp": "00:40:03,124", "timestamp_s": 2403.0}, {"text": "So before I ask a question here, let me", "timestamp": "00:40:08,124", "timestamp_s": 2408.0}, {"text": "show you. So I\u0027m going to go on. So this is the open", "timestamp": "00:40:11,580", "timestamp_s": 2411.0}, {"text": "search dashboard where you can run some open search commands to", "timestamp": "00:40:15,268", "timestamp_s": 2415.0}, {"text": "see the data. So if I, this query,", "timestamp": "00:40:19,476", "timestamp_s": 2419.0}, {"text": "what is this query is going to return? Is just going to return all the", "timestamp": "00:40:22,996", "timestamp_s": 2422.0}, {"text": "different documents. So all the different ids", "timestamp": "00:40:26,206", "timestamp_s": 2426.0}, {"text": "within that doc, within that specific index.", "timestamp": "00:40:30,382", "timestamp_s": 2430.0}, {"text": "So you can see this index called bedrock sample index 665", "timestamp": "00:40:33,574", "timestamp_s": 2433.0}, {"text": "is the same index that we\u0027ve said here. So if you see here", "timestamp": "00:40:37,734", "timestamp_s": 2437.0}, {"text": "is the same vector index, right. And these open search", "timestamp": "00:40:41,278", "timestamp_s": 2441.0}, {"text": "serverless vector database there is nothing more than just the", "timestamp": "00:40:45,102", "timestamp_s": 2445.0}, {"text": "vectors from the s three files that we have uploaded.", "timestamp": "00:40:48,910", "timestamp_s": 2448.0}, {"text": "So you can see here I have multiple, these specific", "timestamp": "00:40:52,590", "timestamp_s": 2452.0}, {"text": "item has a chunk of", "timestamp": "00:40:56,674", "timestamp_s": 2456.0}, {"text": "this file here. So what we can do, we can just copy any chunk.", "timestamp": "00:41:00,050", "timestamp_s": 2460.0}, {"text": "In this case I\u0027ve already selected this chunk and I want to show", "timestamp": "00:41:03,482", "timestamp_s": 2463.0}, {"text": "you how the vector is stored. So if you go and you compute this", "timestamp": "00:41:06,834", "timestamp_s": 2466.0}, {"text": "you can see that it creates the index, it creates the id.", "timestamp": "00:41:10,810", "timestamp_s": 2470.0}, {"text": "The sequence number might be because this specific file", "timestamp": "00:41:14,474", "timestamp_s": 2474.0}, {"text": "has been chunk, has been, you know, parsing to multiple chunks. And this", "timestamp": "00:41:18,026", "timestamp_s": 2478.0}, {"text": "is the sequence number 13. And here you can see the vector,", "timestamp": "00:41:21,508", "timestamp_s": 2481.0}, {"text": "right? So you can see a bunch of numbers. I\u0027m just going to, you know,", "timestamp": "00:41:24,908", "timestamp_s": 2484.0}, {"text": "minimize this. But this is the vector. This is where the titan", "timestamp": "00:41:28,684", "timestamp_s": 2488.0}, {"text": "embedding model has been called to generate this", "timestamp": "00:41:32,236", "timestamp_s": 2492.0}, {"text": "vector. And here is the text.", "timestamp": "00:41:35,676", "timestamp_s": 2495.0}, {"text": "So what knowledge base,", "timestamp": "00:41:38,548", "timestamp_s": 2498.0}, {"text": "bedrock knowledge base automatically did for me was copy,", "timestamp": "00:41:41,988", "timestamp_s": 2501.0}, {"text": "copy this chunk, ran this chunk of text", "timestamp": "00:41:46,406", "timestamp_s": 2506.0}, {"text": "into my embedding model and then it generated the vector.", "timestamp": "00:41:49,822", "timestamp_s": 2509.0}, {"text": "So this is the factor. So now what we can do and", "timestamp": "00:41:53,958", "timestamp_s": 2513.0}, {"text": "you can see here, I think this is the one that I want", "timestamp": "00:41:57,910", "timestamp_s": 2517.0}, {"text": "to show if I\u0027m not mistaken. Let me see.", "timestamp": "00:42:01,414", "timestamp_s": 2521.0}, {"text": "Yeah, here. So this is the chunk that we were gonna,", "timestamp": "00:42:05,414", "timestamp_s": 2525.0}, {"text": "that my, I want to show you that bedrock knowledge", "timestamp": "00:42:09,246", "timestamp_s": 2529.0}, {"text": "base will automatically retrieve and generate an answer for", "timestamp": "00:42:12,878", "timestamp_s": 2532.0}, {"text": "me. So remember we tried with just the foundation model, it didn\u0027t", "timestamp": "00:42:16,270", "timestamp_s": 2536.0}, {"text": "know, right. But now I have this piece of text and with the vector", "timestamp": "00:42:20,174", "timestamp_s": 2540.0}, {"text": "embedding itself that has this information. So what we can do,", "timestamp": "00:42:24,286", "timestamp_s": 2544.0}, {"text": "if you go back to backdrop, you can go on this", "timestamp": "00:42:27,766", "timestamp_s": 2547.0}, {"text": "tab just for I guess usage,", "timestamp": "00:42:31,214", "timestamp_s": 2551.0}, {"text": "you can select a model. Let\u0027s use the same", "timestamp": "00:42:34,406", "timestamp_s": 2554.0}, {"text": "model before and let\u0027s copy.", "timestamp": "00:42:37,746", "timestamp_s": 2557.0}, {"text": "Let\u0027s actually go. I think that the data,", "timestamp": "00:42:41,554", "timestamp_s": 2561.0}, {"text": "let me just, let\u0027s do this. Just give 1 second.", "timestamp": "00:42:45,402", "timestamp_s": 2565.0}, {"text": "Let\u0027s go here. I remember I copied this new features", "timestamp": "00:42:48,666", "timestamp_s": 2568.0}, {"text": "and service launch 2022. And if you", "timestamp": "00:42:52,050", "timestamp_s": 2572.0}, {"text": "go back to bedrock and you can", "timestamp": "00:42:55,370", "timestamp_s": 2575.0}, {"text": "see here that I can just say knowledge", "timestamp": "00:42:58,770", "timestamp_s": 2578.0}, {"text": "base for bedrock allows you to just retrieve the data", "timestamp": "00:43:02,786", "timestamp_s": 2582.0}, {"text": "or retrieve and generate, I\u0027m going to show you both. So if I just", "timestamp": "00:43:06,740", "timestamp_s": 2586.0}, {"text": "go and I answer this, how many new features", "timestamp": "00:43:10,180", "timestamp_s": 2590.0}, {"text": "and service AWS launch in 2022? Remember this is", "timestamp": "00:43:13,892", "timestamp_s": 2593.0}, {"text": "exactly the same question I asked the model before and he", "timestamp": "00:43:17,756", "timestamp_s": 2597.0}, {"text": "said he didn\u0027t know. So what, what I\u0027m going to do first is", "timestamp": "00:43:21,068", "timestamp_s": 2601.0}, {"text": "to generate an answer. So this is going to retrieve the piece of", "timestamp": "00:43:24,388", "timestamp_s": 2604.0}, {"text": "text and then he\u0027s going to send the piece of text to cloud instance as", "timestamp": "00:43:27,724", "timestamp_s": 2607.0}, {"text": "the model. And then finally it\u0027s going to generate an answer based on that.", "timestamp": "00:43:31,090", "timestamp_s": 2611.0}, {"text": "You can see here, it\u0027s saying retrieving and generating the response.", "timestamp": "00:43:35,034", "timestamp_s": 2615.0}, {"text": "And voila. It worked. So over three 3300", "timestamp": "00:43:39,002", "timestamp_s": 2619.0}, {"text": "new features and service were launched by AWS in 2022. And you can see", "timestamp": "00:43:43,402", "timestamp_s": 2623.0}, {"text": "that I have the source detail. So if I click to source this", "timestamp": "00:43:47,274", "timestamp_s": 2627.0}, {"text": "layer, you can see that he actually retrieved from my database", "timestamp": "00:43:50,450", "timestamp_s": 2630.0}, {"text": "a chunk and the same chunk that I was showing before that has these piece", "timestamp": "00:43:54,450", "timestamp_s": 2634.0}, {"text": "of data. So what that rock did automatically with a single", "timestamp": "00:43:58,502", "timestamp_s": 2638.0}, {"text": "API was retrieve the chunk, you know, convert back", "timestamp": "00:44:02,054", "timestamp_s": 2642.0}, {"text": "to text, add that text as the context", "timestamp": "00:44:05,814", "timestamp_s": 2645.0}, {"text": "of my question and then send back finally", "timestamp": "00:44:09,230", "timestamp_s": 2649.0}, {"text": "to my cloud instant model to give the answer that", "timestamp": "00:44:12,910", "timestamp_s": 2652.0}, {"text": "you can see here what you can also do. So if you clear this,", "timestamp": "00:44:16,310", "timestamp_s": 2656.0}, {"text": "what we can also do, we can just say generate response.", "timestamp": "00:44:20,270", "timestamp_s": 2660.0}, {"text": "Sorry, let\u0027s disable generate response. I\u0027m just going", "timestamp": "00:44:23,214", "timestamp_s": 2663.0}, {"text": "to give the answer this question.", "timestamp": "00:44:26,818", "timestamp_s": 2666.0}, {"text": "Many new services and features.", "timestamp": "00:44:29,754", "timestamp_s": 2669.0}, {"text": "How many new features and service did AWS", "timestamp": "00:44:33,034", "timestamp_s": 2673.0}, {"text": "launch in 2022? When I click run", "timestamp": "00:44:38,354", "timestamp_s": 2678.0}, {"text": "what this does. So you see that I disabled and just said I don\u0027t", "timestamp": "00:44:42,354", "timestamp_s": 2682.0}, {"text": "do not generate response, just do the retrieval. So you can see", "timestamp": "00:44:46,346", "timestamp_s": 2686.0}, {"text": "that he has, if you go source detail,", "timestamp": "00:44:52,214", "timestamp_s": 2692.0}, {"text": "it has retrieved multiple", "timestamp": "00:44:56,014", "timestamp_s": 2696.0}, {"text": "chunks for me and I would expect some of them", "timestamp": "00:45:02,078", "timestamp_s": 2702.0}, {"text": "see here, the 3301", "timestamp": "00:45:06,574", "timestamp_s": 2706.0}, {"text": "of the chunks has responded so in this case it returned multiple", "timestamp": "00:45:10,118", "timestamp_s": 2710.0}, {"text": "chunks. You can decide how many chunks you want to", "timestamp": "00:45:14,006", "timestamp_s": 2714.0}, {"text": "retrieve here, right? You can see here maximum number of chunks.", "timestamp": "00:45:17,606", "timestamp_s": 2717.0}, {"text": "And finally what I want to show you everything that I\u0027m doing. The console,", "timestamp": "00:45:21,176", "timestamp_s": 2721.0}, {"text": "you can actually also run via APIs.", "timestamp": "00:45:24,952", "timestamp_s": 2724.0}, {"text": "So you can see I have, let me just run this for you.", "timestamp": "00:45:30,024", "timestamp_s": 2730.0}, {"text": "What you see here, this retrieve and generate is", "timestamp": "00:45:34,504", "timestamp_s": 2734.0}, {"text": "the API that I\u0027m calling. And here we can", "timestamp": "00:45:38,320", "timestamp_s": 2738.0}, {"text": "give the same answer, just copy the same answer,", "timestamp": "00:45:41,584", "timestamp_s": 2741.0}, {"text": "the same question. Apologies. How many new features and service", "timestamp": "00:45:45,108", "timestamp_s": 2745.0}, {"text": "did a launch in 2022?", "timestamp": "00:45:49,684", "timestamp_s": 2749.0}, {"text": "And you can see this is just going to call this a specific function,", "timestamp": "00:45:55,524", "timestamp_s": 2755.0}, {"text": "which is this function here that is calling a bedrock agent", "timestamp": "00:45:59,244", "timestamp_s": 2759.0}, {"text": "client API call, retrieve and generated. I pass some", "timestamp": "00:46:03,404", "timestamp_s": 2763.0}, {"text": "information like my knowledge base id, the model id that I", "timestamp": "00:46:06,932", "timestamp_s": 2766.0}, {"text": "want to use and the session id, and then it\u0027s just", "timestamp": "00:46:10,360", "timestamp_s": 2770.0}, {"text": "actually going to generate the information back for me. So if", "timestamp": "00:46:14,032", "timestamp_s": 2774.0}, {"text": "I run this, you can see it\u0027s running and the", "timestamp": "00:46:17,088", "timestamp_s": 2777.0}, {"text": "answer is back here. So what I wanted to show is you", "timestamp": "00:46:20,656", "timestamp_s": 2780.0}, {"text": "don\u0027t need to only use the console. Of course there are a lot of", "timestamp": "00:46:24,312", "timestamp_s": 2784.0}, {"text": "APIs that you can use and you know, we can actually see the", "timestamp": "00:46:27,896", "timestamp_s": 2787.0}, {"text": "citations, you can see the citations here.", "timestamp": "00:46:31,560", "timestamp_s": 2791.0}, {"text": "Again, the same citation that I have, it comes", "timestamp": "00:46:34,472", "timestamp_s": 2794.0}, {"text": "from. So the API and you can see the response comes", "timestamp": "00:46:37,752", "timestamp_s": 2797.0}, {"text": "with a citation part automatically. And this", "timestamp": "00:46:42,024", "timestamp_s": 2802.0}, {"text": "is pretty good because what open search", "timestamp": "00:46:45,360", "timestamp_s": 2805.0}, {"text": "the combination of knowledge base backdrop and", "timestamp": "00:46:48,480", "timestamp_s": 2808.0}, {"text": "open source serverless is super powerful because it pretty much", "timestamp": "00:46:52,312", "timestamp_s": 2812.0}, {"text": "removes all the cumbersome and manual actions", "timestamp": "00:46:56,336", "timestamp_s": 2816.0}, {"text": "that you need to do in order to create an ad events. Very powerful rack", "timestamp": "00:47:01,072", "timestamp_s": 2821.0}, {"text": "system. So I hopefully you enjoy. Please feel free", "timestamp": "00:47:05,134", "timestamp_s": 2825.0}, {"text": "to reach out if you have any questions. Have a great conference", "timestamp": "00:47:08,822", "timestamp_s": 2828.0}, {"text": "and talk to you soon.", "timestamp": "00:47:12,454", "timestamp_s": 2832.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: '2xhalsIDYco',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              Vectoring Into The Future: AWS Empowered RAG Systems for LLMs
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>Dive into AWS&rsquo; innovative toolkit for Retrieval Augmented Generation (RAG) systems. Harness the power of vector databases, SageMaker JumpStart, and/or BedRock to supercharge your Large Language Models (LLMs) and reshape your GenAI landscape!</p>
<!-- End Text -->
          </div>

          
          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
              <li>
                Samuel Baruffi is a solutions architect with AWS. He wants to talk about vectorizing into the future of retrieval augmented generation systems using large language models. And then in the end, a quick demo just showcasing the capabilities of bedrock and open search.

              </li>
              
              <li>
                AWS is quickly growing the list of services and capabilities that support customers. With a single model now you can perform a combination of different tasks that in the past wouldn't have been possible. What is capable today might very quickly advance in the near future.

              </li>
              
              <li>
                There is something called vector embeddings. Embeddings are semantic representations of words by translating into vector, mathematical vectors. They carry the semantic understanding behind the text that you are embedding. We're going to talk about some databases that AWS offers with the ability to store those vector databases.

              </li>
              
              <li>
                With open search service on AWS for vector it supports. OpenSearch is one of the main vector databases on AWS. Vector support on AWS is also made available through document DB. Amazon Memory DB for Redis now also have the ability for vector storage. Last but not least, you also have Amazon Neptune analytics.

              </li>
              
              <li>
                Amazon Bedrock is the easiest way for you to build generative AI applications on AWS. With Amazon Bedrock you have a broad choice of models, as you can see here. Bedrock has all the encryption capabilities, privacy capabilities, not using your data to train any of those models.

              </li>
              
              <li>
                In my demo I'm going to show you actually in the demo is knowledge base for Amazon bedrock. What knowledge basis achieves is to automatically automate all the ingestion and retrieval for you on this reg system. With knowledge base you can use a single API call to do the retrieval and generation.

              </li>
              
              <li>
                The service allows a no easy and scalable way to create generative AI on bedrock. We're using vector engine open search serverless database. Demo shows how to ask a specific question to a foundational model without a reg system.

              </li>
              
              <li>
                A knowledge base for bedrock allows you to just retrieve the data or retrieve and generate, I'm going to show you both. The console, you can actually also run via APIs. Over three 3300 new features and service were launched by AWS in 2022. Very powerful rack system.
              </li>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./assemblyai/2xhalsIDYco.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:20,760'); seek(20.0)">
              Thanks for joining my session. My name is Samuel Baruffi. I am a
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:24,662'); seek(24.0)">
              solutions architect with AWS and I'm very excited
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:27,968'); seek(27.0)">
              to talk about vectorizing into the future
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:32,104'); seek(32.0)">
              AWS retrieval augmented generation systems using
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:36,320'); seek(36.0)">
              large language models. So a quick agenda
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:39,632'); seek(39.0)">
              for today will be the following.
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:43,384'); seek(43.0)">
              We're going to quickly talk about what are foundational
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:46,776'); seek(46.0)">
              models, large language models. Then we're going
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:51,004'); seek(51.0)">
              to talk about some of the capabilities that are very easy
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:56,334'); seek(56.0)">
              and important to use when it comes to generative AI.
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:01:00,614'); seek(60.0)">
              Then we're going to talk about some limitations of those foundational models.
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:01:04,958'); seek(64.0)">
              Those models are amazing. It has revolutionized
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:01:08,566'); seek(68.0)">
              and it's still revolutionizing many, many industries across
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:01:12,630'); seek(72.0)">
              the world, but they have limitations. So we're
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:01:16,190'); seek(76.0)">
              going to talk about what are those limitations, and we're going to talk about potential
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:01:19,630'); seek(79.0)">
              solutions, especially using retrieval augmented generations,
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:01:24,904'); seek(84.0)">
              which Reg is short for. Then we're
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:28,352'); seek(88.0)">
              going to talk about what type of databases
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:32,400'); seek(92.0)">
              can help us, you know, improve those
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:35,816'); seek(95.0)">
              foundational models with Reg. So we're going to go through
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:39,688'); seek(99.0)">
              the list of currently supported databases offerings on
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:43,424'); seek(103.0)">
              AWS for vector. We're going to explain, explain at
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:47,530'); seek(107.0)">
              a high level the capabilities
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:51,018'); seek(111.0)">
              and the differentiations across those offerings.
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:54,994'); seek(114.0)">
              And then after that we're going to talk about Amazon Bedrock, which is a
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:58,810'); seek(118.0)">
              generative AI managed service
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:02:02,306'); seek(122.0)">
              on AWS that allows you to very easily consume
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:02:06,162'); seek(126.0)">
              different foundational models, both image generation
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:02:09,498'); seek(129.0)">
              text to text, and also embeddings. And then
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:02:12,974'); seek(132.0)">
              we're going to talk about Amazon Bedrock knowledge base,
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:02:16,542'); seek(136.0)">
              which combines the powerful rack
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:02:21,238'); seek(141.0)">
              systems into the bedrock ecosystem
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:24,766'); seek(144.0)">
              and it allows users to very easily configure
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:29,334'); seek(149.0)">
              retrieval augmented generation systems using
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:32,710'); seek(152.0)">
              bedrock foundational models and also using AWS
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:36,630'); seek(156.0)">
              vector databases that are managed. So we're
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:40,260'); seek(160.0)">
              going to talk about how those two words can come together
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:43,748'); seek(163.0)">
              to really empower a lot of companies and users
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:47,316'); seek(167.0)">
              to create very powerful generative AI solutions.
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:51,484'); seek(171.0)">
              And then in the end, we're going to do a quick demo just showcasing
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:54,820'); seek(174.0)">
              the capabilities of bedrock and open search.
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:02:58,812'); seek(178.0)">
              So without further ado, let's get started. So WiFi
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:03:02,732'); seek(182.0)">
              national models, right in a before transformers
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:03:08,160'); seek(188.0)">
              and generative AI was really powerful in
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:03:11,856'); seek(191.0)">
              the past, traditional machine learning models
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:03:15,144'); seek(195.0)">
              were really trained and deployed for specific
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:03:18,912'); seek(198.0)">
              tasks. So you might have some models that were for specific task
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:22,416'); seek(202.0)">
              generation, some models that were really able to do Q
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:25,856'); seek(205.0)">
              and a, some bots, some models that maybe were able to do some type
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:29,920'); seek(209.0)">
              of predictions. So they're really specific
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:34,666'); seek(214.0)">
              models, but you need to deploy all these different models to potentially achieve
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:40,674'); seek(220.0)">
              the combination or the collection of different tasks
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:45,034'); seek(225.0)">
              with generative AI and transformers,
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:48,354'); seek(228.0)">
              the foundational models, if you think about quickly on
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:52,106'); seek(232.0)">
              the traditional machine learning models, you'd have a lot of label
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:55,746'); seek(235.0)">
              data, and you train those models to that specific label
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:58,954'); seek(238.0)">
              data. Right? What foundational models?
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:04:03,192'); seek(243.0)">
              Using transformers enables users
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:04:07,568'); seek(247.0)">
              to actually do all of those tasks within a
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:04:11,320'); seek(251.0)">
              simple, not simple, but within a single model
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:04:15,320'); seek(255.0)">
              that has been trained with unlabeled data. So foundational
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:04:19,520'); seek(259.0)">
              models sometimes are also referred to as general models
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:04:23,424'); seek(263.0)">
              that have good word representations and
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:26,664'); seek(266.0)">
              can do a lot of different tasks that in the
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:30,532'); seek(270.0)">
              past, you need to select the different models.
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:33,804'); seek(273.0)">
              It is very powerful because with a single model now
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:37,748'); seek(277.0)">
              you can perform a combination of different
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:41,300'); seek(281.0)">
              tasks that in the past wouldn't have been possible.
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:45,284'); seek(285.0)">
              So generative AI, you can use for
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:49,220'); seek(289.0)">
              many, many different use cases. Here, it's just
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:53,204'); seek(293.0)">
              demonstrating into four different categories,
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:57,334'); seek(297.0)">
              the capabilities of generative AI. So you
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:05:01,166'); seek(301.0)">
              can enhance customer experience by having, you know, agent assistance
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:05:05,142'); seek(305.0)">
              or, you know, personalizations or chat bots that will
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:05:08,374'); seek(308.0)">
              help enhance your customer experience. You can
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:05:11,430'); seek(311.0)">
              also have boost, you can also help boost employee productivity
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:05:15,542'); seek(315.0)">
              with conversational search. Let's say you
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:05:19,030'); seek(319.0)">
              have vast amount of internal data and
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:22,358'); seek(322.0)">
              you want to make very easy for users internally to consume
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:26,030'); seek(326.0)">
              the data to improve the productivity. Foundational models can
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:30,062'); seek(330.0)">
              help solve that problem and a very good solution. You can
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:33,702'); seek(333.0)">
              also improve business operation. So if you're doing a lot of document
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:37,446'); seek(337.0)">
              processing that maybe before was done by manual labor,
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:41,326'); seek(341.0)">
              you can use those foundational models to potentially process,
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:44,726'); seek(344.0)">
              you know, some entity extraction or maybe document
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:48,238'); seek(348.0)">
              processing or maybe generation of documents. You can use generative
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:52,016'); seek(352.0)">
              AI, and then of course, creativity.
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:05:55,072'); seek(355.0)">
              With a stable diffusion models, you can create many different
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:05:59,120'); seek(359.0)">
              images. You can do video enhancements, you can create music.
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:06:03,080'); seek(363.0)">
              So those generative AI models are not only text generations,
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:06:07,464'); seek(367.0)">
              but you can generate images, videos. And this is a very
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:06:11,464'); seek(371.0)">
              fast paced, evolving technology.
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:06:14,624'); seek(374.0)">
              So what is capable today might
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:18,188'); seek(378.0)">
              very quickly advance in the near future. The text
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:21,332'); seek(381.0)">
              to text models are really, really powerful today. Images have
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:24,620'); seek(384.0)">
              become very powerful. And now we can see that video generations are
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:28,532'); seek(388.0)">
              just starting to get more powerful than ever.
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:31,564'); seek(391.0)">
              So what does aws in
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:35,620'); seek(395.0)">
              terms of generative AI? Right, so AWS
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:40,508'); seek(400.0)">
              is very quickly growing
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:44,402'); seek(404.0)">
              the list of services and capabilities that support customers. To use
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:06:48,346'); seek(408.0)">
              generative AI, we can, we have Amazon Sagemaker,
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:06:52,338'); seek(412.0)">
              which is the platform for any machine
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:06:56,826'); seek(416.0)">
              learning AI requirements, training,
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:06:59,970'); seek(419.0)">
              inference, evaluation, you know, data ingestion,
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:07:03,730'); seek(423.0)">
              data cleaning, you can name it. But when it comes to generative
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:07:07,818'); seek(427.0)">
              AI, Amazon Sagemaker has a, a foundational hub
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:07:11,486'); seek(431.0)">
              called Jumpstart, where you can actually deploy many, many different
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:07:15,198'); seek(435.0)">
              foundational models that are going to be,
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:07:18,214'); seek(438.0)">
              that you're going to deploy within Sagemaker. Sagemaker is going to deploy the
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:21,598'); seek(441.0)">
              infrastructure for you and it's going to match that infrastructure.
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:25,334'); seek(445.0)">
              But then we also have Amazon bedrock, which is a
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:28,750'); seek(448.0)">
              completely managed service with pay as you go approach, that you
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:32,438'); seek(452.0)">
              can select a variety of different model providers
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:36,558'); seek(456.0)">
              and models within those model providers. We're going to talk in
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:40,130'); seek(460.0)">
              a couple of slides into the future of this
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:07:43,362'); seek(463.0)">
              presentation that are going to present some of the models that are capable.
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:07:47,210'); seek(467.0)">
              And Amazon has also done a lot of
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:07:50,978'); seek(470.0)">
              innovation at the hardware level. So you can see with Amazon
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:07:55,066'); seek(475.0)">
              EC two, TRN one, which is
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:07:58,922'); seek(478.0)">
              training instances, which are instances that
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:08:02,802'); seek(482.0)">
              have proprietary innovative accelerators
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:08:07,966'); seek(487.0)">
              for machine learning training from Amazon that really optimizes the cost
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:08:12,070'); seek(492.0)">
              performance for companies that wants to train their own model.
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:08:15,910'); seek(495.0)">
              Those could be foundational models or could be traditional
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:08:19,902'); seek(499.0)">
              machine learning models. But we also have Amazon EC
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:23,966'); seek(503.0)">
              two, InF two, which is short for inferential
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:27,998'); seek(507.0)">
              two, which is a chip that is optimized for accelerating
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:32,558'); seek(512.0)">
              inferential inference from your machine
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:36,154'); seek(516.0)">
              learning models. Those could be foundational models or any other type of model.
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:40,354'); seek(520.0)">
              And then last but not least, Amazon Codewisper,
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:08:44,882'); seek(524.0)">
              which is a generative AI power coding assistant that
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:08:49,034'); seek(529.0)">
              helps developers with code completion security scams.
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:08:52,834'); seek(532.0)">
              You know, chat, you can chat with your code
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:08:56,274'); seek(536.0)">
              and receive recommendations and different helps
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:09:00,470'); seek(540.0)">
              in terms of fixing bugs and so forth. So those are
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:09:03,598'); seek(543.0)">
              the things that AWS offers for generative AI capabilities.
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:09:07,862'); seek(547.0)">
              And, you know, there are a lot more that goes within those services in
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:09:11,550'); seek(551.0)">
              terms of functionality and features as
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:09:15,694'); seek(555.0)">
              much as those models. Foundational models are really, really powerful.
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:09:20,014'); seek(560.0)">
              There are limitations of large language models and, you know,
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:09:23,174'); seek(563.0)">
              large language models and foundational models sometimes just use together.
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:09:28,444'); seek(568.0)">
              But you know, large language models are just models that
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:31,820'); seek(571.0)">
              can generate text or embeddings that really made
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:36,964'); seek(576.0)">
              it possible to use generative AI as
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:09:40,820'); seek(580.0)">
              we know today. But what are some of those limitations that we
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:09:44,420'); seek(584.0)">
              know? So first of all, there is really limited contextual
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:09:48,300'); seek(588.0)">
              understanding. So the model, because it has
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:09:51,788'); seek(591.0)">
              been pre trained, he only knows information
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:09:56,106'); seek(596.0)">
              to the date and is not going to know proprietary,
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:10:00,058'); seek(600.0)">
              you know, private information. So he has limited contextual understanding
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:10:04,410'); seek(604.0)">
              of what you are asking. You might be asking some
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:10:07,946'); seek(607.0)">
              question that is ambiguous and it might have, you know, a contextual
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:10:12,306'); seek(612.0)">
              limitation. In that sense, he also
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:10:16,226'); seek(616.0)">
              has lack of domain specific knowledge. So if you, if you work for
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:10:19,622'); seek(619.0)">
              company a and company a has a lot of private documentation that
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:10:23,478'); seek(623.0)">
              it was not on the Internet, or even if it was in
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:10:26,766'); seek(626.0)">
              the Internet, it might not be an expert on that domain specific.
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:10:30,526'); seek(630.0)">
              So they are known to not be super good in
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:10:33,998'); seek(633.0)">
              specific domains, especially if those domains don't have a lot
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:10:37,358'); seek(637.0)">
              of data on the Internet. Which most of those models
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:10:41,190'); seek(641.0)">
              get trained on top of it.
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:10:45,144'); seek(645.0)">
              So this is a big one, lacks explainability of interval
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:10:48,672'); seek(648.0)">
              ability. So it's very common that those large language
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:10:52,304'); seek(652.0)">
              models might hallucinate. And hallucinate is it
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:10:55,648'); seek(655.0)">
              just means when a response, an output from
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:10:59,536'); seek(659.0)">
              one of those models are generated is stating
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:11:03,112'); seek(663.0)">
              a inaccurate and not factual correct
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:11:06,552'); seek(666.0)">
              information, right. So there is very little explainability of
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:11:10,552'); seek(670.0)">
              why that information began to be. The way those models works is
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:11:14,258'); seek(674.0)">
              just predicting the next word and they might just spit
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:11:17,690'); seek(677.0)">
              it out. A lot of not factual,
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:11:20,290'); seek(680.0)">
              accurate data. And it's really hard to know why
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:11:23,658'); seek(683.0)">
              they have done that. So they lack explainability and interpretability.
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:11:27,994'); seek(687.0)">
              And again, inaccurate information. It's what
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:11:31,498'); seek(691.0)">
              we just described, which you might ask a question, the model
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:11:35,322'); seek(695.0)">
              might give you an answer that sounds very, very confident
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:11:39,640'); seek(699.0)">
              that answer is correct, but in fact, it's just a made up answer and
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:11:43,400'); seek(703.0)">
              is not accurate, not neither factual,
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:11:46,400'); seek(706.0)">
              accurate. So with that said,
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:11:50,256'); seek(710.0)">
              with the limitations that we know, how can we potentially,
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:11:53,976'); seek(713.0)">
              what are the solutions that we can put in place to help solve
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:11:57,840'); seek(717.0)">
              this problem? So there is something called vector embeddings.
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:12:01,624'); seek(721.0)">
              And what are vector embeddings? So vector embeddings
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:12:05,328'); seek(725.0)">
              are using these foundational models.
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:12:08,464'); seek(728.0)">
              Embeddings are semantic representations of
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:12:12,696'); seek(732.0)">
              words by translating
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:12:15,936'); seek(735.0)">
              into vector, mathematical vectors, float vector
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:12:19,928'); seek(739.0)">
              vectors. So you can think about if a user inputs,
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:12:23,152'); seek(743.0)">
              you know, New York and it runs into an embedded model,
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:12:26,776'); seek(746.0)">
              and an embedded model is just a large language model that is able to
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:12:30,624'); seek(750.0)">
              convert text into a array
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:12:34,152'); seek(754.0)">
              of float numbers in a vector.
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:12:37,480'); seek(757.0)">
              So you can see New York might be the
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:12:41,792'); seek(761.0)">
              vector representation of New York, might be the one you see here.
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:12:45,656'); seek(765.0)">
              There are different dimensions on vectors embeddings.
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:12:49,056'); seek(769.0)">
              The bigger the dimensions, the more data and the more float numbers
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:12:52,872'); seek(772.0)">
              you're going to have on the vector array.
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:12:55,664'); seek(775.0)">
              And why are vectors embedding?
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:12:59,320'); seek(779.0)">
              Is important because they carry
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:13:02,936'); seek(782.0)">
              with those numbers, with these mathematical arrays
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:13:06,824'); seek(786.0)">
              of flow numbers, they carry the semantic understanding
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:13:11,296'); seek(791.0)">
              behind the text that you are embedding.
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:13:14,176'); seek(794.0)">
              So, and we're going to talk in a moment why they are important.
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:13:18,264'); seek(798.0)">
              But it's really important that if you have, you know,
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:13:21,552'); seek(801.0)">
              terabytes of data that you want to store and you want to
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:13:25,110'); seek(805.0)">
              very easily retrieve that data based on semantic understanding.
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:13:29,094'); seek(809.0)">
              So you're not doing just an exactly match search, you're asking
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:13:33,366'); seek(813.0)">
              a question. And that question might be related
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:13:36,678'); seek(816.0)">
              to some of those, the context in your text that is also
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:13:40,830'); seek(820.0)">
              known as semantic search. So the numbers will carry
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:13:44,286'); seek(824.0)">
              a representation of the text in
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:13:47,710'); seek(827.0)">
              itself. So now that
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:13:51,626'); seek(831.0)">
              we might have generated. So it's very common on,
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:13:55,810'); seek(835.0)">
              when you have those type of limitations into large
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:13:59,506'); seek(839.0)">
              language models that we just described. One of the common
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:14:03,202'); seek(843.0)">
              and best approaches to solve that is to add
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:14:06,698'); seek(846.0)">
              an ability to retrieve the context from
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:14:10,386'); seek(850.0)">
              your vector space and add the vector,
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:14:14,474'); seek(854.0)">
              the text chunks that will be converted back from numbers
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:14:17,898'); seek(857.0)">
              into text as context to your large language models.
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:14:21,990'); seek(861.0)">
              But one of the challenges that you have once you create
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:14:26,086'); seek(866.0)">
              all these embeddings, let's say you have multiple documents internally
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:14:30,174'); seek(870.0)">
              and you want to translate all those documents, maybe PDF,
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:14:33,518'); seek(873.0)">
              into vectors, what do you do with those vectors?
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:14:37,974'); seek(877.0)">
              And here where vector databases play a big role.
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:14:41,750'); seek(881.0)">
              So you want to make sure you can store those vectors representations,
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:14:45,694'); seek(885.0)">
              those vector embeddings in a database. And then
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:14:49,794'); seek(889.0)">
              after you restore there in the database, you have the ability to retrieve
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:14:53,578'); seek(893.0)">
              by doing semantic search chunks of text that
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:14:57,610'); seek(897.0)">
              are similar to the question or topic you
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:15:01,138'); seek(901.0)">
              are trying to retrieve from. So how does vector
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:15:04,442'); seek(904.0)">
              database works or this vector embedding system?
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:15:07,962'); seek(907.0)">
              So if you think about in this diagram, you're going to have some raw data.
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:15:11,738'); seek(911.0)">
              You know, it could be images, it could be documents, it could be audio.
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:15:15,130'); seek(915.0)">
              For the sake of simplicity, for today's presentation, let's just focus on
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:15:18,722'); seek(918.0)">
              text. So let's say you have a word document and you
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:15:22,122'); seek(922.0)">
              want to create embeddings that behind the
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:15:26,178'); seek(926.0)">
              scenes are going to create vectors, the arrays of vectors
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:15:29,826'); seek(929.0)">
              for you. So what do you do? You create, you chunk that document
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:15:33,930'); seek(933.0)">
              into different pieces, because there are limitations of
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:15:37,794'); seek(937.0)">
              how many words you can create a vector.
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:15:41,914'); seek(941.0)">
              And it is of course very depending on the embedding model, the foundation embedding
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:15:46,202'); seek(946.0)">
              model that you use. But then once you have created
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:15:49,410'); seek(949.0)">
              the chunks, you go through the model and you say, hey, here is the chunk
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:15:52,898'); seek(952.0)">
              of text. Can you create a dense vector encoding for
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:15:56,610'); seek(956.0)">
              me? So that is where it creates the vector embedding space
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:16:00,058'); seek(960.0)">
              which will return an array of flow numbers for you that you
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:16:03,290'); seek(963.0)">
              create your vector embeddings.
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:16:06,614'); seek(966.0)">
              You can also create sparse vectors encoding, which is
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:16:10,494'); seek(970.0)">
              a different way to perform and being more optimized when doing
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:16:14,502'); seek(974.0)">
              the retrieval. Once you have those vectors, then you can
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:16:18,158'); seek(978.0)">
              stores those vectors in a database. And we're going to talk about some
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:16:21,766'); seek(981.0)">
              databases that AWS offers with the ability to
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:16:25,326'); seek(985.0)">
              store those vector databases. And then after,
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:16:28,598'); seek(988.0)">
              finally you can build applications that are able to
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:16:32,014'); seek(992.0)">
              retrieve query your database using semantic understanding
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:16:37,184'); seek(997.0)">
              and using different techniques like KNN
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:16:41,224'); seek(1001.0)">
              and few other ones that you can just ask a question
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:16:44,408'); seek(1004.0)">
              and you find the close similarities,
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:16:47,384'); seek(1007.0)">
              vectors from the probe and query that you've provided.
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:16:51,360'); seek(1011.0)">
              And after that you just, you copied
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:16:54,864'); seek(1014.0)">
              the vectors from your database. You run again in the embedding
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:16:58,384'); seek(1018.0)">
              model though that embedding model, just convert the vectors into
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:17:03,284'); seek(1023.0)">
              text and then you can consume the text into
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:17:06,524'); seek(1026.0)">
              the foundational models as texture text models that you
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:17:10,388'); seek(1030.0)">
              might have available. Now let's just talk
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:17:13,700'); seek(1033.0)">
              about the capabilities and databases that AWS offers
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:17:17,484'); seek(1037.0)">
              you into storing those vectors.
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:17:21,508'); seek(1041.0)">
              So there are a wide array of
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:17:25,476'); seek(1045.0)">
              databases that AWS provides.
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:17:29,034'); seek(1049.0)">
              They have vector capabilities you
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:17:32,178'); seek(1052.0)">
              can see here on the list. We are going to go through most of them
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:17:35,370'); seek(1055.0)">
              and I'm just going to talk to you about a high level why
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:17:41,178'); seek(1061.0)">
              and how they are different from each other. So we're going to have search engines
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:17:45,026'); seek(1065.0)">
              like open search. We're going to have relational databases like
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:17:48,850'); seek(1068.0)">
              Postgres Aurora Postgres and RDS postgres.
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:17:52,866'); seek(1072.0)">
              You're going to have document databases like document DB.
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:17:56,160'); seek(1076.0)">
              You're going to have memory ink in memory
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:17:59,912'); seek(1079.0)">
              databases like memory DB, and graph
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:18:03,184'); seek(1083.0)">
              databases like Neptune. And all of those databases
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:18:06,584'); seek(1086.0)">
              now have capabilities to run and store vector
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:18:11,144'); seek(1091.0)">
              functionality. So let's just start with our first
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:18:14,968'); seek(1094.0)">
              database. Amazon Zarora is
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:18:18,456'); seek(1098.0)">
              a relational database that is a managed database on AWS.
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:18:22,834'); seek(1102.0)">
              So Amazon Aurora Postgres flavor now has
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:18:26,890'); seek(1106.0)">
              the capability to run vectors
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:18:30,778'); seek(1110.0)">
              using a extension called, which is an
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:18:34,106'); seek(1114.0)">
              open source extension called PG Vector. What it allows
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:18:37,962'); seek(1117.0)">
              you to do is to have vector embeddings
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:18:42,434'); seek(1122.0)">
              stored on your relation database. So if you're already storing
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:18:46,194'); seek(1126.0)">
              your data using a relational approach and you just want to store
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:18:50,090'); seek(1130.0)">
              an additional vector representation
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:18:53,502'); seek(1133.0)">
              of the data, you can install PG vector both on Amazon Aurora
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:18:57,646'); seek(1137.0)">
              and RDS postgres flavor.
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:19:00,630'); seek(1140.0)">
              And once you restore those embeddings, you can
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:19:04,510'); seek(1144.0)">
              support different algorithms such as KNN ANN
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:19:08,838'); seek(1148.0)">
              H and SW and IV flat. Those are
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:19:12,190'); seek(1152.0)">
              just different approaches and solutions on
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:19:15,862'); seek(1155.0)">
              how to retrieve close similarities and chunks of embeddings
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:19:20,196'); seek(1160.0)">
              and text for you. And you know, for postgres apps,
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:19:23,932'); seek(1163.0)">
              the good thing is you don't need to make any driver
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:19:28,332'); seek(1168.0)">
              change. You can just literally use install the extension on Amazon Aurora
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:19:32,196'); seek(1172.0)">
              or RDS Aurora and continue to use your database.
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:19:36,036'); seek(1176.0)">
              So this solution is a very good solution for existing
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:19:40,252'); seek(1180.0)">
              postgres SQL users or any users
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:19:43,332'); seek(1183.0)">
              that prefer relation database. You can actually use them.
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:19:46,716'); seek(1186.0)">
              That right? So it's really powerful. There are a lot
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:19:50,198'); seek(1190.0)">
              of integration. So if you have ML
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:19:54,574'); seek(1194.0)">
              background but you are focused on relation database you,
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:19:58,958'); seek(1198.0)">
              I would recommend you taking a look at Amazon Aurora with PG Vector
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:20:04,038'); seek(1204.0)">
              and talking about PG Vector. PG Vector is an open source postgres
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:20:07,958'); seek(1207.0)">
              SQL extension that is designed for efficient vector
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:20:11,598'); seek(1211.0)">
              similarity search and perfect for levering machine learning with
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:20:15,484'); seek(1215.0)">
              your databases. So it supports storing data
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:20:19,076'); seek(1219.0)">
              along with your traditional data types while maintaining
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:20:22,604'); seek(1222.0)">
              postgres robustness features such as acid compliant
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:20:27,484'); seek(1227.0)">
              point in time recover and PG vector handles
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:20:31,316'); seek(1231.0)">
              exactly an approximate nearest neighbor. Search accommodates in
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:20:35,364'); seek(1235.0)">
              various distance measures like l two indian product
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:20:38,924'); seek(1238.0)">
              and cosine distance. Those are just different mathematical expressions
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:20:43,466'); seek(1243.0)">
              that are going to retrieve the similarity semantic
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:20:47,226'); seek(1247.0)">
              search for you as you can see here, PG vector
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:20:50,722'); seek(1250.0)">
              and with Aurora and RDS, sorry with Aurora are
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:20:54,434'); seek(1254.0)">
              also integrated with Amazon bedrock knowledge base. We're going to talk about
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:20:58,242'); seek(1258.0)">
              that in a moment. You have configurable require rate using
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:21:02,178'); seek(1262.0)">
              these different approaches like HM and SW
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:21:05,856'); seek(1265.0)">
              EF underscore search and IV IVF flat
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:21:09,960'); seek(1269.0)">
              probes. The good thing about PG vector, it can
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:21:13,448'); seek(1273.0)">
              scale to support over 1 billion vectors and the
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:21:16,760'); seek(1276.0)">
              dimension it can support vectors with a 16 up to
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:21:20,024'); seek(1280.0)">
              16,000 dimension. So that is a very good
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:21:23,576'); seek(1283.0)">
              way if you have relational databases and you want to store vectors and
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:21:27,072'); seek(1287.0)">
              this could be the place you you go.
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:21:30,184'); seek(1290.0)">
              Second, we nietzsche talked about a very powerful
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:21:34,652'); seek(1294.0)">
              service which is Amazon open search. So Amazon
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:21:38,196'); seek(1298.0)">
              Open Search is a NoSQL database that is
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:21:42,684'); seek(1302.0)">
              has been built from the beginning with scalability
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:21:46,668'); seek(1306.0)">
              and as a distributed database for
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:21:50,028'); seek(1310.0)">
              search. So you can use search and analytics engine
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:21:54,156'); seek(1314.0)">
              on top of open search. You have different
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:21:57,252'); seek(1317.0)">
              types of deployment for open source. So you can have a managed service that you
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:22:00,956'); seek(1320.0)">
              manage different instance behind the scene for you. But it's also
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:22:04,822'); seek(1324.0)">
              have the capability to deploy a serverless open search
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:22:08,478'); seek(1328.0)">
              where you don't need to manage, you know, even the service doesn't need to
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:22:11,982'); seek(1331.0)">
              manage any server for you. It doesn't abstract abstracts that
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:22:15,702'); seek(1335.0)">
              away from you. Open search has also the
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:22:18,942'); seek(1338.0)">
              capability restore vector using the KNN plugin.
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:22:22,630'); seek(1342.0)">
              It also supports different algorithms such
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:22:26,710'); seek(1346.0)">
              as KNN, AM, HMSW and IV
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:22:30,422'); seek(1350.0)">
              flat. IVF flat. So you can see that similar
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:22:34,506'); seek(1354.0)">
              to the Aurora postgres, Opensearch has
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:22:38,186'); seek(1358.0)">
              similar algorithm capability.
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:22:41,074'); seek(1361.0)">
              And if you have DynoDB tables, you can actually use zero ETL
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:22:44,666'); seek(1364.0)">
              from dynoDB to move the data into open source service
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:22:49,202'); seek(1369.0)">
              and you can vectorize those as well. So who are
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:22:53,226'); seek(1373.0)">
              open source service? Very. It's a good fit.
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:22:57,162'); seek(1377.0)">
              So if you are already an open source user or if you prefer NoSQL and
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:23:01,056'); seek(1381.0)">
              you want to do hybrid search as well. So let's say you have a piece
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:23:04,192'); seek(1384.0)">
              of text and you want to search both maybe search or
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:23:07,720'); seek(1387.0)">
              field from the text, but also using the vector semantic capability,
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:23:12,184'); seek(1392.0)">
              open search support that capability for you.
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:23:15,984'); seek(1395.0)">
              And with open search service
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:23:19,968'); seek(1399.0)">
              on AWS for vector it supports.
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:23:23,808'); seek(1403.0)">
              I really like the open search and we'll do a demo later on because you
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:23:28,000'); seek(1408.0)">
              can very easily and cost efficient deploy an open search serverless
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:23:32,258'); seek(1412.0)">
              vector database that will behind the scenes manage all the
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:23:36,386'); seek(1416.0)">
              index shared and manipulation of the data for you
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:23:40,178'); seek(1420.0)">
              and it can scale for over a billion vectors with very high performance
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:23:44,546'); seek(1424.0)">
              with the same dimensionality as Aurora. You can also
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:23:48,586'); seek(1428.0)">
              have configurable recall rates via different segments and EF
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:23:52,418'); seek(1432.0)">
              search. And similar to Amazon Aurora,
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:23:56,354'); seek(1436.0)">
              OpenSearch is one of the main vector databases on AWS
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:24:00,742'); seek(1440.0)">
              and integrates very well with knowledge base
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:24:04,774'); seek(1444.0)">
              on bedrock. But also open search has
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:24:07,982'); seek(1447.0)">
              a plugin called Neuro search that it can provide a
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:24:11,670'); seek(1451.0)">
              very seamless integration between your text ingestion
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:24:16,350'); seek(1456.0)">
              and the vector embedding creation. It can talk to Bedrock,
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:24:20,142'); seek(1460.0)">
              you can talk to OpenAI, you can talk with cohere.
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:24:23,388'); seek(1463.0)">
              By using this neural search it can automatically do all the
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:24:27,132'); seek(1467.0)">
              retrieval generation of the battings for you continuing
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:24:32,252'); seek(1472.0)">
              the segment. Vector support on AWS is
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:24:36,396'); seek(1476.0)">
              also made available through document DB. So document DB is
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:24:39,988'); seek(1479.0)">
              a very fast cloud native document database.
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:24:43,420'); seek(1483.0)">
              So again it's a NoSQL database that has MongoDB API
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:24:47,476'); seek(1487.0)">
              compatibility. You have different provision deployment
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:24:51,282'); seek(1491.0)">
              options that it's a managed service. It also supports
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:24:56,114'); seek(1496.0)">
              the same algorithms that I mentioned before,
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:24:59,314'); seek(1499.0)">
              KNN Am IVF flat.
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:25:03,434'); seek(1503.0)">
              By using MongoDB you can just elevate
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:25:09,002'); seek(1509.0)">
              the capability of your vector search if you're already using documentDB
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:25:12,722'); seek(1512.0)">
              or MongoDB. And what we
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:25:15,910'); seek(1515.0)">
              see here is the good thing about documentDB if
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:25:19,158'); seek(1519.0)">
              you're very familiar with document databases specific
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:25:23,750'); seek(1523.0)">
              JSON usage because document database are really powerful
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:25:27,062'); seek(1527.0)">
              with JSON, if you want to vectorize that information
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:25:30,214'); seek(1530.0)">
              by just enabling vector capabilities
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:25:33,526'); seek(1533.0)">
              on your document DB, it becomes very very powerful
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:25:37,814'); seek(1537.0)">
              and continue. This is a very interesting service.
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:25:41,594'); seek(1541.0)">
              Amazon Memory DB for Redis now also
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:25:45,450'); seek(1545.0)">
              have a feature that is currently in preview and hopefully very soon is
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:25:48,810'); seek(1548.0)">
              going to become GA general available that adds the ability
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:25:52,394'); seek(1552.0)">
              for memory DB, which is already a very popular and
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:25:58,074'); seek(1558.0)">
              performant database to have multi zero
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:26:02,026'); seek(1562.0)">
              ability to handle vector storage, index and
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:26:05,922'); seek(1565.0)">
              search capabilities. So memory DB,
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:26:09,438'); seek(1569.0)">
              like the name says, is a database that stores all the data in
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:26:12,822'); seek(1572.0)">
              memory and is ready's API compatible. It's a fully
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:26:16,758'); seek(1576.0)">
              managed service. You can see it supports different word vector
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:26:21,038'); seek(1581.0)">
              searches, algorithms that we mentioned. It has
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:26:24,534'); seek(1584.0)">
              abilities to support up to 32,000 dimensions
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:26:28,718'); seek(1588.0)">
              of vectors. And this is ideal if you really have a workflow
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:26:32,622'); seek(1592.0)">
              that requires single digit millisecond
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:26:36,054'); seek(1596.0)">
              latencies and throughput for your vector.
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:26:39,534'); seek(1599.0)">
              So let's say you are building a chatbot that should be really quickly or trying
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:26:43,094'); seek(1603.0)">
              to do retrieval augmented generation. That is super powerful.
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:26:47,054'); seek(1607.0)">
              Memory DB might be the best place to look for because
            </span>
            
            <span id="chunk-417" class="transcript-chunks" onclick="console.log('00:26:50,318'); seek(1610.0)">
              that very powerful capability and
            </span>
            
            <span id="chunk-418" class="transcript-chunks" onclick="console.log('00:26:54,030'); seek(1614.0)">
              then fine. Last but not least, you also have Amazon
            </span>
            
            <span id="chunk-419" class="transcript-chunks" onclick="console.log('00:26:57,174'); seek(1617.0)">
              Neptune analytics. So Amazon Neptune is the
            </span>
            
            <span id="chunk-420" class="transcript-chunks" onclick="console.log('00:27:00,518'); seek(1620.0)">
              Amazon graph database. It allows you
            </span>
            
            <span id="chunk-421" class="transcript-chunks" onclick="console.log('00:27:04,214'); seek(1624.0)">
              with the Amazon Neptune analytics allows you to have analytic
            </span>
            
            <span id="chunk-422" class="transcript-chunks" onclick="console.log('00:27:07,590'); seek(1627.0)">
              memory optimized graph database engines. You have
            </span>
            
            <span id="chunk-423" class="transcript-chunks" onclick="console.log('00:27:11,126'); seek(1631.0)">
              different discrete capacity deployments to deploy this database.
            </span>
            
            <span id="chunk-424" class="transcript-chunks" onclick="console.log('00:27:14,942'); seek(1634.0)">
              It supports agents w similarity algorithm.
            </span>
            
            <span id="chunk-425" class="transcript-chunks" onclick="console.log('00:27:19,102'); seek(1639.0)">
              You can see the dimension of that. This database for vectors are
            </span>
            
            <span id="chunk-426" class="transcript-chunks" onclick="console.log('00:27:22,782'); seek(1642.0)">
              much bigger with up to 65,000 and it complements.
            </span>
            
            <span id="chunk-427" class="transcript-chunks" onclick="console.log('00:27:26,478'); seek(1646.0)">
              So it's an addition plugin on top of your Amazon Neptune database.
            </span>
            
            <span id="chunk-428" class="transcript-chunks" onclick="console.log('00:27:30,702'); seek(1650.0)">
              And if you why would you use Neptune
            </span>
            
            <span id="chunk-429" class="transcript-chunks" onclick="console.log('00:27:34,790'); seek(1654.0)">
              analytics for your vector database? So if you're using neural networks, use cases
            </span>
            
            <span id="chunk-430" class="transcript-chunks" onclick="console.log('00:27:39,014'); seek(1659.0)">
              where you need to do vector search graph traversals.
            </span>
            
            <span id="chunk-431" class="transcript-chunks" onclick="console.log('00:27:42,990'); seek(1662.0)">
              This would be a very good approach. You can
            </span>
            
            <span id="chunk-432" class="transcript-chunks" onclick="console.log('00:27:46,262'); seek(1666.0)">
              also use Neptune database with serverless deployment,
            </span>
            
            <span id="chunk-433" class="transcript-chunks" onclick="console.log('00:27:50,654'); seek(1670.0)">
              but Neptune analytics only supports discrete capacity levels
            </span>
            
            <span id="chunk-434" class="transcript-chunks" onclick="console.log('00:27:54,934'); seek(1674.0)">
              at this time. So if you're curious to
            </span>
            
            <span id="chunk-435" class="transcript-chunks" onclick="console.log('00:27:58,490'); seek(1678.0)">
              learn more, I know I just covered very quickly these databases. I would
            </span>
            
            <span id="chunk-436" class="transcript-chunks" onclick="console.log('00:28:01,898'); seek(1681.0)">
              highly recommend that you just do a quick Google and search
            </span>
            
            <span id="chunk-437" class="transcript-chunks" onclick="console.log('00:28:05,842'); seek(1685.0)">
              our AWS documentation about how they work.
            </span>
            
            <span id="chunk-438" class="transcript-chunks" onclick="console.log('00:28:09,194'); seek(1689.0)">
              But now I want to talk about Amazon Bedrock.
            </span>
            
            <span id="chunk-439" class="transcript-chunks" onclick="console.log('00:28:12,994'); seek(1692.0)">
              I mentioned before in the beginning of my presentation that Amazon Bedrock
            </span>
            
            <span id="chunk-440" class="transcript-chunks" onclick="console.log('00:28:17,242'); seek(1697.0)">
              is the easiest way for you to build generative AI applications
            </span>
            
            <span id="chunk-441" class="transcript-chunks" onclick="console.log('00:28:21,162'); seek(1701.0)">
              on AWS. And the amazing thing about Bedrock
            </span>
            
            <span id="chunk-442" class="transcript-chunks" onclick="console.log('00:28:24,400'); seek(1704.0)">
              is a completely managed service for Genai models. So you
            </span>
            
            <span id="chunk-443" class="transcript-chunks" onclick="console.log('00:28:28,520'); seek(1708.0)">
              have a choice of multiple models with industry leading
            </span>
            
            <span id="chunk-444" class="transcript-chunks" onclick="console.log('00:28:32,912'); seek(1712.0)">
              foundational model providers that are available with a single API
            </span>
            
            <span id="chunk-445" class="transcript-chunks" onclick="console.log('00:28:36,264'); seek(1716.0)">
              call if you want. You can also customize and
            </span>
            
            <span id="chunk-446" class="transcript-chunks" onclick="console.log('00:28:39,520'); seek(1719.0)">
              fine tune your models using your own organization data.
            </span>
            
            <span id="chunk-447" class="transcript-chunks" onclick="console.log('00:28:42,688'); seek(1722.0)">
              And Bedrock has taken security
            </span>
            
            <span id="chunk-448" class="transcript-chunks" onclick="console.log('00:28:46,040'); seek(1726.0)">
              as job number zero and it has all
            </span>
            
            <span id="chunk-449" class="transcript-chunks" onclick="console.log('00:28:49,824'); seek(1729.0)">
              the encryption capabilities, privacy capabilities,
            </span>
            
            <span id="chunk-450" class="transcript-chunks" onclick="console.log('00:28:53,240'); seek(1733.0)">
              not using your data to train any of those models. So it's an enterprise
            </span>
            
            <span id="chunk-451" class="transcript-chunks" onclick="console.log('00:28:57,296'); seek(1737.0)">
              grade security and private service. With Amazon Bedrock
            </span>
            
            <span id="chunk-452" class="transcript-chunks" onclick="console.log('00:29:01,432'); seek(1741.0)">
              you have a broad choice of models, as you can see here. This list
            </span>
            
            <span id="chunk-453" class="transcript-chunks" onclick="console.log('00:29:04,760'); seek(1744.0)">
              is just as of today in March 30
            </span>
            
            <span id="chunk-454" class="transcript-chunks" onclick="console.log('00:29:08,760'); seek(1748.0)">
              as I'm recording this session 2024. Right now there
            </span>
            
            <span id="chunk-455" class="transcript-chunks" onclick="console.log('00:29:12,320'); seek(1752.0)">
              are seven different model providers,
            </span>
            
            <span id="chunk-456" class="transcript-chunks" onclick="console.log('00:29:15,712'); seek(1755.0)">
              AI 21, Amazon and tropic cohere,
            </span>
            
            <span id="chunk-457" class="transcript-chunks" onclick="console.log('00:29:19,398'); seek(1759.0)">
              meta nest row and stability.
            </span>
            
            <span id="chunk-458" class="transcript-chunks" onclick="console.log('00:29:22,454'); seek(1762.0)">
              Those models have different capabilities. So you're going to
            </span>
            
            <span id="chunk-459" class="transcript-chunks" onclick="console.log('00:29:25,870'); seek(1765.0)">
              have a text to text model where it's just a foundational model that you send
            </span>
            
            <span id="chunk-460" class="transcript-chunks" onclick="console.log('00:29:29,742'); seek(1769.0)">
              text and it returns text back by predicting the next
            </span>
            
            <span id="chunk-461" class="transcript-chunks" onclick="console.log('00:29:33,070'); seek(1773.0)">
              word. But you also have embedded models such as Amazon
            </span>
            
            <span id="chunk-462" class="transcript-chunks" onclick="console.log('00:29:37,086'); seek(1777.0)">
              text embeddings and Amazon Titan multi model embeddings.
            </span>
            
            <span id="chunk-463" class="transcript-chunks" onclick="console.log('00:29:41,406'); seek(1781.0)">
              But you also have an embeddings with cohere, which is the coherent
            </span>
            
            <span id="chunk-464" class="transcript-chunks" onclick="console.log('00:29:45,286'); seek(1785.0)">
              embedding multilingual. And on top of that,
            </span>
            
            <span id="chunk-465" class="transcript-chunks" onclick="console.log('00:29:48,818'); seek(1788.0)">
              you also have the ability to use bedrock to generate images with
            </span>
            
            <span id="chunk-466" class="transcript-chunks" onclick="console.log('00:29:52,938'); seek(1792.0)">
              stability, AI stable diffusion Excel 1.0,
            </span>
            
            <span id="chunk-467" class="transcript-chunks" onclick="console.log('00:29:57,378'); seek(1797.0)">
              but also with Titan image generator,
            </span>
            
            <span id="chunk-468" class="transcript-chunks" onclick="console.log('00:30:01,834'); seek(1801.0)">
              it's pay as you go. You pay per token that you consume and
            </span>
            
            <span id="chunk-469" class="transcript-chunks" onclick="console.log('00:30:05,890'); seek(1805.0)">
              you can choose the model that you're going to have access. In my demo I'm
            </span>
            
            <span id="chunk-470" class="transcript-chunks" onclick="console.log('00:30:09,530'); seek(1809.0)">
              going to show you actually in the demo, the demo that we're going to show
            </span>
            
            <span id="chunk-471" class="transcript-chunks" onclick="console.log('00:30:12,974'); seek(1812.0)">
              to you today is knowledge base for Amazon
            </span>
            
            <span id="chunk-472" class="transcript-chunks" onclick="console.log('00:30:16,254'); seek(1816.0)">
              bedrock. And this is where I'm trying to bring all my
            </span>
            
            <span id="chunk-473" class="transcript-chunks" onclick="console.log('00:30:19,942'); seek(1819.0)">
              presentation into a single place. Knowing the limitations of large language
            </span>
            
            <span id="chunk-474" class="transcript-chunks" onclick="console.log('00:30:24,254'); seek(1824.0)">
              models that I've discussed in the beginning, one of the ways
            </span>
            
            <span id="chunk-475" class="transcript-chunks" onclick="console.log('00:30:27,822'); seek(1827.0)">
              that you can work around the limitation is by creating a
            </span>
            
            <span id="chunk-476" class="transcript-chunks" onclick="console.log('00:30:32,118'); seek(1832.0)">
              rack system, a retrieval augmented generation. What is a
            </span>
            
            <span id="chunk-477" class="transcript-chunks" onclick="console.log('00:30:35,550'); seek(1835.0)">
              retrieval generation augmented is to bring pieces
            </span>
            
            <span id="chunk-478" class="transcript-chunks" onclick="console.log('00:30:40,378'); seek(1840.0)">
              of data on text into your
            </span>
            
            <span id="chunk-479" class="transcript-chunks" onclick="console.log('00:30:43,866'); seek(1843.0)">
              context before sending to a foundational model.
            </span>
            
            <span id="chunk-480" class="transcript-chunks" onclick="console.log('00:30:47,210'); seek(1847.0)">
              And the ability that you do that, the first thing you need to do is
            </span>
            
            <span id="chunk-481" class="transcript-chunks" onclick="console.log('00:30:50,450'); seek(1850.0)">
              to have a vector database where you can store all the vector embeddings
            </span>
            
            <span id="chunk-482" class="transcript-chunks" onclick="console.log('00:30:55,090'); seek(1855.0)">
              from your specific domain data.
            </span>
            
            <span id="chunk-483" class="transcript-chunks" onclick="console.log('00:30:59,354'); seek(1859.0)">
              You can retrieve the data at the query time. That data
            </span>
            
            <span id="chunk-484" class="transcript-chunks" onclick="console.log('00:31:03,384'); seek(1863.0)">
              is going to be converted from vectors to text and
            </span>
            
            <span id="chunk-485" class="transcript-chunks" onclick="console.log('00:31:06,720'); seek(1866.0)">
              then that data is going to be put it as the context of
            </span>
            
            <span id="chunk-486" class="transcript-chunks" onclick="console.log('00:31:10,064'); seek(1870.0)">
              your query to the foundational model. It's,
            </span>
            
            <span id="chunk-487" class="transcript-chunks" onclick="console.log('00:31:13,592'); seek(1873.0)">
              it can be very cumbersome to build this completely
            </span>
            
            <span id="chunk-488" class="transcript-chunks" onclick="console.log('00:31:17,072'); seek(1877.0)">
              rag solution. So what knowledge basis for Amazon bedrock
            </span>
            
            <span id="chunk-489" class="transcript-chunks" onclick="console.log('00:31:21,384'); seek(1881.0)">
              achieves is to automatically automate
            </span>
            
            <span id="chunk-490" class="transcript-chunks" onclick="console.log('00:31:26,384'); seek(1886.0)">
              all the ingestion and retrieval for
            </span>
            
            <span id="chunk-491" class="transcript-chunks" onclick="console.log('00:31:29,736'); seek(1889.0)">
              you on this reg system. So you connect
            </span>
            
            <span id="chunk-492" class="transcript-chunks" onclick="console.log('00:31:33,792'); seek(1893.0)">
              your knowledge base with a database, you there
            </span>
            
            <span id="chunk-493" class="transcript-chunks" onclick="console.log('00:31:38,032'); seek(1898.0)">
              are currently different supports for databases that are going to show in a moment for
            </span>
            
            <span id="chunk-494" class="transcript-chunks" onclick="console.log('00:31:41,600'); seek(1901.0)">
              vector databases. Then you select an embedding
            </span>
            
            <span id="chunk-495" class="transcript-chunks" onclick="console.log('00:31:45,296'); seek(1905.0)">
              model. Then you put your data on s
            </span>
            
            <span id="chunk-496" class="transcript-chunks" onclick="console.log('00:31:48,864'); seek(1908.0)">
              three simple storage service and
            </span>
            
            <span id="chunk-497" class="transcript-chunks" onclick="console.log('00:31:52,704'); seek(1912.0)">
              as soon as the data hits on that
            </span>
            
            <span id="chunk-498" class="transcript-chunks" onclick="console.log('00:31:56,224'); seek(1916.0)">
              s three you can sync knowledge base which
            </span>
            
            <span id="chunk-499" class="transcript-chunks" onclick="console.log('00:31:59,752'); seek(1919.0)">
              behind the scenes is going to create the embeddings, start embedding in
            </span>
            
            <span id="chunk-500" class="transcript-chunks" onclick="console.log('00:32:03,088'); seek(1923.0)">
              the database and then when you make a call to
            </span>
            
            <span id="chunk-501" class="transcript-chunks" onclick="console.log('00:32:07,120'); seek(1927.0)">
              knowledgebase for bedrock, that call you can decide
            </span>
            
            <span id="chunk-502" class="transcript-chunks" onclick="console.log('00:32:11,144'); seek(1931.0)">
              if that call just retrieved the data from your database
            </span>
            
            <span id="chunk-503" class="transcript-chunks" onclick="console.log('00:32:14,568'); seek(1934.0)">
              or if you want to do retrieve and generation, which means
            </span>
            
            <span id="chunk-504" class="transcript-chunks" onclick="console.log('00:32:18,288'); seek(1938.0)">
              just retrieve the data from Myvector database, send to the
            </span>
            
            <span id="chunk-505" class="transcript-chunks" onclick="console.log('00:32:21,888'); seek(1941.0)">
              foundation model, generate a response with my contacts,
            </span>
            
            <span id="chunk-506" class="transcript-chunks" onclick="console.log('00:32:24,914'); seek(1944.0)">
              awareness information and then give the answer back to the customer.
            </span>
            
            <span id="chunk-507" class="transcript-chunks" onclick="console.log('00:32:28,914'); seek(1948.0)">
              And you can select the model that you want to be used as the foundational
            </span>
            
            <span id="chunk-508" class="transcript-chunks" onclick="console.log('00:32:32,370'); seek(1952.0)">
              model and also the embedding as well.
            </span>
            
            <span id="chunk-509" class="transcript-chunks" onclick="console.log('00:32:35,274'); seek(1955.0)">
              So knowledge base on Bedrock has support for
            </span>
            
            <span id="chunk-510" class="transcript-chunks" onclick="console.log('00:32:38,882'); seek(1958.0)">
              currently different databases. So right now it supports vector engine
            </span>
            
            <span id="chunk-511" class="transcript-chunks" onclick="console.log('00:32:42,602'); seek(1962.0)">
              for open source serverless, redis, enterprise, cloud,
            </span>
            
            <span id="chunk-512" class="transcript-chunks" onclick="console.log('00:32:45,714'); seek(1965.0)">
              Pinecone and Amazon Aurora. There are more capabilities coming soon.
            </span>
            
            <span id="chunk-513" class="transcript-chunks" onclick="console.log('00:32:49,970'); seek(1969.0)">
              For example Mongodb. It's coming to be one of the vector
            </span>
            
            <span id="chunk-514" class="transcript-chunks" onclick="console.log('00:32:53,892'); seek(1973.0)">
              databases support on Amazon Bedrock and hopefully in the future more
            </span>
            
            <span id="chunk-515" class="transcript-chunks" onclick="console.log('00:32:57,460'); seek(1977.0)">
              of the databases that I talked today are also going to be available on
            </span>
            
            <span id="chunk-516" class="transcript-chunks" onclick="console.log('00:33:01,020'); seek(1981.0)">
              bedrock. And the last thing I want to show is with knowledge
            </span>
            
            <span id="chunk-517" class="transcript-chunks" onclick="console.log('00:33:05,396'); seek(1985.0)">
              base for bedrock you can use a single API call to do
            </span>
            
            <span id="chunk-518" class="transcript-chunks" onclick="console.log('00:33:08,868'); seek(1988.0)">
              the retrieval and generation. So if you look at this diagram
            </span>
            
            <span id="chunk-519" class="transcript-chunks" onclick="console.log('00:33:12,524'); seek(1992.0)">
              with a single API call on number one you can think about
            </span>
            
            <span id="chunk-520" class="transcript-chunks" onclick="console.log('00:33:16,260'); seek(1996.0)">
              a search query. So you can say,
            </span>
            
            <span id="chunk-521" class="transcript-chunks" onclick="console.log('00:33:19,384'); seek(1999.0)">
              let's just give an example. You are asking about a
            </span>
            
            <span id="chunk-522" class="transcript-chunks" onclick="console.log('00:33:22,648'); seek(2002.0)">
              proprietary question of your company,
            </span>
            
            <span id="chunk-523" class="transcript-chunks" onclick="console.log('00:33:26,368'); seek(2006.0)">
              right? And you know the foundation model doesn't know the answer.
            </span>
            
            <span id="chunk-524" class="transcript-chunks" onclick="console.log('00:33:29,616'); seek(2009.0)">
              So you can do a search query what bedrock
            </span>
            
            <span id="chunk-525" class="transcript-chunks" onclick="console.log('00:33:33,104'); seek(2013.0)">
              knowledge base you do, realizing that you need to do a retrieval on
            </span>
            
            <span id="chunk-526" class="transcript-chunks" onclick="console.log('00:33:36,600'); seek(2016.0)">
              your vector database. So number two is going to go there, do the retrieval,
            </span>
            
            <span id="chunk-527" class="transcript-chunks" onclick="console.log('00:33:40,720'); seek(2020.0)">
              then behind the scenes going to call your vector
            </span>
            
            <span id="chunk-528" class="transcript-chunks" onclick="console.log('00:33:44,064'); seek(2024.0)">
              database is going to retrieve that
            </span>
            
            <span id="chunk-529" class="transcript-chunks" onclick="console.log('00:33:48,322'); seek(2028.0)">
              embedding. The vector embedding is going to then convert
            </span>
            
            <span id="chunk-530" class="transcript-chunks" onclick="console.log('00:33:52,946'); seek(2032.0)">
              the vector into text. And then on four
            </span>
            
            <span id="chunk-531" class="transcript-chunks" onclick="console.log('00:33:56,186'); seek(2036.0)">
              it's going to send that text as context into your
            </span>
            
            <span id="chunk-532" class="transcript-chunks" onclick="console.log('00:34:00,658'); seek(2040.0)">
              bedrock foundational model, texture text generation.
            </span>
            
            <span id="chunk-533" class="transcript-chunks" onclick="console.log('00:34:04,074'); seek(2044.0)">
              And then finally it's going to send back the generation
            </span>
            
            <span id="chunk-534" class="transcript-chunks" onclick="console.log('00:34:07,826'); seek(2047.0)">
              of answer that it chose. And you can see here soon,
            </span>
            
            <span id="chunk-535" class="transcript-chunks" onclick="console.log('00:34:11,956'); seek(2051.0)">
              you know it's also going to support s three.
            </span>
            
            <span id="chunk-536" class="transcript-chunks" onclick="console.log('00:34:15,404'); seek(2055.0)">
              And now let's jump in to do a
            </span>
            
            <span id="chunk-537" class="transcript-chunks" onclick="console.log('00:34:18,652'); seek(2058.0)">
              quick demo of knowledge base for bedrock.
            </span>
            
            <span id="chunk-538" class="transcript-chunks" onclick="console.log('00:34:28,844'); seek(2068.0)">
              Awesome. So let's just jump into the demo.
            </span>
            
            <span id="chunk-539" class="transcript-chunks" onclick="console.log('00:34:32,356'); seek(2072.0)">
              The demo will be a very straightforward.
            </span>
            
            <span id="chunk-540" class="transcript-chunks" onclick="console.log('00:34:35,884'); seek(2075.0)">
              I have downloaded some files
            </span>
            
            <span id="chunk-541" class="transcript-chunks" onclick="console.log('00:34:40,064'); seek(2080.0)">
              from Amazon shareholder ladder.
            </span>
            
            <span id="chunk-542" class="transcript-chunks" onclick="console.log('00:34:44,552'); seek(2084.0)">
              So you can see here I have the 2019,
            </span>
            
            <span id="chunk-543" class="transcript-chunks" onclick="console.log('00:34:48,608'); seek(2088.0)">
              the 2020, the 2021 and the
            </span>
            
            <span id="chunk-544" class="transcript-chunks" onclick="console.log('00:34:51,712'); seek(2091.0)">
              2022 Amazon shareholder.
            </span>
            
            <span id="chunk-545" class="transcript-chunks" onclick="console.log('00:34:55,352'); seek(2095.0)">
              What I want to show is I have already created a
            </span>
            
            <span id="chunk-546" class="transcript-chunks" onclick="console.log('00:34:58,992'); seek(2098.0)">
              open search database and I have then linked
            </span>
            
            <span id="chunk-547" class="transcript-chunks" onclick="console.log('00:35:04,044'); seek(2104.0)">
              that database into bedrock knowledge base
            </span>
            
            <span id="chunk-548" class="transcript-chunks" onclick="console.log('00:35:07,900'); seek(2107.0)">
              and I want to show you that it created the vectors automatically
            </span>
            
            <span id="chunk-549" class="transcript-chunks" onclick="console.log('00:35:11,316'); seek(2111.0)">
              from s three. So just first let me show you.
            </span>
            
            <span id="chunk-550" class="transcript-chunks" onclick="console.log('00:35:14,636'); seek(2114.0)">
              I have an s three here. So I created an s three
            </span>
            
            <span id="chunk-551" class="transcript-chunks" onclick="console.log('00:35:18,044'); seek(2118.0)">
              bucket on that s three bucket. I just true
            </span>
            
            <span id="chunk-552" class="transcript-chunks" onclick="console.log('00:35:22,364'); seek(2122.0)">
              those four files. I could have as many files as, you know,
            </span>
            
            <span id="chunk-553" class="transcript-chunks" onclick="console.log('00:35:26,852'); seek(2126.0)">
              I wanted here. And what I've done then of
            </span>
            
            <span id="chunk-554" class="transcript-chunks" onclick="console.log('00:35:31,034'); seek(2131.0)">
              course I've created an open search database. So this open
            </span>
            
            <span id="chunk-555" class="transcript-chunks" onclick="console.log('00:35:34,426'); seek(2134.0)">
              search database you can see here, it's an open search serverless database.
            </span>
            
            <span id="chunk-556" class="transcript-chunks" onclick="console.log('00:35:38,202'); seek(2138.0)">
              I have a collection. So let me just close these ones.
            </span>
            
            <span id="chunk-557" class="transcript-chunks" onclick="console.log('00:35:41,242'); seek(2141.0)">
              I have a collection here I call bedrock sample.
            </span>
            
            <span id="chunk-558" class="transcript-chunks" onclick="console.log('00:35:44,930'); seek(2144.0)">
              So I created this database. There is a dashboard also created for
            </span>
            
            <span id="chunk-559" class="transcript-chunks" onclick="console.log('00:35:48,242'); seek(2148.0)">
              this database that I'm going to show in a moment. But the interesting part here
            </span>
            
            <span id="chunk-560" class="transcript-chunks" onclick="console.log('00:35:51,898'); seek(2151.0)">
              is if I go on bedrock, which bedrock is the service that,
            </span>
            
            <span id="chunk-561" class="transcript-chunks" onclick="console.log('00:35:55,394'); seek(2155.0)">
              that allows a no easy and scalable
            </span>
            
            <span id="chunk-562" class="transcript-chunks" onclick="console.log('00:35:59,248'); seek(2159.0)">
              way to create generative AI on bedrock.
            </span>
            
            <span id="chunk-563" class="transcript-chunks" onclick="console.log('00:36:03,584'); seek(2163.0)">
              The first thing we're going to do is let's just ask
            </span>
            
            <span id="chunk-564" class="transcript-chunks" onclick="console.log('00:36:06,912'); seek(2166.0)">
              a very specific question to a foundational model
            </span>
            
            <span id="chunk-565" class="transcript-chunks" onclick="console.log('00:36:10,504'); seek(2170.0)">
              without a reg system. So without using knowledge
            </span>
            
            <span id="chunk-566" class="transcript-chunks" onclick="console.log('00:36:14,016'); seek(2174.0)">
              base. So you can go here on text we can first
            </span>
            
            <span id="chunk-567" class="transcript-chunks" onclick="console.log('00:36:17,888'); seek(2177.0)">
              let's just look for a very specific, I think on the 2020.
            </span>
            
            <span id="chunk-568" class="transcript-chunks" onclick="console.log('00:36:22,694'); seek(2182.0)">
              There is a mention. Let me
            </span>
            
            <span id="chunk-569" class="transcript-chunks" onclick="console.log('00:36:26,278'); seek(2186.0)">
              just find the mention. There is a mention of 3000. Just bear
            </span>
            
            <span id="chunk-570" class="transcript-chunks" onclick="console.log('00:36:30,230'); seek(2190.0)">
              with me. Let me see if I can find on the document.
            </span>
            
            <span id="chunk-571" class="transcript-chunks" onclick="console.log('00:36:33,806'); seek(2193.0)">
              There is a mention somewhere here. I just need to find
            </span>
            
            <span id="chunk-572" class="transcript-chunks" onclick="console.log('00:36:37,574'); seek(2197.0)">
              that AWS has released over 3000
            </span>
            
            <span id="chunk-573" class="transcript-chunks" onclick="console.log('00:36:42,102'); seek(2202.0)">
              features,
            </span>
            
            <span id="chunk-574" class="transcript-chunks" onclick="console.log('00:36:45,374'); seek(2205.0)">
              3000 features and services. I don't think
            </span>
            
            <span id="chunk-575" class="transcript-chunks" onclick="console.log('00:36:48,698'); seek(2208.0)">
              it's highlighting here. So just bear with me.
            </span>
            
            <span id="chunk-576" class="transcript-chunks" onclick="console.log('00:36:52,514'); seek(2212.0)">
              Let me just, let me download this file. So what we're gonna do, we're gonna
            </span>
            
            <span id="chunk-577" class="transcript-chunks" onclick="console.log('00:36:55,762'); seek(2215.0)">
              download the file. Let me just download the file.
            </span>
            
            <span id="chunk-578" class="transcript-chunks" onclick="console.log('00:36:59,706'); seek(2219.0)">
              Let me open the file here. And I think if I search now here
            </span>
            
            <span id="chunk-579" class="transcript-chunks" onclick="console.log('00:37:06,234'); seek(2226.0)">
              features here. So 33 times I was
            </span>
            
            <span id="chunk-580" class="transcript-chunks" onclick="console.log('00:37:09,954'); seek(2229.0)">
              searching wrong. You can see here AWS continues
            </span>
            
            <span id="chunk-581" class="transcript-chunks" onclick="console.log('00:37:13,538'); seek(2233.0)">
              to deliver new capability over 3300
            </span>
            
            <span id="chunk-582" class="transcript-chunks" onclick="console.log('00:37:17,122'); seek(2237.0)">
              new features and services launch in 2022.
            </span>
            
            <span id="chunk-583" class="transcript-chunks" onclick="console.log('00:37:20,330'); seek(2240.0)">
              So what you're going to ask the foundational model without rag is
            </span>
            
            <span id="chunk-584" class="transcript-chunks" onclick="console.log('00:37:24,754'); seek(2244.0)">
              this. Let's go here. Let's go on bedrock.
            </span>
            
            <span id="chunk-585" class="transcript-chunks" onclick="console.log('00:37:28,418'); seek(2248.0)">
              Let's just choose one of the better models in tropic.
            </span>
            
            <span id="chunk-586" class="transcript-chunks" onclick="console.log('00:37:31,386'); seek(2251.0)">
              Let's just go with instant because I know this is just a fast
            </span>
            
            <span id="chunk-587" class="transcript-chunks" onclick="console.log('00:37:35,130'); seek(2255.0)">
              model and say how.
            </span>
            
            <span id="chunk-588" class="transcript-chunks" onclick="console.log('00:37:38,634'); seek(2258.0)">
              So let's ask the model how many new features and services
            </span>
            
            <span id="chunk-589" class="transcript-chunks" onclick="console.log('00:37:43,684'); seek(2263.0)">
              did AWS services
            </span>
            
            <span id="chunk-590" class="transcript-chunks" onclick="console.log('00:37:48,364'); seek(2268.0)">
              did AWS launch in
            </span>
            
            <span id="chunk-591" class="transcript-chunks" onclick="console.log('00:37:51,772'); seek(2271.0)">
              2022? So there is going to be the question.
            </span>
            
            <span id="chunk-592" class="transcript-chunks" onclick="console.log('00:37:55,196'); seek(2275.0)">
              You can see I'm going to go in the model you're going to ask and
            </span>
            
            <span id="chunk-593" class="transcript-chunks" onclick="console.log('00:37:58,108'); seek(2278.0)">
              the model says I don't have exact, I do not have.
            </span>
            
            <span id="chunk-594" class="transcript-chunks" onclick="console.log('00:38:01,804'); seek(2281.0)">
              Let's just wait the finish. And it says I
            </span>
            
            <span id="chunk-595" class="transcript-chunks" onclick="console.log('00:38:05,060'); seek(2285.0)">
              do not have the exact count of numbers or new features services
            </span>
            
            <span id="chunk-596" class="transcript-chunks" onclick="console.log('00:38:09,092'); seek(2289.0)">
              like launch 2022. So what this means in this place
            </span>
            
            <span id="chunk-597" class="transcript-chunks" onclick="console.log('00:38:12,714'); seek(2292.0)">
              here is that the foundational model itself doesn't have
            </span>
            
            <span id="chunk-598" class="transcript-chunks" onclick="console.log('00:38:16,634'); seek(2296.0)">
              that information, right? Exactly. But the document
            </span>
            
            <span id="chunk-599" class="transcript-chunks" onclick="console.log('00:38:20,666'); seek(2300.0)">
              that we have knows. So how do you put these two pieces together?
            </span>
            
            <span id="chunk-600" class="transcript-chunks" onclick="console.log('00:38:24,706'); seek(2304.0)">
              Well, the first thing we can do is if we go on
            </span>
            
            <span id="chunk-601" class="transcript-chunks" onclick="console.log('00:38:28,898'); seek(2308.0)">
              the knowledge base. So let me show you how I've created a knowledge base.
            </span>
            
            <span id="chunk-602" class="transcript-chunks" onclick="console.log('00:38:32,218'); seek(2312.0)">
              So I've already created a knowledge base on dialog.
            </span>
            
            <span id="chunk-603" class="transcript-chunks" onclick="console.log('00:38:36,026'); seek(2316.0)">
              And let me show you how the knowledge base works. So let me just scroll.
            </span>
            
            <span id="chunk-604" class="transcript-chunks" onclick="console.log('00:38:40,216'); seek(2320.0)">
              So you create a knowledge base. Then you choose a
            </span>
            
            <span id="chunk-605" class="transcript-chunks" onclick="console.log('00:38:43,944'); seek(2323.0)">
              data source. So in this case the data source is s
            </span>
            
            <span id="chunk-606" class="transcript-chunks" onclick="console.log('00:38:47,384'); seek(2327.0)">
              three. So you can see that is the s three I showed you. If I
            </span>
            
            <span id="chunk-607" class="transcript-chunks" onclick="console.log('00:38:51,144'); seek(2331.0)">
              go here and I show you can see this, we have these files.
            </span>
            
            <span id="chunk-608" class="transcript-chunks" onclick="console.log('00:38:55,264'); seek(2335.0)">
              So you put, you choose the data source first, which is just an s
            </span>
            
            <span id="chunk-609" class="transcript-chunks" onclick="console.log('00:38:58,528'); seek(2338.0)">
              three bucket. Then you choose the model that you want, bedrock knowledge
            </span>
            
            <span id="chunk-610" class="transcript-chunks" onclick="console.log('00:39:02,696'); seek(2342.0)">
              base to create the vectors for you. So we are using a
            </span>
            
            <span id="chunk-611" class="transcript-chunks" onclick="console.log('00:39:06,608'); seek(2346.0)">
              model that is offered within bedrock, which is the title
            </span>
            
            <span id="chunk-612" class="transcript-chunks" onclick="console.log('00:39:10,480'); seek(2350.0)">
              embedding model version 1.2. Then after that
            </span>
            
            <span id="chunk-613" class="transcript-chunks" onclick="console.log('00:39:14,592'); seek(2354.0)">
              you choose a database that you want to store those
            </span>
            
            <span id="chunk-614" class="transcript-chunks" onclick="console.log('00:39:17,768'); seek(2357.0)">
              vectors. Right? So you want to have a database where the
            </span>
            
            <span id="chunk-615" class="transcript-chunks" onclick="console.log('00:39:21,280'); seek(2361.0)">
              vectors can be stored and then you can retrieve that after the fact.
            </span>
            
            <span id="chunk-616" class="transcript-chunks" onclick="console.log('00:39:25,152'); seek(2365.0)">
              So if you look here we have a vector database. We're using
            </span>
            
            <span id="chunk-617" class="transcript-chunks" onclick="console.log('00:39:28,336'); seek(2368.0)">
              vector engine Amazon open search serverless.
            </span>
            
            <span id="chunk-618" class="transcript-chunks" onclick="console.log('00:39:31,514'); seek(2371.0)">
              We have created the index name. So open search works with multiple
            </span>
            
            <span id="chunk-619" class="transcript-chunks" onclick="console.log('00:39:35,474'); seek(2375.0)">
              index and within those indexes you can have a combination
            </span>
            
            <span id="chunk-620" class="transcript-chunks" onclick="console.log('00:39:38,914'); seek(2378.0)">
              of items and documents. So, and we said when
            </span>
            
            <span id="chunk-621" class="transcript-chunks" onclick="console.log('00:39:42,674'); seek(2382.0)">
              you create new vectors please add the,
            </span>
            
            <span id="chunk-622" class="transcript-chunks" onclick="console.log('00:39:46,954'); seek(2386.0)">
              add the vector into the vector field on that
            </span>
            
            <span id="chunk-623" class="transcript-chunks" onclick="console.log('00:39:50,626'); seek(2390.0)">
              item, on that document and add the text, the text itself
            </span>
            
            <span id="chunk-624" class="transcript-chunks" onclick="console.log('00:39:54,938'); seek(2394.0)">
              into the text field. Because remember open search can do hybrid. So search
            </span>
            
            <span id="chunk-625" class="transcript-chunks" onclick="console.log('00:39:59,316'); seek(2399.0)">
              in this case we're just going to do semantic search which is
            </span>
            
            <span id="chunk-626" class="transcript-chunks" onclick="console.log('00:40:03,124'); seek(2403.0)">
              doing a similarity algorithm on top of your vector.
            </span>
            
            <span id="chunk-627" class="transcript-chunks" onclick="console.log('00:40:08,124'); seek(2408.0)">
              So before I ask a question here, let me
            </span>
            
            <span id="chunk-628" class="transcript-chunks" onclick="console.log('00:40:11,580'); seek(2411.0)">
              show you. So I'm going to go on. So this is the open
            </span>
            
            <span id="chunk-629" class="transcript-chunks" onclick="console.log('00:40:15,268'); seek(2415.0)">
              search dashboard where you can run some open search commands to
            </span>
            
            <span id="chunk-630" class="transcript-chunks" onclick="console.log('00:40:19,476'); seek(2419.0)">
              see the data. So if I, this query,
            </span>
            
            <span id="chunk-631" class="transcript-chunks" onclick="console.log('00:40:22,996'); seek(2422.0)">
              what is this query is going to return? Is just going to return all the
            </span>
            
            <span id="chunk-632" class="transcript-chunks" onclick="console.log('00:40:26,206'); seek(2426.0)">
              different documents. So all the different ids
            </span>
            
            <span id="chunk-633" class="transcript-chunks" onclick="console.log('00:40:30,382'); seek(2430.0)">
              within that doc, within that specific index.
            </span>
            
            <span id="chunk-634" class="transcript-chunks" onclick="console.log('00:40:33,574'); seek(2433.0)">
              So you can see this index called bedrock sample index 665
            </span>
            
            <span id="chunk-635" class="transcript-chunks" onclick="console.log('00:40:37,734'); seek(2437.0)">
              is the same index that we've said here. So if you see here
            </span>
            
            <span id="chunk-636" class="transcript-chunks" onclick="console.log('00:40:41,278'); seek(2441.0)">
              is the same vector index, right. And these open search
            </span>
            
            <span id="chunk-637" class="transcript-chunks" onclick="console.log('00:40:45,102'); seek(2445.0)">
              serverless vector database there is nothing more than just the
            </span>
            
            <span id="chunk-638" class="transcript-chunks" onclick="console.log('00:40:48,910'); seek(2448.0)">
              vectors from the s three files that we have uploaded.
            </span>
            
            <span id="chunk-639" class="transcript-chunks" onclick="console.log('00:40:52,590'); seek(2452.0)">
              So you can see here I have multiple, these specific
            </span>
            
            <span id="chunk-640" class="transcript-chunks" onclick="console.log('00:40:56,674'); seek(2456.0)">
              item has a chunk of
            </span>
            
            <span id="chunk-641" class="transcript-chunks" onclick="console.log('00:41:00,050'); seek(2460.0)">
              this file here. So what we can do, we can just copy any chunk.
            </span>
            
            <span id="chunk-642" class="transcript-chunks" onclick="console.log('00:41:03,482'); seek(2463.0)">
              In this case I've already selected this chunk and I want to show
            </span>
            
            <span id="chunk-643" class="transcript-chunks" onclick="console.log('00:41:06,834'); seek(2466.0)">
              you how the vector is stored. So if you go and you compute this
            </span>
            
            <span id="chunk-644" class="transcript-chunks" onclick="console.log('00:41:10,810'); seek(2470.0)">
              you can see that it creates the index, it creates the id.
            </span>
            
            <span id="chunk-645" class="transcript-chunks" onclick="console.log('00:41:14,474'); seek(2474.0)">
              The sequence number might be because this specific file
            </span>
            
            <span id="chunk-646" class="transcript-chunks" onclick="console.log('00:41:18,026'); seek(2478.0)">
              has been chunk, has been, you know, parsing to multiple chunks. And this
            </span>
            
            <span id="chunk-647" class="transcript-chunks" onclick="console.log('00:41:21,508'); seek(2481.0)">
              is the sequence number 13. And here you can see the vector,
            </span>
            
            <span id="chunk-648" class="transcript-chunks" onclick="console.log('00:41:24,908'); seek(2484.0)">
              right? So you can see a bunch of numbers. I'm just going to, you know,
            </span>
            
            <span id="chunk-649" class="transcript-chunks" onclick="console.log('00:41:28,684'); seek(2488.0)">
              minimize this. But this is the vector. This is where the titan
            </span>
            
            <span id="chunk-650" class="transcript-chunks" onclick="console.log('00:41:32,236'); seek(2492.0)">
              embedding model has been called to generate this
            </span>
            
            <span id="chunk-651" class="transcript-chunks" onclick="console.log('00:41:35,676'); seek(2495.0)">
              vector. And here is the text.
            </span>
            
            <span id="chunk-652" class="transcript-chunks" onclick="console.log('00:41:38,548'); seek(2498.0)">
              So what knowledge base,
            </span>
            
            <span id="chunk-653" class="transcript-chunks" onclick="console.log('00:41:41,988'); seek(2501.0)">
              bedrock knowledge base automatically did for me was copy,
            </span>
            
            <span id="chunk-654" class="transcript-chunks" onclick="console.log('00:41:46,406'); seek(2506.0)">
              copy this chunk, ran this chunk of text
            </span>
            
            <span id="chunk-655" class="transcript-chunks" onclick="console.log('00:41:49,822'); seek(2509.0)">
              into my embedding model and then it generated the vector.
            </span>
            
            <span id="chunk-656" class="transcript-chunks" onclick="console.log('00:41:53,958'); seek(2513.0)">
              So this is the factor. So now what we can do and
            </span>
            
            <span id="chunk-657" class="transcript-chunks" onclick="console.log('00:41:57,910'); seek(2517.0)">
              you can see here, I think this is the one that I want
            </span>
            
            <span id="chunk-658" class="transcript-chunks" onclick="console.log('00:42:01,414'); seek(2521.0)">
              to show if I'm not mistaken. Let me see.
            </span>
            
            <span id="chunk-659" class="transcript-chunks" onclick="console.log('00:42:05,414'); seek(2525.0)">
              Yeah, here. So this is the chunk that we were gonna,
            </span>
            
            <span id="chunk-660" class="transcript-chunks" onclick="console.log('00:42:09,246'); seek(2529.0)">
              that my, I want to show you that bedrock knowledge
            </span>
            
            <span id="chunk-661" class="transcript-chunks" onclick="console.log('00:42:12,878'); seek(2532.0)">
              base will automatically retrieve and generate an answer for
            </span>
            
            <span id="chunk-662" class="transcript-chunks" onclick="console.log('00:42:16,270'); seek(2536.0)">
              me. So remember we tried with just the foundation model, it didn't
            </span>
            
            <span id="chunk-663" class="transcript-chunks" onclick="console.log('00:42:20,174'); seek(2540.0)">
              know, right. But now I have this piece of text and with the vector
            </span>
            
            <span id="chunk-664" class="transcript-chunks" onclick="console.log('00:42:24,286'); seek(2544.0)">
              embedding itself that has this information. So what we can do,
            </span>
            
            <span id="chunk-665" class="transcript-chunks" onclick="console.log('00:42:27,766'); seek(2547.0)">
              if you go back to backdrop, you can go on this
            </span>
            
            <span id="chunk-666" class="transcript-chunks" onclick="console.log('00:42:31,214'); seek(2551.0)">
              tab just for I guess usage,
            </span>
            
            <span id="chunk-667" class="transcript-chunks" onclick="console.log('00:42:34,406'); seek(2554.0)">
              you can select a model. Let's use the same
            </span>
            
            <span id="chunk-668" class="transcript-chunks" onclick="console.log('00:42:37,746'); seek(2557.0)">
              model before and let's copy.
            </span>
            
            <span id="chunk-669" class="transcript-chunks" onclick="console.log('00:42:41,554'); seek(2561.0)">
              Let's actually go. I think that the data,
            </span>
            
            <span id="chunk-670" class="transcript-chunks" onclick="console.log('00:42:45,402'); seek(2565.0)">
              let me just, let's do this. Just give 1 second.
            </span>
            
            <span id="chunk-671" class="transcript-chunks" onclick="console.log('00:42:48,666'); seek(2568.0)">
              Let's go here. I remember I copied this new features
            </span>
            
            <span id="chunk-672" class="transcript-chunks" onclick="console.log('00:42:52,050'); seek(2572.0)">
              and service launch 2022. And if you
            </span>
            
            <span id="chunk-673" class="transcript-chunks" onclick="console.log('00:42:55,370'); seek(2575.0)">
              go back to bedrock and you can
            </span>
            
            <span id="chunk-674" class="transcript-chunks" onclick="console.log('00:42:58,770'); seek(2578.0)">
              see here that I can just say knowledge
            </span>
            
            <span id="chunk-675" class="transcript-chunks" onclick="console.log('00:43:02,786'); seek(2582.0)">
              base for bedrock allows you to just retrieve the data
            </span>
            
            <span id="chunk-676" class="transcript-chunks" onclick="console.log('00:43:06,740'); seek(2586.0)">
              or retrieve and generate, I'm going to show you both. So if I just
            </span>
            
            <span id="chunk-677" class="transcript-chunks" onclick="console.log('00:43:10,180'); seek(2590.0)">
              go and I answer this, how many new features
            </span>
            
            <span id="chunk-678" class="transcript-chunks" onclick="console.log('00:43:13,892'); seek(2593.0)">
              and service AWS launch in 2022? Remember this is
            </span>
            
            <span id="chunk-679" class="transcript-chunks" onclick="console.log('00:43:17,756'); seek(2597.0)">
              exactly the same question I asked the model before and he
            </span>
            
            <span id="chunk-680" class="transcript-chunks" onclick="console.log('00:43:21,068'); seek(2601.0)">
              said he didn't know. So what, what I'm going to do first is
            </span>
            
            <span id="chunk-681" class="transcript-chunks" onclick="console.log('00:43:24,388'); seek(2604.0)">
              to generate an answer. So this is going to retrieve the piece of
            </span>
            
            <span id="chunk-682" class="transcript-chunks" onclick="console.log('00:43:27,724'); seek(2607.0)">
              text and then he's going to send the piece of text to cloud instance as
            </span>
            
            <span id="chunk-683" class="transcript-chunks" onclick="console.log('00:43:31,090'); seek(2611.0)">
              the model. And then finally it's going to generate an answer based on that.
            </span>
            
            <span id="chunk-684" class="transcript-chunks" onclick="console.log('00:43:35,034'); seek(2615.0)">
              You can see here, it's saying retrieving and generating the response.
            </span>
            
            <span id="chunk-685" class="transcript-chunks" onclick="console.log('00:43:39,002'); seek(2619.0)">
              And voila. It worked. So over three 3300
            </span>
            
            <span id="chunk-686" class="transcript-chunks" onclick="console.log('00:43:43,402'); seek(2623.0)">
              new features and service were launched by AWS in 2022. And you can see
            </span>
            
            <span id="chunk-687" class="transcript-chunks" onclick="console.log('00:43:47,274'); seek(2627.0)">
              that I have the source detail. So if I click to source this
            </span>
            
            <span id="chunk-688" class="transcript-chunks" onclick="console.log('00:43:50,450'); seek(2630.0)">
              layer, you can see that he actually retrieved from my database
            </span>
            
            <span id="chunk-689" class="transcript-chunks" onclick="console.log('00:43:54,450'); seek(2634.0)">
              a chunk and the same chunk that I was showing before that has these piece
            </span>
            
            <span id="chunk-690" class="transcript-chunks" onclick="console.log('00:43:58,502'); seek(2638.0)">
              of data. So what that rock did automatically with a single
            </span>
            
            <span id="chunk-691" class="transcript-chunks" onclick="console.log('00:44:02,054'); seek(2642.0)">
              API was retrieve the chunk, you know, convert back
            </span>
            
            <span id="chunk-692" class="transcript-chunks" onclick="console.log('00:44:05,814'); seek(2645.0)">
              to text, add that text as the context
            </span>
            
            <span id="chunk-693" class="transcript-chunks" onclick="console.log('00:44:09,230'); seek(2649.0)">
              of my question and then send back finally
            </span>
            
            <span id="chunk-694" class="transcript-chunks" onclick="console.log('00:44:12,910'); seek(2652.0)">
              to my cloud instant model to give the answer that
            </span>
            
            <span id="chunk-695" class="transcript-chunks" onclick="console.log('00:44:16,310'); seek(2656.0)">
              you can see here what you can also do. So if you clear this,
            </span>
            
            <span id="chunk-696" class="transcript-chunks" onclick="console.log('00:44:20,270'); seek(2660.0)">
              what we can also do, we can just say generate response.
            </span>
            
            <span id="chunk-697" class="transcript-chunks" onclick="console.log('00:44:23,214'); seek(2663.0)">
              Sorry, let's disable generate response. I'm just going
            </span>
            
            <span id="chunk-698" class="transcript-chunks" onclick="console.log('00:44:26,818'); seek(2666.0)">
              to give the answer this question.
            </span>
            
            <span id="chunk-699" class="transcript-chunks" onclick="console.log('00:44:29,754'); seek(2669.0)">
              Many new services and features.
            </span>
            
            <span id="chunk-700" class="transcript-chunks" onclick="console.log('00:44:33,034'); seek(2673.0)">
              How many new features and service did AWS
            </span>
            
            <span id="chunk-701" class="transcript-chunks" onclick="console.log('00:44:38,354'); seek(2678.0)">
              launch in 2022? When I click run
            </span>
            
            <span id="chunk-702" class="transcript-chunks" onclick="console.log('00:44:42,354'); seek(2682.0)">
              what this does. So you see that I disabled and just said I don't
            </span>
            
            <span id="chunk-703" class="transcript-chunks" onclick="console.log('00:44:46,346'); seek(2686.0)">
              do not generate response, just do the retrieval. So you can see
            </span>
            
            <span id="chunk-704" class="transcript-chunks" onclick="console.log('00:44:52,214'); seek(2692.0)">
              that he has, if you go source detail,
            </span>
            
            <span id="chunk-705" class="transcript-chunks" onclick="console.log('00:44:56,014'); seek(2696.0)">
              it has retrieved multiple
            </span>
            
            <span id="chunk-706" class="transcript-chunks" onclick="console.log('00:45:02,078'); seek(2702.0)">
              chunks for me and I would expect some of them
            </span>
            
            <span id="chunk-707" class="transcript-chunks" onclick="console.log('00:45:06,574'); seek(2706.0)">
              see here, the 3301
            </span>
            
            <span id="chunk-708" class="transcript-chunks" onclick="console.log('00:45:10,118'); seek(2710.0)">
              of the chunks has responded so in this case it returned multiple
            </span>
            
            <span id="chunk-709" class="transcript-chunks" onclick="console.log('00:45:14,006'); seek(2714.0)">
              chunks. You can decide how many chunks you want to
            </span>
            
            <span id="chunk-710" class="transcript-chunks" onclick="console.log('00:45:17,606'); seek(2717.0)">
              retrieve here, right? You can see here maximum number of chunks.
            </span>
            
            <span id="chunk-711" class="transcript-chunks" onclick="console.log('00:45:21,176'); seek(2721.0)">
              And finally what I want to show you everything that I'm doing. The console,
            </span>
            
            <span id="chunk-712" class="transcript-chunks" onclick="console.log('00:45:24,952'); seek(2724.0)">
              you can actually also run via APIs.
            </span>
            
            <span id="chunk-713" class="transcript-chunks" onclick="console.log('00:45:30,024'); seek(2730.0)">
              So you can see I have, let me just run this for you.
            </span>
            
            <span id="chunk-714" class="transcript-chunks" onclick="console.log('00:45:34,504'); seek(2734.0)">
              What you see here, this retrieve and generate is
            </span>
            
            <span id="chunk-715" class="transcript-chunks" onclick="console.log('00:45:38,320'); seek(2738.0)">
              the API that I'm calling. And here we can
            </span>
            
            <span id="chunk-716" class="transcript-chunks" onclick="console.log('00:45:41,584'); seek(2741.0)">
              give the same answer, just copy the same answer,
            </span>
            
            <span id="chunk-717" class="transcript-chunks" onclick="console.log('00:45:45,108'); seek(2745.0)">
              the same question. Apologies. How many new features and service
            </span>
            
            <span id="chunk-718" class="transcript-chunks" onclick="console.log('00:45:49,684'); seek(2749.0)">
              did a launch in 2022?
            </span>
            
            <span id="chunk-719" class="transcript-chunks" onclick="console.log('00:45:55,524'); seek(2755.0)">
              And you can see this is just going to call this a specific function,
            </span>
            
            <span id="chunk-720" class="transcript-chunks" onclick="console.log('00:45:59,244'); seek(2759.0)">
              which is this function here that is calling a bedrock agent
            </span>
            
            <span id="chunk-721" class="transcript-chunks" onclick="console.log('00:46:03,404'); seek(2763.0)">
              client API call, retrieve and generated. I pass some
            </span>
            
            <span id="chunk-722" class="transcript-chunks" onclick="console.log('00:46:06,932'); seek(2766.0)">
              information like my knowledge base id, the model id that I
            </span>
            
            <span id="chunk-723" class="transcript-chunks" onclick="console.log('00:46:10,360'); seek(2770.0)">
              want to use and the session id, and then it's just
            </span>
            
            <span id="chunk-724" class="transcript-chunks" onclick="console.log('00:46:14,032'); seek(2774.0)">
              actually going to generate the information back for me. So if
            </span>
            
            <span id="chunk-725" class="transcript-chunks" onclick="console.log('00:46:17,088'); seek(2777.0)">
              I run this, you can see it's running and the
            </span>
            
            <span id="chunk-726" class="transcript-chunks" onclick="console.log('00:46:20,656'); seek(2780.0)">
              answer is back here. So what I wanted to show is you
            </span>
            
            <span id="chunk-727" class="transcript-chunks" onclick="console.log('00:46:24,312'); seek(2784.0)">
              don't need to only use the console. Of course there are a lot of
            </span>
            
            <span id="chunk-728" class="transcript-chunks" onclick="console.log('00:46:27,896'); seek(2787.0)">
              APIs that you can use and you know, we can actually see the
            </span>
            
            <span id="chunk-729" class="transcript-chunks" onclick="console.log('00:46:31,560'); seek(2791.0)">
              citations, you can see the citations here.
            </span>
            
            <span id="chunk-730" class="transcript-chunks" onclick="console.log('00:46:34,472'); seek(2794.0)">
              Again, the same citation that I have, it comes
            </span>
            
            <span id="chunk-731" class="transcript-chunks" onclick="console.log('00:46:37,752'); seek(2797.0)">
              from. So the API and you can see the response comes
            </span>
            
            <span id="chunk-732" class="transcript-chunks" onclick="console.log('00:46:42,024'); seek(2802.0)">
              with a citation part automatically. And this
            </span>
            
            <span id="chunk-733" class="transcript-chunks" onclick="console.log('00:46:45,360'); seek(2805.0)">
              is pretty good because what open search
            </span>
            
            <span id="chunk-734" class="transcript-chunks" onclick="console.log('00:46:48,480'); seek(2808.0)">
              the combination of knowledge base backdrop and
            </span>
            
            <span id="chunk-735" class="transcript-chunks" onclick="console.log('00:46:52,312'); seek(2812.0)">
              open source serverless is super powerful because it pretty much
            </span>
            
            <span id="chunk-736" class="transcript-chunks" onclick="console.log('00:46:56,336'); seek(2816.0)">
              removes all the cumbersome and manual actions
            </span>
            
            <span id="chunk-737" class="transcript-chunks" onclick="console.log('00:47:01,072'); seek(2821.0)">
              that you need to do in order to create an ad events. Very powerful rack
            </span>
            
            <span id="chunk-738" class="transcript-chunks" onclick="console.log('00:47:05,134'); seek(2825.0)">
              system. So I hopefully you enjoy. Please feel free
            </span>
            
            <span id="chunk-739" class="transcript-chunks" onclick="console.log('00:47:08,822'); seek(2828.0)">
              to reach out if you have any questions. Have a great conference
            </span>
            
            <span id="chunk-740" class="transcript-chunks" onclick="console.log('00:47:12,454'); seek(2832.0)">
              and talk to you soon.
            </span>
            
            </div>
          </div>
          
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Samuel%20Baruffi%20-%20Conf42%20Large%20Language%20Models%20%28LLMs%29%202024.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Samuel%20Baruffi%20-%20Conf42%20Large%20Language%20Models%20%28LLMs%29%202024.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #CCB87B;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/llms2024" class="btn btn-sm btn-danger shadow lift" style="background-color: #CCB87B;">
                <i class="fe fe-grid me-2"></i>
                See all 28 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/Samuel%20Baruffi_llm.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Samuel Baruffi
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Principal Solutions Architect @ AWS
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/samuelbaruffi/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Samuel Baruffi's LinkedIn account" />
                  </a>
                  
                  
                  <a href="https://twitter.com/@SamuelBaruffi" target="_blank">
                    <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="Samuel Baruffi's twitter account" />
                  </a>
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by @SamuelBaruffi"
                  data-url="https://www.conf42.com/llms2024"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/llms2024"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>






    <!-- WELCOME -->
    <section class="pt-8 pt-md-11 pb-10 pb-md-15 bg-info" id="register">

      <!-- Shape -->
      <div class="shape shape-blur-3 text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>      </div>

      <!-- Content -->
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 col-md-10 col-lg-8 text-center">

            <!-- Heading -->
            <h1 class="display-2 text-white">
              Join the community!
            </h1>

            <!-- Text -->
            <p class="lead text-white text-opacity-80 mb-6 mb-md-8">
              Learn for free, join the best tech learning community 
              for a <a class="text-white" href="https://www.reddit.com/r/sanfrancisco/comments/1bz90f6/why_are_coffee_shops_in_sf_so_expensive/" target="_blank">price of a pumpkin latte</a>.
            </p>

            <!-- Form -->
            <form class="d-flex align-items-center justify-content-center mb-7 mb-md-9">

              <!-- Label -->
              <span class="text-white text-opacity-80">
                Annual
              </span>

              <!-- Switch -->
              <div class="form-check form-check-dark form-switch mx-3">
                <input class="form-check-input" type="checkbox" id="billingSwitch" data-toggle="price" data-target=".price">
              </div>

              <!-- Label -->
              <span class="text-white text-opacity-80">
                Monthly
              </span>

            </form>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->

    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- PRICING -->
    <section class="mt-n8 mt-md-n15">
      <div class="container">
        <div class="row gx-4">
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-1">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Newsletter</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="0" data-monthly="0">0</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Event notifications, weekly newsletter
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Delayed access</b> to all content
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Immediate access to Keynotes & Panels
                  </p>
                </div>
              
              
              </div>
            </div>

            <!-- Card -->
            <div class="card shadow-lg mb-6 border border-success">
              <div class="card-body">

                <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
</script>

<!-- Form -->
<link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
<p class="emailoctopus-success-message text-success"></p>
<p class="emailoctopus-error-message text-danger"></p>
<form
    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
    method="post"
    data-message-success="Thanks! Check your email for further directions!"
    data-message-missing-email-address="Your email address is required."
    data-message-invalid-email-address="Your email address looks incorrect, please try again."
    data-message-bot-submission-error="This doesn't look like a human submission."
    data-message-consent-required="Please check the checkbox to indicate your consent."
    data-message-invalid-parameters-error="This form has missing or invalid fields."
    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
    class="emailoctopus-form"
    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
>
<div class="form-floating emailoctopus-form-row">
    <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
    <label for="field_0">Email address</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
    <label for="field_1">First Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
    <label for="field_2">Last Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
    <label for="field_4">Company</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
    <label for="field_5">Job Title</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
    <label for="field_3">Phone Number</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
    oninput="updateCountry()"
    >
    <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
    </select>
    <label for="field_7">Country</label>
</div>
<input id="country-destination" name="field_7" type="hidden">
<input id="tz-country" name="field_8" type="hidden">

<input
    name="field_6"
    type="hidden"
    value="Large Language Models"
>

<div class="emailoctopus-form-row-consent">
    <input
    type="checkbox"
    id="consent"
    name="consent"
    >
    <label for="consent">
    I consent to the following terms:
    </label>
    <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
    Terms and Conditions
    </a>
    &amp;
    <a href="./code-of-conduct" target="_blank">
    Code of Conduct
    </a>
</div>
<div
    aria-hidden="true"
    class="emailoctopus-form-row-hp"
>
    <input
    type="text"
    name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
    tabindex="-1"
    autocomplete="nope"
    >
</div>
<div class="mt-6 emailoctopus-form-row-subscribe">
    <input
    type="hidden"
    name="successRedirectUrl"
    >
    <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
    Subscribe to free newsletter <i class="fe fe-arrow-right ms-3"></i>
    </button>
</div>
</form>

<!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
<script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

              </div>
            </div>
          </div>
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-0">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Community</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="8.34" data-monthly="10">8.34</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Access to <a href="https://conf42.circle.so/">Circle community platform</a>
                  </p>
                </div>

                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Immediate access</b> to all content
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <a href="https://conf42.circle.so/c/live-events/" target="_blank"><b>Live events!</b></a>
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <a href="https://conf42.circle.so/c/live-events/" target="_blank">Regular office hours, Q&As, CV reviews</a>
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Courses, quizes & certificates
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Community chats
                  </p>
                </div>
                

                <!-- Button -->
                <a href="https://conf42.circle.so/checkout/subscribe" class="btn w-100 btn-primary">
                  Join the community (7 day free trial)<i class="fe fe-arrow-right ms-3"></i>
                </a>

              </div>
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2025">
                  Site Reliability Engineering (SRE) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2025">
                  Machine Learning 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2025">
                  Observability 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2025">
                  Quantum Computing 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2025">
                  Rustlang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2025">
                  Platform Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2025">
                  MLOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2025">
                  Incident Management 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2025">
                  Kube Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2025">
                  JavaScript 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2025">
                  Prompt Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/robotics2025">
                  Robotics 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2025">
                  DevSecOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2025">
                  Internet of Things (IoT) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>