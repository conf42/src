<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: Building a business-critical data platform to process over £34bn in card transactions</title>
    <meta name="description" content="Explore the amazing world of K8s!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/Sandeep%20Mehta_kube.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Building a business-critical data platform to process over £34bn in card transactions | Conf42"/>
    <meta property="og:description" content="This talk is about building Highly Scalable Self Serve Data Platform to support Data Mesh Revolution by leveraging CNCF technologies. Will share the challenges and mistakes we faced while building the platform which ingrates with every single data point( event stream, API, SFTPs, Files etc)."/>
    <meta property="og:url" content="https://conf42.com/Kube_Native_2023_Sandeep_Mehta_businesscritical_data_platform_process_card_transactions"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/CE2024_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Chaos Engineering 2024
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2024-02-15
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/ce2024" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/aiml2024">
                            Artificial Intelligence & Machine Learning (AI & ML)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.sreday.com/">
                            SREday London
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="./support">
                            Support us
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/DnyHgrC7jC" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Subscribe for FREE
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #CA6B46;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Kube Native 2023 - Online
            </h1>

            <h2 class="text-white">
              
              <time datetime="2023-09-28">September 28 2023</time>
              
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Explore the amazing world of K8s!
 -->
              <script>
                const event_date = new Date("2023-09-28T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2023-09-28T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              <a href="#register" class="btn btn-primary shadow lift me-1 mb-3">
                <i class="fe fe-user-check me-2"></i>
                Subscribe to watch
              </a>
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "wjcWbRczujw"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <a class="btn btn-info lift mb-3" data-bigpicture='{"ytSrc": "O-k-chlFdO8"}' href="#">
                <i class="fe fe-eye me-2"></i>
                Watch Premiere
              </a>
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://youtube.com/playlist?list=PLIuxSyKxlQrAsq4jEk8yDtEYUPWqyqZa5" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "You. Hi everyone,", "timestamp": "00:00:25,410", "timestamp_s": 25.0}, {"text": "thanks for joining. We\u0027ll be talking", "timestamp": "00:00:28,730", "timestamp_s": 28.0}, {"text": "on building a data platform", "timestamp": "00:00:33,210", "timestamp_s": 33.0}, {"text": "to process over 50 billion in card transactions.", "timestamp": "00:00:36,668", "timestamp_s": 36.0}, {"text": "I\u0027m Sandeep, I\u0027m engineering lead data platforms. I\u0027m from Dojo.", "timestamp": "00:00:41,106", "timestamp_s": 41.0}, {"text": "If you don\u0027t know about us,", "timestamp": "00:00:45,570", "timestamp_s": 45.0}, {"text": "we are the fastest growing fintech in Europe by net revenue.", "timestamp": "00:00:48,970", "timestamp_s": 48.0}, {"text": "We power face to face payments for around 15% of", "timestamp": "00:00:52,266", "timestamp_s": 52.0}, {"text": "card transaction in the UK every day. We are mainly focused on", "timestamp": "00:00:56,212", "timestamp_s": 56.0}, {"text": "experience economy of bars, pubs,", "timestamp": "00:01:00,100", "timestamp_s": 60.0}, {"text": "restaurants, even your local corner shop or farmers market. We also", "timestamp": "00:01:03,578", "timestamp_s": 63.0}, {"text": "have a consumer facing app that allows you to join the queue for", "timestamp": "00:01:07,608", "timestamp_s": 67.0}, {"text": "a high street restaurants for up to around 2 miles", "timestamp": "00:01:10,888", "timestamp_s": 70.0}, {"text": "radius. We have an amazing line", "timestamp": "00:01:14,718", "timestamp_s": 74.0}, {"text": "of payment products. We have tap to pay pocket pay.", "timestamp": "00:01:18,732", "timestamp_s": 78.0}, {"text": "We also, sorry, provide the small", "timestamp": "00:01:21,836", "timestamp_s": 81.0}, {"text": "business funding. And we are also building many, many products", "timestamp": "00:01:25,356", "timestamp_s": 85.0}, {"text": "to change how the payment industry works.", "timestamp": "00:01:29,488", "timestamp_s": 89.0}, {"text": "We are going international soon. Hopefully you will see us in", "timestamp": "00:01:33,470", "timestamp_s": 93.0}, {"text": "every corner of Europe first and then in the world.", "timestamp": "00:01:37,488", "timestamp_s": 97.0}, {"text": "What makes us different,", "timestamp": "00:01:41,220", "timestamp_s": 101.0}, {"text": "I guess, and also makes all of this possible is the fact", "timestamp": "00:01:44,836", "timestamp_s": 104.0}, {"text": "that we are highly, highly data driven and value the insights", "timestamp": "00:01:48,116", "timestamp_s": 108.0}, {"text": "in our decision making. When you go", "timestamp": "00:01:52,138", "timestamp_s": 112.0}, {"text": "to a shop and when you tap your card and within a blink", "timestamp": "00:01:55,864", "timestamp_s": 115.0}, {"text": "of a second your transaction happens there and", "timestamp": "00:01:59,678", "timestamp_s": 119.0}, {"text": "you get the goods and the customer, the merchant,", "timestamp": "00:02:03,096", "timestamp_s": 123.0}, {"text": "basically for us it\u0027s the customer, but the merchant who is selling you the", "timestamp": "00:02:07,102", "timestamp_s": 127.0}, {"text": "goods or selling you the services get the money.", "timestamp": "00:02:10,588", "timestamp_s": 130.0}, {"text": "All of this happens within a blink of a second.", "timestamp": "00:02:14,330", "timestamp_s": 134.0}, {"text": "As we just talked about, when you tap a card,", "timestamp": "00:02:17,676", "timestamp_s": 137.0}, {"text": "the first thing happens is the card machine takes the details from the card", "timestamp": "00:02:21,084", "timestamp_s": 141.0}, {"text": "and securely sends these to the authorization gateway. At Dojo,", "timestamp": "00:02:24,640", "timestamp_s": 144.0}, {"text": "we use point to point encryption between the card machine and our authorization", "timestamp": "00:02:28,534", "timestamp_s": 148.0}, {"text": "gateway with hardware security modules in multiple facilities", "timestamp": "00:02:32,250", "timestamp_s": 152.0}, {"text": "with direct pairing to multiple cloud providers.", "timestamp": "00:02:36,730", "timestamp_s": 156.0}, {"text": "It\u0027s highly, highly secure and highly, highly scalable. We can\u0027t let", "timestamp": "00:02:39,658", "timestamp_s": 159.0}, {"text": "our authorization gateway down because that\u0027s the main point", "timestamp": "00:02:43,496", "timestamp_s": 163.0}, {"text": "from where we take the transactions. The authorization", "timestamp": "00:02:47,800", "timestamp_s": 167.0}, {"text": "gateway then contacts the card network such as Visa,", "timestamp": "00:02:51,406", "timestamp_s": 171.0}, {"text": "Mastercard, Amex, and then forwards this request to", "timestamp": "00:02:54,734", "timestamp_s": 174.0}, {"text": "the issuing bank for approval. This will be", "timestamp": "00:02:58,348", "timestamp_s": 178.0}, {"text": "someone like your bank in UK Barclays card,", "timestamp": "00:03:02,092", "timestamp_s": 182.0}, {"text": "Monzo, Tesco, who will then freeze the funds on the customer\u0027s account", "timestamp": "00:03:05,116", "timestamp_s": 185.0}, {"text": "in support. It\u0027s very important to note that the", "timestamp": "00:03:09,344", "timestamp_s": 189.0}, {"text": "money, the actual money has", "timestamp": "00:03:13,792", "timestamp_s": 193.0}, {"text": "not exchanged yet, and it is just a promise", "timestamp": "00:03:17,952", "timestamp_s": 197.0}, {"text": "for a payment that can be reversed as well.", "timestamp": "00:03:21,782", "timestamp_s": 201.0}, {"text": "The card network then sends this approval back to the authorization gateway,", "timestamp": "00:03:25,010", "timestamp_s": 205.0}, {"text": "which is then displayed to the customer as approved or declined.", "timestamp": "00:03:28,842", "timestamp_s": 208.0}, {"text": "And this is how your card transactions actually", "timestamp": "00:03:32,378", "timestamp_s": 212.0}, {"text": "works. And this whole process generates a", "timestamp": "00:03:36,200", "timestamp_s": 216.0}, {"text": "lot of data from a payment point of view,", "timestamp": "00:03:40,008", "timestamp_s": 220.0}, {"text": "because we are a payment company. So we", "timestamp": "00:03:43,750", "timestamp_s": 223.0}, {"text": "have a couple of regulatory challenges where we", "timestamp": "00:03:48,012", "timestamp_s": 228.0}, {"text": "own the end to end payments experience. So we operate under e money license", "timestamp": "00:03:53,532", "timestamp_s": 233.0}, {"text": "from the FCA, which is a financial conduct authority.", "timestamp": "00:03:57,954", "timestamp_s": 237.0}, {"text": "With this comes strict regulatory requirements,", "timestamp": "00:04:01,670", "timestamp_s": 241.0}, {"text": "most notably the fact that we have to ensure the whole time", "timestamp": "00:04:05,030", "timestamp_s": 245.0}, {"text": "that customer funds are safeguarded in case the business becomes irrelevant", "timestamp": "00:04:08,592", "timestamp_s": 248.0}, {"text": "or insolvent.", "timestamp": "00:04:13,050", "timestamp_s": 253.0}, {"text": "Then you have PCI DSS level one", "timestamp": "00:04:16,210", "timestamp_s": 256.0}, {"text": "compliance, which is around safeguarding or not", "timestamp": "00:04:21,570", "timestamp_s": 261.0}, {"text": "safeguarding, storing of full card numbers. So owning", "timestamp": "00:04:25,352", "timestamp_s": 265.0}, {"text": "the whole payment stacks with full card numbers. We also have to comply", "timestamp": "00:04:29,278", "timestamp_s": 269.0}, {"text": "with PCI DSS level one. And we also are", "timestamp": "00:04:32,398", "timestamp_s": 272.0}, {"text": "independently audited every year to ensure that we", "timestamp": "00:04:35,916", "timestamp_s": 275.0}, {"text": "actually follow all the files and guidelines provided", "timestamp": "00:04:39,308", "timestamp_s": 279.0}, {"text": "by PCI. Then we have other complexities", "timestamp": "00:04:43,234", "timestamp_s": 283.0}, {"text": "around schemas. So we process,", "timestamp": "00:04:47,906", "timestamp_s": 287.0}, {"text": "I guess more than 1000 plus data contracts or", "timestamp": "00:04:51,552", "timestamp_s": 291.0}, {"text": "schemas. And this talk, sorry, I completely", "timestamp": "00:04:54,768", "timestamp_s": 294.0}, {"text": "forgot to mention this talk will be around file", "timestamp": "00:04:58,336", "timestamp_s": 298.0}, {"text": "processing. So I\u0027m going to just talk about how we", "timestamp": "00:05:01,738", "timestamp_s": 301.0}, {"text": "built the processing of these", "timestamp": "00:05:05,012", "timestamp_s": 305.0}, {"text": "files coming from different, different sources and all these", "timestamp": "00:05:08,596", "timestamp_s": 308.0}, {"text": "schemes, Visa, Mastercard, and all the payment", "timestamp": "00:05:12,132", "timestamp_s": 312.0}, {"text": "boxes. We have so", "timestamp": "00:05:15,752", "timestamp_s": 315.0}, {"text": "1000 schemas, as I said. And then you have multiple file sizes", "timestamp": "00:05:19,830", "timestamp_s": 319.0}, {"text": "and multiple formats. So it\u0027s just not", "timestamp": "00:05:23,598", "timestamp_s": 323.0}, {"text": "like you have standard file size. Okay, we\u0027re going to have a file", "timestamp": "00:05:27,112", "timestamp_s": 327.0}, {"text": "size range from five mb to ten mb. It doesn\u0027t work like that.", "timestamp": "00:05:30,978", "timestamp_s": 330.0}, {"text": "We have files which are two kb, ten kb,", "timestamp": "00:05:34,508", "timestamp_s": 334.0}, {"text": "50 kb, I don\u0027t know. And then it goes up to gigabytes,", "timestamp": "00:05:37,698", "timestamp_s": 337.0}, {"text": "and then we also get like zipped files as well. Then you", "timestamp": "00:05:41,790", "timestamp_s": 341.0}, {"text": "have a scalability, you can have unpredictable demand.", "timestamp": "00:05:45,840", "timestamp_s": 345.0}, {"text": "Sometimes we have, I don\u0027t know, 500,000 of", "timestamp": "00:05:50,030", "timestamp_s": 350.0}, {"text": "files coming right now because of", "timestamp": "00:05:53,428", "timestamp_s": 353.0}, {"text": "slas between multiple sources, they overlap and all of", "timestamp": "00:05:57,268", "timestamp_s": 357.0}, {"text": "the file comes at the same time. And then all of", "timestamp": "00:06:00,644", "timestamp_s": 360.0}, {"text": "those files sometimes are business critical. So we have to process all of them at", "timestamp": "00:06:03,860", "timestamp_s": 363.0}, {"text": "the same time. So for example,", "timestamp": "00:06:07,208", "timestamp_s": 367.0}, {"text": "if you see this is a snapshot", "timestamp": "00:06:10,760", "timestamp_s": 370.0}, {"text": "of internal reconciliation process performed by our", "timestamp": "00:06:14,334", "timestamp_s": 374.0}, {"text": "payments analytical engineering team, just to ensure", "timestamp": "00:06:17,756", "timestamp_s": 377.0}, {"text": "that a merchant\u0027s net settlement tallies with card transactions that", "timestamp": "00:06:21,490", "timestamp_s": 381.0}, {"text": "have been actually authorized on the tills in their shops.", "timestamp": "00:06:24,972", "timestamp_s": 384.0}, {"text": "As you can see, there\u0027s like CSVs XLS XML", "timestamp": "00:06:28,990", "timestamp_s": 388.0}, {"text": "that many files required to get just that done.", "timestamp": "00:06:33,550", "timestamp_s": 393.0}, {"text": "And also another bit like all", "timestamp": "00:06:38,750", "timestamp_s": 398.0}, {"text": "the files coming in doesn\u0027t just have XLS or XML,", "timestamp": "00:06:44,708", "timestamp_s": 404.0}, {"text": "they have all the files formats possible.", "timestamp": "00:06:48,618", "timestamp_s": 408.0}, {"text": "We have JSON files, we even have Avro", "timestamp": "00:06:52,950", "timestamp_s": 412.0}, {"text": "files. Now we have parquet files", "timestamp": "00:06:56,318", "timestamp_s": 416.0}, {"text": "as well. We have fix", "timestamp": "00:06:59,998", "timestamp_s": 419.0}, {"text": "with files. We have done this proprietary formats", "timestamp": "00:07:03,512", "timestamp_s": 423.0}, {"text": "created by this scheme,", "timestamp": "00:07:07,330", "timestamp_s": 427.0}, {"text": "companies like Visa, Mastercard. For that you had to write", "timestamp": "00:07:10,994", "timestamp_s": 430.0}, {"text": "very heavy custom parsers to actually make sense out of", "timestamp": "00:07:14,988", "timestamp_s": 434.0}, {"text": "those files and put them into your transactional kind", "timestamp": "00:07:18,540", "timestamp_s": 438.0}, {"text": "of data warehouse.", "timestamp": "00:07:22,272", "timestamp_s": 442.0}, {"text": "And the goal", "timestamp": "00:07:25,710", "timestamp_s": 445.0}, {"text": "which we came up, or the goal", "timestamp": "00:07:30,038", "timestamp_s": 450.0}, {"text": "which we thought would be good for us to actually take", "timestamp": "00:07:34,362", "timestamp_s": 454.0}, {"text": "all of these file formats, process them into", "timestamp": "00:07:38,532", "timestamp_s": 458.0}, {"text": "a final single format which can be then later utilized", "timestamp": "00:07:42,068", "timestamp_s": 462.0}, {"text": "by processes downstreams to stream that into", "timestamp": "00:07:45,902", "timestamp_s": 465.0}, {"text": "warehouse, or stream that into Kafka, or stream that into snowflake,", "timestamp": "00:07:49,400", "timestamp_s": 469.0}, {"text": "or stream that into anywhere else, wherever we want.", "timestamp": "00:07:54,862", "timestamp_s": 474.0}, {"text": "And we chose Avro because of most of the powers", "timestamp": "00:07:57,612", "timestamp_s": 477.0}, {"text": "around scheme evolution and mainly", "timestamp": "00:08:01,074", "timestamp_s": 481.0}, {"text": "that I guess. But there now there are multiple different formats", "timestamp": "00:08:06,210", "timestamp_s": 486.0}, {"text": "which you can choose. But we chose Avro at that point.", "timestamp": "00:08:09,682", "timestamp_s": 489.0}, {"text": "And it\u0027s not just payments. There are a lot of other business areas in the", "timestamp": "00:08:14,430", "timestamp_s": 494.0}, {"text": "company which are important. They produce a lot of events data and", "timestamp": "00:08:17,808", "timestamp_s": 497.0}, {"text": "also generate a lot of files data. And that", "timestamp": "00:08:21,952", "timestamp_s": 501.0}, {"text": "can be coming from APIs or that can be coming from external tools or", "timestamp": "00:08:25,508", "timestamp_s": 505.0}, {"text": "that can be generated by their own microservices.", "timestamp": "00:08:29,572", "timestamp_s": 509.0}, {"text": "So to support the processing of files with all the schema evolution,", "timestamp": "00:08:33,330", "timestamp_s": 513.0}, {"text": "with the scale and with all these challenges in mind, it was very", "timestamp": "00:08:36,910", "timestamp_s": 516.0}, {"text": "important for us to design a data platform which is scalable", "timestamp": "00:08:40,712", "timestamp_s": 520.0}, {"text": "and self serve. And now before deep diving into", "timestamp": "00:08:44,302", "timestamp_s": 524.0}, {"text": "the modern data infracessing and how", "timestamp": "00:08:48,490", "timestamp_s": 528.0}, {"text": "we have done it, I would like to take us back into the", "timestamp": "00:08:51,916", "timestamp_s": 531.0}, {"text": "history of data processing.", "timestamp": "00:08:55,308", "timestamp_s": 535.0}, {"text": "There were three generation of data processing.", "timestamp": "00:08:58,430", "timestamp_s": 538.0}, {"text": "First generation was the generation of enterprise data warehouse", "timestamp": "00:09:01,926", "timestamp_s": 541.0}, {"text": "solutions. Big giants like Oracle, IBM, Microsoft were", "timestamp": "00:09:05,398", "timestamp_s": 545.0}, {"text": "building those big big warehouse which only few people", "timestamp": "00:09:09,616", "timestamp_s": 549.0}, {"text": "know how to use. Then came the era", "timestamp": "00:09:14,068", "timestamp_s": 554.0}, {"text": "of big data ecosystem, the era of Hadoop, the era", "timestamp": "00:09:17,578", "timestamp_s": 557.0}, {"text": "of pig hide spark came into the picture.", "timestamp": "00:09:20,874", "timestamp_s": 560.0}, {"text": "We built those monolith big, big centralized,", "timestamp": "00:09:24,510", "timestamp_s": 564.0}, {"text": "beefy hadoops, big data platforms which was again", "timestamp": "00:09:27,726", "timestamp_s": 567.0}, {"text": "only utilized or monitored or operated by", "timestamp": "00:09:32,790", "timestamp_s": 572.0}, {"text": "few people. And huge bottleneck and huge", "timestamp": "00:09:36,572", "timestamp_s": 576.0}, {"text": "number of skill shortage to actually make the", "timestamp": "00:09:40,348", "timestamp_s": 580.0}, {"text": "huge, to make the use of it, I would say.", "timestamp": "00:09:44,476", "timestamp_s": 584.0}, {"text": "Then we talk about current generation, mostly centralized data", "timestamp": "00:09:48,236", "timestamp_s": 588.0}, {"text": "platforms. Mix of batch and real time processing based on tools like", "timestamp": "00:09:52,176", "timestamp_s": 592.0}, {"text": "Kafka, Apache Beam also gives you the flavor of", "timestamp": "00:09:56,656", "timestamp_s": 596.0}, {"text": "the mix. Real time and batch processing, then pubsub,", "timestamp": "00:10:01,730", "timestamp_s": 601.0}, {"text": "then red panda, then all sort of cloud", "timestamp": "00:10:05,466", "timestamp_s": 605.0}, {"text": "managed services like AWS, GCP, other cloud", "timestamp": "00:10:09,412", "timestamp_s": 609.0}, {"text": "providers like confluent, Avon, they are giving", "timestamp": "00:10:12,996", "timestamp_s": 612.0}, {"text": "their own managed services on top. Well, this centralized model", "timestamp": "00:10:16,388", "timestamp_s": 616.0}, {"text": "can work for organization that have a simpler domain with", "timestamp": "00:10:20,056", "timestamp_s": 620.0}, {"text": "a smaller number of diverse conception cases. It files for us", "timestamp": "00:10:23,288", "timestamp_s": 623.0}, {"text": "because we have rich domains, a large number of sources,", "timestamp": "00:10:27,468", "timestamp_s": 627.0}, {"text": "a large number of consumers,", "timestamp": "00:10:31,858", "timestamp_s": 631.0}, {"text": "and most of the companies who are going", "timestamp": "00:10:37,930", "timestamp_s": 637.0}, {"text": "through such a growth, they also have this problem and", "timestamp": "00:10:41,312", "timestamp_s": 641.0}, {"text": "this centralized data platform really doesn\u0027t work. And there are other challenges", "timestamp": "00:10:44,528", "timestamp_s": 644.0}, {"text": "with it. The challenge that the centralized data platform", "timestamp": "00:10:48,566", "timestamp_s": 648.0}, {"text": "is mainly owned by a centralized data team which", "timestamp": "00:10:52,564", "timestamp_s": 652.0}, {"text": "is focused on building, maintaining data", "timestamp": "00:10:57,410", "timestamp_s": 657.0}, {"text": "processing pipelines, then building data contracts working hand in", "timestamp": "00:11:01,092", "timestamp_s": 661.0}, {"text": "hand with stakeholders. But at the end of the day, there\u0027s no clear ownership on", "timestamp": "00:11:04,904", "timestamp_s": 664.0}, {"text": "that. Then issues support for", "timestamp": "00:11:08,488", "timestamp_s": 668.0}, {"text": "all the domains without actually having the domain", "timestamp": "00:11:12,872", "timestamp_s": 672.0}, {"text": "knowledge. Then you have silos, then specialized data team", "timestamp": "00:11:16,418", "timestamp_s": 676.0}, {"text": "which will keep on adding features if they get some time away from", "timestamp": "00:11:21,450", "timestamp_s": 681.0}, {"text": "the support issues or everyday change requests.", "timestamp": "00:11:26,010", "timestamp_s": 686.0}, {"text": "Then another issue is data", "timestamp": "00:11:30,030", "timestamp_s": 690.0}, {"text": "quality, accountability, democratization of data.", "timestamp": "00:11:33,376", "timestamp_s": 693.0}, {"text": "It\u0027s very difficult to enhance or put measures for data quality", "timestamp": "00:11:37,232", "timestamp_s": 697.0}, {"text": "if there is no clear ownership on the data. The fact that", "timestamp": "00:11:40,756", "timestamp_s": 700.0}, {"text": "data team manages data access, it makes it a bottleneck when", "timestamp": "00:11:44,612", "timestamp_s": 704.0}, {"text": "it comes to access request. Then scalability,", "timestamp": "00:11:48,468", "timestamp_s": 708.0}, {"text": "adding new data sources, increased data volumes, data contract changes,", "timestamp": "00:11:53,370", "timestamp_s": 713.0}, {"text": "et cetera, can be delayed due to a huge data team backlog", "timestamp": "00:11:57,320", "timestamp_s": 717.0}, {"text": "because they are the one who are actually", "timestamp": "00:12:01,278", "timestamp_s": 721.0}, {"text": "managing and maintaining the data pipelines. And the byproduct of", "timestamp": "00:12:05,080", "timestamp_s": 725.0}, {"text": "this also is not such a great relationship between", "timestamp": "00:12:09,068", "timestamp_s": 729.0}, {"text": "data team and the other teams, and also a lot of blame game when this", "timestamp": "00:12:13,596", "timestamp_s": 733.0}, {"text": "goes wrong. And over the last decade or", "timestamp": "00:12:16,828", "timestamp_s": 736.0}, {"text": "so, we have successfully applied the domain driven design into", "timestamp": "00:12:20,128", "timestamp_s": 740.0}, {"text": "our engineering or operational side.", "timestamp": "00:12:23,392", "timestamp_s": 743.0}, {"text": "But as a whole data community, we completely, or as a whole engineering", "timestamp": "00:12:27,150", "timestamp_s": 747.0}, {"text": "community, we completely forgot to put that into the data side.", "timestamp": "00:12:31,238", "timestamp_s": 751.0}, {"text": "Now, what should we do in this kind of scenario?", "timestamp": "00:12:34,852", "timestamp_s": 754.0}, {"text": "Right? How should we go on? And what is the right way of building", "timestamp": "00:12:38,266", "timestamp_s": 758.0}, {"text": "that file processing platform which we built at dojo, or any", "timestamp": "00:12:42,468", "timestamp_s": 762.0}, {"text": "kind of data platform which you might want to build it or anybody", "timestamp": "00:12:47,112", "timestamp_s": 767.0}, {"text": "wants to build it. Now imagine this,", "timestamp": "00:12:51,080", "timestamp_s": 771.0}, {"text": "right? What if the centralized data team will", "timestamp": "00:12:54,392", "timestamp_s": 774.0}, {"text": "only focus on creating a generic data infrastructure, building self", "timestamp": "00:12:57,996", "timestamp_s": 777.0}, {"text": "served data platforms by abstracting away all the technical complexities", "timestamp": "00:13:01,772", "timestamp_s": 781.0}, {"text": "and enabling other teams to easily process their own data.", "timestamp": "00:13:06,194", "timestamp_s": 786.0}, {"text": "Apart from that, they will also provide a global governance model and", "timestamp": "00:13:10,032", "timestamp_s": 790.0}, {"text": "policies to have better access management, better naming conventions,", "timestamp": "00:13:14,032", "timestamp_s": 794.0}, {"text": "better cis, better security policies,", "timestamp": "00:13:17,910", "timestamp_s": 797.0}, {"text": "and at the same time, domain ownership moves,", "timestamp": "00:13:20,930", "timestamp_s": 800.0}, {"text": "sorry, data ownership moves from centralized team", "timestamp": "00:13:24,450", "timestamp_s": 804.0}, {"text": "to the domains. I have said domains many times in this", "timestamp": "00:13:28,132", "timestamp_s": 808.0}, {"text": "chat so far, but by domains I mean teams that are working", "timestamp": "00:13:31,268", "timestamp_s": 811.0}, {"text": "on a certain business area, for example, payment, marketing,", "timestamp": "00:13:34,936", "timestamp_s": 814.0}, {"text": "customer, et cetera, et cetera.", "timestamp": "00:13:38,222", "timestamp_s": 818.0}, {"text": "Now, this whole approach brings a set of benefits.", "timestamp": "00:13:42,070", "timestamp_s": 822.0}, {"text": "Finally, the data is owned by people who understand", "timestamp": "00:13:45,336", "timestamp_s": 825.0}, {"text": "it better company wise. You reach a better", "timestamp": "00:13:48,764", "timestamp_s": 828.0}, {"text": "scalability by distributing data processing across the domains.", "timestamp": "00:13:52,236", "timestamp_s": 832.0}, {"text": "Domains are now independent and they are able to add new data sources,", "timestamp": "00:13:56,402", "timestamp_s": 836.0}, {"text": "create new data pipelines, fix the issues by themselves.", "timestamp": "00:14:00,278", "timestamp_s": 840.0}, {"text": "Domains can put better data quality and reliability measures than", "timestamp": "00:14:03,550", "timestamp_s": 843.0}, {"text": "the centralized data team because they understand it better.", "timestamp": "00:14:06,832", "timestamp_s": 846.0}, {"text": "Domains have the flexibility of using only what they need from", "timestamp": "00:14:10,510", "timestamp_s": 850.0}, {"text": "the generic data infrastructure and self serve data platform features,", "timestamp": "00:14:14,516", "timestamp_s": 854.0}, {"text": "which reduces the complexity blast radius if things goes", "timestamp": "00:14:18,490", "timestamp_s": 858.0}, {"text": "bad and things always goes bad. And having", "timestamp": "00:14:22,020", "timestamp_s": 862.0}, {"text": "said that, the centralized data team should", "timestamp": "00:14:25,960", "timestamp_s": 865.0}, {"text": "make sure that there is a good monitoring", "timestamp": "00:14:29,976", "timestamp_s": 869.0}, {"text": "alerting in place to monitor all", "timestamp": "00:14:33,902", "timestamp_s": 873.0}, {"text": "the flavors or features of data platform across", "timestamp": "00:14:37,212", "timestamp_s": 877.0}, {"text": "the domains. Now this approach will also", "timestamp": "00:14:41,196", "timestamp_s": 881.0}, {"text": "enforce well documented data contracts data API,", "timestamp": "00:14:44,476", "timestamp_s": 884.0}, {"text": "which will allow data to flow seamlessly between one system and the another", "timestamp": "00:14:48,610", "timestamp_s": 888.0}, {"text": "system. It can be internal or external as well.", "timestamp": "00:14:52,016", "timestamp_s": 892.0}, {"text": "And having domains owning their data infrastructure brings more visibility on", "timestamp": "00:14:55,440", "timestamp_s": 895.0}, {"text": "resource allocation and utilization, which could", "timestamp": "00:14:59,488", "timestamp_s": 899.0}, {"text": "lead into cost efficiency.", "timestamp": "00:15:03,268", "timestamp_s": 903.0}, {"text": "Now this whole concept is, my friend is data mesh.", "timestamp": "00:15:06,850", "timestamp_s": 906.0}, {"text": "Now data Mesh is, I know I\u0027m talking", "timestamp": "00:15:11,730", "timestamp_s": 911.0}, {"text": "a lot of theory right now, but I will come back how", "timestamp": "00:15:15,316", "timestamp_s": 915.0}, {"text": "we build that dojo. But this is very important. So data mesh", "timestamp": "00:15:18,472", "timestamp_s": 918.0}, {"text": "is like domain ownership. It\u0027s one of the best,", "timestamp": "00:15:22,142", "timestamp_s": 922.0}, {"text": "or sorry, not one of the best. It\u0027s one of the important pillar.", "timestamp": "00:15:25,192", "timestamp_s": 925.0}, {"text": "It\u0027s your data, you own it,", "timestamp": "00:15:30,090", "timestamp_s": 930.0}, {"text": "you manage it, and if there is a problem with it, you fix it.", "timestamp": "00:15:33,548", "timestamp_s": 933.0}, {"text": "Data as a product, data is not a byproduct.", "timestamp": "00:15:39,210", "timestamp_s": 939.0}, {"text": "Treat your data as a product, whether it\u0027s", "timestamp": "00:15:42,806", "timestamp_s": 942.0}, {"text": "a file, whether it\u0027s an event, whether it\u0027s a warehouse, or whether", "timestamp": "00:15:45,894", "timestamp_s": 945.0}, {"text": "it\u0027s a beefy table, all of that treat it as a product.", "timestamp": "00:15:49,408", "timestamp_s": 949.0}, {"text": "Federated computational governance each domain can set", "timestamp": "00:15:53,650", "timestamp_s": 953.0}, {"text": "their own policies or rules over data. For example,", "timestamp": "00:15:57,012", "timestamp_s": 957.0}, {"text": "payment domain sftps encryption standards on payment data or marketing", "timestamp": "00:16:00,580", "timestamp_s": 960.0}, {"text": "domain sftps retention on the customer data to 28 days to", "timestamp": "00:16:04,718", "timestamp_s": 964.0}, {"text": "adhere to GDPR standards. Then the", "timestamp": "00:16:08,424", "timestamp_s": 968.0}, {"text": "final and my favorite bit is self serve data platform.", "timestamp": "00:16:12,008", "timestamp_s": 972.0}, {"text": "This is the key in all of this. If you successfully build", "timestamp": "00:16:15,320", "timestamp_s": 975.0}, {"text": "this, which means self serve data platform,", "timestamp": "00:16:19,676", "timestamp_s": 979.0}, {"text": "you\u0027ve got 80% things right. This will enable teams to own", "timestamp": "00:16:22,860", "timestamp_s": 982.0}, {"text": "and manage their data and data processing. But the big question", "timestamp": "00:16:26,540", "timestamp_s": 986.0}, {"text": "is how you\u0027re going to build it. It looks", "timestamp": "00:16:30,224", "timestamp_s": 990.0}, {"text": "easy now, but when you have so many choices and", "timestamp": "00:16:33,936", "timestamp_s": 993.0}, {"text": "so many people pulling you in conferences that their data platform is the best,", "timestamp": "00:16:37,456", "timestamp_s": 997.0}, {"text": "they have the one stop solution. It can be quite overwhelming,", "timestamp": "00:16:40,916", "timestamp_s": 1000.0}, {"text": "but I guess based on your use case you will do certain", "timestamp": "00:16:46,770", "timestamp_s": 1006.0}, {"text": "PoCs. You would try to try to", "timestamp": "00:16:50,756", "timestamp_s": 1010.0}, {"text": "look at probably open source solutions", "timestamp": "00:16:53,848", "timestamp_s": 1013.0}, {"text": "available before buying already, I don\u0027t know,", "timestamp": "00:16:57,838", "timestamp_s": 1017.0}, {"text": "committing to thousands and thousands of pounds or thousands and thousands of dollars", "timestamp": "00:17:01,432", "timestamp_s": 1021.0}, {"text": "to some managed providers claiming that they can", "timestamp": "00:17:05,032", "timestamp_s": 1025.0}, {"text": "solve all your problems. When we", "timestamp": "00:17:08,828", "timestamp_s": 1028.0}, {"text": "were building this file processing platform, we were quite sure that", "timestamp": "00:17:12,588", "timestamp_s": 1032.0}, {"text": "the platform, as a service or self serve platform offering was the", "timestamp": "00:17:16,668", "timestamp_s": 1036.0}, {"text": "only way to move forward. Now on", "timestamp": "00:17:20,124", "timestamp_s": 1040.0}, {"text": "a high level, four main features in our platform provides this end", "timestamp": "00:17:23,728", "timestamp_s": 1043.0}, {"text": "to end solution for file processing, which we just talked about before,", "timestamp": "00:17:27,168", "timestamp_s": 1047.0}, {"text": "that we have 20 plus different types of", "timestamp": "00:17:30,400", "timestamp_s": 1050.0}, {"text": "files coming in, and then we have around 500k", "timestamp": "00:17:34,388", "timestamp_s": 1054.0}, {"text": "files every day coming in, which we have to process varies in different size,", "timestamp": "00:17:38,388", "timestamp_s": 1058.0}, {"text": "and then they come in in certain hours and we have to scale the system", "timestamp": "00:17:42,052", "timestamp_s": 1062.0}, {"text": "accordingly as well. Now, four components.", "timestamp": "00:17:45,496", "timestamp_s": 1065.0}, {"text": "First component is source connectors, which is ingesting data from", "timestamp": "00:17:48,878", "timestamp_s": 1068.0}, {"text": "external providers in a consistent way. So we", "timestamp": "00:17:52,488", "timestamp_s": 1072.0}, {"text": "did build those connectors to bring the data. Then you have PCI", "timestamp": "00:17:55,708", "timestamp_s": 1075.0}, {"text": "processing platform, which actually makes sure", "timestamp": "00:17:59,026", "timestamp_s": 1079.0}, {"text": "that a clear credit card information is stored,", "timestamp": "00:18:02,620", "timestamp_s": 1082.0}, {"text": "masked and processed successfully and very,", "timestamp": "00:18:06,082", "timestamp_s": 1086.0}, {"text": "very securely, and then being sent to non PCI platform,", "timestamp": "00:18:09,292", "timestamp_s": 1089.0}, {"text": "and the non PCI platform which takes all the non PCI data", "timestamp": "00:18:13,084", "timestamp_s": 1093.0}, {"text": "and also the data coming from all these other domains and", "timestamp": "00:18:17,470", "timestamp_s": 1097.0}, {"text": "everywhere and perform schema", "timestamp": "00:18:20,848", "timestamp_s": 1100.0}, {"text": "evaluation. I always struggle with this word and data", "timestamp": "00:18:25,258", "timestamp_s": 1105.0}, {"text": "validation and generate outputs into that final format which", "timestamp": "00:18:29,236", "timestamp_s": 1109.0}, {"text": "we agreed before Avro and basically chunked Avro", "timestamp": "00:18:32,872", "timestamp_s": 1112.0}, {"text": "because the file size has been different,", "timestamp": "00:18:36,798", "timestamp_s": 1116.0}, {"text": "the source file size. So we make sure that the final avro files", "timestamp": "00:18:41,960", "timestamp_s": 1121.0}, {"text": "are chunked into somewhere around roughly to the same", "timestamp": "00:18:45,902", "timestamp_s": 1125.0}, {"text": "size. So we don\u0027t end up having like one avro file which is two gig,", "timestamp": "00:18:49,292", "timestamp_s": 1129.0}, {"text": "and one avro file which is like few kb\u0027s.", "timestamp": "00:18:52,818", "timestamp_s": 1132.0}, {"text": "Sorry. Then target", "timestamp": "00:18:56,970", "timestamp_s": 1136.0}, {"text": "connectors. Streaming the data generated", "timestamp": "00:19:00,166", "timestamp_s": 1140.0}, {"text": "avro files, let\u0027s say from this lake", "timestamp": "00:19:04,854", "timestamp_s": 1144.0}, {"text": "house kind of, or distributed data lakes into the data warehouse", "timestamp": "00:19:07,958", "timestamp_s": 1147.0}, {"text": "or into any other streaming system or into", "timestamp": "00:19:12,090", "timestamp_s": 1152.0}, {"text": "any other external kind of like warehouse", "timestamp": "00:19:17,410", "timestamp_s": 1157.0}, {"text": "if Snowflake, or loading that", "timestamp": "00:19:21,002", "timestamp_s": 1161.0}, {"text": "into mlops platform and things like that.", "timestamp": "00:19:24,792", "timestamp_s": 1164.0}, {"text": "Now let\u0027s deep dive into all of these components.", "timestamp": "00:19:27,912", "timestamp_s": 1167.0}, {"text": "Connectors, source connectors. We have a number of", "timestamp": "00:19:33,830", "timestamp_s": 1173.0}, {"text": "different data sources. We have storage buckets, we have external", "timestamp": "00:19:37,528", "timestamp_s": 1177.0}, {"text": "APIs, we have webhooks, we have Gmail attachments.", "timestamp": "00:19:41,058", "timestamp_s": 1181.0}, {"text": "Trust me, we still have processes where we have to get the data from attachments.", "timestamp": "00:19:44,690", "timestamp_s": 1184.0}, {"text": "Then we have external sftps servers. So mainly we use", "timestamp": "00:19:48,438", "timestamp_s": 1188.0}, {"text": "Arclone to move most", "timestamp": "00:19:52,880", "timestamp_s": 1192.0}, {"text": "of the data which is coming in files. It\u0027s an amazing", "timestamp": "00:19:56,336", "timestamp_s": 1196.0}, {"text": "open source utility, which comes very handy", "timestamp": "00:19:59,920", "timestamp_s": 1199.0}, {"text": "when you want to move files between two storage systems. You can move", "timestamp": "00:20:03,802", "timestamp_s": 1203.0}, {"text": "from s three to gcs", "timestamp": "00:20:07,492", "timestamp_s": 1207.0}, {"text": "or SFTP to any kind of storage bucket,", "timestamp": "00:20:11,786", "timestamp_s": 1211.0}, {"text": "and it works like a charm. But you", "timestamp": "00:20:14,990", "timestamp_s": 1214.0}, {"text": "have to spend some time on the configuration part of it.", "timestamp": "00:20:22,328", "timestamp_s": 1222.0}, {"text": "Then you have Webex. So if the data", "timestamp": "00:20:25,990", "timestamp_s": 1225.0}, {"text": "was not in files, for example in case of webhooks we batch those events into", "timestamp": "00:20:29,276", "timestamp_s": 1229.0}, {"text": "files to keep things consistent. And we", "timestamp": "00:20:32,956", "timestamp_s": 1232.0}, {"text": "did have some strict lsas slas but we", "timestamp": "00:20:37,180", "timestamp_s": 1237.0}, {"text": "did not have slas to process this information in real time. So in", "timestamp": "00:20:40,400", "timestamp_s": 1240.0}, {"text": "those cases where we don\u0027t have adhere kind of like", "timestamp": "00:20:44,992", "timestamp_s": 1244.0}, {"text": "slas, okay, we need to process this information straight away.", "timestamp": "00:20:48,576", "timestamp_s": 1248.0}, {"text": "We also use webhook kind of connectors", "timestamp": "00:20:51,952", "timestamp_s": 1251.0}, {"text": "which batch those events and send them into the files.", "timestamp": "00:20:56,186", "timestamp_s": 1256.0}, {"text": "I guess we are moving that completely into the overstreaming side now. I guess that", "timestamp": "00:20:59,226", "timestamp_s": 1259.0}, {"text": "was the historic decision which we took. Then we have serverless", "timestamp": "00:21:03,108", "timestamp_s": 1263.0}, {"text": "functions which allows the data to be received automatically by", "timestamp": "00:21:06,302", "timestamp_s": 1266.0}, {"text": "email, including email body. I just talked about the email attachments", "timestamp": "00:21:10,072", "timestamp_s": 1270.0}, {"text": "up there. We have one provider that does not attach a file", "timestamp": "00:21:14,046", "timestamp_s": 1274.0}, {"text": "but provides a system configuration message in the body of the email.", "timestamp": "00:21:17,826", "timestamp_s": 1277.0}, {"text": "So we had to write a parser for that as well.", "timestamp": "00:21:21,532", "timestamp_s": 1281.0}, {"text": "I know they always have use cases like that", "timestamp": "00:21:25,370", "timestamp_s": 1285.0}, {"text": "and then we use these connectors to land the data in the PCI and non", "timestamp": "00:21:29,052", "timestamp_s": 1289.0}, {"text": "PCI platforms like depending on the sensitivity of the data.", "timestamp": "00:21:32,758", "timestamp_s": 1292.0}, {"text": "So if we know that these files", "timestamp": "00:21:36,416", "timestamp_s": 1296.0}, {"text": "are encrypted and they are supposed to", "timestamp": "00:21:39,814", "timestamp_s": 1299.0}, {"text": "be processed by PCI to get the credit card", "timestamp": "00:21:43,344", "timestamp_s": 1303.0}, {"text": "information masked, they directly go to the PCI platform and if", "timestamp": "00:21:46,756", "timestamp_s": 1306.0}, {"text": "they are not they then bypass that process and directly go to", "timestamp": "00:21:50,388", "timestamp_s": 1310.0}, {"text": "the non PCI platform. Before jumping into", "timestamp": "00:21:53,704", "timestamp_s": 1313.0}, {"text": "the PCI platform, just few", "timestamp": "00:21:57,160", "timestamp_s": 1317.0}, {"text": "lines on what is PCI compliance.", "timestamp": "00:22:00,472", "timestamp_s": 1320.0}, {"text": "So all the listeners would understand how", "timestamp": "00:22:03,750", "timestamp_s": 1323.0}, {"text": "much complexity is or how much things you have", "timestamp": "00:22:07,628", "timestamp_s": 1327.0}, {"text": "to consider while building a PCI data platform kind", "timestamp": "00:22:10,924", "timestamp_s": 1330.0}, {"text": "of environment.", "timestamp": "00:22:14,748", "timestamp_s": 1334.0}, {"text": "Adhering to PCI standard is one of our prime", "timestamp": "00:22:18,330", "timestamp_s": 1338.0}, {"text": "concerns given we own the end to end payment stack", "timestamp": "00:22:21,782", "timestamp_s": 1341.0}, {"text": "and these standards are the set of security requirements established by the PCI", "timestamp": "00:22:25,782", "timestamp_s": 1345.0}, {"text": "SSE to ensure that credit card information", "timestamp": "00:22:29,926", "timestamp_s": 1349.0}, {"text": "is process successfully within any organization. Some of the key points", "timestamp": "00:22:33,540", "timestamp_s": 1353.0}, {"text": "from this compliance are at a high level. They are like all", "timestamp": "00:22:37,220", "timestamp_s": 1357.0}, {"text": "the credit card data has to be transmitted through secure encrypted", "timestamp": "00:22:40,468", "timestamp_s": 1360.0}, {"text": "channels and then clear card", "timestamp": "00:22:44,878", "timestamp_s": 1364.0}, {"text": "numbers cannot be", "timestamp": "00:22:48,824", "timestamp_s": 1368.0}, {"text": "stored anywhere unless they are anonymized or encrypted.", "timestamp": "00:22:52,008", "timestamp_s": 1372.0}, {"text": "Then you have the data platform that the platform which deals with the PCI", "timestamp": "00:22:55,790", "timestamp_s": 1375.0}, {"text": "data has to be audited for", "timestamp": "00:22:59,266", "timestamp_s": 1379.0}, {"text": "any security concerns every year.", "timestamp": "00:23:02,492", "timestamp_s": 1382.0}, {"text": "So when we have PCI, so this is our PCI", "timestamp": "00:23:05,210", "timestamp_s": 1385.0}, {"text": "management process within the PCI platform,", "timestamp": "00:23:08,722", "timestamp_s": 1388.0}, {"text": "we have those files coming in, we don\u0027t know the", "timestamp": "00:23:11,870", "timestamp_s": 1391.0}, {"text": "size of the files, they are zipped, they are encrypted.", "timestamp": "00:23:15,248", "timestamp_s": 1395.0}, {"text": "So we have to decrypt the source file in memory using", "timestamp": "00:23:18,742", "timestamp_s": 1398.0}, {"text": "confidential computing nodes. Then we encrypt with our", "timestamp": "00:23:22,660", "timestamp_s": 1402.0}, {"text": "own key and archive the files for future purposes and for safeguarding.", "timestamp": "00:23:26,436", "timestamp_s": 1406.0}, {"text": "Then if it\u0027s a zip file, we unzip on the disk. If the file", "timestamp": "00:23:30,506", "timestamp_s": 1410.0}, {"text": "contains pans, we open the file, we mask the pans, then send the", "timestamp": "00:23:34,298", "timestamp_s": 1414.0}, {"text": "masked version of the file to the non PCI platform. Because now,", "timestamp": "00:23:38,088", "timestamp_s": 1418.0}, {"text": "because it\u0027s masked, it doesn\u0027t fall into the", "timestamp": "00:23:41,848", "timestamp_s": 1421.0}, {"text": "PCI category. And this", "timestamp": "00:23:46,410", "timestamp_s": 1426.0}, {"text": "is how the overall processing looks like.", "timestamp": "00:23:50,252", "timestamp_s": 1430.0}, {"text": "So as you can see, the files start arriving.", "timestamp": "00:23:54,300", "timestamp_s": 1434.0}, {"text": "It\u0027s a bit smaller for me. Yeah.", "timestamp": "00:23:58,750", "timestamp_s": 1438.0}, {"text": "So the file starts arriving into the PCI storage bucket", "timestamp": "00:24:01,856", "timestamp_s": 1441.0}, {"text": "and this is all running in GKE.", "timestamp": "00:24:07,310", "timestamp_s": 1447.0}, {"text": "In Kubernetes, Rclone is running as", "timestamp": "00:24:11,034", "timestamp_s": 1451.0}, {"text": "a cron job in Kubernetes. For object storage we are", "timestamp": "00:24:14,308", "timestamp_s": 1454.0}, {"text": "using GCP, GCP\u0027s gcs", "timestamp": "00:24:17,828", "timestamp_s": 1457.0}, {"text": "and for queues we are using pubsub at the moment.", "timestamp": "00:24:21,418", "timestamp_s": 1461.0}, {"text": "So just so you know that we are completely GCP based,", "timestamp": "00:24:24,870", "timestamp_s": 1464.0}, {"text": "but most of our workloads and most of our processing power", "timestamp": "00:24:29,670", "timestamp_s": 1469.0}, {"text": "runs on GKE. So it\u0027s a", "timestamp": "00:24:34,230", "timestamp_s": 1474.0}, {"text": "good mixture of being cloud native as well as cloud agnostic", "timestamp": "00:24:37,484", "timestamp_s": 1477.0}, {"text": "at the same time. So these connectors are running, they are pulling the file from", "timestamp": "00:24:41,778", "timestamp_s": 1481.0}, {"text": "SFTP or storage or s three, and then these files arrives into", "timestamp": "00:24:45,756", "timestamp_s": 1485.0}, {"text": "object storage. The moment the file arrives in object storage,", "timestamp": "00:24:49,756", "timestamp_s": 1489.0}, {"text": "a file event has been created that okay, the file is", "timestamp": "00:24:53,238", "timestamp_s": 1493.0}, {"text": "created, the files is created, the file is created, and that goes into a pub", "timestamp": "00:24:56,528", "timestamp_s": 1496.0}, {"text": "sub queue. And then based on the number", "timestamp": "00:24:59,248", "timestamp_s": 1499.0}, {"text": "of messages in the queue, the HPA will scale the workload. We will", "timestamp": "00:25:02,852", "timestamp_s": 1502.0}, {"text": "talk about scaling in detail in the later part of the presentation.", "timestamp": "00:25:06,788", "timestamp_s": 1506.0}, {"text": "We typically have around 300 pods running at peak", "timestamp": "00:25:12,450", "timestamp_s": 1512.0}, {"text": "hours across 40 nodes to process around 300", "timestamp": "00:25:16,318", "timestamp_s": 1516.0}, {"text": "or 200k files within like 30 minutes.", "timestamp": "00:25:20,600", "timestamp_s": 1520.0}, {"text": "Pods will then fetch the file information from these events.", "timestamp": "00:25:24,070", "timestamp_s": 1524.0}, {"text": "In the pub subtopic process, the files mask the content if required.", "timestamp": "00:25:28,018", "timestamp_s": 1528.0}, {"text": "We have very strict slas and scaling of the platform", "timestamp": "00:25:32,250", "timestamp_s": 1532.0}, {"text": "to meet those slas is a critical part of our architecture.", "timestamp": "00:25:35,804", "timestamp_s": 1535.0}, {"text": "We are using horizontal pod scaling and cluster auto scaling together to", "timestamp": "00:25:39,702", "timestamp_s": 1539.0}, {"text": "scale the platform.", "timestamp": "00:25:43,408", "timestamp_s": 1543.0}, {"text": "A bit more about auto scaling now. Auto scaling is a crucial", "timestamp": "00:25:47,150", "timestamp_s": 1547.0}, {"text": "part of our platform.", "timestamp": "00:25:50,666", "timestamp_s": 1550.0}, {"text": "We have to process these files as soon as they arrive so", "timestamp": "00:25:54,210", "timestamp_s": 1554.0}, {"text": "we can perform the settlement and billing operations and also pay our merchants", "timestamp": "00:25:59,268", "timestamp_s": 1559.0}, {"text": "and do the reconciliation of the money,", "timestamp": "00:26:03,530", "timestamp_s": 1563.0}, {"text": "which is very crucial to our business also.", "timestamp": "00:26:07,256", "timestamp_s": 1567.0}, {"text": "On the other hand, we also wanted to make sure that our infrastructure is cost", "timestamp": "00:26:11,896", "timestamp_s": 1571.0}, {"text": "effective and we are not running workloads when they are not", "timestamp": "00:26:15,032", "timestamp_s": 1575.0}, {"text": "needed to be aligned with bit more like a", "timestamp": "00:26:18,572", "timestamp_s": 1578.0}, {"text": "phenopsy culture. There are", "timestamp": "00:26:22,124", "timestamp_s": 1582.0}, {"text": "a few challenges we faced when we implemented horizontal port scaling,", "timestamp": "00:26:25,724", "timestamp_s": 1585.0}, {"text": "setting up resources like on the pods,", "timestamp": "00:26:28,998", "timestamp_s": 1588.0}, {"text": "that was a bit difficult", "timestamp": "00:26:32,294", "timestamp_s": 1592.0}, {"text": "to decide what should be the starting request and what should be", "timestamp": "00:26:38,670", "timestamp_s": 1598.0}, {"text": "the limit. I know there has been a lot of talks", "timestamp": "00:26:42,224", "timestamp_s": 1602.0}, {"text": "in kubernetes that we don\u0027t need to put limits and stuff like that, but in", "timestamp": "00:26:46,298", "timestamp_s": 1606.0}, {"text": "our case we had to do it because we are scaling so many pods and", "timestamp": "00:26:49,748", "timestamp_s": 1609.0}, {"text": "pods can consume like a lot of memory and resources. So we", "timestamp": "00:26:53,028", "timestamp_s": 1613.0}, {"text": "tried a lot of different options when we were", "timestamp": "00:26:56,296", "timestamp_s": 1616.0}, {"text": "trying this in production. We started hating pagerduty", "timestamp": "00:26:59,672", "timestamp_s": 1619.0}, {"text": "but eventually leveraging worked out for us and", "timestamp": "00:27:04,230", "timestamp_s": 1624.0}, {"text": "it\u0027s now scaling quite nicely. And there are two types of scaling", "timestamp": "00:27:11,850", "timestamp_s": 1631.0}, {"text": "available, right? High level two types. We have horizontal", "timestamp": "00:27:17,050", "timestamp_s": 1637.0}, {"text": "auto scaling which updates a workload with the aim of scaling", "timestamp": "00:27:20,834", "timestamp_s": 1640.0}, {"text": "the workload to match the demand. It actually means that the response", "timestamp": "00:27:24,598", "timestamp_s": 1644.0}, {"text": "to increase the load is deploy more pods and if", "timestamp": "00:27:28,118", "timestamp_s": 1648.0}, {"text": "the load decreases, scale back down the deployment. By removing the scaled", "timestamp": "00:27:31,408", "timestamp_s": 1651.0}, {"text": "pods. Then you have vertical auto scaling means assigning more", "timestamp": "00:27:35,178", "timestamp_s": 1655.0}, {"text": "resources, for example memory or cpu, to the pods that are already", "timestamp": "00:27:39,028", "timestamp_s": 1659.0}, {"text": "running in", "timestamp": "00:27:42,356", "timestamp_s": 1662.0}, {"text": "the deployment. You can trigger.", "timestamp": "00:27:46,168", "timestamp_s": 1666.0}, {"text": "There are multiple ways to trigger this auto scaling you can trigger based on resource", "timestamp": "00:27:50,286", "timestamp_s": 1670.0}, {"text": "usage. For example when a pods given memory or cpu exceeds", "timestamp": "00:27:54,142", "timestamp_s": 1674.0}, {"text": "a threshold, you can add more pods if you", "timestamp": "00:27:58,178", "timestamp_s": 1678.0}, {"text": "want to. Then metrics within Kubernetes", "timestamp": "00:28:01,308", "timestamp_s": 1681.0}, {"text": "any metrics reported by Kubernetes object with the cluster, such as I", "timestamp": "00:28:05,122", "timestamp_s": 1685.0}, {"text": "don\u0027t know, input output rate or", "timestamp": "00:28:08,688", "timestamp_s": 1688.0}, {"text": "things like that. Then also like metrics coming from external sources", "timestamp": "00:28:12,208", "timestamp_s": 1692.0}, {"text": "like pub sub. For example you can create an external metrics based", "timestamp": "00:28:16,086", "timestamp_s": 1696.0}, {"text": "on the size of the queue. Configure the horizontal pod scaler to", "timestamp": "00:28:20,352", "timestamp_s": 1700.0}, {"text": "automatically increase the number of pods when", "timestamp": "00:28:24,212", "timestamp_s": 1704.0}, {"text": "the queue size reaches a given threshold and to reduce the", "timestamp": "00:28:27,572", "timestamp_s": 1707.0}, {"text": "number of pods when the queue size shrinks. This is", "timestamp": "00:28:31,188", "timestamp_s": 1711.0}, {"text": "exactly what we did and this is exactly we", "timestamp": "00:28:34,648", "timestamp_s": 1714.0}, {"text": "did and used to scale our platform we", "timestamp": "00:28:38,232", "timestamp_s": 1718.0}, {"text": "are talking about so far. We talked about HPA and adding more number of", "timestamp": "00:28:42,488", "timestamp_s": 1722.0}, {"text": "pods to scale the deployment.", "timestamp": "00:28:46,890", "timestamp_s": 1726.0}, {"text": "But we also need to remember that Kubernetes cluster", "timestamp": "00:28:50,890", "timestamp_s": 1730.0}, {"text": "also need to increase its capacity. How do we", "timestamp": "00:28:54,002", "timestamp_s": 1734.0}, {"text": "do it? How do we fit all these scaling", "timestamp": "00:28:57,808", "timestamp_s": 1737.0}, {"text": "pods into kubernetes? For that we", "timestamp": "00:29:00,998", "timestamp_s": 1740.0}, {"text": "need to add more nodes and we use Kubernetes cluster", "timestamp": "00:29:05,088", "timestamp_s": 1745.0}, {"text": "autoscaler.", "timestamp": "00:29:09,190", "timestamp_s": 1749.0}, {"text": "Kubernetes cluster or autoscaler is a tool that automatically adjusts", "timestamp": "00:29:12,290", "timestamp_s": 1752.0}, {"text": "the size of kubernetes cluster by scaling up or down by adding or", "timestamp": "00:29:16,122", "timestamp_s": 1756.0}, {"text": "removing nodes. When one of the following condition is true,", "timestamp": "00:29:19,988", "timestamp_s": 1759.0}, {"text": "there are pods in the pending state in the cluster", "timestamp": "00:29:23,620", "timestamp_s": 1763.0}, {"text": "due to insufficient resources. And there are nodes in the cluster", "timestamp": "00:29:27,022", "timestamp_s": 1767.0}, {"text": "that have been underutilized for an extended period of time and", "timestamp": "00:29:30,366", "timestamp_s": 1770.0}, {"text": "their pods can be placed on other existing nodes.", "timestamp": "00:29:34,872", "timestamp_s": 1774.0}, {"text": "One very thing, very important thing to remember is that if your pods have", "timestamp": "00:29:39,770", "timestamp_s": 1779.0}, {"text": "requested too few resources when it first started,", "timestamp": "00:29:43,772", "timestamp_s": 1783.0}, {"text": "and after some point your", "timestamp": "00:29:48,270", "timestamp_s": 1788.0}, {"text": "pod wants more cpu or more memory, but your", "timestamp": "00:29:52,672", "timestamp_s": 1792.0}, {"text": "node in which your pod is actually running", "timestamp": "00:29:56,352", "timestamp_s": 1796.0}, {"text": "is experiencing resource shortages.", "timestamp": "00:29:59,824", "timestamp_s": 1799.0}, {"text": "In this case, cluster autoscaler won\u0027t do anything for you.", "timestamp": "00:30:02,930", "timestamp_s": 1802.0}, {"text": "We actually did not read the documentation properly", "timestamp": "00:30:06,596", "timestamp_s": 1806.0}, {"text": "and we believe the other way around and we lost good couple of days trying", "timestamp": "00:30:09,962", "timestamp_s": 1809.0}, {"text": "to figure it out why the processing is very slow.", "timestamp": "00:30:13,732", "timestamp_s": 1813.0}, {"text": "You\u0027ll have to go back and revisit the resources for the ports all the time.", "timestamp": "00:30:17,590", "timestamp_s": 1817.0}, {"text": "Now we know the HP and CA works together to scale the", "timestamp": "00:30:22,630", "timestamp_s": 1822.0}, {"text": "platform and", "timestamp": "00:30:26,108", "timestamp_s": 1826.0}, {"text": "it works hand in hand and our", "timestamp": "00:30:30,092", "timestamp_s": 1830.0}, {"text": "files processing can become very", "timestamp": "00:30:33,996", "timestamp_s": 1833.0}, {"text": "scalable all of a sudden because we adopted kubernetes", "timestamp": "00:30:38,112", "timestamp_s": 1838.0}, {"text": "and all these flavors of scalability with it.", "timestamp": "00:30:42,326", "timestamp_s": 1842.0}, {"text": "And this is how it actually looks like right now.", "timestamp": "00:30:49,870", "timestamp_s": 1849.0}, {"text": "If you can see, I\u0027m going to take you back again to the", "timestamp": "00:30:53,392", "timestamp_s": 1853.0}, {"text": "processing. You have object storage. All the files are landing and landing and", "timestamp": "00:30:56,868", "timestamp_s": 1856.0}, {"text": "then the queue is becoming, having those events of file creation,", "timestamp": "00:31:00,548", "timestamp_s": 1860.0}, {"text": "right, and the queue is becoming big and big and big. Now how", "timestamp": "00:31:04,026", "timestamp_s": 1864.0}, {"text": "do we scale it? We said unact messages meant.", "timestamp": "00:31:07,688", "timestamp_s": 1867.0}, {"text": "That means this is a pub sub terminology, but that means", "timestamp": "00:31:10,782", "timestamp_s": 1870.0}, {"text": "not processed events divided by four is equal to number", "timestamp": "00:31:15,370", "timestamp_s": 1875.0}, {"text": "of pods or number of workers required.", "timestamp": "00:31:19,052", "timestamp_s": 1879.0}, {"text": "But we still have a maximum", "timestamp": "00:31:24,810", "timestamp_s": 1884.0}, {"text": "limit as well. For example, if I have 500k files", "timestamp": "00:31:28,530", "timestamp_s": 1888.0}, {"text": "still needs to be process, I cannot be running, I don\u0027t know,", "timestamp": "00:31:32,406", "timestamp_s": 1892.0}, {"text": "125k pods. So we can", "timestamp": "00:31:36,990", "timestamp_s": 1896.0}, {"text": "still say okay, maximum 300 or maximum 400 pods can", "timestamp": "00:31:40,688", "timestamp_s": 1900.0}, {"text": "be running at a certain point in time on this particular cluster.", "timestamp": "00:31:44,548", "timestamp_s": 1904.0}, {"text": "And that actually works because the file processing is very fast. So within few", "timestamp": "00:31:48,138", "timestamp_s": 1908.0}, {"text": "seconds it process one file or within a second or", "timestamp": "00:31:52,452", "timestamp_s": 1912.0}, {"text": "so.", "timestamp": "00:31:56,008", "timestamp_s": 1916.0}, {"text": "And this is how the non PCI platform looks", "timestamp": "00:32:00,070", "timestamp_s": 1920.0}, {"text": "like. And sometimes this is the platform where all the", "timestamp": "00:32:04,632", "timestamp_s": 1924.0}, {"text": "validation, all the schema", "timestamp": "00:32:08,844", "timestamp_s": 1928.0}, {"text": "contracts, all the monitoring events and everything", "timestamp": "00:32:13,458", "timestamp_s": 1933.0}, {"text": "kind of is encapsulated into this", "timestamp": "00:32:17,132", "timestamp_s": 1937.0}, {"text": "group of microservices or collection of tools or infrastructure", "timestamp": "00:32:21,312", "timestamp_s": 1941.0}, {"text": "as you can say. So all the collector,", "timestamp": "00:32:25,622", "timestamp_s": 1945.0}, {"text": "it works exactly the same as PCI, just a bit more that it", "timestamp": "00:32:29,230", "timestamp_s": 1949.0}, {"text": "has some extra flavors of schema history and file", "timestamp": "00:32:33,252", "timestamp_s": 1953.0}, {"text": "stores and things like that. So all the connectors", "timestamp": "00:32:38,058", "timestamp_s": 1958.0}, {"text": "send files into the source bucket,", "timestamp": "00:32:41,482", "timestamp_s": 1961.0}, {"text": "which is non PCI bucket. Then file creation events generate", "timestamp": "00:32:44,310", "timestamp_s": 1964.0}, {"text": "that file creation event into the topic. Then HPA comes into", "timestamp": "00:32:48,950", "timestamp_s": 1968.0}, {"text": "the picture it scales the deployment of", "timestamp": "00:32:52,408", "timestamp_s": 1972.0}, {"text": "these translate parts. We call them translate because they\u0027re doing the translation based", "timestamp": "00:32:56,616", "timestamp_s": 1976.0}, {"text": "on the config provided. And then the CA cluster auto scaler", "timestamp": "00:33:00,492", "timestamp_s": 1980.0}, {"text": "kicks in to scale the cluster, and then the translate pods actually", "timestamp": "00:33:04,274", "timestamp_s": 1984.0}, {"text": "parse and translate every single file, every single source file", "timestamp": "00:33:08,332", "timestamp_s": 1988.0}, {"text": "into chunked, every files. Now translate process completely works", "timestamp": "00:33:11,494", "timestamp_s": 1991.0}, {"text": "based on what\u0027s inside the schema of", "timestamp": "00:33:15,136", "timestamp_s": 1995.0}, {"text": "the file. And this is where it becomes more like a self", "timestamp": "00:33:18,768", "timestamp_s": 1998.0}, {"text": "serve data platform. So every single pipeline", "timestamp": "00:33:22,416", "timestamp_s": 2002.0}, {"text": "belongs to a single domain. Payments have its", "timestamp": "00:33:27,690", "timestamp_s": 2007.0}, {"text": "own pipeline here, marketing have its own pipeline here.", "timestamp": "00:33:31,028", "timestamp_s": 2011.0}, {"text": "And every single schema history, if you see there is", "timestamp": "00:33:34,548", "timestamp_s": 2014.0}, {"text": "like one schema history at the end of the day and there is a UI", "timestamp": "00:33:40,216", "timestamp_s": 2020.0}, {"text": "on top of it from where users can log in,", "timestamp": "00:33:43,358", "timestamp_s": 2023.0}, {"text": "go and challenges the schema, they can say okay,", "timestamp": "00:33:46,824", "timestamp_s": 2026.0}, {"text": "now this file contains an extra column, and I want", "timestamp": "00:33:50,012", "timestamp_s": 2030.0}, {"text": "to process this extra column, but I don\u0027t want to go", "timestamp": "00:33:53,548", "timestamp_s": 2033.0}, {"text": "to the data team and raise a request and ask them to process this.", "timestamp": "00:33:56,764", "timestamp_s": 2036.0}, {"text": "I would like to do it by myself.", "timestamp": "00:34:01,950", "timestamp_s": 2041.0}, {"text": "And this is how it happens. So they go", "timestamp": "00:34:05,070", "timestamp_s": 2045.0}, {"text": "to this web interface and there\u0027s schema version,", "timestamp": "00:34:08,784", "timestamp_s": 2048.0}, {"text": "schema name, source, blah blah blah, lot of information there.", "timestamp": "00:34:12,426", "timestamp_s": 2052.0}, {"text": "We are actually trying to make it a bit more nicer now.", "timestamp": "00:34:16,660", "timestamp_s": 2056.0}, {"text": "We are actually taking away all the configuration out.", "timestamp": "00:34:20,770", "timestamp_s": 2060.0}, {"text": "Now we have Argo CD workloads and things like that.", "timestamp": "00:34:23,828", "timestamp_s": 2063.0}, {"text": "So we\u0027re taking that all out and we\u0027re just leaving the schema bit there.", "timestamp": "00:34:27,032", "timestamp_s": 2067.0}, {"text": "But the gist here is like the users can", "timestamp": "00:34:30,584", "timestamp_s": 2070.0}, {"text": "actually, or the domain owners or domain, those teams", "timestamp": "00:34:34,632", "timestamp_s": 2074.0}, {"text": "can actually manage their own pipelines by themselves. We provide", "timestamp": "00:34:38,178", "timestamp_s": 2078.0}, {"text": "the data catalog by using data hub, they can discover", "timestamp": "00:34:44,410", "timestamp_s": 2084.0}, {"text": "everything, what they need to do. That is also an ongoing", "timestamp": "00:34:48,066", "timestamp_s": 2088.0}, {"text": "project at the moment, but it\u0027s very interesting. Maybe someday we\u0027ll talk about this more", "timestamp": "00:34:51,558", "timestamp_s": 2091.0}, {"text": "then we provide monitoring on top of it. The schema registry", "timestamp": "00:34:55,232", "timestamp_s": 2095.0}, {"text": "also have a component where you can say, you know what,", "timestamp": "00:34:59,334", "timestamp_s": 2099.0}, {"text": "I want to know when my file arrives and", "timestamp": "00:35:03,076", "timestamp_s": 2103.0}, {"text": "when my file lands into the bigquery or my data warehouse.", "timestamp": "00:35:06,708", "timestamp_s": 2106.0}, {"text": "And if that doesn\u0027t happen by 09:00 in the morning, I want to", "timestamp": "00:35:10,426", "timestamp_s": 2110.0}, {"text": "get alerted because my processes are going to fail and", "timestamp": "00:35:13,944", "timestamp_s": 2113.0}, {"text": "I need to notify downstream stakeholders.", "timestamp": "00:35:17,656", "timestamp_s": 2117.0}, {"text": "Any other reason? So that\u0027s how", "timestamp": "00:35:20,654", "timestamp_s": 2120.0}, {"text": "the schema registry plays a very key role. And at the end of the day", "timestamp": "00:35:24,328", "timestamp_s": 2124.0}, {"text": "it\u0027s a data contract between the source and the processing and", "timestamp": "00:35:27,564", "timestamp_s": 2127.0}, {"text": "the target. When we", "timestamp": "00:35:31,228", "timestamp_s": 2131.0}, {"text": "process files from PCI to non PCI environment with the", "timestamp": "00:35:35,212", "timestamp_s": 2135.0}, {"text": "help of schema SD, the files moves from many different stages throughout", "timestamp": "00:35:38,384", "timestamp_s": 2138.0}, {"text": "the whole processing journey and the state management", "timestamp": "00:35:42,902", "timestamp_s": 2142.0}, {"text": "of the file becomes very important because you", "timestamp": "00:35:46,422", "timestamp_s": 2146.0}, {"text": "want the file processing to be fault tolerant. You want to", "timestamp": "00:35:50,496", "timestamp_s": 2150.0}, {"text": "handle errors when the error happens.", "timestamp": "00:35:53,684", "timestamp_s": 2153.0}, {"text": "You also want to support kind of live monitoring. You also want to", "timestamp": "00:35:58,290", "timestamp_s": 2158.0}, {"text": "prevent duplicate processing, because queues can", "timestamp": "00:36:01,828", "timestamp_s": 2161.0}, {"text": "have duplicate events. And you", "timestamp": "00:36:05,352", "timestamp_s": 2165.0}, {"text": "want to make sure that once the file is processed, is processed.", "timestamp": "00:36:10,136", "timestamp_s": 2170.0}, {"text": "Now let\u0027s see how the flow works. So object file is created,", "timestamp": "00:36:14,150", "timestamp_s": 2174.0}, {"text": "it goes into the file event, subscription topic, for example.", "timestamp": "00:36:18,250", "timestamp_s": 2178.0}, {"text": "So then it\u0027s kind of in a to do state. And after that", "timestamp": "00:36:22,252", "timestamp_s": 2182.0}, {"text": "the HPA is listening to that topic,", "timestamp": "00:36:25,820", "timestamp_s": 2185.0}, {"text": "and then it say, okay, let\u0027s scale everything and", "timestamp": "00:36:30,006", "timestamp_s": 2190.0}, {"text": "all the pod starts consuming from this topic, and they consume", "timestamp": "00:36:34,480", "timestamp_s": 2194.0}, {"text": "from this topic. They goes first to the store,", "timestamp": "00:36:38,278", "timestamp_s": 2198.0}, {"text": "file store, or you can call it a data store, a state store,", "timestamp": "00:36:41,760", "timestamp_s": 2201.0}, {"text": "to check whether the file is already being processed by some other pod or not.", "timestamp": "00:36:45,684", "timestamp_s": 2205.0}, {"text": "If that\u0027s the case, then they skip it. If not,", "timestamp": "00:36:49,284", "timestamp_s": 2209.0}, {"text": "then they put that status into in progress, and then they start processing it.", "timestamp": "00:36:53,428", "timestamp_s": 2213.0}, {"text": "And if everything is succeeded, they said, okay, translate is", "timestamp": "00:36:57,128", "timestamp_s": 2217.0}, {"text": "completed, or translate was started before translate completed without any", "timestamp": "00:37:01,016", "timestamp_s": 2221.0}, {"text": "error, everybody\u0027s happy. And if", "timestamp": "00:37:04,632", "timestamp_s": 2224.0}, {"text": "that doesn\u0027t happen, if there\u0027s an error, then they say, okay, there was an error.", "timestamp": "00:37:07,928", "timestamp_s": 2227.0}, {"text": "And for some transient errors, we can actually resend", "timestamp": "00:37:11,906", "timestamp_s": 2231.0}, {"text": "the files to be processed again. So they put the status", "timestamp": "00:37:15,218", "timestamp_s": 2235.0}, {"text": "of the file to to do again so that some other pod can pick it", "timestamp": "00:37:18,818", "timestamp_s": 2238.0}, {"text": "up.", "timestamp": "00:37:21,488", "timestamp_s": 2241.0}, {"text": "This is also very useful for monitoring.", "timestamp": "00:37:24,830", "timestamp_s": 2244.0}, {"text": "So all these events are being sent into metricstore.", "timestamp": "00:37:28,870", "timestamp_s": 2248.0}, {"text": "And then we have a file monitoring service which actually talk", "timestamp": "00:37:32,278", "timestamp_s": 2252.0}, {"text": "to the schema registrar, and based on the config provided in those", "timestamp": "00:37:36,068", "timestamp_s": 2256.0}, {"text": "schemas or feeds, what we call it,", "timestamp": "00:37:39,972", "timestamp_s": 2259.0}, {"text": "actually aggregate this information and start generating", "timestamp": "00:37:43,960", "timestamp_s": 2263.0}, {"text": "metrics, report or alerts, or send", "timestamp": "00:37:48,950", "timestamp_s": 2268.0}, {"text": "more aggregated information to Grafana and", "timestamp": "00:37:52,952", "timestamp_s": 2272.0}, {"text": "for infrastructure observability. So most,", "timestamp": "00:37:58,876", "timestamp_s": 2278.0}, {"text": "as I said before, everything what we do and", "timestamp": "00:38:02,090", "timestamp_s": 2282.0}, {"text": "everything what we run mostly is on kubernetes. So we", "timestamp": "00:38:06,028", "timestamp_s": 2286.0}, {"text": "are running Prometheus integrations at the moment, getting all the important metrics, such as", "timestamp": "00:38:09,968", "timestamp_s": 2289.0}, {"text": "resource usage pods, health nodes, health pub sub", "timestamp": "00:38:14,048", "timestamp_s": 2294.0}, {"text": "queue metrics, et cetera, whatever,", "timestamp": "00:38:17,392", "timestamp_s": 2297.0}, {"text": "literally to Grafana. And then we have live dashboards running,", "timestamp": "00:38:21,150", "timestamp_s": 2301.0}, {"text": "which actually reflects the status of the platform.", "timestamp": "00:38:25,090", "timestamp_s": 2305.0}, {"text": "And the users can actually go and see their own feeds,", "timestamp": "00:38:28,050", "timestamp_s": 2308.0}, {"text": "their own pipelines, and see if anything", "timestamp": "00:38:31,354", "timestamp_s": 2311.0}, {"text": "is down or not. And they also get alerted. We also get alerted", "timestamp": "00:38:34,996", "timestamp_s": 2314.0}, {"text": "because the centralized team own the infrastructure, so they actually come as", "timestamp": "00:38:39,518", "timestamp_s": 2319.0}, {"text": "a second line support to fix if the issues are happening there.", "timestamp": "00:38:43,128", "timestamp_s": 2323.0}, {"text": "I\u0027m not going to touch much into the analytics platform,", "timestamp": "00:38:48,410", "timestamp_s": 2328.0}, {"text": "but analytics platform is made basically", "timestamp": "00:38:51,740", "timestamp_s": 2331.0}, {"text": "to analyze all the raw data", "timestamp": "00:38:55,900", "timestamp_s": 2335.0}, {"text": "which is coming into bigquery and then run some DBT", "timestamp": "00:38:59,504", "timestamp_s": 2339.0}, {"text": "models and then create those drive tables and", "timestamp": "00:39:03,238", "timestamp_s": 2343.0}, {"text": "then the insights out of it.", "timestamp": "00:39:06,832", "timestamp_s": 2346.0}, {"text": "Leveraging is based on Kubernetes and then this can be", "timestamp": "00:39:10,910", "timestamp_s": 2350.0}, {"text": "also not. This can be. This is really this whole deployment", "timestamp": "00:39:14,292", "timestamp_s": 2354.0}, {"text": "of analytics platform is owned by every single domain. So payments", "timestamp": "00:39:18,202", "timestamp_s": 2358.0}, {"text": "have its own, marketing have its own, customer has its", "timestamp": "00:39:21,754", "timestamp_s": 2361.0}, {"text": "own, everybody have their own kind", "timestamp": "00:39:25,048", "timestamp_s": 2365.0}, {"text": "of analytics platform. This is my", "timestamp": "00:39:30,408", "timestamp_s": 2370.0}, {"text": "kind of like a showcase end to end file monitoring.", "timestamp": "00:39:33,800", "timestamp_s": 2373.0}, {"text": "And this is actually the slack message. Look like if you see that stage", "timestamp": "00:39:38,334", "timestamp_s": 2378.0}, {"text": "one, stage two, stage three, stage four, stage five and see the stage", "timestamp": "00:39:41,602", "timestamp_s": 2381.0}, {"text": "four is failing and the user can just click on it which file", "timestamp": "00:39:45,362", "timestamp_s": 2385.0}, {"text": "is failing and then from there we have playbooks and then", "timestamp": "00:39:49,334", "timestamp_s": 2389.0}, {"text": "we have ways to identify the errors", "timestamp": "00:39:53,072", "timestamp_s": 2393.0}, {"text": "and ways to fix them as well. This is how the", "timestamp": "00:39:56,598", "timestamp_s": 2396.0}, {"text": "overall ecosystem of data platform looks like. I just talked", "timestamp": "00:40:00,768", "timestamp_s": 2400.0}, {"text": "about today the PCI platform and data file processing platform and only", "timestamp": "00:40:04,756", "timestamp_s": 2404.0}, {"text": "touched the analytics platform, but we have done a", "timestamp": "00:40:08,356", "timestamp_s": 2408.0}, {"text": "lot of work in streaming side, we have done a lot of work in discovery,", "timestamp": "00:40:13,368", "timestamp_s": 2413.0}, {"text": "observability, quality, governance,", "timestamp": "00:40:16,910", "timestamp_s": 2416.0}, {"text": "developer experience and we are still doing a lot", "timestamp": "00:40:20,310", "timestamp_s": 2420.0}, {"text": "more. And we still have to go a long way to", "timestamp": "00:40:23,832", "timestamp_s": 2423.0}, {"text": "completely embrace this self serve data platform or data mesh.", "timestamp": "00:40:27,356", "timestamp_s": 2427.0}, {"text": "And if anybody is interested please join.", "timestamp": "00:40:32,410", "timestamp_s": 2432.0}, {"text": "Go to this dojo career page, not just data team. We are hiding across", "timestamp": "00:40:36,194", "timestamp_s": 2436.0}, {"text": "I guess all the functions. And of course thank you for your", "timestamp": "00:40:42,090", "timestamp_s": 2442.0}, {"text": "time. And if you want to dm me directly", "timestamp": "00:40:45,212", "timestamp_s": 2445.0}, {"text": "or connect me on LinkedIn, this is my, this is my profile.", "timestamp": "00:40:48,658", "timestamp_s": 2448.0}, {"text": "Thank you so much, have a good day.", "timestamp": "00:40:52,042", "timestamp_s": 2452.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: 'wjcWbRczujw',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              Building a business-critical data platform to process over £34bn in card transactions
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>This talk is about building Highly Scalable Self Serve Data Platform to support Data Mesh Revolution by leveraging CNCF technologies. Will share the challenges and mistakes we faced while building the platform which ingrates with every single data point( event stream, API, SFTPs, Files etc).</p>
<!-- End Text -->
          </div>

          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
              <li>
                Dojo is the fastest growing fintech in Europe by net revenue. We power face to face payments for around 15% of card transaction in the UK every day. We are highly, highly data driven and value the insights in our decision making. This talk will be around file processing.

              </li>
              
              <li>
                There were three generation of data processing. Current generation is mostly centralized data platforms. Domains can be independent and create new data sources by themselves. This approach brings a set of benefits.

              </li>
              
              <li>
                Adhering to PCI standard is one of our prime concerns given we own the end to end payment stack. Most of our workloads and most of our processing power runs on GKE. We have very strict slas and scaling of the platform to meet those slas is a critical part of our architecture.

              </li>
              
              <li>
                A bit more about auto scaling. Auto scaling is a crucial part of our platform. There are two types of scaling available, right? High level two types. Vertical auto scaling means assigning more resources to the pods that are already running. Multiple ways to trigger this auto scaling you can trigger based on resource usage.

              </li>
              
              <li>
                We use Kubernetes cluster autoscaler to scale the size of kubernetes. It works by automatically scaling up or down by adding or removing nodes. Files processing can become very scalable all of a sudden. This is where it becomes more like a self serve data platform.
              </li>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/assemblyai/wjcWbRczujw.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:25,410'); seek(25.0)">
              You. Hi everyone,
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:28,730'); seek(28.0)">
              thanks for joining. We'll be talking
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:33,210'); seek(33.0)">
              on building a data platform
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:36,668'); seek(36.0)">
              to process over 50 billion in card transactions.
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:41,106'); seek(41.0)">
              I'm Sandeep, I'm engineering lead data platforms. I'm from Dojo.
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:45,570'); seek(45.0)">
              If you don't know about us,
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:48,970'); seek(48.0)">
              we are the fastest growing fintech in Europe by net revenue.
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:52,266'); seek(52.0)">
              We power face to face payments for around 15% of
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:56,212'); seek(56.0)">
              card transaction in the UK every day. We are mainly focused on
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:01:00,100'); seek(60.0)">
              experience economy of bars, pubs,
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:01:03,578'); seek(63.0)">
              restaurants, even your local corner shop or farmers market. We also
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:01:07,608'); seek(67.0)">
              have a consumer facing app that allows you to join the queue for
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:01:10,888'); seek(70.0)">
              a high street restaurants for up to around 2 miles
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:01:14,718'); seek(74.0)">
              radius. We have an amazing line
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:01:18,732'); seek(78.0)">
              of payment products. We have tap to pay pocket pay.
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:01:21,836'); seek(81.0)">
              We also, sorry, provide the small
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:01:25,356'); seek(85.0)">
              business funding. And we are also building many, many products
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:29,488'); seek(89.0)">
              to change how the payment industry works.
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:33,470'); seek(93.0)">
              We are going international soon. Hopefully you will see us in
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:37,488'); seek(97.0)">
              every corner of Europe first and then in the world.
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:41,220'); seek(101.0)">
              What makes us different,
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:44,836'); seek(104.0)">
              I guess, and also makes all of this possible is the fact
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:48,116'); seek(108.0)">
              that we are highly, highly data driven and value the insights
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:52,138'); seek(112.0)">
              in our decision making. When you go
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:55,864'); seek(115.0)">
              to a shop and when you tap your card and within a blink
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:59,678'); seek(119.0)">
              of a second your transaction happens there and
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:02:03,096'); seek(123.0)">
              you get the goods and the customer, the merchant,
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:02:07,102'); seek(127.0)">
              basically for us it's the customer, but the merchant who is selling you the
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:02:10,588'); seek(130.0)">
              goods or selling you the services get the money.
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:02:14,330'); seek(134.0)">
              All of this happens within a blink of a second.
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:02:17,676'); seek(137.0)">
              As we just talked about, when you tap a card,
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:02:21,084'); seek(141.0)">
              the first thing happens is the card machine takes the details from the card
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:24,640'); seek(144.0)">
              and securely sends these to the authorization gateway. At Dojo,
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:28,534'); seek(148.0)">
              we use point to point encryption between the card machine and our authorization
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:32,250'); seek(152.0)">
              gateway with hardware security modules in multiple facilities
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:36,730'); seek(156.0)">
              with direct pairing to multiple cloud providers.
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:39,658'); seek(159.0)">
              It's highly, highly secure and highly, highly scalable. We can't let
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:43,496'); seek(163.0)">
              our authorization gateway down because that's the main point
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:47,800'); seek(167.0)">
              from where we take the transactions. The authorization
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:51,406'); seek(171.0)">
              gateway then contacts the card network such as Visa,
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:54,734'); seek(174.0)">
              Mastercard, Amex, and then forwards this request to
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:02:58,348'); seek(178.0)">
              the issuing bank for approval. This will be
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:03:02,092'); seek(182.0)">
              someone like your bank in UK Barclays card,
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:03:05,116'); seek(185.0)">
              Monzo, Tesco, who will then freeze the funds on the customer's account
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:03:09,344'); seek(189.0)">
              in support. It's very important to note that the
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:03:13,792'); seek(193.0)">
              money, the actual money has
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:03:17,952'); seek(197.0)">
              not exchanged yet, and it is just a promise
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:21,782'); seek(201.0)">
              for a payment that can be reversed as well.
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:25,010'); seek(205.0)">
              The card network then sends this approval back to the authorization gateway,
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:28,842'); seek(208.0)">
              which is then displayed to the customer as approved or declined.
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:32,378'); seek(212.0)">
              And this is how your card transactions actually
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:36,200'); seek(216.0)">
              works. And this whole process generates a
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:40,008'); seek(220.0)">
              lot of data from a payment point of view,
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:43,750'); seek(223.0)">
              because we are a payment company. So we
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:48,012'); seek(228.0)">
              have a couple of regulatory challenges where we
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:53,532'); seek(233.0)">
              own the end to end payments experience. So we operate under e money license
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:57,954'); seek(237.0)">
              from the FCA, which is a financial conduct authority.
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:04:01,670'); seek(241.0)">
              With this comes strict regulatory requirements,
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:04:05,030'); seek(245.0)">
              most notably the fact that we have to ensure the whole time
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:04:08,592'); seek(248.0)">
              that customer funds are safeguarded in case the business becomes irrelevant
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:04:13,050'); seek(253.0)">
              or insolvent.
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:04:16,210'); seek(256.0)">
              Then you have PCI DSS level one
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:04:21,570'); seek(261.0)">
              compliance, which is around safeguarding or not
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:25,352'); seek(265.0)">
              safeguarding, storing of full card numbers. So owning
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:29,278'); seek(269.0)">
              the whole payment stacks with full card numbers. We also have to comply
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:32,398'); seek(272.0)">
              with PCI DSS level one. And we also are
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:35,916'); seek(275.0)">
              independently audited every year to ensure that we
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:39,308'); seek(279.0)">
              actually follow all the files and guidelines provided
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:43,234'); seek(283.0)">
              by PCI. Then we have other complexities
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:47,906'); seek(287.0)">
              around schemas. So we process,
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:51,552'); seek(291.0)">
              I guess more than 1000 plus data contracts or
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:54,768'); seek(294.0)">
              schemas. And this talk, sorry, I completely
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:04:58,336'); seek(298.0)">
              forgot to mention this talk will be around file
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:05:01,738'); seek(301.0)">
              processing. So I'm going to just talk about how we
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:05:05,012'); seek(305.0)">
              built the processing of these
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:05:08,596'); seek(308.0)">
              files coming from different, different sources and all these
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:05:12,132'); seek(312.0)">
              schemes, Visa, Mastercard, and all the payment
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:05:15,752'); seek(315.0)">
              boxes. We have so
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:19,830'); seek(319.0)">
              1000 schemas, as I said. And then you have multiple file sizes
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:23,598'); seek(323.0)">
              and multiple formats. So it's just not
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:27,112'); seek(327.0)">
              like you have standard file size. Okay, we're going to have a file
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:30,978'); seek(330.0)">
              size range from five mb to ten mb. It doesn't work like that.
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:34,508'); seek(334.0)">
              We have files which are two kb, ten kb,
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:37,698'); seek(337.0)">
              50 kb, I don't know. And then it goes up to gigabytes,
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:41,790'); seek(341.0)">
              and then we also get like zipped files as well. Then you
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:45,840'); seek(345.0)">
              have a scalability, you can have unpredictable demand.
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:50,030'); seek(350.0)">
              Sometimes we have, I don't know, 500,000 of
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:05:53,428'); seek(353.0)">
              files coming right now because of
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:05:57,268'); seek(357.0)">
              slas between multiple sources, they overlap and all of
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:06:00,644'); seek(360.0)">
              the file comes at the same time. And then all of
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:06:03,860'); seek(363.0)">
              those files sometimes are business critical. So we have to process all of them at
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:06:07,208'); seek(367.0)">
              the same time. So for example,
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:06:10,760'); seek(370.0)">
              if you see this is a snapshot
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:14,334'); seek(374.0)">
              of internal reconciliation process performed by our
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:17,756'); seek(377.0)">
              payments analytical engineering team, just to ensure
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:21,490'); seek(381.0)">
              that a merchant's net settlement tallies with card transactions that
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:24,972'); seek(384.0)">
              have been actually authorized on the tills in their shops.
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:28,990'); seek(388.0)">
              As you can see, there's like CSVs XLS XML
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:33,550'); seek(393.0)">
              that many files required to get just that done.
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:38,750'); seek(398.0)">
              And also another bit like all
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:44,708'); seek(404.0)">
              the files coming in doesn't just have XLS or XML,
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:06:48,618'); seek(408.0)">
              they have all the files formats possible.
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:06:52,950'); seek(412.0)">
              We have JSON files, we even have Avro
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:06:56,318'); seek(416.0)">
              files. Now we have parquet files
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:06:59,998'); seek(419.0)">
              as well. We have fix
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:07:03,512'); seek(423.0)">
              with files. We have done this proprietary formats
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:07:07,330'); seek(427.0)">
              created by this scheme,
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:07:10,994'); seek(430.0)">
              companies like Visa, Mastercard. For that you had to write
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:07:14,988'); seek(434.0)">
              very heavy custom parsers to actually make sense out of
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:07:18,540'); seek(438.0)">
              those files and put them into your transactional kind
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:22,272'); seek(442.0)">
              of data warehouse.
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:25,710'); seek(445.0)">
              And the goal
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:30,038'); seek(450.0)">
              which we came up, or the goal
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:34,362'); seek(454.0)">
              which we thought would be good for us to actually take
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:38,532'); seek(458.0)">
              all of these file formats, process them into
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:42,068'); seek(462.0)">
              a final single format which can be then later utilized
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:07:45,902'); seek(465.0)">
              by processes downstreams to stream that into
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:07:49,400'); seek(469.0)">
              warehouse, or stream that into Kafka, or stream that into snowflake,
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:07:54,862'); seek(474.0)">
              or stream that into anywhere else, wherever we want.
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:07:57,612'); seek(477.0)">
              And we chose Avro because of most of the powers
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:08:01,074'); seek(481.0)">
              around scheme evolution and mainly
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:08:06,210'); seek(486.0)">
              that I guess. But there now there are multiple different formats
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:08:09,682'); seek(489.0)">
              which you can choose. But we chose Avro at that point.
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:08:14,430'); seek(494.0)">
              And it's not just payments. There are a lot of other business areas in the
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:08:17,808'); seek(497.0)">
              company which are important. They produce a lot of events data and
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:08:21,952'); seek(501.0)">
              also generate a lot of files data. And that
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:25,508'); seek(505.0)">
              can be coming from APIs or that can be coming from external tools or
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:29,572'); seek(509.0)">
              that can be generated by their own microservices.
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:33,330'); seek(513.0)">
              So to support the processing of files with all the schema evolution,
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:36,910'); seek(516.0)">
              with the scale and with all these challenges in mind, it was very
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:40,712'); seek(520.0)">
              important for us to design a data platform which is scalable
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:08:44,302'); seek(524.0)">
              and self serve. And now before deep diving into
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:08:48,490'); seek(528.0)">
              the modern data infracessing and how
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:08:51,916'); seek(531.0)">
              we have done it, I would like to take us back into the
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:08:55,308'); seek(535.0)">
              history of data processing.
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:08:58,430'); seek(538.0)">
              There were three generation of data processing.
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:09:01,926'); seek(541.0)">
              First generation was the generation of enterprise data warehouse
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:09:05,398'); seek(545.0)">
              solutions. Big giants like Oracle, IBM, Microsoft were
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:09:09,616'); seek(549.0)">
              building those big big warehouse which only few people
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:09:14,068'); seek(554.0)">
              know how to use. Then came the era
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:09:17,578'); seek(557.0)">
              of big data ecosystem, the era of Hadoop, the era
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:09:20,874'); seek(560.0)">
              of pig hide spark came into the picture.
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:09:24,510'); seek(564.0)">
              We built those monolith big, big centralized,
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:27,726'); seek(567.0)">
              beefy hadoops, big data platforms which was again
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:32,790'); seek(572.0)">
              only utilized or monitored or operated by
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:09:36,572'); seek(576.0)">
              few people. And huge bottleneck and huge
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:09:40,348'); seek(580.0)">
              number of skill shortage to actually make the
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:09:44,476'); seek(584.0)">
              huge, to make the use of it, I would say.
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:09:48,236'); seek(588.0)">
              Then we talk about current generation, mostly centralized data
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:09:52,176'); seek(592.0)">
              platforms. Mix of batch and real time processing based on tools like
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:09:56,656'); seek(596.0)">
              Kafka, Apache Beam also gives you the flavor of
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:10:01,730'); seek(601.0)">
              the mix. Real time and batch processing, then pubsub,
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:10:05,466'); seek(605.0)">
              then red panda, then all sort of cloud
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:10:09,412'); seek(609.0)">
              managed services like AWS, GCP, other cloud
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:10:12,996'); seek(612.0)">
              providers like confluent, Avon, they are giving
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:10:16,388'); seek(616.0)">
              their own managed services on top. Well, this centralized model
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:10:20,056'); seek(620.0)">
              can work for organization that have a simpler domain with
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:10:23,288'); seek(623.0)">
              a smaller number of diverse conception cases. It files for us
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:10:27,468'); seek(627.0)">
              because we have rich domains, a large number of sources,
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:10:31,858'); seek(631.0)">
              a large number of consumers,
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:10:37,930'); seek(637.0)">
              and most of the companies who are going
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:10:41,312'); seek(641.0)">
              through such a growth, they also have this problem and
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:10:44,528'); seek(644.0)">
              this centralized data platform really doesn't work. And there are other challenges
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:10:48,566'); seek(648.0)">
              with it. The challenge that the centralized data platform
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:10:52,564'); seek(652.0)">
              is mainly owned by a centralized data team which
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:10:57,410'); seek(657.0)">
              is focused on building, maintaining data
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:11:01,092'); seek(661.0)">
              processing pipelines, then building data contracts working hand in
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:11:04,904'); seek(664.0)">
              hand with stakeholders. But at the end of the day, there's no clear ownership on
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:11:08,488'); seek(668.0)">
              that. Then issues support for
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:11:12,872'); seek(672.0)">
              all the domains without actually having the domain
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:11:16,418'); seek(676.0)">
              knowledge. Then you have silos, then specialized data team
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:11:21,450'); seek(681.0)">
              which will keep on adding features if they get some time away from
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:11:26,010'); seek(686.0)">
              the support issues or everyday change requests.
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:11:30,030'); seek(690.0)">
              Then another issue is data
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:11:33,376'); seek(693.0)">
              quality, accountability, democratization of data.
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:11:37,232'); seek(697.0)">
              It's very difficult to enhance or put measures for data quality
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:11:40,756'); seek(700.0)">
              if there is no clear ownership on the data. The fact that
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:11:44,612'); seek(704.0)">
              data team manages data access, it makes it a bottleneck when
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:11:48,468'); seek(708.0)">
              it comes to access request. Then scalability,
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:11:53,370'); seek(713.0)">
              adding new data sources, increased data volumes, data contract changes,
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:11:57,320'); seek(717.0)">
              et cetera, can be delayed due to a huge data team backlog
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:12:01,278'); seek(721.0)">
              because they are the one who are actually
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:12:05,080'); seek(725.0)">
              managing and maintaining the data pipelines. And the byproduct of
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:12:09,068'); seek(729.0)">
              this also is not such a great relationship between
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:12:13,596'); seek(733.0)">
              data team and the other teams, and also a lot of blame game when this
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:12:16,828'); seek(736.0)">
              goes wrong. And over the last decade or
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:12:20,128'); seek(740.0)">
              so, we have successfully applied the domain driven design into
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:12:23,392'); seek(743.0)">
              our engineering or operational side.
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:12:27,150'); seek(747.0)">
              But as a whole data community, we completely, or as a whole engineering
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:12:31,238'); seek(751.0)">
              community, we completely forgot to put that into the data side.
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:12:34,852'); seek(754.0)">
              Now, what should we do in this kind of scenario?
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:12:38,266'); seek(758.0)">
              Right? How should we go on? And what is the right way of building
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:12:42,468'); seek(762.0)">
              that file processing platform which we built at dojo, or any
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:12:47,112'); seek(767.0)">
              kind of data platform which you might want to build it or anybody
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:12:51,080'); seek(771.0)">
              wants to build it. Now imagine this,
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:12:54,392'); seek(774.0)">
              right? What if the centralized data team will
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:12:57,996'); seek(777.0)">
              only focus on creating a generic data infrastructure, building self
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:13:01,772'); seek(781.0)">
              served data platforms by abstracting away all the technical complexities
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:13:06,194'); seek(786.0)">
              and enabling other teams to easily process their own data.
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:13:10,032'); seek(790.0)">
              Apart from that, they will also provide a global governance model and
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:13:14,032'); seek(794.0)">
              policies to have better access management, better naming conventions,
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:13:17,910'); seek(797.0)">
              better cis, better security policies,
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:13:20,930'); seek(800.0)">
              and at the same time, domain ownership moves,
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:13:24,450'); seek(804.0)">
              sorry, data ownership moves from centralized team
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:13:28,132'); seek(808.0)">
              to the domains. I have said domains many times in this
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:13:31,268'); seek(811.0)">
              chat so far, but by domains I mean teams that are working
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:13:34,936'); seek(814.0)">
              on a certain business area, for example, payment, marketing,
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:13:38,222'); seek(818.0)">
              customer, et cetera, et cetera.
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:13:42,070'); seek(822.0)">
              Now, this whole approach brings a set of benefits.
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:13:45,336'); seek(825.0)">
              Finally, the data is owned by people who understand
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:13:48,764'); seek(828.0)">
              it better company wise. You reach a better
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:13:52,236'); seek(832.0)">
              scalability by distributing data processing across the domains.
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:13:56,402'); seek(836.0)">
              Domains are now independent and they are able to add new data sources,
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:14:00,278'); seek(840.0)">
              create new data pipelines, fix the issues by themselves.
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:14:03,550'); seek(843.0)">
              Domains can put better data quality and reliability measures than
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:14:06,832'); seek(846.0)">
              the centralized data team because they understand it better.
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:14:10,510'); seek(850.0)">
              Domains have the flexibility of using only what they need from
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:14:14,516'); seek(854.0)">
              the generic data infrastructure and self serve data platform features,
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:14:18,490'); seek(858.0)">
              which reduces the complexity blast radius if things goes
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:14:22,020'); seek(862.0)">
              bad and things always goes bad. And having
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:14:25,960'); seek(865.0)">
              said that, the centralized data team should
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:14:29,976'); seek(869.0)">
              make sure that there is a good monitoring
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:14:33,902'); seek(873.0)">
              alerting in place to monitor all
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:14:37,212'); seek(877.0)">
              the flavors or features of data platform across
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:14:41,196'); seek(881.0)">
              the domains. Now this approach will also
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:14:44,476'); seek(884.0)">
              enforce well documented data contracts data API,
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:14:48,610'); seek(888.0)">
              which will allow data to flow seamlessly between one system and the another
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:14:52,016'); seek(892.0)">
              system. It can be internal or external as well.
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:14:55,440'); seek(895.0)">
              And having domains owning their data infrastructure brings more visibility on
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:14:59,488'); seek(899.0)">
              resource allocation and utilization, which could
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:15:03,268'); seek(903.0)">
              lead into cost efficiency.
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:15:06,850'); seek(906.0)">
              Now this whole concept is, my friend is data mesh.
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:15:11,730'); seek(911.0)">
              Now data Mesh is, I know I'm talking
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:15:15,316'); seek(915.0)">
              a lot of theory right now, but I will come back how
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:15:18,472'); seek(918.0)">
              we build that dojo. But this is very important. So data mesh
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:15:22,142'); seek(922.0)">
              is like domain ownership. It's one of the best,
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:15:25,192'); seek(925.0)">
              or sorry, not one of the best. It's one of the important pillar.
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:15:30,090'); seek(930.0)">
              It's your data, you own it,
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:15:33,548'); seek(933.0)">
              you manage it, and if there is a problem with it, you fix it.
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:15:39,210'); seek(939.0)">
              Data as a product, data is not a byproduct.
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:15:42,806'); seek(942.0)">
              Treat your data as a product, whether it's
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:15:45,894'); seek(945.0)">
              a file, whether it's an event, whether it's a warehouse, or whether
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:15:49,408'); seek(949.0)">
              it's a beefy table, all of that treat it as a product.
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:15:53,650'); seek(953.0)">
              Federated computational governance each domain can set
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:15:57,012'); seek(957.0)">
              their own policies or rules over data. For example,
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:16:00,580'); seek(960.0)">
              payment domain sftps encryption standards on payment data or marketing
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:16:04,718'); seek(964.0)">
              domain sftps retention on the customer data to 28 days to
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:16:08,424'); seek(968.0)">
              adhere to GDPR standards. Then the
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:16:12,008'); seek(972.0)">
              final and my favorite bit is self serve data platform.
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:16:15,320'); seek(975.0)">
              This is the key in all of this. If you successfully build
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:16:19,676'); seek(979.0)">
              this, which means self serve data platform,
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:16:22,860'); seek(982.0)">
              you've got 80% things right. This will enable teams to own
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:16:26,540'); seek(986.0)">
              and manage their data and data processing. But the big question
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:16:30,224'); seek(990.0)">
              is how you're going to build it. It looks
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:16:33,936'); seek(993.0)">
              easy now, but when you have so many choices and
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:16:37,456'); seek(997.0)">
              so many people pulling you in conferences that their data platform is the best,
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:16:40,916'); seek(1000.0)">
              they have the one stop solution. It can be quite overwhelming,
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:16:46,770'); seek(1006.0)">
              but I guess based on your use case you will do certain
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:16:50,756'); seek(1010.0)">
              PoCs. You would try to try to
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:16:53,848'); seek(1013.0)">
              look at probably open source solutions
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:16:57,838'); seek(1017.0)">
              available before buying already, I don't know,
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:17:01,432'); seek(1021.0)">
              committing to thousands and thousands of pounds or thousands and thousands of dollars
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:17:05,032'); seek(1025.0)">
              to some managed providers claiming that they can
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:17:08,828'); seek(1028.0)">
              solve all your problems. When we
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:17:12,588'); seek(1032.0)">
              were building this file processing platform, we were quite sure that
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:17:16,668'); seek(1036.0)">
              the platform, as a service or self serve platform offering was the
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:17:20,124'); seek(1040.0)">
              only way to move forward. Now on
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:17:23,728'); seek(1043.0)">
              a high level, four main features in our platform provides this end
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:17:27,168'); seek(1047.0)">
              to end solution for file processing, which we just talked about before,
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:17:30,400'); seek(1050.0)">
              that we have 20 plus different types of
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:17:34,388'); seek(1054.0)">
              files coming in, and then we have around 500k
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:17:38,388'); seek(1058.0)">
              files every day coming in, which we have to process varies in different size,
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:17:42,052'); seek(1062.0)">
              and then they come in in certain hours and we have to scale the system
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:17:45,496'); seek(1065.0)">
              accordingly as well. Now, four components.
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:17:48,878'); seek(1068.0)">
              First component is source connectors, which is ingesting data from
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:17:52,488'); seek(1072.0)">
              external providers in a consistent way. So we
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:17:55,708'); seek(1075.0)">
              did build those connectors to bring the data. Then you have PCI
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:17:59,026'); seek(1079.0)">
              processing platform, which actually makes sure
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:18:02,620'); seek(1082.0)">
              that a clear credit card information is stored,
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:18:06,082'); seek(1086.0)">
              masked and processed successfully and very,
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:18:09,292'); seek(1089.0)">
              very securely, and then being sent to non PCI platform,
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:18:13,084'); seek(1093.0)">
              and the non PCI platform which takes all the non PCI data
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:18:17,470'); seek(1097.0)">
              and also the data coming from all these other domains and
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:18:20,848'); seek(1100.0)">
              everywhere and perform schema
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:18:25,258'); seek(1105.0)">
              evaluation. I always struggle with this word and data
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:18:29,236'); seek(1109.0)">
              validation and generate outputs into that final format which
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:18:32,872'); seek(1112.0)">
              we agreed before Avro and basically chunked Avro
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:18:36,798'); seek(1116.0)">
              because the file size has been different,
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:18:41,960'); seek(1121.0)">
              the source file size. So we make sure that the final avro files
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:18:45,902'); seek(1125.0)">
              are chunked into somewhere around roughly to the same
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:18:49,292'); seek(1129.0)">
              size. So we don't end up having like one avro file which is two gig,
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:18:52,818'); seek(1132.0)">
              and one avro file which is like few kb's.
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:18:56,970'); seek(1136.0)">
              Sorry. Then target
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:19:00,166'); seek(1140.0)">
              connectors. Streaming the data generated
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:19:04,854'); seek(1144.0)">
              avro files, let's say from this lake
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:19:07,958'); seek(1147.0)">
              house kind of, or distributed data lakes into the data warehouse
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:19:12,090'); seek(1152.0)">
              or into any other streaming system or into
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:19:17,410'); seek(1157.0)">
              any other external kind of like warehouse
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:19:21,002'); seek(1161.0)">
              if Snowflake, or loading that
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:19:24,792'); seek(1164.0)">
              into mlops platform and things like that.
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:19:27,912'); seek(1167.0)">
              Now let's deep dive into all of these components.
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:19:33,830'); seek(1173.0)">
              Connectors, source connectors. We have a number of
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:19:37,528'); seek(1177.0)">
              different data sources. We have storage buckets, we have external
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:19:41,058'); seek(1181.0)">
              APIs, we have webhooks, we have Gmail attachments.
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:19:44,690'); seek(1184.0)">
              Trust me, we still have processes where we have to get the data from attachments.
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:19:48,438'); seek(1188.0)">
              Then we have external sftps servers. So mainly we use
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:19:52,880'); seek(1192.0)">
              Arclone to move most
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:19:56,336'); seek(1196.0)">
              of the data which is coming in files. It's an amazing
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:19:59,920'); seek(1199.0)">
              open source utility, which comes very handy
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:20:03,802'); seek(1203.0)">
              when you want to move files between two storage systems. You can move
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:20:07,492'); seek(1207.0)">
              from s three to gcs
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:20:11,786'); seek(1211.0)">
              or SFTP to any kind of storage bucket,
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:20:14,990'); seek(1214.0)">
              and it works like a charm. But you
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:20:22,328'); seek(1222.0)">
              have to spend some time on the configuration part of it.
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:20:25,990'); seek(1225.0)">
              Then you have Webex. So if the data
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:20:29,276'); seek(1229.0)">
              was not in files, for example in case of webhooks we batch those events into
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:20:32,956'); seek(1232.0)">
              files to keep things consistent. And we
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:20:37,180'); seek(1237.0)">
              did have some strict lsas slas but we
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:20:40,400'); seek(1240.0)">
              did not have slas to process this information in real time. So in
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:20:44,992'); seek(1244.0)">
              those cases where we don't have adhere kind of like
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:20:48,576'); seek(1248.0)">
              slas, okay, we need to process this information straight away.
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:20:51,952'); seek(1251.0)">
              We also use webhook kind of connectors
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:20:56,186'); seek(1256.0)">
              which batch those events and send them into the files.
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:20:59,226'); seek(1259.0)">
              I guess we are moving that completely into the overstreaming side now. I guess that
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:21:03,108'); seek(1263.0)">
              was the historic decision which we took. Then we have serverless
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:21:06,302'); seek(1266.0)">
              functions which allows the data to be received automatically by
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:21:10,072'); seek(1270.0)">
              email, including email body. I just talked about the email attachments
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:21:14,046'); seek(1274.0)">
              up there. We have one provider that does not attach a file
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:21:17,826'); seek(1277.0)">
              but provides a system configuration message in the body of the email.
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:21:21,532'); seek(1281.0)">
              So we had to write a parser for that as well.
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:21:25,370'); seek(1285.0)">
              I know they always have use cases like that
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:21:29,052'); seek(1289.0)">
              and then we use these connectors to land the data in the PCI and non
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:21:32,758'); seek(1292.0)">
              PCI platforms like depending on the sensitivity of the data.
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:21:36,416'); seek(1296.0)">
              So if we know that these files
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:21:39,814'); seek(1299.0)">
              are encrypted and they are supposed to
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:21:43,344'); seek(1303.0)">
              be processed by PCI to get the credit card
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:21:46,756'); seek(1306.0)">
              information masked, they directly go to the PCI platform and if
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:21:50,388'); seek(1310.0)">
              they are not they then bypass that process and directly go to
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:21:53,704'); seek(1313.0)">
              the non PCI platform. Before jumping into
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:21:57,160'); seek(1317.0)">
              the PCI platform, just few
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:22:00,472'); seek(1320.0)">
              lines on what is PCI compliance.
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:22:03,750'); seek(1323.0)">
              So all the listeners would understand how
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:22:07,628'); seek(1327.0)">
              much complexity is or how much things you have
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:22:10,924'); seek(1330.0)">
              to consider while building a PCI data platform kind
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:22:14,748'); seek(1334.0)">
              of environment.
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:22:18,330'); seek(1338.0)">
              Adhering to PCI standard is one of our prime
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:22:21,782'); seek(1341.0)">
              concerns given we own the end to end payment stack
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:22:25,782'); seek(1345.0)">
              and these standards are the set of security requirements established by the PCI
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:22:29,926'); seek(1349.0)">
              SSE to ensure that credit card information
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:22:33,540'); seek(1353.0)">
              is process successfully within any organization. Some of the key points
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:22:37,220'); seek(1357.0)">
              from this compliance are at a high level. They are like all
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:22:40,468'); seek(1360.0)">
              the credit card data has to be transmitted through secure encrypted
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:22:44,878'); seek(1364.0)">
              channels and then clear card
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:22:48,824'); seek(1368.0)">
              numbers cannot be
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:22:52,008'); seek(1372.0)">
              stored anywhere unless they are anonymized or encrypted.
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:22:55,790'); seek(1375.0)">
              Then you have the data platform that the platform which deals with the PCI
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:22:59,266'); seek(1379.0)">
              data has to be audited for
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:23:02,492'); seek(1382.0)">
              any security concerns every year.
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:23:05,210'); seek(1385.0)">
              So when we have PCI, so this is our PCI
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:23:08,722'); seek(1388.0)">
              management process within the PCI platform,
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:23:11,870'); seek(1391.0)">
              we have those files coming in, we don't know the
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:23:15,248'); seek(1395.0)">
              size of the files, they are zipped, they are encrypted.
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:23:18,742'); seek(1398.0)">
              So we have to decrypt the source file in memory using
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:23:22,660'); seek(1402.0)">
              confidential computing nodes. Then we encrypt with our
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:23:26,436'); seek(1406.0)">
              own key and archive the files for future purposes and for safeguarding.
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:23:30,506'); seek(1410.0)">
              Then if it's a zip file, we unzip on the disk. If the file
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:23:34,298'); seek(1414.0)">
              contains pans, we open the file, we mask the pans, then send the
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:23:38,088'); seek(1418.0)">
              masked version of the file to the non PCI platform. Because now,
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:23:41,848'); seek(1421.0)">
              because it's masked, it doesn't fall into the
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:23:46,410'); seek(1426.0)">
              PCI category. And this
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:23:50,252'); seek(1430.0)">
              is how the overall processing looks like.
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:23:54,300'); seek(1434.0)">
              So as you can see, the files start arriving.
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:23:58,750'); seek(1438.0)">
              It's a bit smaller for me. Yeah.
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:24:01,856'); seek(1441.0)">
              So the file starts arriving into the PCI storage bucket
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:24:07,310'); seek(1447.0)">
              and this is all running in GKE.
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:24:11,034'); seek(1451.0)">
              In Kubernetes, Rclone is running as
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:24:14,308'); seek(1454.0)">
              a cron job in Kubernetes. For object storage we are
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:24:17,828'); seek(1457.0)">
              using GCP, GCP's gcs
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:24:21,418'); seek(1461.0)">
              and for queues we are using pubsub at the moment.
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:24:24,870'); seek(1464.0)">
              So just so you know that we are completely GCP based,
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:24:29,670'); seek(1469.0)">
              but most of our workloads and most of our processing power
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:24:34,230'); seek(1474.0)">
              runs on GKE. So it's a
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:24:37,484'); seek(1477.0)">
              good mixture of being cloud native as well as cloud agnostic
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:24:41,778'); seek(1481.0)">
              at the same time. So these connectors are running, they are pulling the file from
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:24:45,756'); seek(1485.0)">
              SFTP or storage or s three, and then these files arrives into
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:24:49,756'); seek(1489.0)">
              object storage. The moment the file arrives in object storage,
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:24:53,238'); seek(1493.0)">
              a file event has been created that okay, the file is
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:24:56,528'); seek(1496.0)">
              created, the files is created, the file is created, and that goes into a pub
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:24:59,248'); seek(1499.0)">
              sub queue. And then based on the number
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:25:02,852'); seek(1502.0)">
              of messages in the queue, the HPA will scale the workload. We will
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:25:06,788'); seek(1506.0)">
              talk about scaling in detail in the later part of the presentation.
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:25:12,450'); seek(1512.0)">
              We typically have around 300 pods running at peak
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:25:16,318'); seek(1516.0)">
              hours across 40 nodes to process around 300
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:25:20,600'); seek(1520.0)">
              or 200k files within like 30 minutes.
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:25:24,070'); seek(1524.0)">
              Pods will then fetch the file information from these events.
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:25:28,018'); seek(1528.0)">
              In the pub subtopic process, the files mask the content if required.
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:25:32,250'); seek(1532.0)">
              We have very strict slas and scaling of the platform
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:25:35,804'); seek(1535.0)">
              to meet those slas is a critical part of our architecture.
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:25:39,702'); seek(1539.0)">
              We are using horizontal pod scaling and cluster auto scaling together to
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:25:43,408'); seek(1543.0)">
              scale the platform.
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:25:47,150'); seek(1547.0)">
              A bit more about auto scaling now. Auto scaling is a crucial
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:25:50,666'); seek(1550.0)">
              part of our platform.
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:25:54,210'); seek(1554.0)">
              We have to process these files as soon as they arrive so
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:25:59,268'); seek(1559.0)">
              we can perform the settlement and billing operations and also pay our merchants
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:26:03,530'); seek(1563.0)">
              and do the reconciliation of the money,
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:26:07,256'); seek(1567.0)">
              which is very crucial to our business also.
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:26:11,896'); seek(1571.0)">
              On the other hand, we also wanted to make sure that our infrastructure is cost
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:26:15,032'); seek(1575.0)">
              effective and we are not running workloads when they are not
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:26:18,572'); seek(1578.0)">
              needed to be aligned with bit more like a
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:26:22,124'); seek(1582.0)">
              phenopsy culture. There are
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:26:25,724'); seek(1585.0)">
              a few challenges we faced when we implemented horizontal port scaling,
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:26:28,998'); seek(1588.0)">
              setting up resources like on the pods,
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:26:32,294'); seek(1592.0)">
              that was a bit difficult
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:26:38,670'); seek(1598.0)">
              to decide what should be the starting request and what should be
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:26:42,224'); seek(1602.0)">
              the limit. I know there has been a lot of talks
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:26:46,298'); seek(1606.0)">
              in kubernetes that we don't need to put limits and stuff like that, but in
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:26:49,748'); seek(1609.0)">
              our case we had to do it because we are scaling so many pods and
            </span>
            
            <span id="chunk-417" class="transcript-chunks" onclick="console.log('00:26:53,028'); seek(1613.0)">
              pods can consume like a lot of memory and resources. So we
            </span>
            
            <span id="chunk-418" class="transcript-chunks" onclick="console.log('00:26:56,296'); seek(1616.0)">
              tried a lot of different options when we were
            </span>
            
            <span id="chunk-419" class="transcript-chunks" onclick="console.log('00:26:59,672'); seek(1619.0)">
              trying this in production. We started hating pagerduty
            </span>
            
            <span id="chunk-420" class="transcript-chunks" onclick="console.log('00:27:04,230'); seek(1624.0)">
              but eventually leveraging worked out for us and
            </span>
            
            <span id="chunk-421" class="transcript-chunks" onclick="console.log('00:27:11,850'); seek(1631.0)">
              it's now scaling quite nicely. And there are two types of scaling
            </span>
            
            <span id="chunk-422" class="transcript-chunks" onclick="console.log('00:27:17,050'); seek(1637.0)">
              available, right? High level two types. We have horizontal
            </span>
            
            <span id="chunk-423" class="transcript-chunks" onclick="console.log('00:27:20,834'); seek(1640.0)">
              auto scaling which updates a workload with the aim of scaling
            </span>
            
            <span id="chunk-424" class="transcript-chunks" onclick="console.log('00:27:24,598'); seek(1644.0)">
              the workload to match the demand. It actually means that the response
            </span>
            
            <span id="chunk-425" class="transcript-chunks" onclick="console.log('00:27:28,118'); seek(1648.0)">
              to increase the load is deploy more pods and if
            </span>
            
            <span id="chunk-426" class="transcript-chunks" onclick="console.log('00:27:31,408'); seek(1651.0)">
              the load decreases, scale back down the deployment. By removing the scaled
            </span>
            
            <span id="chunk-427" class="transcript-chunks" onclick="console.log('00:27:35,178'); seek(1655.0)">
              pods. Then you have vertical auto scaling means assigning more
            </span>
            
            <span id="chunk-428" class="transcript-chunks" onclick="console.log('00:27:39,028'); seek(1659.0)">
              resources, for example memory or cpu, to the pods that are already
            </span>
            
            <span id="chunk-429" class="transcript-chunks" onclick="console.log('00:27:42,356'); seek(1662.0)">
              running in
            </span>
            
            <span id="chunk-430" class="transcript-chunks" onclick="console.log('00:27:46,168'); seek(1666.0)">
              the deployment. You can trigger.
            </span>
            
            <span id="chunk-431" class="transcript-chunks" onclick="console.log('00:27:50,286'); seek(1670.0)">
              There are multiple ways to trigger this auto scaling you can trigger based on resource
            </span>
            
            <span id="chunk-432" class="transcript-chunks" onclick="console.log('00:27:54,142'); seek(1674.0)">
              usage. For example when a pods given memory or cpu exceeds
            </span>
            
            <span id="chunk-433" class="transcript-chunks" onclick="console.log('00:27:58,178'); seek(1678.0)">
              a threshold, you can add more pods if you
            </span>
            
            <span id="chunk-434" class="transcript-chunks" onclick="console.log('00:28:01,308'); seek(1681.0)">
              want to. Then metrics within Kubernetes
            </span>
            
            <span id="chunk-435" class="transcript-chunks" onclick="console.log('00:28:05,122'); seek(1685.0)">
              any metrics reported by Kubernetes object with the cluster, such as I
            </span>
            
            <span id="chunk-436" class="transcript-chunks" onclick="console.log('00:28:08,688'); seek(1688.0)">
              don't know, input output rate or
            </span>
            
            <span id="chunk-437" class="transcript-chunks" onclick="console.log('00:28:12,208'); seek(1692.0)">
              things like that. Then also like metrics coming from external sources
            </span>
            
            <span id="chunk-438" class="transcript-chunks" onclick="console.log('00:28:16,086'); seek(1696.0)">
              like pub sub. For example you can create an external metrics based
            </span>
            
            <span id="chunk-439" class="transcript-chunks" onclick="console.log('00:28:20,352'); seek(1700.0)">
              on the size of the queue. Configure the horizontal pod scaler to
            </span>
            
            <span id="chunk-440" class="transcript-chunks" onclick="console.log('00:28:24,212'); seek(1704.0)">
              automatically increase the number of pods when
            </span>
            
            <span id="chunk-441" class="transcript-chunks" onclick="console.log('00:28:27,572'); seek(1707.0)">
              the queue size reaches a given threshold and to reduce the
            </span>
            
            <span id="chunk-442" class="transcript-chunks" onclick="console.log('00:28:31,188'); seek(1711.0)">
              number of pods when the queue size shrinks. This is
            </span>
            
            <span id="chunk-443" class="transcript-chunks" onclick="console.log('00:28:34,648'); seek(1714.0)">
              exactly what we did and this is exactly we
            </span>
            
            <span id="chunk-444" class="transcript-chunks" onclick="console.log('00:28:38,232'); seek(1718.0)">
              did and used to scale our platform we
            </span>
            
            <span id="chunk-445" class="transcript-chunks" onclick="console.log('00:28:42,488'); seek(1722.0)">
              are talking about so far. We talked about HPA and adding more number of
            </span>
            
            <span id="chunk-446" class="transcript-chunks" onclick="console.log('00:28:46,890'); seek(1726.0)">
              pods to scale the deployment.
            </span>
            
            <span id="chunk-447" class="transcript-chunks" onclick="console.log('00:28:50,890'); seek(1730.0)">
              But we also need to remember that Kubernetes cluster
            </span>
            
            <span id="chunk-448" class="transcript-chunks" onclick="console.log('00:28:54,002'); seek(1734.0)">
              also need to increase its capacity. How do we
            </span>
            
            <span id="chunk-449" class="transcript-chunks" onclick="console.log('00:28:57,808'); seek(1737.0)">
              do it? How do we fit all these scaling
            </span>
            
            <span id="chunk-450" class="transcript-chunks" onclick="console.log('00:29:00,998'); seek(1740.0)">
              pods into kubernetes? For that we
            </span>
            
            <span id="chunk-451" class="transcript-chunks" onclick="console.log('00:29:05,088'); seek(1745.0)">
              need to add more nodes and we use Kubernetes cluster
            </span>
            
            <span id="chunk-452" class="transcript-chunks" onclick="console.log('00:29:09,190'); seek(1749.0)">
              autoscaler.
            </span>
            
            <span id="chunk-453" class="transcript-chunks" onclick="console.log('00:29:12,290'); seek(1752.0)">
              Kubernetes cluster or autoscaler is a tool that automatically adjusts
            </span>
            
            <span id="chunk-454" class="transcript-chunks" onclick="console.log('00:29:16,122'); seek(1756.0)">
              the size of kubernetes cluster by scaling up or down by adding or
            </span>
            
            <span id="chunk-455" class="transcript-chunks" onclick="console.log('00:29:19,988'); seek(1759.0)">
              removing nodes. When one of the following condition is true,
            </span>
            
            <span id="chunk-456" class="transcript-chunks" onclick="console.log('00:29:23,620'); seek(1763.0)">
              there are pods in the pending state in the cluster
            </span>
            
            <span id="chunk-457" class="transcript-chunks" onclick="console.log('00:29:27,022'); seek(1767.0)">
              due to insufficient resources. And there are nodes in the cluster
            </span>
            
            <span id="chunk-458" class="transcript-chunks" onclick="console.log('00:29:30,366'); seek(1770.0)">
              that have been underutilized for an extended period of time and
            </span>
            
            <span id="chunk-459" class="transcript-chunks" onclick="console.log('00:29:34,872'); seek(1774.0)">
              their pods can be placed on other existing nodes.
            </span>
            
            <span id="chunk-460" class="transcript-chunks" onclick="console.log('00:29:39,770'); seek(1779.0)">
              One very thing, very important thing to remember is that if your pods have
            </span>
            
            <span id="chunk-461" class="transcript-chunks" onclick="console.log('00:29:43,772'); seek(1783.0)">
              requested too few resources when it first started,
            </span>
            
            <span id="chunk-462" class="transcript-chunks" onclick="console.log('00:29:48,270'); seek(1788.0)">
              and after some point your
            </span>
            
            <span id="chunk-463" class="transcript-chunks" onclick="console.log('00:29:52,672'); seek(1792.0)">
              pod wants more cpu or more memory, but your
            </span>
            
            <span id="chunk-464" class="transcript-chunks" onclick="console.log('00:29:56,352'); seek(1796.0)">
              node in which your pod is actually running
            </span>
            
            <span id="chunk-465" class="transcript-chunks" onclick="console.log('00:29:59,824'); seek(1799.0)">
              is experiencing resource shortages.
            </span>
            
            <span id="chunk-466" class="transcript-chunks" onclick="console.log('00:30:02,930'); seek(1802.0)">
              In this case, cluster autoscaler won't do anything for you.
            </span>
            
            <span id="chunk-467" class="transcript-chunks" onclick="console.log('00:30:06,596'); seek(1806.0)">
              We actually did not read the documentation properly
            </span>
            
            <span id="chunk-468" class="transcript-chunks" onclick="console.log('00:30:09,962'); seek(1809.0)">
              and we believe the other way around and we lost good couple of days trying
            </span>
            
            <span id="chunk-469" class="transcript-chunks" onclick="console.log('00:30:13,732'); seek(1813.0)">
              to figure it out why the processing is very slow.
            </span>
            
            <span id="chunk-470" class="transcript-chunks" onclick="console.log('00:30:17,590'); seek(1817.0)">
              You'll have to go back and revisit the resources for the ports all the time.
            </span>
            
            <span id="chunk-471" class="transcript-chunks" onclick="console.log('00:30:22,630'); seek(1822.0)">
              Now we know the HP and CA works together to scale the
            </span>
            
            <span id="chunk-472" class="transcript-chunks" onclick="console.log('00:30:26,108'); seek(1826.0)">
              platform and
            </span>
            
            <span id="chunk-473" class="transcript-chunks" onclick="console.log('00:30:30,092'); seek(1830.0)">
              it works hand in hand and our
            </span>
            
            <span id="chunk-474" class="transcript-chunks" onclick="console.log('00:30:33,996'); seek(1833.0)">
              files processing can become very
            </span>
            
            <span id="chunk-475" class="transcript-chunks" onclick="console.log('00:30:38,112'); seek(1838.0)">
              scalable all of a sudden because we adopted kubernetes
            </span>
            
            <span id="chunk-476" class="transcript-chunks" onclick="console.log('00:30:42,326'); seek(1842.0)">
              and all these flavors of scalability with it.
            </span>
            
            <span id="chunk-477" class="transcript-chunks" onclick="console.log('00:30:49,870'); seek(1849.0)">
              And this is how it actually looks like right now.
            </span>
            
            <span id="chunk-478" class="transcript-chunks" onclick="console.log('00:30:53,392'); seek(1853.0)">
              If you can see, I'm going to take you back again to the
            </span>
            
            <span id="chunk-479" class="transcript-chunks" onclick="console.log('00:30:56,868'); seek(1856.0)">
              processing. You have object storage. All the files are landing and landing and
            </span>
            
            <span id="chunk-480" class="transcript-chunks" onclick="console.log('00:31:00,548'); seek(1860.0)">
              then the queue is becoming, having those events of file creation,
            </span>
            
            <span id="chunk-481" class="transcript-chunks" onclick="console.log('00:31:04,026'); seek(1864.0)">
              right, and the queue is becoming big and big and big. Now how
            </span>
            
            <span id="chunk-482" class="transcript-chunks" onclick="console.log('00:31:07,688'); seek(1867.0)">
              do we scale it? We said unact messages meant.
            </span>
            
            <span id="chunk-483" class="transcript-chunks" onclick="console.log('00:31:10,782'); seek(1870.0)">
              That means this is a pub sub terminology, but that means
            </span>
            
            <span id="chunk-484" class="transcript-chunks" onclick="console.log('00:31:15,370'); seek(1875.0)">
              not processed events divided by four is equal to number
            </span>
            
            <span id="chunk-485" class="transcript-chunks" onclick="console.log('00:31:19,052'); seek(1879.0)">
              of pods or number of workers required.
            </span>
            
            <span id="chunk-486" class="transcript-chunks" onclick="console.log('00:31:24,810'); seek(1884.0)">
              But we still have a maximum
            </span>
            
            <span id="chunk-487" class="transcript-chunks" onclick="console.log('00:31:28,530'); seek(1888.0)">
              limit as well. For example, if I have 500k files
            </span>
            
            <span id="chunk-488" class="transcript-chunks" onclick="console.log('00:31:32,406'); seek(1892.0)">
              still needs to be process, I cannot be running, I don't know,
            </span>
            
            <span id="chunk-489" class="transcript-chunks" onclick="console.log('00:31:36,990'); seek(1896.0)">
              125k pods. So we can
            </span>
            
            <span id="chunk-490" class="transcript-chunks" onclick="console.log('00:31:40,688'); seek(1900.0)">
              still say okay, maximum 300 or maximum 400 pods can
            </span>
            
            <span id="chunk-491" class="transcript-chunks" onclick="console.log('00:31:44,548'); seek(1904.0)">
              be running at a certain point in time on this particular cluster.
            </span>
            
            <span id="chunk-492" class="transcript-chunks" onclick="console.log('00:31:48,138'); seek(1908.0)">
              And that actually works because the file processing is very fast. So within few
            </span>
            
            <span id="chunk-493" class="transcript-chunks" onclick="console.log('00:31:52,452'); seek(1912.0)">
              seconds it process one file or within a second or
            </span>
            
            <span id="chunk-494" class="transcript-chunks" onclick="console.log('00:31:56,008'); seek(1916.0)">
              so.
            </span>
            
            <span id="chunk-495" class="transcript-chunks" onclick="console.log('00:32:00,070'); seek(1920.0)">
              And this is how the non PCI platform looks
            </span>
            
            <span id="chunk-496" class="transcript-chunks" onclick="console.log('00:32:04,632'); seek(1924.0)">
              like. And sometimes this is the platform where all the
            </span>
            
            <span id="chunk-497" class="transcript-chunks" onclick="console.log('00:32:08,844'); seek(1928.0)">
              validation, all the schema
            </span>
            
            <span id="chunk-498" class="transcript-chunks" onclick="console.log('00:32:13,458'); seek(1933.0)">
              contracts, all the monitoring events and everything
            </span>
            
            <span id="chunk-499" class="transcript-chunks" onclick="console.log('00:32:17,132'); seek(1937.0)">
              kind of is encapsulated into this
            </span>
            
            <span id="chunk-500" class="transcript-chunks" onclick="console.log('00:32:21,312'); seek(1941.0)">
              group of microservices or collection of tools or infrastructure
            </span>
            
            <span id="chunk-501" class="transcript-chunks" onclick="console.log('00:32:25,622'); seek(1945.0)">
              as you can say. So all the collector,
            </span>
            
            <span id="chunk-502" class="transcript-chunks" onclick="console.log('00:32:29,230'); seek(1949.0)">
              it works exactly the same as PCI, just a bit more that it
            </span>
            
            <span id="chunk-503" class="transcript-chunks" onclick="console.log('00:32:33,252'); seek(1953.0)">
              has some extra flavors of schema history and file
            </span>
            
            <span id="chunk-504" class="transcript-chunks" onclick="console.log('00:32:38,058'); seek(1958.0)">
              stores and things like that. So all the connectors
            </span>
            
            <span id="chunk-505" class="transcript-chunks" onclick="console.log('00:32:41,482'); seek(1961.0)">
              send files into the source bucket,
            </span>
            
            <span id="chunk-506" class="transcript-chunks" onclick="console.log('00:32:44,310'); seek(1964.0)">
              which is non PCI bucket. Then file creation events generate
            </span>
            
            <span id="chunk-507" class="transcript-chunks" onclick="console.log('00:32:48,950'); seek(1968.0)">
              that file creation event into the topic. Then HPA comes into
            </span>
            
            <span id="chunk-508" class="transcript-chunks" onclick="console.log('00:32:52,408'); seek(1972.0)">
              the picture it scales the deployment of
            </span>
            
            <span id="chunk-509" class="transcript-chunks" onclick="console.log('00:32:56,616'); seek(1976.0)">
              these translate parts. We call them translate because they're doing the translation based
            </span>
            
            <span id="chunk-510" class="transcript-chunks" onclick="console.log('00:33:00,492'); seek(1980.0)">
              on the config provided. And then the CA cluster auto scaler
            </span>
            
            <span id="chunk-511" class="transcript-chunks" onclick="console.log('00:33:04,274'); seek(1984.0)">
              kicks in to scale the cluster, and then the translate pods actually
            </span>
            
            <span id="chunk-512" class="transcript-chunks" onclick="console.log('00:33:08,332'); seek(1988.0)">
              parse and translate every single file, every single source file
            </span>
            
            <span id="chunk-513" class="transcript-chunks" onclick="console.log('00:33:11,494'); seek(1991.0)">
              into chunked, every files. Now translate process completely works
            </span>
            
            <span id="chunk-514" class="transcript-chunks" onclick="console.log('00:33:15,136'); seek(1995.0)">
              based on what's inside the schema of
            </span>
            
            <span id="chunk-515" class="transcript-chunks" onclick="console.log('00:33:18,768'); seek(1998.0)">
              the file. And this is where it becomes more like a self
            </span>
            
            <span id="chunk-516" class="transcript-chunks" onclick="console.log('00:33:22,416'); seek(2002.0)">
              serve data platform. So every single pipeline
            </span>
            
            <span id="chunk-517" class="transcript-chunks" onclick="console.log('00:33:27,690'); seek(2007.0)">
              belongs to a single domain. Payments have its
            </span>
            
            <span id="chunk-518" class="transcript-chunks" onclick="console.log('00:33:31,028'); seek(2011.0)">
              own pipeline here, marketing have its own pipeline here.
            </span>
            
            <span id="chunk-519" class="transcript-chunks" onclick="console.log('00:33:34,548'); seek(2014.0)">
              And every single schema history, if you see there is
            </span>
            
            <span id="chunk-520" class="transcript-chunks" onclick="console.log('00:33:40,216'); seek(2020.0)">
              like one schema history at the end of the day and there is a UI
            </span>
            
            <span id="chunk-521" class="transcript-chunks" onclick="console.log('00:33:43,358'); seek(2023.0)">
              on top of it from where users can log in,
            </span>
            
            <span id="chunk-522" class="transcript-chunks" onclick="console.log('00:33:46,824'); seek(2026.0)">
              go and challenges the schema, they can say okay,
            </span>
            
            <span id="chunk-523" class="transcript-chunks" onclick="console.log('00:33:50,012'); seek(2030.0)">
              now this file contains an extra column, and I want
            </span>
            
            <span id="chunk-524" class="transcript-chunks" onclick="console.log('00:33:53,548'); seek(2033.0)">
              to process this extra column, but I don't want to go
            </span>
            
            <span id="chunk-525" class="transcript-chunks" onclick="console.log('00:33:56,764'); seek(2036.0)">
              to the data team and raise a request and ask them to process this.
            </span>
            
            <span id="chunk-526" class="transcript-chunks" onclick="console.log('00:34:01,950'); seek(2041.0)">
              I would like to do it by myself.
            </span>
            
            <span id="chunk-527" class="transcript-chunks" onclick="console.log('00:34:05,070'); seek(2045.0)">
              And this is how it happens. So they go
            </span>
            
            <span id="chunk-528" class="transcript-chunks" onclick="console.log('00:34:08,784'); seek(2048.0)">
              to this web interface and there's schema version,
            </span>
            
            <span id="chunk-529" class="transcript-chunks" onclick="console.log('00:34:12,426'); seek(2052.0)">
              schema name, source, blah blah blah, lot of information there.
            </span>
            
            <span id="chunk-530" class="transcript-chunks" onclick="console.log('00:34:16,660'); seek(2056.0)">
              We are actually trying to make it a bit more nicer now.
            </span>
            
            <span id="chunk-531" class="transcript-chunks" onclick="console.log('00:34:20,770'); seek(2060.0)">
              We are actually taking away all the configuration out.
            </span>
            
            <span id="chunk-532" class="transcript-chunks" onclick="console.log('00:34:23,828'); seek(2063.0)">
              Now we have Argo CD workloads and things like that.
            </span>
            
            <span id="chunk-533" class="transcript-chunks" onclick="console.log('00:34:27,032'); seek(2067.0)">
              So we're taking that all out and we're just leaving the schema bit there.
            </span>
            
            <span id="chunk-534" class="transcript-chunks" onclick="console.log('00:34:30,584'); seek(2070.0)">
              But the gist here is like the users can
            </span>
            
            <span id="chunk-535" class="transcript-chunks" onclick="console.log('00:34:34,632'); seek(2074.0)">
              actually, or the domain owners or domain, those teams
            </span>
            
            <span id="chunk-536" class="transcript-chunks" onclick="console.log('00:34:38,178'); seek(2078.0)">
              can actually manage their own pipelines by themselves. We provide
            </span>
            
            <span id="chunk-537" class="transcript-chunks" onclick="console.log('00:34:44,410'); seek(2084.0)">
              the data catalog by using data hub, they can discover
            </span>
            
            <span id="chunk-538" class="transcript-chunks" onclick="console.log('00:34:48,066'); seek(2088.0)">
              everything, what they need to do. That is also an ongoing
            </span>
            
            <span id="chunk-539" class="transcript-chunks" onclick="console.log('00:34:51,558'); seek(2091.0)">
              project at the moment, but it's very interesting. Maybe someday we'll talk about this more
            </span>
            
            <span id="chunk-540" class="transcript-chunks" onclick="console.log('00:34:55,232'); seek(2095.0)">
              then we provide monitoring on top of it. The schema registry
            </span>
            
            <span id="chunk-541" class="transcript-chunks" onclick="console.log('00:34:59,334'); seek(2099.0)">
              also have a component where you can say, you know what,
            </span>
            
            <span id="chunk-542" class="transcript-chunks" onclick="console.log('00:35:03,076'); seek(2103.0)">
              I want to know when my file arrives and
            </span>
            
            <span id="chunk-543" class="transcript-chunks" onclick="console.log('00:35:06,708'); seek(2106.0)">
              when my file lands into the bigquery or my data warehouse.
            </span>
            
            <span id="chunk-544" class="transcript-chunks" onclick="console.log('00:35:10,426'); seek(2110.0)">
              And if that doesn't happen by 09:00 in the morning, I want to
            </span>
            
            <span id="chunk-545" class="transcript-chunks" onclick="console.log('00:35:13,944'); seek(2113.0)">
              get alerted because my processes are going to fail and
            </span>
            
            <span id="chunk-546" class="transcript-chunks" onclick="console.log('00:35:17,656'); seek(2117.0)">
              I need to notify downstream stakeholders.
            </span>
            
            <span id="chunk-547" class="transcript-chunks" onclick="console.log('00:35:20,654'); seek(2120.0)">
              Any other reason? So that's how
            </span>
            
            <span id="chunk-548" class="transcript-chunks" onclick="console.log('00:35:24,328'); seek(2124.0)">
              the schema registry plays a very key role. And at the end of the day
            </span>
            
            <span id="chunk-549" class="transcript-chunks" onclick="console.log('00:35:27,564'); seek(2127.0)">
              it's a data contract between the source and the processing and
            </span>
            
            <span id="chunk-550" class="transcript-chunks" onclick="console.log('00:35:31,228'); seek(2131.0)">
              the target. When we
            </span>
            
            <span id="chunk-551" class="transcript-chunks" onclick="console.log('00:35:35,212'); seek(2135.0)">
              process files from PCI to non PCI environment with the
            </span>
            
            <span id="chunk-552" class="transcript-chunks" onclick="console.log('00:35:38,384'); seek(2138.0)">
              help of schema SD, the files moves from many different stages throughout
            </span>
            
            <span id="chunk-553" class="transcript-chunks" onclick="console.log('00:35:42,902'); seek(2142.0)">
              the whole processing journey and the state management
            </span>
            
            <span id="chunk-554" class="transcript-chunks" onclick="console.log('00:35:46,422'); seek(2146.0)">
              of the file becomes very important because you
            </span>
            
            <span id="chunk-555" class="transcript-chunks" onclick="console.log('00:35:50,496'); seek(2150.0)">
              want the file processing to be fault tolerant. You want to
            </span>
            
            <span id="chunk-556" class="transcript-chunks" onclick="console.log('00:35:53,684'); seek(2153.0)">
              handle errors when the error happens.
            </span>
            
            <span id="chunk-557" class="transcript-chunks" onclick="console.log('00:35:58,290'); seek(2158.0)">
              You also want to support kind of live monitoring. You also want to
            </span>
            
            <span id="chunk-558" class="transcript-chunks" onclick="console.log('00:36:01,828'); seek(2161.0)">
              prevent duplicate processing, because queues can
            </span>
            
            <span id="chunk-559" class="transcript-chunks" onclick="console.log('00:36:05,352'); seek(2165.0)">
              have duplicate events. And you
            </span>
            
            <span id="chunk-560" class="transcript-chunks" onclick="console.log('00:36:10,136'); seek(2170.0)">
              want to make sure that once the file is processed, is processed.
            </span>
            
            <span id="chunk-561" class="transcript-chunks" onclick="console.log('00:36:14,150'); seek(2174.0)">
              Now let's see how the flow works. So object file is created,
            </span>
            
            <span id="chunk-562" class="transcript-chunks" onclick="console.log('00:36:18,250'); seek(2178.0)">
              it goes into the file event, subscription topic, for example.
            </span>
            
            <span id="chunk-563" class="transcript-chunks" onclick="console.log('00:36:22,252'); seek(2182.0)">
              So then it's kind of in a to do state. And after that
            </span>
            
            <span id="chunk-564" class="transcript-chunks" onclick="console.log('00:36:25,820'); seek(2185.0)">
              the HPA is listening to that topic,
            </span>
            
            <span id="chunk-565" class="transcript-chunks" onclick="console.log('00:36:30,006'); seek(2190.0)">
              and then it say, okay, let's scale everything and
            </span>
            
            <span id="chunk-566" class="transcript-chunks" onclick="console.log('00:36:34,480'); seek(2194.0)">
              all the pod starts consuming from this topic, and they consume
            </span>
            
            <span id="chunk-567" class="transcript-chunks" onclick="console.log('00:36:38,278'); seek(2198.0)">
              from this topic. They goes first to the store,
            </span>
            
            <span id="chunk-568" class="transcript-chunks" onclick="console.log('00:36:41,760'); seek(2201.0)">
              file store, or you can call it a data store, a state store,
            </span>
            
            <span id="chunk-569" class="transcript-chunks" onclick="console.log('00:36:45,684'); seek(2205.0)">
              to check whether the file is already being processed by some other pod or not.
            </span>
            
            <span id="chunk-570" class="transcript-chunks" onclick="console.log('00:36:49,284'); seek(2209.0)">
              If that's the case, then they skip it. If not,
            </span>
            
            <span id="chunk-571" class="transcript-chunks" onclick="console.log('00:36:53,428'); seek(2213.0)">
              then they put that status into in progress, and then they start processing it.
            </span>
            
            <span id="chunk-572" class="transcript-chunks" onclick="console.log('00:36:57,128'); seek(2217.0)">
              And if everything is succeeded, they said, okay, translate is
            </span>
            
            <span id="chunk-573" class="transcript-chunks" onclick="console.log('00:37:01,016'); seek(2221.0)">
              completed, or translate was started before translate completed without any
            </span>
            
            <span id="chunk-574" class="transcript-chunks" onclick="console.log('00:37:04,632'); seek(2224.0)">
              error, everybody's happy. And if
            </span>
            
            <span id="chunk-575" class="transcript-chunks" onclick="console.log('00:37:07,928'); seek(2227.0)">
              that doesn't happen, if there's an error, then they say, okay, there was an error.
            </span>
            
            <span id="chunk-576" class="transcript-chunks" onclick="console.log('00:37:11,906'); seek(2231.0)">
              And for some transient errors, we can actually resend
            </span>
            
            <span id="chunk-577" class="transcript-chunks" onclick="console.log('00:37:15,218'); seek(2235.0)">
              the files to be processed again. So they put the status
            </span>
            
            <span id="chunk-578" class="transcript-chunks" onclick="console.log('00:37:18,818'); seek(2238.0)">
              of the file to to do again so that some other pod can pick it
            </span>
            
            <span id="chunk-579" class="transcript-chunks" onclick="console.log('00:37:21,488'); seek(2241.0)">
              up.
            </span>
            
            <span id="chunk-580" class="transcript-chunks" onclick="console.log('00:37:24,830'); seek(2244.0)">
              This is also very useful for monitoring.
            </span>
            
            <span id="chunk-581" class="transcript-chunks" onclick="console.log('00:37:28,870'); seek(2248.0)">
              So all these events are being sent into metricstore.
            </span>
            
            <span id="chunk-582" class="transcript-chunks" onclick="console.log('00:37:32,278'); seek(2252.0)">
              And then we have a file monitoring service which actually talk
            </span>
            
            <span id="chunk-583" class="transcript-chunks" onclick="console.log('00:37:36,068'); seek(2256.0)">
              to the schema registrar, and based on the config provided in those
            </span>
            
            <span id="chunk-584" class="transcript-chunks" onclick="console.log('00:37:39,972'); seek(2259.0)">
              schemas or feeds, what we call it,
            </span>
            
            <span id="chunk-585" class="transcript-chunks" onclick="console.log('00:37:43,960'); seek(2263.0)">
              actually aggregate this information and start generating
            </span>
            
            <span id="chunk-586" class="transcript-chunks" onclick="console.log('00:37:48,950'); seek(2268.0)">
              metrics, report or alerts, or send
            </span>
            
            <span id="chunk-587" class="transcript-chunks" onclick="console.log('00:37:52,952'); seek(2272.0)">
              more aggregated information to Grafana and
            </span>
            
            <span id="chunk-588" class="transcript-chunks" onclick="console.log('00:37:58,876'); seek(2278.0)">
              for infrastructure observability. So most,
            </span>
            
            <span id="chunk-589" class="transcript-chunks" onclick="console.log('00:38:02,090'); seek(2282.0)">
              as I said before, everything what we do and
            </span>
            
            <span id="chunk-590" class="transcript-chunks" onclick="console.log('00:38:06,028'); seek(2286.0)">
              everything what we run mostly is on kubernetes. So we
            </span>
            
            <span id="chunk-591" class="transcript-chunks" onclick="console.log('00:38:09,968'); seek(2289.0)">
              are running Prometheus integrations at the moment, getting all the important metrics, such as
            </span>
            
            <span id="chunk-592" class="transcript-chunks" onclick="console.log('00:38:14,048'); seek(2294.0)">
              resource usage pods, health nodes, health pub sub
            </span>
            
            <span id="chunk-593" class="transcript-chunks" onclick="console.log('00:38:17,392'); seek(2297.0)">
              queue metrics, et cetera, whatever,
            </span>
            
            <span id="chunk-594" class="transcript-chunks" onclick="console.log('00:38:21,150'); seek(2301.0)">
              literally to Grafana. And then we have live dashboards running,
            </span>
            
            <span id="chunk-595" class="transcript-chunks" onclick="console.log('00:38:25,090'); seek(2305.0)">
              which actually reflects the status of the platform.
            </span>
            
            <span id="chunk-596" class="transcript-chunks" onclick="console.log('00:38:28,050'); seek(2308.0)">
              And the users can actually go and see their own feeds,
            </span>
            
            <span id="chunk-597" class="transcript-chunks" onclick="console.log('00:38:31,354'); seek(2311.0)">
              their own pipelines, and see if anything
            </span>
            
            <span id="chunk-598" class="transcript-chunks" onclick="console.log('00:38:34,996'); seek(2314.0)">
              is down or not. And they also get alerted. We also get alerted
            </span>
            
            <span id="chunk-599" class="transcript-chunks" onclick="console.log('00:38:39,518'); seek(2319.0)">
              because the centralized team own the infrastructure, so they actually come as
            </span>
            
            <span id="chunk-600" class="transcript-chunks" onclick="console.log('00:38:43,128'); seek(2323.0)">
              a second line support to fix if the issues are happening there.
            </span>
            
            <span id="chunk-601" class="transcript-chunks" onclick="console.log('00:38:48,410'); seek(2328.0)">
              I'm not going to touch much into the analytics platform,
            </span>
            
            <span id="chunk-602" class="transcript-chunks" onclick="console.log('00:38:51,740'); seek(2331.0)">
              but analytics platform is made basically
            </span>
            
            <span id="chunk-603" class="transcript-chunks" onclick="console.log('00:38:55,900'); seek(2335.0)">
              to analyze all the raw data
            </span>
            
            <span id="chunk-604" class="transcript-chunks" onclick="console.log('00:38:59,504'); seek(2339.0)">
              which is coming into bigquery and then run some DBT
            </span>
            
            <span id="chunk-605" class="transcript-chunks" onclick="console.log('00:39:03,238'); seek(2343.0)">
              models and then create those drive tables and
            </span>
            
            <span id="chunk-606" class="transcript-chunks" onclick="console.log('00:39:06,832'); seek(2346.0)">
              then the insights out of it.
            </span>
            
            <span id="chunk-607" class="transcript-chunks" onclick="console.log('00:39:10,910'); seek(2350.0)">
              Leveraging is based on Kubernetes and then this can be
            </span>
            
            <span id="chunk-608" class="transcript-chunks" onclick="console.log('00:39:14,292'); seek(2354.0)">
              also not. This can be. This is really this whole deployment
            </span>
            
            <span id="chunk-609" class="transcript-chunks" onclick="console.log('00:39:18,202'); seek(2358.0)">
              of analytics platform is owned by every single domain. So payments
            </span>
            
            <span id="chunk-610" class="transcript-chunks" onclick="console.log('00:39:21,754'); seek(2361.0)">
              have its own, marketing have its own, customer has its
            </span>
            
            <span id="chunk-611" class="transcript-chunks" onclick="console.log('00:39:25,048'); seek(2365.0)">
              own, everybody have their own kind
            </span>
            
            <span id="chunk-612" class="transcript-chunks" onclick="console.log('00:39:30,408'); seek(2370.0)">
              of analytics platform. This is my
            </span>
            
            <span id="chunk-613" class="transcript-chunks" onclick="console.log('00:39:33,800'); seek(2373.0)">
              kind of like a showcase end to end file monitoring.
            </span>
            
            <span id="chunk-614" class="transcript-chunks" onclick="console.log('00:39:38,334'); seek(2378.0)">
              And this is actually the slack message. Look like if you see that stage
            </span>
            
            <span id="chunk-615" class="transcript-chunks" onclick="console.log('00:39:41,602'); seek(2381.0)">
              one, stage two, stage three, stage four, stage five and see the stage
            </span>
            
            <span id="chunk-616" class="transcript-chunks" onclick="console.log('00:39:45,362'); seek(2385.0)">
              four is failing and the user can just click on it which file
            </span>
            
            <span id="chunk-617" class="transcript-chunks" onclick="console.log('00:39:49,334'); seek(2389.0)">
              is failing and then from there we have playbooks and then
            </span>
            
            <span id="chunk-618" class="transcript-chunks" onclick="console.log('00:39:53,072'); seek(2393.0)">
              we have ways to identify the errors
            </span>
            
            <span id="chunk-619" class="transcript-chunks" onclick="console.log('00:39:56,598'); seek(2396.0)">
              and ways to fix them as well. This is how the
            </span>
            
            <span id="chunk-620" class="transcript-chunks" onclick="console.log('00:40:00,768'); seek(2400.0)">
              overall ecosystem of data platform looks like. I just talked
            </span>
            
            <span id="chunk-621" class="transcript-chunks" onclick="console.log('00:40:04,756'); seek(2404.0)">
              about today the PCI platform and data file processing platform and only
            </span>
            
            <span id="chunk-622" class="transcript-chunks" onclick="console.log('00:40:08,356'); seek(2408.0)">
              touched the analytics platform, but we have done a
            </span>
            
            <span id="chunk-623" class="transcript-chunks" onclick="console.log('00:40:13,368'); seek(2413.0)">
              lot of work in streaming side, we have done a lot of work in discovery,
            </span>
            
            <span id="chunk-624" class="transcript-chunks" onclick="console.log('00:40:16,910'); seek(2416.0)">
              observability, quality, governance,
            </span>
            
            <span id="chunk-625" class="transcript-chunks" onclick="console.log('00:40:20,310'); seek(2420.0)">
              developer experience and we are still doing a lot
            </span>
            
            <span id="chunk-626" class="transcript-chunks" onclick="console.log('00:40:23,832'); seek(2423.0)">
              more. And we still have to go a long way to
            </span>
            
            <span id="chunk-627" class="transcript-chunks" onclick="console.log('00:40:27,356'); seek(2427.0)">
              completely embrace this self serve data platform or data mesh.
            </span>
            
            <span id="chunk-628" class="transcript-chunks" onclick="console.log('00:40:32,410'); seek(2432.0)">
              And if anybody is interested please join.
            </span>
            
            <span id="chunk-629" class="transcript-chunks" onclick="console.log('00:40:36,194'); seek(2436.0)">
              Go to this dojo career page, not just data team. We are hiding across
            </span>
            
            <span id="chunk-630" class="transcript-chunks" onclick="console.log('00:40:42,090'); seek(2442.0)">
              I guess all the functions. And of course thank you for your
            </span>
            
            <span id="chunk-631" class="transcript-chunks" onclick="console.log('00:40:45,212'); seek(2445.0)">
              time. And if you want to dm me directly
            </span>
            
            <span id="chunk-632" class="transcript-chunks" onclick="console.log('00:40:48,658'); seek(2448.0)">
              or connect me on LinkedIn, this is my, this is my profile.
            </span>
            
            <span id="chunk-633" class="transcript-chunks" onclick="console.log('00:40:52,042'); seek(2452.0)">
              Thank you so much, have a good day.
            </span>
            
            </div>
          </div>
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Conf42%20Kube%20Native%202023%20-%20Sandeep%20Mehta.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Conf42%20Kube%20Native%202023%20-%20Sandeep%20Mehta.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #CA6B46;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/kubenative2023" class="btn btn-sm btn-danger shadow lift" style="background-color: #CA6B46;">
                <i class="fe fe-grid me-2"></i>
                See all 21 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/Sandeep%20Mehta_kube.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Sandeep Mehta
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Engineering Manager, Data Platforms @ Dojo
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/sandeep-mehta26/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Sandeep Mehta's LinkedIn account" />
                  </a>
                  
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by Sandeep Mehta"
                  data-url="https://www.conf42.com/kubenative2023"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/kubenative2023"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>





  <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
    </script>
    <!-- SUBSCRIBE -->
    <section class="pt-8 pt-md-11 bg-gradient-light-white" id="register">
        <div class="container">
          <div class="row align-items-center justify-content-between mb-8 mb-md-11">
            <div class="col-12 col-md-6 order-md-2" data-aos="fade-left">
  
              <!-- Heading -->
              <h2>
                Awesome tech events for <br>
                <span class="text-success"><span data-typed='{"strings": ["software engineers.", "tech leaders.", "SREs.", "DevOps.", "CTOs.",  "managers.", "architects.", "QAs.", "developers.", "coders.", "founders.", "CEOs.", "students.", "geeks.", "ethical hackers.", "educators.", "enthusiasts.", "directors.", "researchers.", "PHDs.", "evangelists.", "tech authors."]}'></span></span>
              </h2>
  
              <!-- Text -->
              <p class="fs-lg text-muted mb-6">
  
              </p>
  
              <!-- List -->
              <div class="row">
                <div class="col-12 col-lg-12">
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <!-- Text -->
                    <p class="text-success">
                      Priority access to all content
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Video hallway track
                    </p>
                  </div>

                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Community chat
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Exclusive promotions and giveaways
                    </p>
                  </div>
  
                </div>
              </div> <!-- / .row -->
  
            </div>
            <div class="col-12 col-md-6 col-lg-5 order-md-1">
  
              <!-- Card -->
              <div class="card shadow-light-lg">
  
                <!-- Body -->
                <div class="card-body">
  
                  <!-- Form -->
                  <link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
                  <p class="emailoctopus-success-message text-success"></p>
                  <p class="emailoctopus-error-message text-danger"></p>
                  <form
                    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
                    method="post"
                    data-message-success="Thanks! Check your email for further directions!"
                    data-message-missing-email-address="Your email address is required."
                    data-message-invalid-email-address="Your email address looks incorrect, please try again."
                    data-message-bot-submission-error="This doesn't look like a human submission."
                    data-message-consent-required="Please check the checkbox to indicate your consent."
                    data-message-invalid-parameters-error="This form has missing or invalid fields."
                    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
                    class="emailoctopus-form"
                    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
                  >
                    <div class="form-floating emailoctopus-form-row">
                      <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
                      <label for="field_0">Email address</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
                      <label for="field_1">First Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
                      <label for="field_2">Last Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
                      <label for="field_4">Company</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
                      <label for="field_5">Job Title</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
                      <label for="field_3">Phone Number</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
                        oninput="updateCountry()"
                      >
                        <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
                      </select>
                      <label for="field_7">Country</label>
                    </div>
                    <input id="country-destination" name="field_7" type="hidden">
                    <input id="tz-country" name="field_8" type="hidden">
                    
                    <input
                      name="field_6"
                      type="hidden"
                      value="Kube Native"
                    >
                    
                    <div class="emailoctopus-form-row-consent">
                      <input
                        type="checkbox"
                        id="consent"
                        name="consent"
                      >
                      <label for="consent">
                        I consent to the following terms:
                      </label>
                      <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
                        Terms and Conditions
                      </a>
                      &amp;
                      <a href="./code-of-conduct" target="_blank">
                        Code of Conduct
                      </a>
                    </div>
                    <div
                      aria-hidden="true"
                      class="emailoctopus-form-row-hp"
                    >
                      <input
                        type="text"
                        name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
                        tabindex="-1"
                        autocomplete="nope"
                      >
                    </div>
                    <div class="mt-6 emailoctopus-form-row-subscribe">
                      <input
                        type="hidden"
                        name="successRedirectUrl"
                      >
                      <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
                        Subscribe
                      </button>
                    </div>
                  </form>
  
                </div>
  
              </div>
  
            </div>
  
          </div> <!-- / .row -->
        </div> <!-- / .container -->
      </section>

      <!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
      <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/aiml2024">
                  Artificial Intelligence & Machine Learning (AI & ML) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.sreday.com/">
                  SREday London 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

  </body>
</html>