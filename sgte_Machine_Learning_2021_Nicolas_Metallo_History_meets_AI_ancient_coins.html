<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: History meets AI: Unveiling the secrets of ancient coins</title>
    <meta name="description" content="Like the Machines need our help to take over the world">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/ml_nicolas.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="History meets AI: Unveiling the secrets of ancient coins | Conf42"/>
    <meta property="og:description" content="The University of Oxford houses 21 millions of objects in the collections of its Gardens, Libraries & Museums.   Preserving these assets requires great care. In this talk, we will review how AWS helped them build a sector leading ML solution that increased access to its collections for students, researchers, and public visitors while saving its staff and volunteers a massive amount of work.   This talk will show recent work related to the new AWS Case Study titled “University of Oxford introduces a sector leading Machine Learning prototype to augment Digitisation in Numismatics”."/>
    <meta property="og:url" content="https://conf42.com/Machine_Learning_2021_Nicolas_Metallo_History_meets_AI_ancient_coins"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/SREday2023_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        SREday Amsterdam 2024
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2024-11-21
                      </p>
                      <!-- Button -->
                      <a href="https://sreday.com/2024-amsterdam/" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2025">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2025">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2025">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2025">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2025">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2025">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2025">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2025">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2025">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2025">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2025">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/robotics2025">
                            Robotics
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2025">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2025">
                            Internet of Things (IoT)
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://sreday.com/2024-amsterdam/">
                            SREday Amsterdam
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="./support">
                            Support us
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Subscribe for FREE
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #198B91;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Machine Learning 2021 - Online
            </h1>

            <h2 class="text-white">
              
              Content unlocked! Welcome to the community!
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Like the Machines need our help to take over the world
 -->
              <script>
                const event_date = new Date("2021-07-29T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2021-07-29T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "5uJdBnY-zcE"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <a class="btn btn-info lift mb-3" data-bigpicture='{"ytSrc": "h6kzwaBwrCY"}' href="#">
                <i class="fe fe-eye me-2"></i>
                Watch Premiere
              </a>
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://youtube.com/playlist?list=PLIuxSyKxlQrD02X7IKNNxFMy_K8oEejAu" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hi, everyone, and welcome to this session. History meets AI,", "timestamp": "00:00:22,090", "timestamp_s": 22.0}, {"text": "unveiling the secrets of ancient coins. My name is", "timestamp": "00:00:26,194", "timestamp_s": 26.0}, {"text": "Nico. I work with the EMEA public sector at Amazon Web", "timestamp": "00:00:29,708", "timestamp_s": 29.0}, {"text": "Services. So today we\u0027re going to split this session into", "timestamp": "00:00:33,308", "timestamp_s": 33.0}, {"text": "two parts. The first part is going to be talking about this unveiling", "timestamp": "00:00:37,036", "timestamp_s": 37.0}, {"text": "of the secret of ancient coins. We care going to explore the challenge", "timestamp": "00:00:42,114", "timestamp_s": 42.0}, {"text": "that we had at hand, and we are also going to explore the", "timestamp": "00:00:46,330", "timestamp_s": 46.0}, {"text": "solution that we came up with. Then the second part of this session is", "timestamp": "00:00:49,468", "timestamp_s": 49.0}, {"text": "going to be dedicated to hands on examples where I\u0027m", "timestamp": "00:00:53,428", "timestamp_s": 53.0}, {"text": "going to show you some ways that you can build your own application to", "timestamp": "00:00:57,434", "timestamp_s": 57.0}, {"text": "solve challenge similar to this. So we\u0027re going to be focusing on", "timestamp": "00:01:01,108", "timestamp_s": 61.0}, {"text": "three things. Number one is going to be image classification.", "timestamp": "00:01:04,628", "timestamp_s": 64.0}, {"text": "Number two is going to be background removal and image segmentation. And number", "timestamp": "00:01:07,870", "timestamp_s": 67.0}, {"text": "three is going to be how to build a visual search engine.", "timestamp": "00:01:11,672", "timestamp_s": 71.0}, {"text": "So with that, let\u0027s dive right into the challenge that", "timestamp": "00:01:16,008", "timestamp_s": 76.0}, {"text": "we had at hand. So first, let\u0027s start with these.", "timestamp": "00:01:19,308", "timestamp_s": 79.0}, {"text": "Why? So the University of Oxford houses 21 million", "timestamp": "00:01:22,428", "timestamp_s": 82.0}, {"text": "objects in the collections of its gardens, libraries and museums.", "timestamp": "00:01:26,396", "timestamp_s": 86.0}, {"text": "Glam for short. One aspect of their mission is", "timestamp": "00:01:30,758", "timestamp_s": 90.0}, {"text": "that they want to preserve these assets and make them accessible to", "timestamp": "00:01:34,528", "timestamp_s": 94.0}, {"text": "the world for education and research. But of course,", "timestamp": "00:01:37,744", "timestamp_s": 97.0}, {"text": "there are only so many space that you can have for these.", "timestamp": "00:01:41,264", "timestamp_s": 101.0}, {"text": "So the organization only has enough space to display", "timestamp": "00:01:44,996", "timestamp_s": 104.0}, {"text": "about 10% of its holding at a single time. And there\u0027s", "timestamp": "00:01:48,938", "timestamp_s": 108.0}, {"text": "an enormous backlog of artifacts still waiting to be cataloged.", "timestamp": "00:01:51,994", "timestamp_s": 111.0}, {"text": "So to optimize the access to these collections for digital", "timestamp": "00:01:55,790", "timestamp_s": 115.0}, {"text": "teaching and research, Glam asked the question,", "timestamp": "00:01:59,422", "timestamp_s": 119.0}, {"text": "can we maybe use machine learning to help us?", "timestamp": "00:02:03,192", "timestamp_s": 123.0}, {"text": "If we are successful, that will reduce", "timestamp": "00:02:06,652", "timestamp_s": 126.0}, {"text": "the time that a research department needs to identify and", "timestamp": "00:02:10,178", "timestamp_s": 130.0}, {"text": "catalog an object. But before we even", "timestamp": "00:02:13,772", "timestamp_s": 133.0}, {"text": "think of that, the first thing that we had to identify is a", "timestamp": "00:02:17,196", "timestamp_s": 137.0}, {"text": "suitable, well cataloged collection that will become", "timestamp": "00:02:20,828", "timestamp_s": 140.0}, {"text": "the prototype candidate. So that candidate was", "timestamp": "00:02:24,464", "timestamp_s": 144.0}, {"text": "the roman provincial coinage. Digital collection. This is a", "timestamp": "00:02:28,272", "timestamp_s": 148.0}, {"text": "world renowned research project in numinastics.", "timestamp": "00:02:31,584", "timestamp_s": 151.0}, {"text": "The team included a curator with previous experience in", "timestamp": "00:02:34,930", "timestamp_s": 154.0}, {"text": "developing digital collections from the ground up. This person is", "timestamp": "00:02:38,708", "timestamp_s": 158.0}, {"text": "Sharon Meirat. He\u0027s the curator for the Herberdin coin room", "timestamp": "00:02:42,372", "timestamp_s": 162.0}, {"text": "in the Ashmolian Museum. So the first step in", "timestamp": "00:02:46,216", "timestamp_s": 166.0}, {"text": "any machine learning project is to decide what you", "timestamp": "00:02:49,768", "timestamp_s": 169.0}, {"text": "want to predict. In this case, Anshanesh Babu, who is", "timestamp": "00:02:53,032", "timestamp_s": 173.0}, {"text": "the system architect and network manager", "timestamp": "00:02:57,176", "timestamp_s": 177.0}, {"text": "from clan, wanted to predict a very simple outcome.", "timestamp": "00:03:00,798", "timestamp_s": 180.0}, {"text": "Heads or tails. That is, is the specimen", "timestamp": "00:03:04,730", "timestamp_s": 184.0}, {"text": "that I have in front of me that I\u0027m looking at. This photograph is that", "timestamp": "00:03:08,258", "timestamp_s": 188.0}, {"text": "of the overs or the reverse of a coin,", "timestamp": "00:03:11,968", "timestamp_s": 191.0}, {"text": "which is another way of saying that given a known training data,", "timestamp": "00:03:15,230", "timestamp_s": 195.0}, {"text": "can we have a machine learning solution? Predict the right side of a coin", "timestamp": "00:03:19,550", "timestamp_s": 199.0}, {"text": "with a high degree of a crest. So now", "timestamp": "00:03:22,922", "timestamp_s": 202.0}, {"text": "that we have the why we want to do this,", "timestamp": "00:03:26,324", "timestamp_s": 206.0}, {"text": "let\u0027s move into what are the actual things that", "timestamp": "00:03:29,828", "timestamp_s": 209.0}, {"text": "we want to solve for. So this is the moment when the Ashmore", "timestamp": "00:03:33,604", "timestamp_s": 213.0}, {"text": "Museum came to AWS and together we started discussing", "timestamp": "00:03:37,342", "timestamp_s": 217.0}, {"text": "what is a normal day for the", "timestamp": "00:03:41,198", "timestamp_s": 221.0}, {"text": "people who are working at this museums, what care, the challenges that they are facing?", "timestamp": "00:03:44,744", "timestamp_s": 224.0}, {"text": "What are the limitations and constraints that they have.", "timestamp": "00:03:48,258", "timestamp_s": 228.0}, {"text": "So we knew from before, the Asmonian Museum has built the world\u0027s largest", "timestamp": "00:03:51,788", "timestamp_s": 231.0}, {"text": "digital collection of roman provincial coinage that is open to", "timestamp": "00:03:55,346", "timestamp_s": 235.0}, {"text": "anyone to browse online for free. Now,", "timestamp": "00:03:59,088", "timestamp_s": 239.0}, {"text": "getting an item into this collection requires expert input", "timestamp": "00:04:01,952", "timestamp_s": 241.0}, {"text": "from curators, but these people are highly skilled", "timestamp": "00:04:06,118", "timestamp_s": 246.0}, {"text": "and very care, making this task very difficult to", "timestamp": "00:04:09,718", "timestamp_s": 249.0}, {"text": "escape. So the way that this works is that, for example,", "timestamp": "00:04:13,552", "timestamp_s": 253.0}, {"text": "you may have a multitude of physical specimens and you want", "timestamp": "00:04:17,028", "timestamp_s": 257.0}, {"text": "to catalog them. AWS items. Maybe the item that you", "timestamp": "00:04:20,548", "timestamp_s": 260.0}, {"text": "want to catalog this for already exists in the collections and", "timestamp": "00:04:23,988", "timestamp_s": 263.0}, {"text": "this is just another specimen to that item. Or maybe", "timestamp": "00:04:27,608", "timestamp_s": 267.0}, {"text": "the item is completely new to these digital collection. Some cases", "timestamp": "00:04:31,224", "timestamp_s": 271.0}, {"text": "you may have all the information available for these specimen,", "timestamp": "00:04:35,438", "timestamp_s": 275.0}, {"text": "or maybe in some other cases, you may lack some other", "timestamp": "00:04:38,658", "timestamp_s": 278.0}, {"text": "information. Also, something that might happen is that", "timestamp": "00:04:42,364", "timestamp_s": 282.0}, {"text": "other research institutions, or maybe even individuals might reach", "timestamp": "00:04:45,980", "timestamp_s": 285.0}, {"text": "out to these ashmolian museum with the simple question, look,", "timestamp": "00:04:49,868", "timestamp_s": 289.0}, {"text": "we have this item. Do you know what it is? And the", "timestamp": "00:04:53,552", "timestamp_s": 293.0}, {"text": "answer to this question is at times very complex", "timestamp": "00:04:57,088", "timestamp_s": 297.0}, {"text": "because of the sheer volume of items that need to", "timestamp": "00:05:01,650", "timestamp_s": 301.0}, {"text": "be processed. Oftentimes, groups of", "timestamp": "00:05:05,188", "timestamp_s": 305.0}, {"text": "people who want to help out. The mission of the university volunteers", "timestamp": "00:05:08,708", "timestamp_s": 308.0}, {"text": "to help out with this task. But normally,", "timestamp": "00:05:13,182", "timestamp_s": 313.0}, {"text": "because of the way that this is established, in some cases,", "timestamp": "00:05:17,102", "timestamp_s": 317.0}, {"text": "even the most simple task cannot be accomplished", "timestamp": "00:05:20,782", "timestamp_s": 320.0}, {"text": "by a single person or a small group of individuals.", "timestamp": "00:05:25,270", "timestamp_s": 325.0}, {"text": "Right? When I mean task, I mean getting a specimen", "timestamp": "00:05:28,802", "timestamp_s": 328.0}, {"text": "and identifying the right item that this specimen belongs to.", "timestamp": "00:05:32,674", "timestamp_s": 332.0}, {"text": "So what we wanted to do is not automate this", "timestamp": "00:05:36,924", "timestamp_s": 336.0}, {"text": "task, but augment the humans behind it.", "timestamp": "00:05:40,992", "timestamp_s": 340.0}, {"text": "Build tools that can support these people who", "timestamp": "00:05:44,320", "timestamp_s": 344.0}, {"text": "are working with this every day in a way that they can focus on", "timestamp": "00:05:48,032", "timestamp_s": 348.0}, {"text": "more relevant tasks, avoiding, for example,", "timestamp": "00:05:51,732", "timestamp_s": 351.0}, {"text": "spending hours and hours rotating photos so that", "timestamp": "00:05:54,724", "timestamp_s": 354.0}, {"text": "they are aligned perfectly before they move to the next task.", "timestamp": "00:05:58,628", "timestamp_s": 358.0}, {"text": "In this case, these customer objective is to reduce the", "timestamp": "00:06:02,610", "timestamp_s": 362.0}, {"text": "time that it takes for the correct appraisal of a single specimen.", "timestamp": "00:06:06,248", "timestamp_s": 366.0}, {"text": "Currently, these is estimated between 10 minutes and several hours", "timestamp": "00:06:10,446", "timestamp_s": 370.0}, {"text": "for each item. You can imagine that you get an item", "timestamp": "00:06:14,360", "timestamp_s": 374.0}, {"text": "and you want to spend some time corroborating", "timestamp": "00:06:18,066", "timestamp_s": 378.0}, {"text": "that the information that you have at hand that is available matches the", "timestamp": "00:06:22,370", "timestamp_s": 382.0}, {"text": "one that you have in the collection. And if it doesn\u0027t match,", "timestamp": "00:06:26,188", "timestamp_s": 386.0}, {"text": "then you need to figure out what is that missing", "timestamp": "00:06:29,232", "timestamp_s": 389.0}, {"text": "information. And for this, you can have a", "timestamp": "00:06:32,598", "timestamp_s": 392.0}, {"text": "multitude of combinations, making this exponentially", "timestamp": "00:06:36,592", "timestamp_s": 396.0}, {"text": "difficult when you have items that are not", "timestamp": "00:06:40,358", "timestamp_s": 400.0}, {"text": "the standard ones. Right? So the difficult items will require", "timestamp": "00:06:43,860", "timestamp_s": 403.0}, {"text": "an enormous amount of time, and normally they", "timestamp": "00:06:47,866", "timestamp_s": 407.0}, {"text": "will require an expert who is very", "timestamp": "00:06:51,748", "timestamp_s": 411.0}, {"text": "scars. These sense. So let\u0027s take deep into what", "timestamp": "00:06:55,016", "timestamp_s": 415.0}, {"text": "we are talking about. So, these are two screenshots from", "timestamp": "00:06:59,432", "timestamp_s": 419.0}, {"text": "the digital collection. The image that you see on the left are", "timestamp": "00:07:03,032", "timestamp_s": 423.0}, {"text": "three items. So three coins.", "timestamp": "00:07:06,504", "timestamp_s": 426.0}, {"text": "And you can see that we have the overs and the rivers on the left.", "timestamp": "00:07:10,410", "timestamp_s": 430.0}, {"text": "And then we have information on the right, where you", "timestamp": "00:07:13,804", "timestamp_s": 433.0}, {"text": "can see, for example, the inscription that is written on the", "timestamp": "00:07:17,228", "timestamp_s": 437.0}, {"text": "overs and the rivers, the city that belongs to the region,", "timestamp": "00:07:20,684", "timestamp_s": 440.0}, {"text": "these province, even the person that is in the", "timestamp": "00:07:24,102", "timestamp_s": 444.0}, {"text": "image. Now, the item that you see on the left, on the right.", "timestamp": "00:07:27,472", "timestamp_s": 447.0}, {"text": "Care different specimens to this same item,", "timestamp": "00:07:30,800", "timestamp_s": 450.0}, {"text": "right. So you can see how the quality of the specimen varies", "timestamp": "00:07:34,634", "timestamp_s": 454.0}, {"text": "in a big way. These, what you can see, care four", "timestamp": "00:07:39,170", "timestamp_s": 459.0}, {"text": "photos of the same coins. So you can see", "timestamp": "00:07:42,580", "timestamp_s": 462.0}, {"text": "that we have a very high quality on the left, where we can", "timestamp": "00:07:45,848", "timestamp_s": 465.0}, {"text": "figure out the text that is written. We can very", "timestamp": "00:07:50,470", "timestamp_s": 470.0}, {"text": "easily figure out the person. But then when we look at examples", "timestamp": "00:07:54,152", "timestamp_s": 474.0}, {"text": "like the ones that are in the middle, right, in the top and the bottom,", "timestamp": "00:07:58,222", "timestamp_s": 478.0}, {"text": "we are having a pretty difficult time discerning what is what in this picture.", "timestamp": "00:08:02,330", "timestamp_s": 482.0}, {"text": "So when you\u0027re presented with an item like this and you have to match it", "timestamp": "00:08:06,210", "timestamp_s": 486.0}, {"text": "to the image on the left, this quickly becomes a very difficult task.", "timestamp": "00:08:09,660", "timestamp_s": 489.0}, {"text": "So this comes back to the question, can we use machine learning to", "timestamp": "00:08:13,510", "timestamp_s": 493.0}, {"text": "solve this? Why? So now we know the why. We know", "timestamp": "00:08:17,168", "timestamp_s": 497.0}, {"text": "the what. Now let\u0027s move at how did we", "timestamp": "00:08:20,548", "timestamp_s": 500.0}, {"text": "solve this? So these", "timestamp": "00:08:24,228", "timestamp_s": 504.0}, {"text": "first thing that you can see is that these images,", "timestamp": "00:08:28,228", "timestamp_s": 508.0}, {"text": "right? So let\u0027s take the image on the right doesn\u0027t", "timestamp": "00:08:32,650", "timestamp_s": 512.0}, {"text": "quite look the same as this image.", "timestamp": "00:08:36,126", "timestamp_s": 516.0}, {"text": "So this one on the left, for example, this has been taken with a professional", "timestamp": "00:08:39,406", "timestamp_s": 519.0}, {"text": "equipment, has been taken without a background.", "timestamp": "00:08:43,518", "timestamp_s": 523.0}, {"text": "So you can see that the illumination is very constant. You can see that", "timestamp": "00:08:46,850", "timestamp_s": 526.0}, {"text": "this is very high resolution, and there\u0027s also", "timestamp": "00:08:50,220", "timestamp_s": 530.0}, {"text": "no blurriness, and everything is on focus.", "timestamp": "00:08:53,900", "timestamp_s": 533.0}, {"text": "So this is not always the case, especially when we get", "timestamp": "00:08:57,420", "timestamp_s": 537.0}, {"text": "images. The Ashmore museum gets images that belong to", "timestamp": "00:09:00,960", "timestamp_s": 540.0}, {"text": "individuals or other research institutions who might not have the same", "timestamp": "00:09:04,592", "timestamp_s": 544.0}, {"text": "researchers for capturing this information. So some", "timestamp": "00:09:08,656", "timestamp_s": 548.0}, {"text": "of the technical challenges that", "timestamp": "00:09:11,988", "timestamp_s": 551.0}, {"text": "we can face is that first, the image will be very low", "timestamp": "00:09:15,924", "timestamp_s": 555.0}, {"text": "resolution. For example, let\u0027s say you take it with a smartphone,", "timestamp": "00:09:19,412", "timestamp_s": 559.0}, {"text": "maybe it\u0027s blurry or noisy. There is also a", "timestamp": "00:09:23,270", "timestamp_s": 563.0}, {"text": "very inconsistent illumination across the image, so some", "timestamp": "00:09:26,808", "timestamp_s": 566.0}, {"text": "areas might be darker than others. Also,", "timestamp": "00:09:30,552", "timestamp_s": 570.0}, {"text": "the physical condition of the coin might be that the coin might be highly deteriorated,", "timestamp": "00:09:33,832", "timestamp_s": 573.0}, {"text": "right? So this will play against actually", "timestamp": "00:09:38,322", "timestamp_s": 578.0}, {"text": "finding out similar items. And also, the problem itself is", "timestamp": "00:09:42,268", "timestamp_s": 582.0}, {"text": "very hard because we are talking about coins or objects that", "timestamp": "00:09:46,108", "timestamp_s": 586.0}, {"text": "are more than 2000 years old in some cases. So in", "timestamp": "00:09:49,868", "timestamp_s": 589.0}, {"text": "short, photos that are taken by non museum personnel look", "timestamp": "00:09:53,248", "timestamp_s": 593.0}, {"text": "very different than images within the digital collection,", "timestamp": "00:09:56,672", "timestamp_s": 596.0}, {"text": "making visual search very challenged. So the way that we thought about", "timestamp": "00:10:00,430", "timestamp_s": 600.0}, {"text": "this is that we should first split the task into two.", "timestamp": "00:10:03,652", "timestamp_s": 603.0}, {"text": "First, one is let\u0027s improve the base image quality and let\u0027s", "timestamp": "00:10:07,924", "timestamp_s": 607.0}, {"text": "make this coin look as much as possible to", "timestamp": "00:10:11,722", "timestamp_s": 611.0}, {"text": "look as similar as possible to the one that we have in these", "timestamp": "00:10:16,308", "timestamp_s": 616.0}, {"text": "digital collection. Right? So we want to. For example, in this case, we have", "timestamp": "00:10:19,768", "timestamp_s": 619.0}, {"text": "a blurry background, we have a rotation, we have low resolution.", "timestamp": "00:10:23,304", "timestamp_s": 623.0}, {"text": "So we want to account for all of those things and create", "timestamp": "00:10:26,622", "timestamp_s": 626.0}, {"text": "an image that is very similar to the ones on the right. Once we have", "timestamp": "00:10:29,932", "timestamp_s": 629.0}, {"text": "this image, we can extract features out of it", "timestamp": "00:10:33,308", "timestamp_s": 633.0}, {"text": "and search in the collection to bring back the most similarly", "timestamp": "00:10:36,844", "timestamp_s": 636.0}, {"text": "looking items. So this is an example of", "timestamp": "00:10:40,118", "timestamp_s": 640.0}, {"text": "what we\u0027re doing here. You can see that we are detecting", "timestamp": "00:10:43,776", "timestamp_s": 643.0}, {"text": "the shape of the coin and then we", "timestamp": "00:10:47,174", "timestamp_s": 647.0}, {"text": "care coins, all of these activities at the same time,", "timestamp": "00:10:50,528", "timestamp_s": 650.0}, {"text": "right? So we are removing the background, we are rotating", "timestamp": "00:10:53,476", "timestamp_s": 653.0}, {"text": "these image, and then we are also increased the resolution", "timestamp": "00:10:57,274", "timestamp_s": 657.0}, {"text": "of this image. So that way we have the item on the right,", "timestamp": "00:11:00,778", "timestamp_s": 660.0}, {"text": "which is more similar than the image that we had on the left.", "timestamp": "00:11:04,484", "timestamp_s": 664.0}, {"text": "Once we had this image on the right,", "timestamp": "00:11:07,848", "timestamp_s": 667.0}, {"text": "we come back to this metadata that we have also extracted", "timestamp": "00:11:11,990", "timestamp_s": 671.0}, {"text": "from the image, right? So we know if the image is heads on tails", "timestamp": "00:11:15,438", "timestamp_s": 675.0}, {"text": "or tails with a 95% aggressive. So we know that", "timestamp": "00:11:19,906", "timestamp_s": 679.0}, {"text": "in this case, we are looking at the overs of a coin and we can", "timestamp": "00:11:23,692", "timestamp_s": 683.0}, {"text": "scan through all the images in the collection,", "timestamp": "00:11:27,420", "timestamp_s": 687.0}, {"text": "but only at the overs. We don\u0027t need to look at the back aws well,", "timestamp": "00:11:30,850", "timestamp_s": 690.0}, {"text": "and we can also use this other", "timestamp": "00:11:34,800", "timestamp_s": 694.0}, {"text": "information, like, for example, the material, the region, the city,", "timestamp": "00:11:38,032", "timestamp_s": 698.0}, {"text": "the province, and the person who is at the coin to make the", "timestamp": "00:11:41,844", "timestamp_s": 701.0}, {"text": "task of identifying this item easier. So with this,", "timestamp": "00:11:45,972", "timestamp_s": 705.0}, {"text": "let\u0027s move to a very quick demo of what this", "timestamp": "00:11:50,020", "timestamp_s": 710.0}, {"text": "proof of concept was. And just", "timestamp": "00:11:54,004", "timestamp_s": 714.0}, {"text": "have to say that this demo has been produced more than a year ago.", "timestamp": "00:11:57,576", "timestamp_s": 717.0}, {"text": "There is a new open source solution that is in the works.", "timestamp": "00:12:02,470", "timestamp_s": 722.0}, {"text": "It\u0027s not going to be restricted only to coins, but rather any collections", "timestamp": "00:12:05,910", "timestamp_s": 725.0}, {"text": "object that you will have either physical or digital,", "timestamp": "00:12:09,906", "timestamp_s": 729.0}, {"text": "say gems or fossils. Any object", "timestamp": "00:12:12,738", "timestamp_s": 732.0}, {"text": "with the idea, the care concept that you want to visually search for", "timestamp": "00:12:16,220", "timestamp_s": 736.0}, {"text": "similar items inside a collection. If you\u0027re interested in something", "timestamp": "00:12:20,512", "timestamp_s": 740.0}, {"text": "like this, keep posted to this video. We\u0027re going to add", "timestamp": "00:12:24,416", "timestamp_s": 744.0}, {"text": "any news that come out. Anything that", "timestamp": "00:12:28,656", "timestamp_s": 748.0}, {"text": "is released will be added in the comments below this", "timestamp": "00:12:32,468", "timestamp_s": 752.0}, {"text": "video. So with this, this is a web application created", "timestamp": "00:12:35,668", "timestamp_s": 755.0}, {"text": "using streamlip and show you.", "timestamp": "00:12:39,802", "timestamp_s": 759.0}, {"text": "So the idea for this is that we can interact with these models", "timestamp": "00:12:43,204", "timestamp_s": 763.0}, {"text": "that we have created in a way that we can,", "timestamp": "00:12:47,454", "timestamp_s": 767.0}, {"text": "for example, upload a picture. This case, the first thing that we", "timestamp": "00:12:51,352", "timestamp_s": 771.0}, {"text": "want to do is either choose an example from a library or", "timestamp": "00:12:54,648", "timestamp_s": 774.0}, {"text": "upload a picture. In this case, we choose the image that we saw before.", "timestamp": "00:12:58,680", "timestamp_s": 778.0}, {"text": "Blurry background, image rotated, low resolution.", "timestamp": "00:13:02,332", "timestamp_s": 782.0}, {"text": "So what we want to do is first find a region of interest", "timestamp": "00:13:05,954", "timestamp_s": 785.0}, {"text": "out of this image, remove the background, auto rotate it,", "timestamp": "00:13:09,708", "timestamp_s": 789.0}, {"text": "and these finally apply some deep blur and upscaling to", "timestamp": "00:13:13,040", "timestamp_s": 793.0}, {"text": "the image. So once we have finished this and this is all", "timestamp": "00:13:16,768", "timestamp_s": 796.0}, {"text": "happening in real time, you will have this image.", "timestamp": "00:13:20,288", "timestamp_s": 800.0}, {"text": "That is the output of this process.", "timestamp": "00:13:24,610", "timestamp_s": 804.0}, {"text": "Once we have this, we want to extract also metadata", "timestamp": "00:13:27,956", "timestamp_s": 807.0}, {"text": "out of this image, right? So for example,", "timestamp": "00:13:32,610", "timestamp_s": 812.0}, {"text": "is the overs, who is the person", "timestamp": "00:13:37,510", "timestamp_s": 817.0}, {"text": "that is in the image? What is the material that this coin is made", "timestamp": "00:13:40,600", "timestamp_s": 820.0}, {"text": "of? What is the reason that this belongs to? And so on.", "timestamp": "00:13:44,152", "timestamp_s": 824.0}, {"text": "Once we have this metadata, we care going to use the features that", "timestamp": "00:13:48,010", "timestamp_s": 828.0}, {"text": "we have extracted out of this image. So this is,", "timestamp": "00:13:51,932", "timestamp_s": 831.0}, {"text": "for example, the faces, the eyes,", "timestamp": "00:13:57,210", "timestamp_s": 837.0}, {"text": "the way that these are placed in the image. We care going to use this", "timestamp": "00:14:00,732", "timestamp_s": 840.0}, {"text": "to look inside our collection. And you can see that we are", "timestamp": "00:14:04,048", "timestamp_s": 844.0}, {"text": "going to come back with eight results that", "timestamp": "00:14:08,128", "timestamp_s": 848.0}, {"text": "are similar to the image that we are looking for. So in", "timestamp": "00:14:12,692", "timestamp_s": 852.0}, {"text": "this case, volunteers, for example,", "timestamp": "00:14:15,988", "timestamp_s": 855.0}, {"text": "doesn\u0027t have to go through thousands of images. They only", "timestamp": "00:14:19,170", "timestamp_s": 859.0}, {"text": "have to focus on eight images. And they also have information", "timestamp": "00:14:22,388", "timestamp_s": 862.0}, {"text": "that can point them in the right direction. Right. So they have", "timestamp": "00:14:26,052", "timestamp_s": 866.0}, {"text": "the region, the person who is in the picture, and also they", "timestamp": "00:14:29,688", "timestamp_s": 869.0}, {"text": "have similar items. So maybe when they see an item that", "timestamp": "00:14:32,968", "timestamp_s": 872.0}, {"text": "already exists, this is just another specimen, they can quickly", "timestamp": "00:14:37,032", "timestamp_s": 877.0}, {"text": "attach this to that one. So what are the benefits of using", "timestamp": "00:14:40,970", "timestamp_s": 880.0}, {"text": "aws for dash model? So the first one is that this is very quick and", "timestamp": "00:14:44,860", "timestamp_s": 884.0}, {"text": "easy experimentation. They built and deploy eleven machine learning models in about ten weeks.", "timestamp": "00:14:48,428", "timestamp_s": 888.0}, {"text": "There\u0027s a smaller workload, right. So you can imagine that saving", "timestamp": "00:14:52,848", "timestamp_s": 892.0}, {"text": "up minutes of every task in a", "timestamp": "00:14:56,800", "timestamp_s": 896.0}, {"text": "pipeline. In the end, when you have a large volume of", "timestamp": "00:14:59,984", "timestamp_s": 899.0}, {"text": "items that you have to digitalize they adapt to a lot of time.", "timestamp": "00:15:04,450", "timestamp_s": 904.0}, {"text": "In this case, it\u0027s estimated that they will save up to three years", "timestamp": "00:15:07,652", "timestamp_s": 907.0}, {"text": "of work cataloging a collection of 300,000 coins.", "timestamp": "00:15:11,300", "timestamp_s": 911.0}, {"text": "Less time. The coin analysis is expected to take just", "timestamp": "00:15:15,338", "timestamp_s": 915.0}, {"text": "a few minutes versus times that are ranging from 10", "timestamp": "00:15:18,552", "timestamp_s": 918.0}, {"text": "minutes to maybe hours. And also more value, right?", "timestamp": "00:15:21,832", "timestamp_s": 921.0}, {"text": "So this is complementing the work that is already being carried out", "timestamp": "00:15:25,128", "timestamp_s": 925.0}, {"text": "by volunteers. This is not automating anything, this is augmenting", "timestamp": "00:15:28,428", "timestamp_s": 928.0}, {"text": "the people, the humans who are behind this.", "timestamp": "00:15:32,970", "timestamp_s": 932.0}, {"text": "So these are some quotes of this. I thought this project", "timestamp": "00:15:36,252", "timestamp_s": 936.0}, {"text": "would be complex and time consuming, but using Aws made it easy.", "timestamp": "00:15:39,692", "timestamp_s": 939.0}, {"text": "Another one, this comes from Jerome. Now we", "timestamp": "00:15:43,870", "timestamp_s": 943.0}, {"text": "can focus our volunteers on other steps that add value machine learning process", "timestamp": "00:15:46,944", "timestamp_s": 946.0}, {"text": "improves the workflow and productivity and adds value for the public.", "timestamp": "00:15:50,960", "timestamp_s": 950.0}, {"text": "With this, let\u0027s have a look at this very small task", "timestamp": "00:15:55,108", "timestamp_s": 955.0}, {"text": "as an example. We want to remove the background of this, right?", "timestamp": "00:15:58,906", "timestamp_s": 958.0}, {"text": "And we are going to see in one of the examples how we can do", "timestamp": "00:16:01,956", "timestamp_s": 961.0}, {"text": "this actually technically.", "timestamp": "00:16:04,408", "timestamp_s": 964.0}, {"text": "And doing this doesn\u0027t have to be all", "timestamp": "00:16:07,910", "timestamp_s": 967.0}, {"text": "done by yourself. For example, there are some solutions available", "timestamp": "00:16:11,752", "timestamp_s": 971.0}, {"text": "in the marketplace that you can use an out of the box,", "timestamp": "00:16:15,944", "timestamp_s": 975.0}, {"text": "right, for background removal. And in this case, this one,", "timestamp": "00:16:19,580", "timestamp_s": 979.0}, {"text": "for example, at this time you have a price for every API call and you", "timestamp": "00:16:22,908", "timestamp_s": 982.0}, {"text": "can just subscribe to this one. So if you have images that you", "timestamp": "00:16:26,828", "timestamp_s": 986.0}, {"text": "want to remove this background for, then you will just subscribe", "timestamp": "00:16:30,048", "timestamp_s": 990.0}, {"text": "to this API and then just run them through this", "timestamp": "00:16:33,302", "timestamp_s": 993.0}, {"text": "service right through this endpoint. Another way that you can do it is of course", "timestamp": "00:16:38,240", "timestamp_s": 998.0}, {"text": "you can build your own algorithm. And we\u0027re going to see an example", "timestamp": "00:16:41,872", "timestamp_s": 1001.0}, {"text": "actually out of this, where you pick up, for example,", "timestamp": "00:16:45,460", "timestamp_s": 1005.0}, {"text": "this data set that is an image segmentation data", "timestamp": "00:16:48,850", "timestamp_s": 1008.0}, {"text": "set, open images, and you have more than 600 classes", "timestamp": "00:16:52,212", "timestamp_s": 1012.0}, {"text": "where these segmentation masks are available. Then you", "timestamp": "00:16:55,934", "timestamp_s": 1015.0}, {"text": "use an algorithm. In this case you\u0027re", "timestamp": "00:16:59,528", "timestamp_s": 1019.0}, {"text": "using mask or CNN. And we can use different machine learning", "timestamp": "00:17:02,638", "timestamp_s": 1022.0}, {"text": "frameworks, Pytorch, Tensorflow, Mxnet, together with", "timestamp": "00:17:05,900", "timestamp_s": 1025.0}, {"text": "Sagemaker and different ways of doing training.", "timestamp": "00:17:10,252", "timestamp_s": 1030.0}, {"text": "So with this you can build also very", "timestamp": "00:17:14,330", "timestamp_s": 1034.0}, {"text": "easily, you can build your own custom pipeline. These shows us some resources.", "timestamp": "00:17:17,868", "timestamp_s": 1037.0}, {"text": "I\u0027m going to add these to the description of the video anyway,", "timestamp": "00:17:22,242", "timestamp_s": 1042.0}, {"text": "but just to give you an idea of other things that you can do,", "timestamp": "00:17:25,664", "timestamp_s": 1045.0}, {"text": "there is a recent collaboration between hiringface and Sagemaker", "timestamp": "00:17:29,970", "timestamp_s": 1049.0}, {"text": "that is very useful. It\u0027s very robust,", "timestamp": "00:17:33,978", "timestamp_s": 1053.0}, {"text": "secure, and also I", "timestamp": "00:17:37,002", "timestamp_s": 1057.0}, {"text": "added some documents and repositories for", "timestamp": "00:17:40,852", "timestamp_s": 1060.0}, {"text": "deploying your very own web application for machine", "timestamp": "00:17:45,030", "timestamp_s": 1065.0}, {"text": "learning. So with that, I\u0027m coins to actually change the", "timestamp": "00:17:49,118", "timestamp_s": 1069.0}, {"text": "focus to the second bit of the presentation.", "timestamp": "00:17:52,728", "timestamp_s": 1072.0}, {"text": "And I\u0027m going to move to this one. Okay,", "timestamp": "00:17:56,578", "timestamp_s": 1076.0}, {"text": "so now we want to explore these idea of", "timestamp": "00:18:01,290", "timestamp_s": 1081.0}, {"text": "building your own machine learning solution,", "timestamp": "00:18:04,924", "timestamp_s": 1084.0}, {"text": "right? So we want to build the same thing. How can we do,", "timestamp": "00:18:07,714", "timestamp_s": 1087.0}, {"text": "we want to create these heads versus tails model", "timestamp": "00:18:12,190", "timestamp_s": 1092.0}, {"text": "the classifier. We want to remove the background and also we want to visually search", "timestamp": "00:18:15,760", "timestamp_s": 1095.0}, {"text": "these images in a collection. So how can we do it? Okay, so let\u0027s", "timestamp": "00:18:19,600", "timestamp_s": 1099.0}, {"text": "focus first on the first one. Okay, so image classification.", "timestamp": "00:18:23,542", "timestamp_s": 1103.0}, {"text": "So for that one, I\u0027m going to show you now,", "timestamp": "00:18:27,410", "timestamp_s": 1107.0}, {"text": "Sagemaker Studio. This is an end to end platform", "timestamp": "00:18:30,050", "timestamp_s": 1110.0}, {"text": "for machine learning from AWS. In this case, I\u0027m not", "timestamp": "00:18:34,260", "timestamp_s": 1114.0}, {"text": "going to go into a lot of detail about what thing", "timestamp": "00:18:37,688", "timestamp_s": 1117.0}, {"text": "does what or anything like that,", "timestamp": "00:18:41,096", "timestamp_s": 1121.0}, {"text": "but I\u0027m going to show you that there is something called", "timestamp": "00:18:44,310", "timestamp_s": 1124.0}, {"text": "Shamstat. And what is that? Basically when you click", "timestamp": "00:18:48,060", "timestamp_s": 1128.0}, {"text": "here, let\u0027s take the first one. Right? So model popular image", "timestamp": "00:18:51,356", "timestamp_s": 1131.0}, {"text": "classification based on. Okay, so that\u0027s exactly what we want to do. We want", "timestamp": "00:18:54,898", "timestamp_s": 1134.0}, {"text": "to build an image classifier. Let\u0027s do some more exploration.", "timestamp": "00:18:58,064", "timestamp_s": 1138.0}, {"text": "Okay, so when we explore it, you see that,", "timestamp": "00:19:01,974", "timestamp_s": 1141.0}, {"text": "for example, I particularly like this architecture.", "timestamp": "00:19:05,984", "timestamp_s": 1145.0}, {"text": "Efficient. Net has a very good performance.", "timestamp": "00:19:09,750", "timestamp_s": 1149.0}, {"text": "And you can see how you have different versions of this", "timestamp": "00:19:13,834", "timestamp_s": 1153.0}, {"text": "available out of the box. So these one are feature", "timestamp": "00:19:17,444", "timestamp_s": 1157.0}, {"text": "vector extractor. Right. And we\u0027ll get to", "timestamp": "00:19:21,386", "timestamp_s": 1161.0}, {"text": "why this is important in a second. But just", "timestamp": "00:19:25,048", "timestamp_s": 1165.0}, {"text": "keep them in mind for now. What we want to choose this is we", "timestamp": "00:19:28,856", "timestamp_s": 1168.0}, {"text": "want to choose the biggest variation, the b seven,", "timestamp": "00:19:32,712", "timestamp_s": 1172.0}, {"text": "these most performant, and we want to use these for our", "timestamp": "00:19:36,284", "timestamp_s": 1176.0}, {"text": "model. So once you click these and you have selected", "timestamp": "00:19:40,348", "timestamp_s": 1180.0}, {"text": "these model or these,", "timestamp": "00:19:44,002", "timestamp_s": 1184.0}, {"text": "then we can either deploy", "timestamp": "00:19:47,710", "timestamp_s": 1187.0}, {"text": "the version that is available without any changes.", "timestamp": "00:19:51,366", "timestamp_s": 1191.0}, {"text": "This model has been trained with imagenet.", "timestamp": "00:19:55,390", "timestamp_s": 1195.0}, {"text": "So let\u0027s go back for a second. So we have this.", "timestamp": "00:19:58,518", "timestamp_s": 1198.0}, {"text": "What is this? So this is jumpstart is a repository of", "timestamp": "00:20:02,580", "timestamp_s": 1202.0}, {"text": "solutions and models that you can quickly", "timestamp": "00:20:06,340", "timestamp_s": 1206.0}, {"text": "deploy with one click. In this case,", "timestamp": "00:20:10,356", "timestamp_s": 1210.0}, {"text": "we want to look at vision models and we want to look at", "timestamp": "00:20:14,450", "timestamp_s": 1214.0}, {"text": "solving the task image classification, right. So we", "timestamp": "00:20:17,912", "timestamp_s": 1217.0}, {"text": "also have the data set that this model has been trained on", "timestamp": "00:20:21,688", "timestamp_s": 1221.0}, {"text": "and we know if the model is fine tunable or", "timestamp": "00:20:25,752", "timestamp_s": 1225.0}, {"text": "not. This case it is. Right? So the same as this", "timestamp": "00:20:29,148", "timestamp_s": 1229.0}, {"text": "model that we have here. So how can you fine", "timestamp": "00:20:33,068", "timestamp_s": 1233.0}, {"text": "tune it? Well, you just go here to fine tune", "timestamp": "00:20:36,508", "timestamp_s": 1236.0}, {"text": "model. You choose the data source and you find your s", "timestamp": "00:20:39,698", "timestamp_s": 1239.0}, {"text": "three buck. You choose it, choose the directory name where you have it and", "timestamp": "00:20:43,328", "timestamp_s": 1243.0}, {"text": "then you can choose the instance that you want to use to", "timestamp": "00:20:47,168", "timestamp_s": 1247.0}, {"text": "train and then the parameters that you want to use and", "timestamp": "00:20:50,528", "timestamp_s": 1250.0}, {"text": "you will train it. And once this is trained, you can deploy it", "timestamp": "00:20:54,548", "timestamp_s": 1254.0}, {"text": "as an endpoint and use this model for inference.", "timestamp": "00:20:57,988", "timestamp_s": 1257.0}, {"text": "So how should you position your data?", "timestamp": "00:21:01,730", "timestamp_s": 1261.0}, {"text": "So you would have your input directory.", "timestamp": "00:21:05,330", "timestamp_s": 1265.0}, {"text": "This is the s three bucket that we were talking about before. And these you", "timestamp": "00:21:08,430", "timestamp_s": 1268.0}, {"text": "will have two folders. First one will be the overs and then", "timestamp": "00:21:11,368", "timestamp_s": 1271.0}, {"text": "you will have your examples and then you will have the reverse.", "timestamp": "00:21:15,064", "timestamp_s": 1275.0}, {"text": "Right, an example. And with that you don\u0027t have to", "timestamp": "00:21:18,802", "timestamp_s": 1278.0}, {"text": "do anything else. You can directly train it from this", "timestamp": "00:21:22,364", "timestamp_s": 1282.0}, {"text": "screen. Once this is trained and deployed,", "timestamp": "00:21:26,556", "timestamp_s": 1286.0}, {"text": "you can deploy it. And what you\u0027re going to see is something like this.", "timestamp": "00:21:30,130", "timestamp_s": 1290.0}, {"text": "So you can see that this takes around 10 minutes", "timestamp": "00:21:33,696", "timestamp_s": 1293.0}, {"text": "maybe to deploy or even less than that. This is using", "timestamp": "00:21:37,648", "timestamp_s": 1297.0}, {"text": "a CPU instance in this case. So you don\u0027t have to worry about", "timestamp": "00:21:41,360", "timestamp_s": 1301.0}, {"text": "GPU or CPU. You can use both.", "timestamp": "00:21:45,172", "timestamp_s": 1305.0}, {"text": "And you have an endpoint, you have a notebook that will", "timestamp": "00:21:48,690", "timestamp_s": 1308.0}, {"text": "show you how you can", "timestamp": "00:21:52,660", "timestamp_s": 1312.0}, {"text": "use this,", "timestamp": "00:21:56,248", "timestamp_s": 1316.0}, {"text": "how you can use this endpoint,", "timestamp": "00:21:59,430", "timestamp_s": 1319.0}, {"text": "right? So this one you see that we have two pictures.", "timestamp": "00:22:03,118", "timestamp_s": 1323.0}, {"text": "In this case we are using the original", "timestamp": "00:22:06,862", "timestamp_s": 1326.0}, {"text": "model. So the only thing that it has to do is pick up", "timestamp": "00:22:10,578", "timestamp_s": 1330.0}, {"text": "that this is a cat and a dog. And then you can see here", "timestamp": "00:22:13,772", "timestamp_s": 1333.0}, {"text": "top five model predictions or tabby, et cetera and so on.", "timestamp": "00:22:17,580", "timestamp_s": 1337.0}, {"text": "Top five model, et cetera. If you were using your", "timestamp": "00:22:20,992", "timestamp_s": 1340.0}, {"text": "own model, these classes", "timestamp": "00:22:24,448", "timestamp_s": 1344.0}, {"text": "will have been drivers and overs,", "timestamp": "00:22:27,782", "timestamp_s": 1347.0}, {"text": "right. So with that, let\u0027s actually move to", "timestamp": "00:22:31,590", "timestamp_s": 1351.0}, {"text": "the second model that we want to do. So we finish", "timestamp": "00:22:34,996", "timestamp_s": 1354.0}, {"text": "an image classifier and now we want to move to a segmentation model.", "timestamp": "00:22:38,452", "timestamp_s": 1358.0}, {"text": "We want to remove the background. So you", "timestamp": "00:22:42,580", "timestamp_s": 1362.0}, {"text": "can use your own segmentation", "timestamp": "00:22:47,368", "timestamp_s": 1367.0}, {"text": "model or you can just check other solutions", "timestamp": "00:22:51,662", "timestamp_s": 1371.0}, {"text": "that are open and available. So this is a website", "timestamp": "00:22:55,906", "timestamp_s": 1375.0}, {"text": "that I really like, papers with code. The task", "timestamp": "00:22:59,292", "timestamp_s": 1379.0}, {"text": "that we want to solve for is saliency detection.", "timestamp": "00:23:03,330", "timestamp_s": 1383.0}, {"text": "And you can see that you also have here", "timestamp": "00:23:07,710", "timestamp_s": 1387.0}, {"text": "available things like YouTube", "timestamp": "00:23:10,992", "timestamp_s": 1390.0}, {"text": "net. This one is very successful at detecting background", "timestamp": "00:23:15,078", "timestamp_s": 1395.0}, {"text": "and removing it. So choosing the most important object in the", "timestamp": "00:23:19,734", "timestamp_s": 1399.0}, {"text": "image and these removing the background. So this", "timestamp": "00:23:23,028", "timestamp_s": 1403.0}, {"text": "is also something that you can use with Sagemaker and then deploy", "timestamp": "00:23:26,628", "timestamp_s": 1406.0}, {"text": "it as an endpoint. Because we want to build something", "timestamp": "00:23:30,298", "timestamp_s": 1410.0}, {"text": "that is very custom.", "timestamp": "00:23:33,752", "timestamp_s": 1413.0}, {"text": "We care going to go through a different route and we care going to use", "timestamp": "00:23:37,990", "timestamp_s": 1417.0}, {"text": "an open data set, in this case these open image", "timestamp": "00:23:43,430", "timestamp_s": 1423.0}, {"text": "data set. We\u0027re going to look for coin, but it can be other things", "timestamp": "00:23:46,798", "timestamp_s": 1426.0}, {"text": "as well. And you can see that we have here", "timestamp": "00:23:50,172", "timestamp_s": 1430.0}, {"text": "the segmentation mask and they are available. So we are going to use this", "timestamp": "00:23:54,108", "timestamp_s": 1434.0}, {"text": "segmentation mask to train our model. So for", "timestamp": "00:23:57,740", "timestamp_s": 1437.0}, {"text": "this we\u0027re going to use this repo that we", "timestamp": "00:24:01,712", "timestamp_s": 1441.0}, {"text": "have here. I\u0027m going to put these, this is in the links that are available", "timestamp": "00:24:05,328", "timestamp_s": 1445.0}, {"text": "in the presentation and will be made available, the description of", "timestamp": "00:24:08,960", "timestamp_s": 1448.0}, {"text": "the video. And I\u0027m just going to walk you through some of the steps", "timestamp": "00:24:13,376", "timestamp_s": 1453.0}, {"text": "that we want to do this, you want to do here. So we\u0027re", "timestamp": "00:24:17,226", "timestamp_s": 1457.0}, {"text": "going to use custom library that is called Ice vision. This is", "timestamp": "00:24:20,698", "timestamp_s": 1460.0}, {"text": "built on top of Pytorch and it\u0027s on top of Pytorch lightning", "timestamp": "00:24:24,616", "timestamp_s": 1464.0}, {"text": "and also fast AI.", "timestamp": "00:24:28,542", "timestamp_s": 1468.0}, {"text": "So it uses both things for training. And at", "timestamp": "00:24:31,726", "timestamp_s": 1471.0}, {"text": "the same time it has available many,", "timestamp": "00:24:35,528", "timestamp_s": 1475.0}, {"text": "many algorithms out of the box. So for example,", "timestamp": "00:24:38,076", "timestamp_s": 1478.0}, {"text": "factor CNN or Mascar CNN. So this is these thing that I\u0027m", "timestamp": "00:24:41,740", "timestamp_s": 1481.0}, {"text": "going to be using for training in this session.", "timestamp": "00:24:45,234", "timestamp_s": 1485.0}, {"text": "So the first thing that we want to do is we want to", "timestamp": "00:24:49,870", "timestamp_s": 1489.0}, {"text": "download that data set and all the", "timestamp": "00:24:53,088", "timestamp_s": 1493.0}, {"text": "images, but only for the class coin,", "timestamp": "00:24:56,928", "timestamp_s": 1496.0}, {"text": "right? There are more than 600 classes available,", "timestamp": "00:25:01,466", "timestamp_s": 1501.0}, {"text": "but we only want to use this one coin.", "timestamp": "00:25:05,188", "timestamp_s": 1505.0}, {"text": "And 600 are these, these are the 600", "timestamp": "00:25:08,370", "timestamp_s": 1508.0}, {"text": "like person, piano, et cetera and so on. So we only want", "timestamp": "00:25:12,260", "timestamp_s": 1512.0}, {"text": "to train this model on coins.", "timestamp": "00:25:15,832", "timestamp_s": 1515.0}, {"text": "Okay, so the first thing that we do, we download the data and", "timestamp": "00:25:19,190", "timestamp_s": 1519.0}, {"text": "extract these images and the segmentation mask, we save them", "timestamp": "00:25:23,384", "timestamp_s": 1523.0}, {"text": "locally and then we convert these annotations because originally", "timestamp": "00:25:27,068", "timestamp_s": 1527.0}, {"text": "they use one vocabulary for this", "timestamp": "00:25:31,506", "timestamp_s": 1531.0}, {"text": "annotation and we want to move it to another one. So we move it from", "timestamp": "00:25:35,452", "timestamp_s": 1535.0}, {"text": "something that is called Pascal to another one that is called cocoa.", "timestamp": "00:25:38,716", "timestamp_s": 1538.0}, {"text": "Common objects in comma. So once we do", "timestamp": "00:25:42,102", "timestamp_s": 1542.0}, {"text": "this, we upload the data with this one", "timestamp": "00:25:45,328", "timestamp_s": 1545.0}, {"text": "line of code, right? We upload the data to a string,", "timestamp": "00:25:49,232", "timestamp_s": 1549.0}, {"text": "which is our object storage, storage.", "timestamp": "00:25:53,226", "timestamp_s": 1553.0}, {"text": "And we define what", "timestamp": "00:25:57,650", "timestamp_s": 1557.0}, {"text": "are the resources that we want to use for training. This case we want to", "timestamp": "00:26:01,588", "timestamp_s": 1561.0}, {"text": "use CPU instance. So we use this, these p, three,", "timestamp": "00:26:05,288", "timestamp_s": 1565.0}, {"text": "two, x large. And I\u0027m not going to use a spot,", "timestamp": "00:26:08,216", "timestamp_s": 1568.0}, {"text": "but you can think about spot as a way for going", "timestamp": "00:26:11,630", "timestamp_s": 1571.0}, {"text": "into an auction for unused compute capacity.", "timestamp": "00:26:16,652", "timestamp_s": 1576.0}, {"text": "And you bid for this unused capacity.", "timestamp": "00:26:20,250", "timestamp_s": 1580.0}, {"text": "Normally the savings range from 60% to 90%.", "timestamp": "00:26:24,146", "timestamp_s": 1584.0}, {"text": "So this is whatever the on demand price is,", "timestamp": "00:26:28,288", "timestamp_s": 1588.0}, {"text": "60% to 90% less than on demand price.", "timestamp": "00:26:31,790", "timestamp_s": 1591.0}, {"text": "And the only caveat that you have is that these resources,", "timestamp": "00:26:36,080", "timestamp_s": 1596.0}, {"text": "because you are bidding for them, once someone wants", "timestamp": "00:26:40,598", "timestamp_s": 1600.0}, {"text": "to use on demand researchers, your capacity will be", "timestamp": "00:26:44,992", "timestamp_s": 1604.0}, {"text": "taken away and given to them. So effectively your training will stop.", "timestamp": "00:26:48,404", "timestamp_s": 1608.0}, {"text": "The good thing is that all of this is already taken care of on", "timestamp": "00:26:53,028", "timestamp_s": 1613.0}, {"text": "AWS and you are saving checkpoints as you are", "timestamp": "00:26:57,288", "timestamp_s": 1617.0}, {"text": "moving on with your training. So in this way, if your training", "timestamp": "00:27:00,664", "timestamp_s": 1620.0}, {"text": "suddenly stops, for example, once this", "timestamp": "00:27:04,264", "timestamp_s": 1624.0}, {"text": "compute capacity becomes available again, you can start using", "timestamp": "00:27:08,108", "timestamp_s": 1628.0}, {"text": "it one more time. So I would recommend you to use", "timestamp": "00:27:11,916", "timestamp_s": 1631.0}, {"text": "these things because with only three lines of code you", "timestamp": "00:27:15,692", "timestamp_s": 1635.0}, {"text": "can save maybe from 60% to 90% of the cost.", "timestamp": "00:27:19,408", "timestamp_s": 1639.0}, {"text": "So once we", "timestamp": "00:27:23,360", "timestamp_s": 1643.0}, {"text": "have set up that configuration,", "timestamp": "00:27:26,928", "timestamp_s": 1646.0}, {"text": "we go here and we create something that is", "timestamp": "00:27:29,942", "timestamp_s": 1649.0}, {"text": "called an estimator, right? And we take our", "timestamp": "00:27:33,088", "timestamp_s": 1653.0}, {"text": "train script which is this one,", "timestamp": "00:27:36,996", "timestamp_s": 1656.0}, {"text": "the source directory where everything is.", "timestamp": "00:27:39,970", "timestamp_s": 1659.0}, {"text": "Let me show you this case. It\u0027s only two files,", "timestamp": "00:27:43,590", "timestamp_s": 1663.0}, {"text": "requires TXT and train and we pass", "timestamp": "00:27:46,942", "timestamp_s": 1666.0}, {"text": "arguments parameters to these", "timestamp": "00:27:51,048", "timestamp_s": 1671.0}, {"text": "training shop. So what this is going to do effectively is create a container", "timestamp": "00:27:54,152", "timestamp_s": 1674.0}, {"text": "new, different from what you\u0027re seeing here. Another instance only", "timestamp": "00:27:58,386", "timestamp_s": 1678.0}, {"text": "for this task and you will only have to pay for the amount", "timestamp": "00:28:02,396", "timestamp_s": 1682.0}, {"text": "of time that you\u0027ve been training, not more than", "timestamp": "00:28:06,252", "timestamp_s": 1686.0}, {"text": "that. So with that you can see that we", "timestamp": "00:28:09,568", "timestamp_s": 1689.0}, {"text": "create this estimator and then we fit to the data that", "timestamp": "00:28:15,552", "timestamp_s": 1695.0}, {"text": "we had. So inputs, this is the data that we downloaded and", "timestamp": "00:28:18,928", "timestamp_s": 1698.0}, {"text": "then uploaded to s three. And after some time", "timestamp": "00:28:22,768", "timestamp_s": 1702.0}, {"text": "this is going to finish and it\u0027s going to tell us that", "timestamp": "00:28:26,116", "timestamp_s": 1706.0}, {"text": "it was successful. Of course you can also track this if", "timestamp": "00:28:29,652", "timestamp_s": 1709.0}, {"text": "you go to the AWS console and you", "timestamp": "00:28:33,188", "timestamp_s": 1713.0}, {"text": "can see the shops here for example, you can see", "timestamp": "00:28:36,648", "timestamp_s": 1716.0}, {"text": "how much this training took. This is around 22 minutes and we were", "timestamp": "00:28:40,808", "timestamp_s": 1720.0}, {"text": "charged for 22 minutes. If we were using spot instances", "timestamp": "00:28:44,792", "timestamp_s": 1724.0}, {"text": "we would have had reduction of", "timestamp": "00:28:50,570", "timestamp_s": 1730.0}, {"text": "around 70% of the cost in this case. So once this", "timestamp": "00:28:54,092", "timestamp_s": 1734.0}, {"text": "is finished training we want to deploy this model and", "timestamp": "00:28:58,316", "timestamp_s": 1738.0}, {"text": "run our predictions. So for that we can use this other example", "timestamp": "00:29:02,032", "timestamp_s": 1742.0}, {"text": "where what I\u0027m actually doing here is I\u0027m creating a", "timestamp": "00:29:05,904", "timestamp_s": 1745.0}, {"text": "container but I\u0027m running this model,", "timestamp": "00:29:10,112", "timestamp_s": 1750.0}, {"text": "right. So you can see all the steps, just want to show you don\u0027t want", "timestamp": "00:29:13,508", "timestamp_s": 1753.0}, {"text": "to stay on the details too much. You can", "timestamp": "00:29:17,188", "timestamp_s": 1757.0}, {"text": "explore this at your own time. But I just want to", "timestamp": "00:29:21,364", "timestamp_s": 1761.0}, {"text": "show you the results of this. You can see that the", "timestamp": "00:29:24,728", "timestamp_s": 1764.0}, {"text": "actual time that it takes for a prediction is quite quick,", "timestamp": "00:29:28,888", "timestamp_s": 1768.0}, {"text": "right. And the quality is quite", "timestamp": "00:29:32,120", "timestamp_s": 1772.0}, {"text": "good right. So we have the image on the left and we only want to", "timestamp": "00:29:35,592", "timestamp_s": 1775.0}, {"text": "pick up one coins. So we pick up the one on the right and you", "timestamp": "00:29:38,604", "timestamp_s": 1778.0}, {"text": "can see how the background has been removed completely", "timestamp": "00:29:41,948", "timestamp_s": 1781.0}, {"text": "and the image is clean. So with", "timestamp": "00:29:46,730", "timestamp_s": 1786.0}, {"text": "that and conscious of time, going to move to the last item today", "timestamp": "00:29:50,108", "timestamp_s": 1790.0}, {"text": "and that is how can we build a visual search engine.", "timestamp": "00:29:54,416", "timestamp_s": 1794.0}, {"text": "And for that we care going to follow this blog post", "timestamp": "00:29:58,656", "timestamp_s": 1798.0}, {"text": "building a visual search application with Amazon,", "timestamp": "00:30:02,260", "timestamp_s": 1802.0}, {"text": "sagemaker and elasticsearch.", "timestamp": "00:30:04,698", "timestamp_s": 1804.0}, {"text": "So basically what we want to do is you have, and this is using", "timestamp": "00:30:08,050", "timestamp_s": 1808.0}, {"text": "an open source data set from clothes fashion.", "timestamp": "00:30:11,988", "timestamp_s": 1811.0}, {"text": "But of course you can think that you can change these", "timestamp": "00:30:15,422", "timestamp_s": 1815.0}, {"text": "things, these images, to the images", "timestamp": "00:30:19,112", "timestamp_s": 1819.0}, {"text": "that you have, for example, coins, right. So what this is going to do is", "timestamp": "00:30:22,718", "timestamp_s": 1822.0}, {"text": "it\u0027s going to run a convolutional neural network against", "timestamp": "00:30:26,392", "timestamp_s": 1826.0}, {"text": "these images. It\u0027s going to extract these feature vectors. And this is", "timestamp": "00:30:29,820", "timestamp_s": 1829.0}, {"text": "going back to that model, right, that we were talking about,", "timestamp": "00:30:33,388", "timestamp_s": 1833.0}, {"text": "the Shamstad model. Right. So we", "timestamp": "00:30:36,572", "timestamp_s": 1836.0}, {"text": "have this feature vector structure.", "timestamp": "00:30:40,812", "timestamp_s": 1840.0}, {"text": "Right. So we can actually deploy this and", "timestamp": "00:30:44,658", "timestamp_s": 1844.0}, {"text": "we don\u0027t have to do any type of custom modeling. We have the model right", "timestamp": "00:30:48,352", "timestamp_s": 1848.0}, {"text": "here. So once we have these vectors,", "timestamp": "00:30:52,196", "timestamp_s": 1852.0}, {"text": "we input all of these vectors into elasticsearch,", "timestamp": "00:30:56,218", "timestamp_s": 1856.0}, {"text": "and then we do something called k nearest", "timestamp": "00:30:59,658", "timestamp_s": 1859.0}, {"text": "neighbors search. So we look at the images", "timestamp": "00:31:03,594", "timestamp_s": 1863.0}, {"text": "that have the lowest distance between them, between the feature vectors", "timestamp": "00:31:07,166", "timestamp_s": 1867.0}, {"text": "from these images and the reference image", "timestamp": "00:31:11,534", "timestamp_s": 1871.0}, {"text": "that we have, right. So if you go through these steps,", "timestamp": "00:31:14,798", "timestamp_s": 1874.0}, {"text": "you will see that clicking here,", "timestamp": "00:31:18,730", "timestamp_s": 1878.0}, {"text": "launch a stack. This is going to open up this", "timestamp": "00:31:21,596", "timestamp_s": 1881.0}, {"text": "screen where basically we just create the resources", "timestamp": "00:31:25,036", "timestamp_s": 1885.0}, {"text": "that you need to run this. So it will create an", "timestamp": "00:31:28,898", "timestamp_s": 1888.0}, {"text": "S three bucket, it will create a sage maker notebook. And then the only", "timestamp": "00:31:32,912", "timestamp_s": 1892.0}, {"text": "thing that you need to do is actually, let me show you,", "timestamp": "00:31:36,352", "timestamp_s": 1896.0}, {"text": "open your notebook that was recently increased,", "timestamp": "00:31:39,790", "timestamp_s": 1899.0}, {"text": "increased. And you care going to be presented with", "timestamp": "00:31:43,126", "timestamp_s": 1903.0}, {"text": "this repo, right. And this repo is this one.", "timestamp": "00:31:48,050", "timestamp_s": 1908.0}, {"text": "Again, the link to this is,", "timestamp": "00:31:52,550", "timestamp_s": 1912.0}, {"text": "you can find it in the description of the video.", "timestamp": "00:31:56,120", "timestamp_s": 1916.0}, {"text": "Let\u0027s dive right into it. Right. So we have this image,", "timestamp": "00:32:00,070", "timestamp_s": 1920.0}, {"text": "visual image search. The first thing that we want to do", "timestamp": "00:32:03,806", "timestamp_s": 1923.0}, {"text": "is get these trend data, right. So this is almost 10,000", "timestamp": "00:32:07,068", "timestamp_s": 1927.0}, {"text": "high resolution images. In this case. In your use case,", "timestamp": "00:32:11,500", "timestamp_s": 1931.0}, {"text": "this will be your images. It wouldn\u0027t be these 10,000 images, it will", "timestamp": "00:32:15,932", "timestamp_s": 1935.0}, {"text": "be yours. And you can see", "timestamp": "00:32:19,648", "timestamp_s": 1939.0}, {"text": "that the first step that we do is we get this", "timestamp": "00:32:23,600", "timestamp_s": 1943.0}, {"text": "data and then we do some transformations, and then", "timestamp": "00:32:27,136", "timestamp_s": 1947.0}, {"text": "we upload this data to a string where we will have it.", "timestamp": "00:32:30,608", "timestamp_s": 1950.0}, {"text": "That will be the location that we are going to read from once we want", "timestamp": "00:32:34,260", "timestamp_s": 1954.0}, {"text": "to train our model. So once we have these images,", "timestamp": "00:32:37,764", "timestamp_s": 1957.0}, {"text": "we are going to be using a pretrained model", "timestamp": "00:32:42,690", "timestamp_s": 1962.0}, {"text": "that comes included in the Keras libraries.", "timestamp": "00:32:46,680", "timestamp_s": 1966.0}, {"text": "This case, it will be Resnet 50. But like we", "timestamp": "00:32:49,910", "timestamp_s": 1969.0}, {"text": "were seeing before, you can actually, instead of doing all of these steps, you can", "timestamp": "00:32:53,288", "timestamp_s": 1973.0}, {"text": "just use the model that we saw before.", "timestamp": "00:32:56,808", "timestamp_s": 1976.0}, {"text": "Right. Let me go again. So this model, you can just, once you deploy", "timestamp": "00:33:00,284", "timestamp_s": 1980.0}, {"text": "it, you click deployment, you will be presented with", "timestamp": "00:33:04,034", "timestamp_s": 1984.0}, {"text": "an endpoint URL. And that is the one that you can use to do", "timestamp": "00:33:07,772", "timestamp_s": 1987.0}, {"text": "this task. Otherwise, let\u0027s continue with this custom", "timestamp": "00:33:11,568", "timestamp_s": 1991.0}, {"text": "implementation. So we take this Resnet 50", "timestamp": "00:33:16,176", "timestamp_s": 1996.0}, {"text": "and we want to deploy it as", "timestamp": "00:33:20,190", "timestamp_s": 2000.0}, {"text": "an endpoint, right. So that\u0027s what we do now", "timestamp": "00:33:23,776", "timestamp_s": 2003.0}, {"text": "we use this piece of script. It\u0027s the one", "timestamp": "00:33:27,460", "timestamp_s": 2007.0}, {"text": "that we are going to be using to pick up the model, load it into", "timestamp": "00:33:30,708", "timestamp_s": 2010.0}, {"text": "memory, and then run all of these images", "timestamp": "00:33:34,376", "timestamp_s": 2014.0}, {"text": "through this and only return the feature vectors,", "timestamp": "00:33:38,238", "timestamp_s": 2018.0}, {"text": "not the actual label, out of it, just the feature vectors.", "timestamp": "00:33:41,422", "timestamp_s": 2021.0}, {"text": "So that is what we do here.", "timestamp": "00:33:45,910", "timestamp_s": 2025.0}, {"text": "So in this place we are going to deploy the model", "timestamp": "00:33:49,276", "timestamp_s": 2029.0}, {"text": "as a sage maker endpoint. This normally takes around 10 minutes.", "timestamp": "00:33:53,180", "timestamp_s": 2033.0}, {"text": "You can see that I\u0027m using CPU instance.", "timestamp": "00:33:56,348", "timestamp_s": 2036.0}, {"text": "This case I\u0027m going to deploy only one, but you can", "timestamp": "00:33:59,810", "timestamp_s": 2039.0}, {"text": "change it if you want this to be quicker, for example. So all", "timestamp": "00:34:03,392", "timestamp_s": 2043.0}, {"text": "the requests will be routed to one instance.", "timestamp": "00:34:07,200", "timestamp_s": 2047.0}, {"text": "In this case we are going to be using an example image", "timestamp": "00:34:10,370", "timestamp_s": 2050.0}, {"text": "and this is the result that comes", "timestamp": "00:34:14,458", "timestamp_s": 2054.0}, {"text": "back from these input. So these are the feature vectors.", "timestamp": "00:34:17,876", "timestamp_s": 2057.0}, {"text": "Once we tested that, this actually works. We want to build", "timestamp": "00:34:22,938", "timestamp_s": 2062.0}, {"text": "this index, right? So we want to first get all", "timestamp": "00:34:26,392", "timestamp_s": 2066.0}, {"text": "the images, all the keys of these files on s", "timestamp": "00:34:29,848", "timestamp_s": 2069.0}, {"text": "three. And then we want to basically", "timestamp": "00:34:33,192", "timestamp_s": 2073.0}, {"text": "process all of those images. We want to get the feature vectors out of all", "timestamp": "00:34:36,552", "timestamp_s": 2076.0}, {"text": "of those images and we want to upload them or", "timestamp": "00:34:40,188", "timestamp_s": 2080.0}, {"text": "get them into this elasticsearch index.", "timestamp": "00:34:44,348", "timestamp_s": 2084.0}, {"text": "So once we have done that, you can see", "timestamp": "00:34:48,518", "timestamp_s": 2088.0}, {"text": "that that is what we are coins here, we care, importing these features", "timestamp": "00:34:52,448", "timestamp_s": 2092.0}, {"text": "into elasticsearch. And the next thing that we can do is", "timestamp": "00:34:58,430", "timestamp_s": 2098.0}, {"text": "now we can do a test. So you see that", "timestamp": "00:35:02,020", "timestamp_s": 2102.0}, {"text": "we have the first image, the query image here,", "timestamp": "00:35:05,972", "timestamp_s": 2105.0}, {"text": "and now we say, okay, so bring me back", "timestamp": "00:35:10,610", "timestamp_s": 2110.0}, {"text": "examples out of your index, bring me back", "timestamp": "00:35:14,328", "timestamp_s": 2114.0}, {"text": "the most similarly looking images, right? So you can", "timestamp": "00:35:17,832", "timestamp_s": 2117.0}, {"text": "see that you\u0027re only returning outfits", "timestamp": "00:35:21,512", "timestamp_s": 2121.0}, {"text": "that have all of these patterns. So these are very similar", "timestamp": "00:35:25,390", "timestamp_s": 2125.0}, {"text": "between each other and the same", "timestamp": "00:35:29,610", "timestamp_s": 2129.0}, {"text": "thing. We use a different method, but these is the same", "timestamp": "00:35:33,132", "timestamp_s": 2133.0}, {"text": "result and you can see what this looks", "timestamp": "00:35:36,252", "timestamp_s": 2136.0}, {"text": "like, right? So in your case, using your own data,", "timestamp": "00:35:40,096", "timestamp_s": 2140.0}, {"text": "this will be presenting one coin as the reference image,", "timestamp": "00:35:43,312", "timestamp_s": 2143.0}, {"text": "the input image, and then returning", "timestamp": "00:35:46,838", "timestamp_s": 2146.0}, {"text": "all of these most similarly looking images", "timestamp": "00:35:51,250", "timestamp_s": 2151.0}, {"text": "in the collection, right? So the good thing about this application is", "timestamp": "00:35:55,562", "timestamp_s": 2155.0}, {"text": "that it actually also involves this implementation, that it", "timestamp": "00:35:58,868", "timestamp_s": 2158.0}, {"text": "also involves deploying a full stack visual search application. So this is great", "timestamp": "00:36:02,804", "timestamp_s": 2162.0}, {"text": "if you\u0027re doing a demo. So what", "timestamp": "00:36:06,632", "timestamp_s": 2166.0}, {"text": "you will do is these are several steps", "timestamp": "00:36:09,928", "timestamp_s": 2169.0}, {"text": "for creating the architecture.", "timestamp": "00:36:14,150", "timestamp_s": 2174.0}, {"text": "But basically once you run all of these steps, you\u0027re going to", "timestamp": "00:36:17,246", "timestamp_s": 2177.0}, {"text": "be presented with an application that looks like this.", "timestamp": "00:36:20,764", "timestamp_s": 2180.0}, {"text": "And I actually have it running locally here. So you", "timestamp": "00:36:23,756", "timestamp_s": 2183.0}, {"text": "see that, for example, you will choose how many", "timestamp": "00:36:27,308", "timestamp_s": 2187.0}, {"text": "items you want to return out of this. And these", "timestamp": "00:36:31,232", "timestamp_s": 2191.0}, {"text": "you can choose an image,", "timestamp": "00:36:34,560", "timestamp_s": 2194.0}, {"text": "and you will just submit your shop and then", "timestamp": "00:36:38,030", "timestamp_s": 2198.0}, {"text": "get the results back. Let me show you, for example,", "timestamp": "00:36:41,812", "timestamp_s": 2201.0}, {"text": "in here. The way that this will look is something", "timestamp": "00:36:46,050", "timestamp_s": 2206.0}, {"text": "like this. So, at the end of your experimentation, if you want,", "timestamp": "00:36:49,636", "timestamp_s": 2209.0}, {"text": "you can delete all of the resources that we created, and then you", "timestamp": "00:36:53,252", "timestamp_s": 2213.0}, {"text": "will just finish with your", "timestamp": "00:36:57,188", "timestamp_s": 2217.0}, {"text": "experimentation. You wouldn\u0027t have any extra cost out of this.", "timestamp": "00:37:01,076", "timestamp_s": 2221.0}, {"text": "So, with that, I actually wanted to come back to original", "timestamp": "00:37:06,570", "timestamp_s": 2226.0}, {"text": "presentation, and I wanted to thank you for staying with us so", "timestamp": "00:37:10,418", "timestamp_s": 2230.0}, {"text": "long, and I hope you find this presentation useful. Thank you very", "timestamp": "00:37:14,572", "timestamp_s": 2234.0}, {"text": "much.", "timestamp": "00:37:18,268", "timestamp_s": 2238.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: '5uJdBnY-zcE',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              History meets AI: Unveiling the secrets of ancient coins
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>The University of Oxford houses 21 millions of objects in the collections of its Gardens, Libraries &amp; Museums. </p>
<p>Preserving these assets requires great care. In this talk, we will review how AWS helped them build a sector leading ML solution that increased access to its collections for students, researchers, and public visitors while saving its staff and volunteers a massive amount of work. </p>
<p>This talk will show recent work related to the new AWS Case Study titled “University of Oxford introduces a sector leading Machine Learning prototype to augment Digitisation in Numismatics”.</p>
<!-- End Text -->
          </div>

          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
              <li>
                History meets AI, unveiling the secrets of ancient coins. Second part of this session dedicated to hands on examples. Show you some ways that you can build your own application to solve challenge similar to this.

              </li>
              
              <li>
                The University of Oxford houses 21 million objects in the collections of its gardens, libraries and museums. To optimize the access to these collections for digital teaching and research, Glam asked the question, can we maybe use machine learning to help us?

              </li>
              
              <li>
                Asmonian Museum has built the world's largest digital collection of roman provincial coinage that is open to anyone to browse online for free. Getting an item into this collection requires expert input from curators. What we wanted to do is not automate this task, but augment the humans behind it.

              </li>
              
              <li>
                There is a new open source solution that is in the works. It's not going to be restricted only to coins, but rather any collections object. Anything that is released will be added in the comments below this video.

              </li>
              
              <li>
                Using aws for dash, volunteers can easily digitalize large collections of coins. The process is very quick and easy experimentation. You can build your own algorithm. This improves the workflow and productivity and adds value for the public.

              </li>
              
              <li>
                Sagemaker Studio is an end to end platform for machine learning from AWS. You can directly train it from this screen. Once this is trained, you can deploy it as an endpoint and use this model for inference.

              </li>
              
              <li>
                With only three lines of code you can save maybe from 60% to 90% of the cost. The task that we want to solve for is saliency detection. We use custom library that is called Ice vision. It uses both things for training. Think about spot as a way for going into an auction for unused compute capacity.

              </li>
              
              <li>
                Building a visual search application with Amazon, sagemaker and elasticsearch. Using an open source data set from clothes fashion. Running a convolutional neural network against these images. Once we tested that, this actually works.
              </li>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./assemblyai/5uJdBnY-zcE.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:22,090'); seek(22.0)">
              Hi, everyone, and welcome to this session. History meets AI,
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:26,194'); seek(26.0)">
              unveiling the secrets of ancient coins. My name is
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:29,708'); seek(29.0)">
              Nico. I work with the EMEA public sector at Amazon Web
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:33,308'); seek(33.0)">
              Services. So today we're going to split this session into
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:37,036'); seek(37.0)">
              two parts. The first part is going to be talking about this unveiling
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:42,114'); seek(42.0)">
              of the secret of ancient coins. We care going to explore the challenge
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:46,330'); seek(46.0)">
              that we had at hand, and we are also going to explore the
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:49,468'); seek(49.0)">
              solution that we came up with. Then the second part of this session is
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:53,428'); seek(53.0)">
              going to be dedicated to hands on examples where I'm
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:57,434'); seek(57.0)">
              going to show you some ways that you can build your own application to
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:01:01,108'); seek(61.0)">
              solve challenge similar to this. So we're going to be focusing on
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:01:04,628'); seek(64.0)">
              three things. Number one is going to be image classification.
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:01:07,870'); seek(67.0)">
              Number two is going to be background removal and image segmentation. And number
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:01:11,672'); seek(71.0)">
              three is going to be how to build a visual search engine.
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:01:16,008'); seek(76.0)">
              So with that, let's dive right into the challenge that
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:01:19,308'); seek(79.0)">
              we had at hand. So first, let's start with these.
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:01:22,428'); seek(82.0)">
              Why? So the University of Oxford houses 21 million
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:26,396'); seek(86.0)">
              objects in the collections of its gardens, libraries and museums.
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:30,758'); seek(90.0)">
              Glam for short. One aspect of their mission is
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:34,528'); seek(94.0)">
              that they want to preserve these assets and make them accessible to
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:37,744'); seek(97.0)">
              the world for education and research. But of course,
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:41,264'); seek(101.0)">
              there are only so many space that you can have for these.
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:44,996'); seek(104.0)">
              So the organization only has enough space to display
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:48,938'); seek(108.0)">
              about 10% of its holding at a single time. And there's
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:51,994'); seek(111.0)">
              an enormous backlog of artifacts still waiting to be cataloged.
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:55,790'); seek(115.0)">
              So to optimize the access to these collections for digital
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:01:59,422'); seek(119.0)">
              teaching and research, Glam asked the question,
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:02:03,192'); seek(123.0)">
              can we maybe use machine learning to help us?
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:02:06,652'); seek(126.0)">
              If we are successful, that will reduce
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:02:10,178'); seek(130.0)">
              the time that a research department needs to identify and
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:02:13,772'); seek(133.0)">
              catalog an object. But before we even
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:02:17,196'); seek(137.0)">
              think of that, the first thing that we had to identify is a
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:20,828'); seek(140.0)">
              suitable, well cataloged collection that will become
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:24,464'); seek(144.0)">
              the prototype candidate. So that candidate was
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:28,272'); seek(148.0)">
              the roman provincial coinage. Digital collection. This is a
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:31,584'); seek(151.0)">
              world renowned research project in numinastics.
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:34,930'); seek(154.0)">
              The team included a curator with previous experience in
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:38,708'); seek(158.0)">
              developing digital collections from the ground up. This person is
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:42,372'); seek(162.0)">
              Sharon Meirat. He's the curator for the Herberdin coin room
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:46,216'); seek(166.0)">
              in the Ashmolian Museum. So the first step in
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:49,768'); seek(169.0)">
              any machine learning project is to decide what you
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:02:53,032'); seek(173.0)">
              want to predict. In this case, Anshanesh Babu, who is
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:02:57,176'); seek(177.0)">
              the system architect and network manager
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:03:00,798'); seek(180.0)">
              from clan, wanted to predict a very simple outcome.
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:03:04,730'); seek(184.0)">
              Heads or tails. That is, is the specimen
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:03:08,258'); seek(188.0)">
              that I have in front of me that I'm looking at. This photograph is that
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:03:11,968'); seek(191.0)">
              of the overs or the reverse of a coin,
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:15,230'); seek(195.0)">
              which is another way of saying that given a known training data,
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:19,550'); seek(199.0)">
              can we have a machine learning solution? Predict the right side of a coin
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:22,922'); seek(202.0)">
              with a high degree of a crest. So now
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:26,324'); seek(206.0)">
              that we have the why we want to do this,
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:29,828'); seek(209.0)">
              let's move into what are the actual things that
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:33,604'); seek(213.0)">
              we want to solve for. So this is the moment when the Ashmore
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:37,342'); seek(217.0)">
              Museum came to AWS and together we started discussing
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:41,198'); seek(221.0)">
              what is a normal day for the
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:44,744'); seek(224.0)">
              people who are working at this museums, what care, the challenges that they are facing?
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:48,258'); seek(228.0)">
              What are the limitations and constraints that they have.
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:03:51,788'); seek(231.0)">
              So we knew from before, the Asmonian Museum has built the world's largest
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:03:55,346'); seek(235.0)">
              digital collection of roman provincial coinage that is open to
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:03:59,088'); seek(239.0)">
              anyone to browse online for free. Now,
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:04:01,952'); seek(241.0)">
              getting an item into this collection requires expert input
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:04:06,118'); seek(246.0)">
              from curators, but these people are highly skilled
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:04:09,718'); seek(249.0)">
              and very care, making this task very difficult to
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:13,552'); seek(253.0)">
              escape. So the way that this works is that, for example,
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:17,028'); seek(257.0)">
              you may have a multitude of physical specimens and you want
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:20,548'); seek(260.0)">
              to catalog them. AWS items. Maybe the item that you
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:23,988'); seek(263.0)">
              want to catalog this for already exists in the collections and
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:27,608'); seek(267.0)">
              this is just another specimen to that item. Or maybe
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:31,224'); seek(271.0)">
              the item is completely new to these digital collection. Some cases
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:35,438'); seek(275.0)">
              you may have all the information available for these specimen,
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:38,658'); seek(278.0)">
              or maybe in some other cases, you may lack some other
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:42,364'); seek(282.0)">
              information. Also, something that might happen is that
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:04:45,980'); seek(285.0)">
              other research institutions, or maybe even individuals might reach
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:04:49,868'); seek(289.0)">
              out to these ashmolian museum with the simple question, look,
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:04:53,552'); seek(293.0)">
              we have this item. Do you know what it is? And the
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:04:57,088'); seek(297.0)">
              answer to this question is at times very complex
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:05:01,650'); seek(301.0)">
              because of the sheer volume of items that need to
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:05:05,188'); seek(305.0)">
              be processed. Oftentimes, groups of
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:08,708'); seek(308.0)">
              people who want to help out. The mission of the university volunteers
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:13,182'); seek(313.0)">
              to help out with this task. But normally,
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:17,102'); seek(317.0)">
              because of the way that this is established, in some cases,
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:20,782'); seek(320.0)">
              even the most simple task cannot be accomplished
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:25,270'); seek(325.0)">
              by a single person or a small group of individuals.
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:28,802'); seek(328.0)">
              Right? When I mean task, I mean getting a specimen
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:32,674'); seek(332.0)">
              and identifying the right item that this specimen belongs to.
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:36,924'); seek(336.0)">
              So what we wanted to do is not automate this
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:40,992'); seek(340.0)">
              task, but augment the humans behind it.
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:05:44,320'); seek(344.0)">
              Build tools that can support these people who
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:05:48,032'); seek(348.0)">
              are working with this every day in a way that they can focus on
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:05:51,732'); seek(351.0)">
              more relevant tasks, avoiding, for example,
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:05:54,724'); seek(354.0)">
              spending hours and hours rotating photos so that
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:05:58,628'); seek(358.0)">
              they are aligned perfectly before they move to the next task.
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:06:02,610'); seek(362.0)">
              In this case, these customer objective is to reduce the
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:06,248'); seek(366.0)">
              time that it takes for the correct appraisal of a single specimen.
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:10,446'); seek(370.0)">
              Currently, these is estimated between 10 minutes and several hours
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:14,360'); seek(374.0)">
              for each item. You can imagine that you get an item
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:18,066'); seek(378.0)">
              and you want to spend some time corroborating
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:22,370'); seek(382.0)">
              that the information that you have at hand that is available matches the
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:26,188'); seek(386.0)">
              one that you have in the collection. And if it doesn't match,
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:29,232'); seek(389.0)">
              then you need to figure out what is that missing
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:32,598'); seek(392.0)">
              information. And for this, you can have a
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:06:36,592'); seek(396.0)">
              multitude of combinations, making this exponentially
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:06:40,358'); seek(400.0)">
              difficult when you have items that are not
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:06:43,860'); seek(403.0)">
              the standard ones. Right? So the difficult items will require
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:06:47,866'); seek(407.0)">
              an enormous amount of time, and normally they
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:06:51,748'); seek(411.0)">
              will require an expert who is very
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:06:55,016'); seek(415.0)">
              scars. These sense. So let's take deep into what
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:06:59,432'); seek(419.0)">
              we are talking about. So, these are two screenshots from
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:07:03,032'); seek(423.0)">
              the digital collection. The image that you see on the left are
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:07:06,504'); seek(426.0)">
              three items. So three coins.
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:10,410'); seek(430.0)">
              And you can see that we have the overs and the rivers on the left.
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:13,804'); seek(433.0)">
              And then we have information on the right, where you
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:17,228'); seek(437.0)">
              can see, for example, the inscription that is written on the
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:20,684'); seek(440.0)">
              overs and the rivers, the city that belongs to the region,
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:24,102'); seek(444.0)">
              these province, even the person that is in the
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:27,472'); seek(447.0)">
              image. Now, the item that you see on the left, on the right.
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:07:30,800'); seek(450.0)">
              Care different specimens to this same item,
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:07:34,634'); seek(454.0)">
              right. So you can see how the quality of the specimen varies
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:07:39,170'); seek(459.0)">
              in a big way. These, what you can see, care four
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:07:42,580'); seek(462.0)">
              photos of the same coins. So you can see
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:07:45,848'); seek(465.0)">
              that we have a very high quality on the left, where we can
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:07:50,470'); seek(470.0)">
              figure out the text that is written. We can very
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:07:54,152'); seek(474.0)">
              easily figure out the person. But then when we look at examples
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:07:58,222'); seek(478.0)">
              like the ones that are in the middle, right, in the top and the bottom,
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:08:02,330'); seek(482.0)">
              we are having a pretty difficult time discerning what is what in this picture.
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:08:06,210'); seek(486.0)">
              So when you're presented with an item like this and you have to match it
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:09,660'); seek(489.0)">
              to the image on the left, this quickly becomes a very difficult task.
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:13,510'); seek(493.0)">
              So this comes back to the question, can we use machine learning to
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:17,168'); seek(497.0)">
              solve this? Why? So now we know the why. We know
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:20,548'); seek(500.0)">
              the what. Now let's move at how did we
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:24,228'); seek(504.0)">
              solve this? So these
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:08:28,228'); seek(508.0)">
              first thing that you can see is that these images,
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:08:32,650'); seek(512.0)">
              right? So let's take the image on the right doesn't
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:08:36,126'); seek(516.0)">
              quite look the same as this image.
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:08:39,406'); seek(519.0)">
              So this one on the left, for example, this has been taken with a professional
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:08:43,518'); seek(523.0)">
              equipment, has been taken without a background.
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:08:46,850'); seek(526.0)">
              So you can see that the illumination is very constant. You can see that
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:08:50,220'); seek(530.0)">
              this is very high resolution, and there's also
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:08:53,900'); seek(533.0)">
              no blurriness, and everything is on focus.
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:08:57,420'); seek(537.0)">
              So this is not always the case, especially when we get
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:09:00,960'); seek(540.0)">
              images. The Ashmore museum gets images that belong to
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:09:04,592'); seek(544.0)">
              individuals or other research institutions who might not have the same
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:09:08,656'); seek(548.0)">
              researchers for capturing this information. So some
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:11,988'); seek(551.0)">
              of the technical challenges that
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:15,924'); seek(555.0)">
              we can face is that first, the image will be very low
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:09:19,412'); seek(559.0)">
              resolution. For example, let's say you take it with a smartphone,
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:09:23,270'); seek(563.0)">
              maybe it's blurry or noisy. There is also a
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:09:26,808'); seek(566.0)">
              very inconsistent illumination across the image, so some
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:09:30,552'); seek(570.0)">
              areas might be darker than others. Also,
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:09:33,832'); seek(573.0)">
              the physical condition of the coin might be that the coin might be highly deteriorated,
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:09:38,322'); seek(578.0)">
              right? So this will play against actually
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:09:42,268'); seek(582.0)">
              finding out similar items. And also, the problem itself is
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:09:46,108'); seek(586.0)">
              very hard because we are talking about coins or objects that
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:09:49,868'); seek(589.0)">
              are more than 2000 years old in some cases. So in
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:09:53,248'); seek(593.0)">
              short, photos that are taken by non museum personnel look
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:09:56,672'); seek(596.0)">
              very different than images within the digital collection,
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:10:00,430'); seek(600.0)">
              making visual search very challenged. So the way that we thought about
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:10:03,652'); seek(603.0)">
              this is that we should first split the task into two.
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:10:07,924'); seek(607.0)">
              First, one is let's improve the base image quality and let's
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:10:11,722'); seek(611.0)">
              make this coin look as much as possible to
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:10:16,308'); seek(616.0)">
              look as similar as possible to the one that we have in these
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:10:19,768'); seek(619.0)">
              digital collection. Right? So we want to. For example, in this case, we have
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:10:23,304'); seek(623.0)">
              a blurry background, we have a rotation, we have low resolution.
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:10:26,622'); seek(626.0)">
              So we want to account for all of those things and create
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:10:29,932'); seek(629.0)">
              an image that is very similar to the ones on the right. Once we have
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:10:33,308'); seek(633.0)">
              this image, we can extract features out of it
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:10:36,844'); seek(636.0)">
              and search in the collection to bring back the most similarly
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:10:40,118'); seek(640.0)">
              looking items. So this is an example of
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:10:43,776'); seek(643.0)">
              what we're doing here. You can see that we are detecting
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:10:47,174'); seek(647.0)">
              the shape of the coin and then we
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:10:50,528'); seek(650.0)">
              care coins, all of these activities at the same time,
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:10:53,476'); seek(653.0)">
              right? So we are removing the background, we are rotating
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:10:57,274'); seek(657.0)">
              these image, and then we are also increased the resolution
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:11:00,778'); seek(660.0)">
              of this image. So that way we have the item on the right,
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:11:04,484'); seek(664.0)">
              which is more similar than the image that we had on the left.
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:11:07,848'); seek(667.0)">
              Once we had this image on the right,
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:11:11,990'); seek(671.0)">
              we come back to this metadata that we have also extracted
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:11:15,438'); seek(675.0)">
              from the image, right? So we know if the image is heads on tails
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:11:19,906'); seek(679.0)">
              or tails with a 95% aggressive. So we know that
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:11:23,692'); seek(683.0)">
              in this case, we are looking at the overs of a coin and we can
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:11:27,420'); seek(687.0)">
              scan through all the images in the collection,
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:11:30,850'); seek(690.0)">
              but only at the overs. We don't need to look at the back aws well,
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:11:34,800'); seek(694.0)">
              and we can also use this other
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:11:38,032'); seek(698.0)">
              information, like, for example, the material, the region, the city,
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:11:41,844'); seek(701.0)">
              the province, and the person who is at the coin to make the
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:11:45,972'); seek(705.0)">
              task of identifying this item easier. So with this,
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:11:50,020'); seek(710.0)">
              let's move to a very quick demo of what this
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:11:54,004'); seek(714.0)">
              proof of concept was. And just
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:11:57,576'); seek(717.0)">
              have to say that this demo has been produced more than a year ago.
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:12:02,470'); seek(722.0)">
              There is a new open source solution that is in the works.
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:12:05,910'); seek(725.0)">
              It's not going to be restricted only to coins, but rather any collections
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:12:09,906'); seek(729.0)">
              object that you will have either physical or digital,
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:12:12,738'); seek(732.0)">
              say gems or fossils. Any object
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:12:16,220'); seek(736.0)">
              with the idea, the care concept that you want to visually search for
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:12:20,512'); seek(740.0)">
              similar items inside a collection. If you're interested in something
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:12:24,416'); seek(744.0)">
              like this, keep posted to this video. We're going to add
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:12:28,656'); seek(748.0)">
              any news that come out. Anything that
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:12:32,468'); seek(752.0)">
              is released will be added in the comments below this
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:12:35,668'); seek(755.0)">
              video. So with this, this is a web application created
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:12:39,802'); seek(759.0)">
              using streamlip and show you.
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:12:43,204'); seek(763.0)">
              So the idea for this is that we can interact with these models
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:12:47,454'); seek(767.0)">
              that we have created in a way that we can,
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:12:51,352'); seek(771.0)">
              for example, upload a picture. This case, the first thing that we
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:12:54,648'); seek(774.0)">
              want to do is either choose an example from a library or
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:12:58,680'); seek(778.0)">
              upload a picture. In this case, we choose the image that we saw before.
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:13:02,332'); seek(782.0)">
              Blurry background, image rotated, low resolution.
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:13:05,954'); seek(785.0)">
              So what we want to do is first find a region of interest
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:13:09,708'); seek(789.0)">
              out of this image, remove the background, auto rotate it,
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:13:13,040'); seek(793.0)">
              and these finally apply some deep blur and upscaling to
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:13:16,768'); seek(796.0)">
              the image. So once we have finished this and this is all
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:13:20,288'); seek(800.0)">
              happening in real time, you will have this image.
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:13:24,610'); seek(804.0)">
              That is the output of this process.
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:13:27,956'); seek(807.0)">
              Once we have this, we want to extract also metadata
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:13:32,610'); seek(812.0)">
              out of this image, right? So for example,
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:13:37,510'); seek(817.0)">
              is the overs, who is the person
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:13:40,600'); seek(820.0)">
              that is in the image? What is the material that this coin is made
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:13:44,152'); seek(824.0)">
              of? What is the reason that this belongs to? And so on.
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:13:48,010'); seek(828.0)">
              Once we have this metadata, we care going to use the features that
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:13:51,932'); seek(831.0)">
              we have extracted out of this image. So this is,
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:13:57,210'); seek(837.0)">
              for example, the faces, the eyes,
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:14:00,732'); seek(840.0)">
              the way that these are placed in the image. We care going to use this
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:14:04,048'); seek(844.0)">
              to look inside our collection. And you can see that we are
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:14:08,128'); seek(848.0)">
              going to come back with eight results that
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:14:12,692'); seek(852.0)">
              are similar to the image that we are looking for. So in
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:14:15,988'); seek(855.0)">
              this case, volunteers, for example,
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:14:19,170'); seek(859.0)">
              doesn't have to go through thousands of images. They only
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:14:22,388'); seek(862.0)">
              have to focus on eight images. And they also have information
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:14:26,052'); seek(866.0)">
              that can point them in the right direction. Right. So they have
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:14:29,688'); seek(869.0)">
              the region, the person who is in the picture, and also they
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:14:32,968'); seek(872.0)">
              have similar items. So maybe when they see an item that
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:14:37,032'); seek(877.0)">
              already exists, this is just another specimen, they can quickly
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:14:40,970'); seek(880.0)">
              attach this to that one. So what are the benefits of using
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:14:44,860'); seek(884.0)">
              aws for dash model? So the first one is that this is very quick and
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:14:48,428'); seek(888.0)">
              easy experimentation. They built and deploy eleven machine learning models in about ten weeks.
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:14:52,848'); seek(892.0)">
              There's a smaller workload, right. So you can imagine that saving
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:14:56,800'); seek(896.0)">
              up minutes of every task in a
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:14:59,984'); seek(899.0)">
              pipeline. In the end, when you have a large volume of
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:15:04,450'); seek(904.0)">
              items that you have to digitalize they adapt to a lot of time.
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:15:07,652'); seek(907.0)">
              In this case, it's estimated that they will save up to three years
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:15:11,300'); seek(911.0)">
              of work cataloging a collection of 300,000 coins.
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:15:15,338'); seek(915.0)">
              Less time. The coin analysis is expected to take just
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:15:18,552'); seek(918.0)">
              a few minutes versus times that are ranging from 10
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:15:21,832'); seek(921.0)">
              minutes to maybe hours. And also more value, right?
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:15:25,128'); seek(925.0)">
              So this is complementing the work that is already being carried out
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:15:28,428'); seek(928.0)">
              by volunteers. This is not automating anything, this is augmenting
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:15:32,970'); seek(932.0)">
              the people, the humans who are behind this.
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:15:36,252'); seek(936.0)">
              So these are some quotes of this. I thought this project
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:15:39,692'); seek(939.0)">
              would be complex and time consuming, but using Aws made it easy.
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:15:43,870'); seek(943.0)">
              Another one, this comes from Jerome. Now we
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:15:46,944'); seek(946.0)">
              can focus our volunteers on other steps that add value machine learning process
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:15:50,960'); seek(950.0)">
              improves the workflow and productivity and adds value for the public.
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:15:55,108'); seek(955.0)">
              With this, let's have a look at this very small task
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:15:58,906'); seek(958.0)">
              as an example. We want to remove the background of this, right?
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:16:01,956'); seek(961.0)">
              And we are going to see in one of the examples how we can do
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:16:04,408'); seek(964.0)">
              this actually technically.
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:16:07,910'); seek(967.0)">
              And doing this doesn't have to be all
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:16:11,752'); seek(971.0)">
              done by yourself. For example, there are some solutions available
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:16:15,944'); seek(975.0)">
              in the marketplace that you can use an out of the box,
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:16:19,580'); seek(979.0)">
              right, for background removal. And in this case, this one,
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:16:22,908'); seek(982.0)">
              for example, at this time you have a price for every API call and you
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:16:26,828'); seek(986.0)">
              can just subscribe to this one. So if you have images that you
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:16:30,048'); seek(990.0)">
              want to remove this background for, then you will just subscribe
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:16:33,302'); seek(993.0)">
              to this API and then just run them through this
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:16:38,240'); seek(998.0)">
              service right through this endpoint. Another way that you can do it is of course
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:16:41,872'); seek(1001.0)">
              you can build your own algorithm. And we're going to see an example
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:16:45,460'); seek(1005.0)">
              actually out of this, where you pick up, for example,
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:16:48,850'); seek(1008.0)">
              this data set that is an image segmentation data
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:16:52,212'); seek(1012.0)">
              set, open images, and you have more than 600 classes
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:16:55,934'); seek(1015.0)">
              where these segmentation masks are available. Then you
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:16:59,528'); seek(1019.0)">
              use an algorithm. In this case you're
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:17:02,638'); seek(1022.0)">
              using mask or CNN. And we can use different machine learning
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:17:05,900'); seek(1025.0)">
              frameworks, Pytorch, Tensorflow, Mxnet, together with
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:17:10,252'); seek(1030.0)">
              Sagemaker and different ways of doing training.
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:17:14,330'); seek(1034.0)">
              So with this you can build also very
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:17:17,868'); seek(1037.0)">
              easily, you can build your own custom pipeline. These shows us some resources.
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:17:22,242'); seek(1042.0)">
              I'm going to add these to the description of the video anyway,
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:17:25,664'); seek(1045.0)">
              but just to give you an idea of other things that you can do,
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:17:29,970'); seek(1049.0)">
              there is a recent collaboration between hiringface and Sagemaker
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:17:33,978'); seek(1053.0)">
              that is very useful. It's very robust,
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:17:37,002'); seek(1057.0)">
              secure, and also I
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:17:40,852'); seek(1060.0)">
              added some documents and repositories for
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:17:45,030'); seek(1065.0)">
              deploying your very own web application for machine
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:17:49,118'); seek(1069.0)">
              learning. So with that, I'm coins to actually change the
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:17:52,728'); seek(1072.0)">
              focus to the second bit of the presentation.
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:17:56,578'); seek(1076.0)">
              And I'm going to move to this one. Okay,
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:18:01,290'); seek(1081.0)">
              so now we want to explore these idea of
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:18:04,924'); seek(1084.0)">
              building your own machine learning solution,
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:18:07,714'); seek(1087.0)">
              right? So we want to build the same thing. How can we do,
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:18:12,190'); seek(1092.0)">
              we want to create these heads versus tails model
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:18:15,760'); seek(1095.0)">
              the classifier. We want to remove the background and also we want to visually search
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:18:19,600'); seek(1099.0)">
              these images in a collection. So how can we do it? Okay, so let's
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:18:23,542'); seek(1103.0)">
              focus first on the first one. Okay, so image classification.
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:18:27,410'); seek(1107.0)">
              So for that one, I'm going to show you now,
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:18:30,050'); seek(1110.0)">
              Sagemaker Studio. This is an end to end platform
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:18:34,260'); seek(1114.0)">
              for machine learning from AWS. In this case, I'm not
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:18:37,688'); seek(1117.0)">
              going to go into a lot of detail about what thing
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:18:41,096'); seek(1121.0)">
              does what or anything like that,
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:18:44,310'); seek(1124.0)">
              but I'm going to show you that there is something called
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:18:48,060'); seek(1128.0)">
              Shamstat. And what is that? Basically when you click
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:18:51,356'); seek(1131.0)">
              here, let's take the first one. Right? So model popular image
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:18:54,898'); seek(1134.0)">
              classification based on. Okay, so that's exactly what we want to do. We want
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:18:58,064'); seek(1138.0)">
              to build an image classifier. Let's do some more exploration.
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:19:01,974'); seek(1141.0)">
              Okay, so when we explore it, you see that,
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:19:05,984'); seek(1145.0)">
              for example, I particularly like this architecture.
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:19:09,750'); seek(1149.0)">
              Efficient. Net has a very good performance.
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:19:13,834'); seek(1153.0)">
              And you can see how you have different versions of this
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:19:17,444'); seek(1157.0)">
              available out of the box. So these one are feature
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:19:21,386'); seek(1161.0)">
              vector extractor. Right. And we'll get to
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:19:25,048'); seek(1165.0)">
              why this is important in a second. But just
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:19:28,856'); seek(1168.0)">
              keep them in mind for now. What we want to choose this is we
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:19:32,712'); seek(1172.0)">
              want to choose the biggest variation, the b seven,
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:19:36,284'); seek(1176.0)">
              these most performant, and we want to use these for our
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:19:40,348'); seek(1180.0)">
              model. So once you click these and you have selected
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:19:44,002'); seek(1184.0)">
              these model or these,
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:19:47,710'); seek(1187.0)">
              then we can either deploy
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:19:51,366'); seek(1191.0)">
              the version that is available without any changes.
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:19:55,390'); seek(1195.0)">
              This model has been trained with imagenet.
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:19:58,518'); seek(1198.0)">
              So let's go back for a second. So we have this.
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:20:02,580'); seek(1202.0)">
              What is this? So this is jumpstart is a repository of
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:20:06,340'); seek(1206.0)">
              solutions and models that you can quickly
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:20:10,356'); seek(1210.0)">
              deploy with one click. In this case,
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:20:14,450'); seek(1214.0)">
              we want to look at vision models and we want to look at
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:20:17,912'); seek(1217.0)">
              solving the task image classification, right. So we
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:20:21,688'); seek(1221.0)">
              also have the data set that this model has been trained on
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:20:25,752'); seek(1225.0)">
              and we know if the model is fine tunable or
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:20:29,148'); seek(1229.0)">
              not. This case it is. Right? So the same as this
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:20:33,068'); seek(1233.0)">
              model that we have here. So how can you fine
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:20:36,508'); seek(1236.0)">
              tune it? Well, you just go here to fine tune
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:20:39,698'); seek(1239.0)">
              model. You choose the data source and you find your s
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:20:43,328'); seek(1243.0)">
              three buck. You choose it, choose the directory name where you have it and
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:20:47,168'); seek(1247.0)">
              then you can choose the instance that you want to use to
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:20:50,528'); seek(1250.0)">
              train and then the parameters that you want to use and
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:20:54,548'); seek(1254.0)">
              you will train it. And once this is trained, you can deploy it
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:20:57,988'); seek(1257.0)">
              as an endpoint and use this model for inference.
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:21:01,730'); seek(1261.0)">
              So how should you position your data?
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:21:05,330'); seek(1265.0)">
              So you would have your input directory.
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:21:08,430'); seek(1268.0)">
              This is the s three bucket that we were talking about before. And these you
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:21:11,368'); seek(1271.0)">
              will have two folders. First one will be the overs and then
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:21:15,064'); seek(1275.0)">
              you will have your examples and then you will have the reverse.
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:21:18,802'); seek(1278.0)">
              Right, an example. And with that you don't have to
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:21:22,364'); seek(1282.0)">
              do anything else. You can directly train it from this
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:21:26,556'); seek(1286.0)">
              screen. Once this is trained and deployed,
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:21:30,130'); seek(1290.0)">
              you can deploy it. And what you're going to see is something like this.
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:21:33,696'); seek(1293.0)">
              So you can see that this takes around 10 minutes
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:21:37,648'); seek(1297.0)">
              maybe to deploy or even less than that. This is using
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:21:41,360'); seek(1301.0)">
              a CPU instance in this case. So you don't have to worry about
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:21:45,172'); seek(1305.0)">
              GPU or CPU. You can use both.
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:21:48,690'); seek(1308.0)">
              And you have an endpoint, you have a notebook that will
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:21:52,660'); seek(1312.0)">
              show you how you can
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:21:56,248'); seek(1316.0)">
              use this,
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:21:59,430'); seek(1319.0)">
              how you can use this endpoint,
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:22:03,118'); seek(1323.0)">
              right? So this one you see that we have two pictures.
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:22:06,862'); seek(1326.0)">
              In this case we are using the original
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:22:10,578'); seek(1330.0)">
              model. So the only thing that it has to do is pick up
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:22:13,772'); seek(1333.0)">
              that this is a cat and a dog. And then you can see here
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:22:17,580'); seek(1337.0)">
              top five model predictions or tabby, et cetera and so on.
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:22:20,992'); seek(1340.0)">
              Top five model, et cetera. If you were using your
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:22:24,448'); seek(1344.0)">
              own model, these classes
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:22:27,782'); seek(1347.0)">
              will have been drivers and overs,
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:22:31,590'); seek(1351.0)">
              right. So with that, let's actually move to
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:22:34,996'); seek(1354.0)">
              the second model that we want to do. So we finish
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:22:38,452'); seek(1358.0)">
              an image classifier and now we want to move to a segmentation model.
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:22:42,580'); seek(1362.0)">
              We want to remove the background. So you
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:22:47,368'); seek(1367.0)">
              can use your own segmentation
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:22:51,662'); seek(1371.0)">
              model or you can just check other solutions
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:22:55,906'); seek(1375.0)">
              that are open and available. So this is a website
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:22:59,292'); seek(1379.0)">
              that I really like, papers with code. The task
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:23:03,330'); seek(1383.0)">
              that we want to solve for is saliency detection.
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:23:07,710'); seek(1387.0)">
              And you can see that you also have here
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:23:10,992'); seek(1390.0)">
              available things like YouTube
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:23:15,078'); seek(1395.0)">
              net. This one is very successful at detecting background
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:23:19,734'); seek(1399.0)">
              and removing it. So choosing the most important object in the
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:23:23,028'); seek(1403.0)">
              image and these removing the background. So this
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:23:26,628'); seek(1406.0)">
              is also something that you can use with Sagemaker and then deploy
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:23:30,298'); seek(1410.0)">
              it as an endpoint. Because we want to build something
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:23:33,752'); seek(1413.0)">
              that is very custom.
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:23:37,990'); seek(1417.0)">
              We care going to go through a different route and we care going to use
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:23:43,430'); seek(1423.0)">
              an open data set, in this case these open image
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:23:46,798'); seek(1426.0)">
              data set. We're going to look for coin, but it can be other things
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:23:50,172'); seek(1430.0)">
              as well. And you can see that we have here
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:23:54,108'); seek(1434.0)">
              the segmentation mask and they are available. So we are going to use this
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:23:57,740'); seek(1437.0)">
              segmentation mask to train our model. So for
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:24:01,712'); seek(1441.0)">
              this we're going to use this repo that we
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:24:05,328'); seek(1445.0)">
              have here. I'm going to put these, this is in the links that are available
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:24:08,960'); seek(1448.0)">
              in the presentation and will be made available, the description of
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:24:13,376'); seek(1453.0)">
              the video. And I'm just going to walk you through some of the steps
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:24:17,226'); seek(1457.0)">
              that we want to do this, you want to do here. So we're
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:24:20,698'); seek(1460.0)">
              going to use custom library that is called Ice vision. This is
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:24:24,616'); seek(1464.0)">
              built on top of Pytorch and it's on top of Pytorch lightning
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:24:28,542'); seek(1468.0)">
              and also fast AI.
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:24:31,726'); seek(1471.0)">
              So it uses both things for training. And at
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:24:35,528'); seek(1475.0)">
              the same time it has available many,
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:24:38,076'); seek(1478.0)">
              many algorithms out of the box. So for example,
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:24:41,740'); seek(1481.0)">
              factor CNN or Mascar CNN. So this is these thing that I'm
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:24:45,234'); seek(1485.0)">
              going to be using for training in this session.
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:24:49,870'); seek(1489.0)">
              So the first thing that we want to do is we want to
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:24:53,088'); seek(1493.0)">
              download that data set and all the
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:24:56,928'); seek(1496.0)">
              images, but only for the class coin,
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:25:01,466'); seek(1501.0)">
              right? There are more than 600 classes available,
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:25:05,188'); seek(1505.0)">
              but we only want to use this one coin.
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:25:08,370'); seek(1508.0)">
              And 600 are these, these are the 600
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:25:12,260'); seek(1512.0)">
              like person, piano, et cetera and so on. So we only want
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:25:15,832'); seek(1515.0)">
              to train this model on coins.
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:25:19,190'); seek(1519.0)">
              Okay, so the first thing that we do, we download the data and
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:25:23,384'); seek(1523.0)">
              extract these images and the segmentation mask, we save them
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:25:27,068'); seek(1527.0)">
              locally and then we convert these annotations because originally
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:25:31,506'); seek(1531.0)">
              they use one vocabulary for this
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:25:35,452'); seek(1535.0)">
              annotation and we want to move it to another one. So we move it from
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:25:38,716'); seek(1538.0)">
              something that is called Pascal to another one that is called cocoa.
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:25:42,102'); seek(1542.0)">
              Common objects in comma. So once we do
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:25:45,328'); seek(1545.0)">
              this, we upload the data with this one
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:25:49,232'); seek(1549.0)">
              line of code, right? We upload the data to a string,
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:25:53,226'); seek(1553.0)">
              which is our object storage, storage.
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:25:57,650'); seek(1557.0)">
              And we define what
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:26:01,588'); seek(1561.0)">
              are the resources that we want to use for training. This case we want to
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:26:05,288'); seek(1565.0)">
              use CPU instance. So we use this, these p, three,
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:26:08,216'); seek(1568.0)">
              two, x large. And I'm not going to use a spot,
            </span>
            
            <span id="chunk-417" class="transcript-chunks" onclick="console.log('00:26:11,630'); seek(1571.0)">
              but you can think about spot as a way for going
            </span>
            
            <span id="chunk-418" class="transcript-chunks" onclick="console.log('00:26:16,652'); seek(1576.0)">
              into an auction for unused compute capacity.
            </span>
            
            <span id="chunk-419" class="transcript-chunks" onclick="console.log('00:26:20,250'); seek(1580.0)">
              And you bid for this unused capacity.
            </span>
            
            <span id="chunk-420" class="transcript-chunks" onclick="console.log('00:26:24,146'); seek(1584.0)">
              Normally the savings range from 60% to 90%.
            </span>
            
            <span id="chunk-421" class="transcript-chunks" onclick="console.log('00:26:28,288'); seek(1588.0)">
              So this is whatever the on demand price is,
            </span>
            
            <span id="chunk-422" class="transcript-chunks" onclick="console.log('00:26:31,790'); seek(1591.0)">
              60% to 90% less than on demand price.
            </span>
            
            <span id="chunk-423" class="transcript-chunks" onclick="console.log('00:26:36,080'); seek(1596.0)">
              And the only caveat that you have is that these resources,
            </span>
            
            <span id="chunk-424" class="transcript-chunks" onclick="console.log('00:26:40,598'); seek(1600.0)">
              because you are bidding for them, once someone wants
            </span>
            
            <span id="chunk-425" class="transcript-chunks" onclick="console.log('00:26:44,992'); seek(1604.0)">
              to use on demand researchers, your capacity will be
            </span>
            
            <span id="chunk-426" class="transcript-chunks" onclick="console.log('00:26:48,404'); seek(1608.0)">
              taken away and given to them. So effectively your training will stop.
            </span>
            
            <span id="chunk-427" class="transcript-chunks" onclick="console.log('00:26:53,028'); seek(1613.0)">
              The good thing is that all of this is already taken care of on
            </span>
            
            <span id="chunk-428" class="transcript-chunks" onclick="console.log('00:26:57,288'); seek(1617.0)">
              AWS and you are saving checkpoints as you are
            </span>
            
            <span id="chunk-429" class="transcript-chunks" onclick="console.log('00:27:00,664'); seek(1620.0)">
              moving on with your training. So in this way, if your training
            </span>
            
            <span id="chunk-430" class="transcript-chunks" onclick="console.log('00:27:04,264'); seek(1624.0)">
              suddenly stops, for example, once this
            </span>
            
            <span id="chunk-431" class="transcript-chunks" onclick="console.log('00:27:08,108'); seek(1628.0)">
              compute capacity becomes available again, you can start using
            </span>
            
            <span id="chunk-432" class="transcript-chunks" onclick="console.log('00:27:11,916'); seek(1631.0)">
              it one more time. So I would recommend you to use
            </span>
            
            <span id="chunk-433" class="transcript-chunks" onclick="console.log('00:27:15,692'); seek(1635.0)">
              these things because with only three lines of code you
            </span>
            
            <span id="chunk-434" class="transcript-chunks" onclick="console.log('00:27:19,408'); seek(1639.0)">
              can save maybe from 60% to 90% of the cost.
            </span>
            
            <span id="chunk-435" class="transcript-chunks" onclick="console.log('00:27:23,360'); seek(1643.0)">
              So once we
            </span>
            
            <span id="chunk-436" class="transcript-chunks" onclick="console.log('00:27:26,928'); seek(1646.0)">
              have set up that configuration,
            </span>
            
            <span id="chunk-437" class="transcript-chunks" onclick="console.log('00:27:29,942'); seek(1649.0)">
              we go here and we create something that is
            </span>
            
            <span id="chunk-438" class="transcript-chunks" onclick="console.log('00:27:33,088'); seek(1653.0)">
              called an estimator, right? And we take our
            </span>
            
            <span id="chunk-439" class="transcript-chunks" onclick="console.log('00:27:36,996'); seek(1656.0)">
              train script which is this one,
            </span>
            
            <span id="chunk-440" class="transcript-chunks" onclick="console.log('00:27:39,970'); seek(1659.0)">
              the source directory where everything is.
            </span>
            
            <span id="chunk-441" class="transcript-chunks" onclick="console.log('00:27:43,590'); seek(1663.0)">
              Let me show you this case. It's only two files,
            </span>
            
            <span id="chunk-442" class="transcript-chunks" onclick="console.log('00:27:46,942'); seek(1666.0)">
              requires TXT and train and we pass
            </span>
            
            <span id="chunk-443" class="transcript-chunks" onclick="console.log('00:27:51,048'); seek(1671.0)">
              arguments parameters to these
            </span>
            
            <span id="chunk-444" class="transcript-chunks" onclick="console.log('00:27:54,152'); seek(1674.0)">
              training shop. So what this is going to do effectively is create a container
            </span>
            
            <span id="chunk-445" class="transcript-chunks" onclick="console.log('00:27:58,386'); seek(1678.0)">
              new, different from what you're seeing here. Another instance only
            </span>
            
            <span id="chunk-446" class="transcript-chunks" onclick="console.log('00:28:02,396'); seek(1682.0)">
              for this task and you will only have to pay for the amount
            </span>
            
            <span id="chunk-447" class="transcript-chunks" onclick="console.log('00:28:06,252'); seek(1686.0)">
              of time that you've been training, not more than
            </span>
            
            <span id="chunk-448" class="transcript-chunks" onclick="console.log('00:28:09,568'); seek(1689.0)">
              that. So with that you can see that we
            </span>
            
            <span id="chunk-449" class="transcript-chunks" onclick="console.log('00:28:15,552'); seek(1695.0)">
              create this estimator and then we fit to the data that
            </span>
            
            <span id="chunk-450" class="transcript-chunks" onclick="console.log('00:28:18,928'); seek(1698.0)">
              we had. So inputs, this is the data that we downloaded and
            </span>
            
            <span id="chunk-451" class="transcript-chunks" onclick="console.log('00:28:22,768'); seek(1702.0)">
              then uploaded to s three. And after some time
            </span>
            
            <span id="chunk-452" class="transcript-chunks" onclick="console.log('00:28:26,116'); seek(1706.0)">
              this is going to finish and it's going to tell us that
            </span>
            
            <span id="chunk-453" class="transcript-chunks" onclick="console.log('00:28:29,652'); seek(1709.0)">
              it was successful. Of course you can also track this if
            </span>
            
            <span id="chunk-454" class="transcript-chunks" onclick="console.log('00:28:33,188'); seek(1713.0)">
              you go to the AWS console and you
            </span>
            
            <span id="chunk-455" class="transcript-chunks" onclick="console.log('00:28:36,648'); seek(1716.0)">
              can see the shops here for example, you can see
            </span>
            
            <span id="chunk-456" class="transcript-chunks" onclick="console.log('00:28:40,808'); seek(1720.0)">
              how much this training took. This is around 22 minutes and we were
            </span>
            
            <span id="chunk-457" class="transcript-chunks" onclick="console.log('00:28:44,792'); seek(1724.0)">
              charged for 22 minutes. If we were using spot instances
            </span>
            
            <span id="chunk-458" class="transcript-chunks" onclick="console.log('00:28:50,570'); seek(1730.0)">
              we would have had reduction of
            </span>
            
            <span id="chunk-459" class="transcript-chunks" onclick="console.log('00:28:54,092'); seek(1734.0)">
              around 70% of the cost in this case. So once this
            </span>
            
            <span id="chunk-460" class="transcript-chunks" onclick="console.log('00:28:58,316'); seek(1738.0)">
              is finished training we want to deploy this model and
            </span>
            
            <span id="chunk-461" class="transcript-chunks" onclick="console.log('00:29:02,032'); seek(1742.0)">
              run our predictions. So for that we can use this other example
            </span>
            
            <span id="chunk-462" class="transcript-chunks" onclick="console.log('00:29:05,904'); seek(1745.0)">
              where what I'm actually doing here is I'm creating a
            </span>
            
            <span id="chunk-463" class="transcript-chunks" onclick="console.log('00:29:10,112'); seek(1750.0)">
              container but I'm running this model,
            </span>
            
            <span id="chunk-464" class="transcript-chunks" onclick="console.log('00:29:13,508'); seek(1753.0)">
              right. So you can see all the steps, just want to show you don't want
            </span>
            
            <span id="chunk-465" class="transcript-chunks" onclick="console.log('00:29:17,188'); seek(1757.0)">
              to stay on the details too much. You can
            </span>
            
            <span id="chunk-466" class="transcript-chunks" onclick="console.log('00:29:21,364'); seek(1761.0)">
              explore this at your own time. But I just want to
            </span>
            
            <span id="chunk-467" class="transcript-chunks" onclick="console.log('00:29:24,728'); seek(1764.0)">
              show you the results of this. You can see that the
            </span>
            
            <span id="chunk-468" class="transcript-chunks" onclick="console.log('00:29:28,888'); seek(1768.0)">
              actual time that it takes for a prediction is quite quick,
            </span>
            
            <span id="chunk-469" class="transcript-chunks" onclick="console.log('00:29:32,120'); seek(1772.0)">
              right. And the quality is quite
            </span>
            
            <span id="chunk-470" class="transcript-chunks" onclick="console.log('00:29:35,592'); seek(1775.0)">
              good right. So we have the image on the left and we only want to
            </span>
            
            <span id="chunk-471" class="transcript-chunks" onclick="console.log('00:29:38,604'); seek(1778.0)">
              pick up one coins. So we pick up the one on the right and you
            </span>
            
            <span id="chunk-472" class="transcript-chunks" onclick="console.log('00:29:41,948'); seek(1781.0)">
              can see how the background has been removed completely
            </span>
            
            <span id="chunk-473" class="transcript-chunks" onclick="console.log('00:29:46,730'); seek(1786.0)">
              and the image is clean. So with
            </span>
            
            <span id="chunk-474" class="transcript-chunks" onclick="console.log('00:29:50,108'); seek(1790.0)">
              that and conscious of time, going to move to the last item today
            </span>
            
            <span id="chunk-475" class="transcript-chunks" onclick="console.log('00:29:54,416'); seek(1794.0)">
              and that is how can we build a visual search engine.
            </span>
            
            <span id="chunk-476" class="transcript-chunks" onclick="console.log('00:29:58,656'); seek(1798.0)">
              And for that we care going to follow this blog post
            </span>
            
            <span id="chunk-477" class="transcript-chunks" onclick="console.log('00:30:02,260'); seek(1802.0)">
              building a visual search application with Amazon,
            </span>
            
            <span id="chunk-478" class="transcript-chunks" onclick="console.log('00:30:04,698'); seek(1804.0)">
              sagemaker and elasticsearch.
            </span>
            
            <span id="chunk-479" class="transcript-chunks" onclick="console.log('00:30:08,050'); seek(1808.0)">
              So basically what we want to do is you have, and this is using
            </span>
            
            <span id="chunk-480" class="transcript-chunks" onclick="console.log('00:30:11,988'); seek(1811.0)">
              an open source data set from clothes fashion.
            </span>
            
            <span id="chunk-481" class="transcript-chunks" onclick="console.log('00:30:15,422'); seek(1815.0)">
              But of course you can think that you can change these
            </span>
            
            <span id="chunk-482" class="transcript-chunks" onclick="console.log('00:30:19,112'); seek(1819.0)">
              things, these images, to the images
            </span>
            
            <span id="chunk-483" class="transcript-chunks" onclick="console.log('00:30:22,718'); seek(1822.0)">
              that you have, for example, coins, right. So what this is going to do is
            </span>
            
            <span id="chunk-484" class="transcript-chunks" onclick="console.log('00:30:26,392'); seek(1826.0)">
              it's going to run a convolutional neural network against
            </span>
            
            <span id="chunk-485" class="transcript-chunks" onclick="console.log('00:30:29,820'); seek(1829.0)">
              these images. It's going to extract these feature vectors. And this is
            </span>
            
            <span id="chunk-486" class="transcript-chunks" onclick="console.log('00:30:33,388'); seek(1833.0)">
              going back to that model, right, that we were talking about,
            </span>
            
            <span id="chunk-487" class="transcript-chunks" onclick="console.log('00:30:36,572'); seek(1836.0)">
              the Shamstad model. Right. So we
            </span>
            
            <span id="chunk-488" class="transcript-chunks" onclick="console.log('00:30:40,812'); seek(1840.0)">
              have this feature vector structure.
            </span>
            
            <span id="chunk-489" class="transcript-chunks" onclick="console.log('00:30:44,658'); seek(1844.0)">
              Right. So we can actually deploy this and
            </span>
            
            <span id="chunk-490" class="transcript-chunks" onclick="console.log('00:30:48,352'); seek(1848.0)">
              we don't have to do any type of custom modeling. We have the model right
            </span>
            
            <span id="chunk-491" class="transcript-chunks" onclick="console.log('00:30:52,196'); seek(1852.0)">
              here. So once we have these vectors,
            </span>
            
            <span id="chunk-492" class="transcript-chunks" onclick="console.log('00:30:56,218'); seek(1856.0)">
              we input all of these vectors into elasticsearch,
            </span>
            
            <span id="chunk-493" class="transcript-chunks" onclick="console.log('00:30:59,658'); seek(1859.0)">
              and then we do something called k nearest
            </span>
            
            <span id="chunk-494" class="transcript-chunks" onclick="console.log('00:31:03,594'); seek(1863.0)">
              neighbors search. So we look at the images
            </span>
            
            <span id="chunk-495" class="transcript-chunks" onclick="console.log('00:31:07,166'); seek(1867.0)">
              that have the lowest distance between them, between the feature vectors
            </span>
            
            <span id="chunk-496" class="transcript-chunks" onclick="console.log('00:31:11,534'); seek(1871.0)">
              from these images and the reference image
            </span>
            
            <span id="chunk-497" class="transcript-chunks" onclick="console.log('00:31:14,798'); seek(1874.0)">
              that we have, right. So if you go through these steps,
            </span>
            
            <span id="chunk-498" class="transcript-chunks" onclick="console.log('00:31:18,730'); seek(1878.0)">
              you will see that clicking here,
            </span>
            
            <span id="chunk-499" class="transcript-chunks" onclick="console.log('00:31:21,596'); seek(1881.0)">
              launch a stack. This is going to open up this
            </span>
            
            <span id="chunk-500" class="transcript-chunks" onclick="console.log('00:31:25,036'); seek(1885.0)">
              screen where basically we just create the resources
            </span>
            
            <span id="chunk-501" class="transcript-chunks" onclick="console.log('00:31:28,898'); seek(1888.0)">
              that you need to run this. So it will create an
            </span>
            
            <span id="chunk-502" class="transcript-chunks" onclick="console.log('00:31:32,912'); seek(1892.0)">
              S three bucket, it will create a sage maker notebook. And then the only
            </span>
            
            <span id="chunk-503" class="transcript-chunks" onclick="console.log('00:31:36,352'); seek(1896.0)">
              thing that you need to do is actually, let me show you,
            </span>
            
            <span id="chunk-504" class="transcript-chunks" onclick="console.log('00:31:39,790'); seek(1899.0)">
              open your notebook that was recently increased,
            </span>
            
            <span id="chunk-505" class="transcript-chunks" onclick="console.log('00:31:43,126'); seek(1903.0)">
              increased. And you care going to be presented with
            </span>
            
            <span id="chunk-506" class="transcript-chunks" onclick="console.log('00:31:48,050'); seek(1908.0)">
              this repo, right. And this repo is this one.
            </span>
            
            <span id="chunk-507" class="transcript-chunks" onclick="console.log('00:31:52,550'); seek(1912.0)">
              Again, the link to this is,
            </span>
            
            <span id="chunk-508" class="transcript-chunks" onclick="console.log('00:31:56,120'); seek(1916.0)">
              you can find it in the description of the video.
            </span>
            
            <span id="chunk-509" class="transcript-chunks" onclick="console.log('00:32:00,070'); seek(1920.0)">
              Let's dive right into it. Right. So we have this image,
            </span>
            
            <span id="chunk-510" class="transcript-chunks" onclick="console.log('00:32:03,806'); seek(1923.0)">
              visual image search. The first thing that we want to do
            </span>
            
            <span id="chunk-511" class="transcript-chunks" onclick="console.log('00:32:07,068'); seek(1927.0)">
              is get these trend data, right. So this is almost 10,000
            </span>
            
            <span id="chunk-512" class="transcript-chunks" onclick="console.log('00:32:11,500'); seek(1931.0)">
              high resolution images. In this case. In your use case,
            </span>
            
            <span id="chunk-513" class="transcript-chunks" onclick="console.log('00:32:15,932'); seek(1935.0)">
              this will be your images. It wouldn't be these 10,000 images, it will
            </span>
            
            <span id="chunk-514" class="transcript-chunks" onclick="console.log('00:32:19,648'); seek(1939.0)">
              be yours. And you can see
            </span>
            
            <span id="chunk-515" class="transcript-chunks" onclick="console.log('00:32:23,600'); seek(1943.0)">
              that the first step that we do is we get this
            </span>
            
            <span id="chunk-516" class="transcript-chunks" onclick="console.log('00:32:27,136'); seek(1947.0)">
              data and then we do some transformations, and then
            </span>
            
            <span id="chunk-517" class="transcript-chunks" onclick="console.log('00:32:30,608'); seek(1950.0)">
              we upload this data to a string where we will have it.
            </span>
            
            <span id="chunk-518" class="transcript-chunks" onclick="console.log('00:32:34,260'); seek(1954.0)">
              That will be the location that we are going to read from once we want
            </span>
            
            <span id="chunk-519" class="transcript-chunks" onclick="console.log('00:32:37,764'); seek(1957.0)">
              to train our model. So once we have these images,
            </span>
            
            <span id="chunk-520" class="transcript-chunks" onclick="console.log('00:32:42,690'); seek(1962.0)">
              we are going to be using a pretrained model
            </span>
            
            <span id="chunk-521" class="transcript-chunks" onclick="console.log('00:32:46,680'); seek(1966.0)">
              that comes included in the Keras libraries.
            </span>
            
            <span id="chunk-522" class="transcript-chunks" onclick="console.log('00:32:49,910'); seek(1969.0)">
              This case, it will be Resnet 50. But like we
            </span>
            
            <span id="chunk-523" class="transcript-chunks" onclick="console.log('00:32:53,288'); seek(1973.0)">
              were seeing before, you can actually, instead of doing all of these steps, you can
            </span>
            
            <span id="chunk-524" class="transcript-chunks" onclick="console.log('00:32:56,808'); seek(1976.0)">
              just use the model that we saw before.
            </span>
            
            <span id="chunk-525" class="transcript-chunks" onclick="console.log('00:33:00,284'); seek(1980.0)">
              Right. Let me go again. So this model, you can just, once you deploy
            </span>
            
            <span id="chunk-526" class="transcript-chunks" onclick="console.log('00:33:04,034'); seek(1984.0)">
              it, you click deployment, you will be presented with
            </span>
            
            <span id="chunk-527" class="transcript-chunks" onclick="console.log('00:33:07,772'); seek(1987.0)">
              an endpoint URL. And that is the one that you can use to do
            </span>
            
            <span id="chunk-528" class="transcript-chunks" onclick="console.log('00:33:11,568'); seek(1991.0)">
              this task. Otherwise, let's continue with this custom
            </span>
            
            <span id="chunk-529" class="transcript-chunks" onclick="console.log('00:33:16,176'); seek(1996.0)">
              implementation. So we take this Resnet 50
            </span>
            
            <span id="chunk-530" class="transcript-chunks" onclick="console.log('00:33:20,190'); seek(2000.0)">
              and we want to deploy it as
            </span>
            
            <span id="chunk-531" class="transcript-chunks" onclick="console.log('00:33:23,776'); seek(2003.0)">
              an endpoint, right. So that's what we do now
            </span>
            
            <span id="chunk-532" class="transcript-chunks" onclick="console.log('00:33:27,460'); seek(2007.0)">
              we use this piece of script. It's the one
            </span>
            
            <span id="chunk-533" class="transcript-chunks" onclick="console.log('00:33:30,708'); seek(2010.0)">
              that we are going to be using to pick up the model, load it into
            </span>
            
            <span id="chunk-534" class="transcript-chunks" onclick="console.log('00:33:34,376'); seek(2014.0)">
              memory, and then run all of these images
            </span>
            
            <span id="chunk-535" class="transcript-chunks" onclick="console.log('00:33:38,238'); seek(2018.0)">
              through this and only return the feature vectors,
            </span>
            
            <span id="chunk-536" class="transcript-chunks" onclick="console.log('00:33:41,422'); seek(2021.0)">
              not the actual label, out of it, just the feature vectors.
            </span>
            
            <span id="chunk-537" class="transcript-chunks" onclick="console.log('00:33:45,910'); seek(2025.0)">
              So that is what we do here.
            </span>
            
            <span id="chunk-538" class="transcript-chunks" onclick="console.log('00:33:49,276'); seek(2029.0)">
              So in this place we are going to deploy the model
            </span>
            
            <span id="chunk-539" class="transcript-chunks" onclick="console.log('00:33:53,180'); seek(2033.0)">
              as a sage maker endpoint. This normally takes around 10 minutes.
            </span>
            
            <span id="chunk-540" class="transcript-chunks" onclick="console.log('00:33:56,348'); seek(2036.0)">
              You can see that I'm using CPU instance.
            </span>
            
            <span id="chunk-541" class="transcript-chunks" onclick="console.log('00:33:59,810'); seek(2039.0)">
              This case I'm going to deploy only one, but you can
            </span>
            
            <span id="chunk-542" class="transcript-chunks" onclick="console.log('00:34:03,392'); seek(2043.0)">
              change it if you want this to be quicker, for example. So all
            </span>
            
            <span id="chunk-543" class="transcript-chunks" onclick="console.log('00:34:07,200'); seek(2047.0)">
              the requests will be routed to one instance.
            </span>
            
            <span id="chunk-544" class="transcript-chunks" onclick="console.log('00:34:10,370'); seek(2050.0)">
              In this case we are going to be using an example image
            </span>
            
            <span id="chunk-545" class="transcript-chunks" onclick="console.log('00:34:14,458'); seek(2054.0)">
              and this is the result that comes
            </span>
            
            <span id="chunk-546" class="transcript-chunks" onclick="console.log('00:34:17,876'); seek(2057.0)">
              back from these input. So these are the feature vectors.
            </span>
            
            <span id="chunk-547" class="transcript-chunks" onclick="console.log('00:34:22,938'); seek(2062.0)">
              Once we tested that, this actually works. We want to build
            </span>
            
            <span id="chunk-548" class="transcript-chunks" onclick="console.log('00:34:26,392'); seek(2066.0)">
              this index, right? So we want to first get all
            </span>
            
            <span id="chunk-549" class="transcript-chunks" onclick="console.log('00:34:29,848'); seek(2069.0)">
              the images, all the keys of these files on s
            </span>
            
            <span id="chunk-550" class="transcript-chunks" onclick="console.log('00:34:33,192'); seek(2073.0)">
              three. And then we want to basically
            </span>
            
            <span id="chunk-551" class="transcript-chunks" onclick="console.log('00:34:36,552'); seek(2076.0)">
              process all of those images. We want to get the feature vectors out of all
            </span>
            
            <span id="chunk-552" class="transcript-chunks" onclick="console.log('00:34:40,188'); seek(2080.0)">
              of those images and we want to upload them or
            </span>
            
            <span id="chunk-553" class="transcript-chunks" onclick="console.log('00:34:44,348'); seek(2084.0)">
              get them into this elasticsearch index.
            </span>
            
            <span id="chunk-554" class="transcript-chunks" onclick="console.log('00:34:48,518'); seek(2088.0)">
              So once we have done that, you can see
            </span>
            
            <span id="chunk-555" class="transcript-chunks" onclick="console.log('00:34:52,448'); seek(2092.0)">
              that that is what we are coins here, we care, importing these features
            </span>
            
            <span id="chunk-556" class="transcript-chunks" onclick="console.log('00:34:58,430'); seek(2098.0)">
              into elasticsearch. And the next thing that we can do is
            </span>
            
            <span id="chunk-557" class="transcript-chunks" onclick="console.log('00:35:02,020'); seek(2102.0)">
              now we can do a test. So you see that
            </span>
            
            <span id="chunk-558" class="transcript-chunks" onclick="console.log('00:35:05,972'); seek(2105.0)">
              we have the first image, the query image here,
            </span>
            
            <span id="chunk-559" class="transcript-chunks" onclick="console.log('00:35:10,610'); seek(2110.0)">
              and now we say, okay, so bring me back
            </span>
            
            <span id="chunk-560" class="transcript-chunks" onclick="console.log('00:35:14,328'); seek(2114.0)">
              examples out of your index, bring me back
            </span>
            
            <span id="chunk-561" class="transcript-chunks" onclick="console.log('00:35:17,832'); seek(2117.0)">
              the most similarly looking images, right? So you can
            </span>
            
            <span id="chunk-562" class="transcript-chunks" onclick="console.log('00:35:21,512'); seek(2121.0)">
              see that you're only returning outfits
            </span>
            
            <span id="chunk-563" class="transcript-chunks" onclick="console.log('00:35:25,390'); seek(2125.0)">
              that have all of these patterns. So these are very similar
            </span>
            
            <span id="chunk-564" class="transcript-chunks" onclick="console.log('00:35:29,610'); seek(2129.0)">
              between each other and the same
            </span>
            
            <span id="chunk-565" class="transcript-chunks" onclick="console.log('00:35:33,132'); seek(2133.0)">
              thing. We use a different method, but these is the same
            </span>
            
            <span id="chunk-566" class="transcript-chunks" onclick="console.log('00:35:36,252'); seek(2136.0)">
              result and you can see what this looks
            </span>
            
            <span id="chunk-567" class="transcript-chunks" onclick="console.log('00:35:40,096'); seek(2140.0)">
              like, right? So in your case, using your own data,
            </span>
            
            <span id="chunk-568" class="transcript-chunks" onclick="console.log('00:35:43,312'); seek(2143.0)">
              this will be presenting one coin as the reference image,
            </span>
            
            <span id="chunk-569" class="transcript-chunks" onclick="console.log('00:35:46,838'); seek(2146.0)">
              the input image, and then returning
            </span>
            
            <span id="chunk-570" class="transcript-chunks" onclick="console.log('00:35:51,250'); seek(2151.0)">
              all of these most similarly looking images
            </span>
            
            <span id="chunk-571" class="transcript-chunks" onclick="console.log('00:35:55,562'); seek(2155.0)">
              in the collection, right? So the good thing about this application is
            </span>
            
            <span id="chunk-572" class="transcript-chunks" onclick="console.log('00:35:58,868'); seek(2158.0)">
              that it actually also involves this implementation, that it
            </span>
            
            <span id="chunk-573" class="transcript-chunks" onclick="console.log('00:36:02,804'); seek(2162.0)">
              also involves deploying a full stack visual search application. So this is great
            </span>
            
            <span id="chunk-574" class="transcript-chunks" onclick="console.log('00:36:06,632'); seek(2166.0)">
              if you're doing a demo. So what
            </span>
            
            <span id="chunk-575" class="transcript-chunks" onclick="console.log('00:36:09,928'); seek(2169.0)">
              you will do is these are several steps
            </span>
            
            <span id="chunk-576" class="transcript-chunks" onclick="console.log('00:36:14,150'); seek(2174.0)">
              for creating the architecture.
            </span>
            
            <span id="chunk-577" class="transcript-chunks" onclick="console.log('00:36:17,246'); seek(2177.0)">
              But basically once you run all of these steps, you're going to
            </span>
            
            <span id="chunk-578" class="transcript-chunks" onclick="console.log('00:36:20,764'); seek(2180.0)">
              be presented with an application that looks like this.
            </span>
            
            <span id="chunk-579" class="transcript-chunks" onclick="console.log('00:36:23,756'); seek(2183.0)">
              And I actually have it running locally here. So you
            </span>
            
            <span id="chunk-580" class="transcript-chunks" onclick="console.log('00:36:27,308'); seek(2187.0)">
              see that, for example, you will choose how many
            </span>
            
            <span id="chunk-581" class="transcript-chunks" onclick="console.log('00:36:31,232'); seek(2191.0)">
              items you want to return out of this. And these
            </span>
            
            <span id="chunk-582" class="transcript-chunks" onclick="console.log('00:36:34,560'); seek(2194.0)">
              you can choose an image,
            </span>
            
            <span id="chunk-583" class="transcript-chunks" onclick="console.log('00:36:38,030'); seek(2198.0)">
              and you will just submit your shop and then
            </span>
            
            <span id="chunk-584" class="transcript-chunks" onclick="console.log('00:36:41,812'); seek(2201.0)">
              get the results back. Let me show you, for example,
            </span>
            
            <span id="chunk-585" class="transcript-chunks" onclick="console.log('00:36:46,050'); seek(2206.0)">
              in here. The way that this will look is something
            </span>
            
            <span id="chunk-586" class="transcript-chunks" onclick="console.log('00:36:49,636'); seek(2209.0)">
              like this. So, at the end of your experimentation, if you want,
            </span>
            
            <span id="chunk-587" class="transcript-chunks" onclick="console.log('00:36:53,252'); seek(2213.0)">
              you can delete all of the resources that we created, and then you
            </span>
            
            <span id="chunk-588" class="transcript-chunks" onclick="console.log('00:36:57,188'); seek(2217.0)">
              will just finish with your
            </span>
            
            <span id="chunk-589" class="transcript-chunks" onclick="console.log('00:37:01,076'); seek(2221.0)">
              experimentation. You wouldn't have any extra cost out of this.
            </span>
            
            <span id="chunk-590" class="transcript-chunks" onclick="console.log('00:37:06,570'); seek(2226.0)">
              So, with that, I actually wanted to come back to original
            </span>
            
            <span id="chunk-591" class="transcript-chunks" onclick="console.log('00:37:10,418'); seek(2230.0)">
              presentation, and I wanted to thank you for staying with us so
            </span>
            
            <span id="chunk-592" class="transcript-chunks" onclick="console.log('00:37:14,572'); seek(2234.0)">
              long, and I hope you find this presentation useful. Thank you very
            </span>
            
            <span id="chunk-593" class="transcript-chunks" onclick="console.log('00:37:18,268'); seek(2238.0)">
              much.
            </span>
            
            </div>
          </div>
          

          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/ml2021" class="btn btn-sm btn-danger shadow lift" style="background-color: #198B91;">
                <i class="fe fe-grid me-2"></i>
                See all 23 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/ml_nicolas.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Nicolas Metallo
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Senior Data Scientist @ AWS
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/nicolas-metallo/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Nicolas Metallo's LinkedIn account" />
                  </a>
                  
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by Nicolas Metallo"
                  data-url="https://www.conf42.com/ml2021"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/ml2021"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>





  <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
    </script>
    <!-- SUBSCRIBE -->
    <section class="pt-8 pt-md-11 bg-gradient-light-white" id="register">
        <div class="container">
          <div class="row align-items-center justify-content-between mb-8 mb-md-11">
            <div class="col-12 col-md-6 order-md-2" data-aos="fade-left">
  
              <!-- Heading -->
              <h2>
                Awesome tech events for <br>
                <span class="text-success"><span data-typed='{"strings": ["software engineers.", "tech leaders.", "SREs.", "DevOps.", "CTOs.",  "managers.", "architects.", "QAs.", "developers.", "coders.", "founders.", "CEOs.", "students.", "geeks.", "ethical hackers.", "educators.", "enthusiasts.", "directors.", "researchers.", "PHDs.", "evangelists.", "tech authors."]}'></span></span>
              </h2>
  
              <!-- Text -->
              <p class="fs-lg text-muted mb-6">
  
              </p>
  
              <!-- List -->
              <div class="row">
                <div class="col-12 col-lg-12">
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <!-- Text -->
                    <p class="text-success">
                      Priority access to all content
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Video hallway track
                    </p>
                  </div>

                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Community chat
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Exclusive promotions and giveaways
                    </p>
                  </div>
  
                </div>
              </div> <!-- / .row -->
  
            </div>
            <div class="col-12 col-md-6 col-lg-5 order-md-1">
  
              <!-- Card -->
              <div class="card shadow-light-lg">
  
                <!-- Body -->
                <div class="card-body">
  
                  <!-- Form -->
                  <link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
                  <p class="emailoctopus-success-message text-success"></p>
                  <p class="emailoctopus-error-message text-danger"></p>
                  <form
                    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
                    method="post"
                    data-message-success="Thanks! Check your email for further directions!"
                    data-message-missing-email-address="Your email address is required."
                    data-message-invalid-email-address="Your email address looks incorrect, please try again."
                    data-message-bot-submission-error="This doesn't look like a human submission."
                    data-message-consent-required="Please check the checkbox to indicate your consent."
                    data-message-invalid-parameters-error="This form has missing or invalid fields."
                    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
                    class="emailoctopus-form"
                    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
                  >
                    <div class="form-floating emailoctopus-form-row">
                      <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
                      <label for="field_0">Email address</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
                      <label for="field_1">First Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
                      <label for="field_2">Last Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
                      <label for="field_4">Company</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
                      <label for="field_5">Job Title</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
                      <label for="field_3">Phone Number</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
                        oninput="updateCountry()"
                      >
                        <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
                      </select>
                      <label for="field_7">Country</label>
                    </div>
                    <input id="country-destination" name="field_7" type="hidden">
                    <input id="tz-country" name="field_8" type="hidden">
                    
                    <input
                      name="field_6"
                      type="hidden"
                      value="Machine Learning"
                    >
                    
                    <div class="emailoctopus-form-row-consent">
                      <input
                        type="checkbox"
                        id="consent"
                        name="consent"
                      >
                      <label for="consent">
                        I consent to the following terms:
                      </label>
                      <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
                        Terms and Conditions
                      </a>
                      &amp;
                      <a href="./code-of-conduct" target="_blank">
                        Code of Conduct
                      </a>
                    </div>
                    <div
                      aria-hidden="true"
                      class="emailoctopus-form-row-hp"
                    >
                      <input
                        type="text"
                        name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
                        tabindex="-1"
                        autocomplete="nope"
                      >
                    </div>
                    <div class="mt-6 emailoctopus-form-row-subscribe">
                      <input
                        type="hidden"
                        name="successRedirectUrl"
                      >
                      <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
                        Subscribe
                      </button>
                    </div>
                  </form>
  
                </div>
  
              </div>
  
            </div>
  
          </div> <!-- / .row -->
        </div> <!-- / .container -->
      </section>

      <!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
      <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2025">
                  Site Reliability Engineering (SRE) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2025">
                  Machine Learning 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2025">
                  Observability 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2025">
                  Quantum Computing 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2025">
                  Rustlang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2025">
                  Platform Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2025">
                  MLOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2025">
                  Incident Management 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2025">
                  Kube Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2025">
                  JavaScript 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2025">
                  Prompt Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/robotics2025">
                  Robotics 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2025">
                  DevSecOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2025">
                  Internet of Things (IoT) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://sreday.com/2024-amsterdam/">
                  SREday Amsterdam 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>