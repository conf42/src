<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: Hodor: Detecting and addressing overload in LinkedIn microservices</title>
    <meta name="description" content="Build Solid Systems to defend against intergalactic invaders!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/sre_bryan_vivek.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Hodor: Detecting and addressing overload in LinkedIn microservices | Conf42"/>
    <meta property="og:description" content="When pushed hard enough any system will eventually suffer, and ultimately fail unless relief is provided in some form. At LinkedIn, we have developed a framework for our microservices to help with these issues: Hodor (Holistic Overload Detection & Overload Remediation).   As the name suggests, it is designed to detect service overloads from multiple potential root causes, and to automatically improve the situation by dropping just enough traffic to allow the service to recover.   Hodor then maintains an optimal traffic level to prevent the service from reentering overload. All of this is done without manual tuning or specifying thresholds. In this talk, we will introduce Hodor, provide an overview of the framework, describe how it detects overloads, and how requests are dropped to provide relief."/>
    <meta property="og:url" content="https://conf42.com/Site_Reliability_Engineering_2022_Bryan_Barkley_Vivek_Deshpande_hodor_overload_linkedin"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/PROMPT2024_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Prompt Engineering 2024
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2024-11-14
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/prompt2024" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://sreday.com/2024-amsterdam/">
                            SREday Amsterdam
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="./support">
                            Support us
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Subscribe for FREE
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #E36414;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Site Reliability Engineering 2022 - Online
            </h1>

            <h2 class="text-white">
              
              Content unlocked! Welcome to the community!
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Build Solid Systems to defend against intergalactic invaders!
 -->
              <script>
                const event_date = new Date("2022-06-09T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2022-06-09T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "7s-mx-IEEkc"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <a class="btn btn-info lift mb-3" data-bigpicture='{"ytSrc": "FclEiSDfX14"}' href="#">
                <i class="fe fe-eye me-2"></i>
                Watch Premiere
              </a>
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://youtube.com/playlist?list=PLIuxSyKxlQrD6irhy2GbMrApRWlc8mSFy" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hi, my name is Brian Barkley. I\u0027m an engineer at LinkedIn,", "timestamp": "00:02:15,160", "timestamp_s": 135.0}, {"text": "and I\u0027m going to be joined by my colleague Vivek Deshpande to", "timestamp": "00:02:18,416", "timestamp_s": 138.0}, {"text": "discuss a framework that we\u0027ve helped to develop called Hodor.", "timestamp": "00:02:21,962", "timestamp_s": 141.0}, {"text": "LinkedIn counts on Hodor to protect our microservices by detecting", "timestamp": "00:02:25,720", "timestamp_s": 145.0}, {"text": "when our systems have become overloaded and providing relief to", "timestamp": "00:02:29,824", "timestamp_s": 149.0}, {"text": "bring them back to a stable state. So this is", "timestamp": "00:02:33,658", "timestamp_s": 153.0}, {"text": "our goal. We want to increase our overall service resiliency,", "timestamp": "00:02:37,298", "timestamp_s": 157.0}, {"text": "uptime, and availability, while minimizing impact to", "timestamp": "00:02:41,208", "timestamp_s": 161.0}, {"text": "these members who are using the site. We also want to", "timestamp": "00:02:44,978", "timestamp_s": 164.0}, {"text": "do this with an out of the box solution that doesn\u0027t require service owners", "timestamp": "00:02:48,194", "timestamp_s": 168.0}, {"text": "to have to customize things or maintain configuration that\u0027s specific to", "timestamp": "00:02:51,628", "timestamp_s": 171.0}, {"text": "their service. I\u0027ll also note that what we\u0027ll be presenting", "timestamp": "00:02:55,142", "timestamp_s": 175.0}, {"text": "here is all within the context of code running on the Java virtual", "timestamp": "00:02:58,988", "timestamp_s": 178.0}, {"text": "machine, though some of the concepts would translate well to other", "timestamp": "00:03:02,572", "timestamp_s": 182.0}, {"text": "runtime environments. So here\u0027s our", "timestamp": "00:03:05,898", "timestamp_s": 185.0}, {"text": "agenda for the talk. I\u0027ll provide an overview of Hodor, then Vivek", "timestamp": "00:03:09,098", "timestamp_s": 189.0}, {"text": "will discuss the various types of overload detectors we\u0027ve developed.", "timestamp": "00:03:13,088", "timestamp_s": 193.0}, {"text": "I\u0027ll talk about how we remediate overloads situations,", "timestamp": "00:03:16,452", "timestamp_s": 196.0}, {"text": "how we rolled this out to hundreds of existing services safely.", "timestamp": "00:03:20,276", "timestamp_s": 200.0}, {"text": "We\u0027ll take a look at a success story from our", "timestamp": "00:03:23,732", "timestamp_s": 203.0}, {"text": "production environment and discuss some related work and", "timestamp": "00:03:27,298", "timestamp_s": 207.0}, {"text": "what else we have planned for the future.", "timestamp": "00:03:31,042", "timestamp_s": 211.0}, {"text": "So, for anyone wondering about the name, as you can see,", "timestamp": "00:03:34,560", "timestamp_s": 214.0}, {"text": "Hodor stands for holistic overload detection and", "timestamp": "00:03:37,746", "timestamp_s": 217.0}, {"text": "overload remediation. It protects our services and", "timestamp": "00:03:41,846", "timestamp_s": 221.0}, {"text": "so also has a similarity in that respect to a certain fictional character.", "timestamp": "00:03:45,622", "timestamp_s": 225.0}, {"text": "So let\u0027s get into some of the details of Hodor situations", "timestamp": "00:03:50,340", "timestamp_s": 230.0}, {"text": "that it\u0027s meant to address and how the pieces fit together.", "timestamp": "00:03:53,692", "timestamp_s": 233.0}, {"text": "Start with let\u0027s talk about what it means for a service to be overloads.", "timestamp": "00:03:57,240", "timestamp_s": 237.0}, {"text": "We define it as the point at which it\u0027s unable to serve traffic", "timestamp": "00:04:01,248", "timestamp_s": 241.0}, {"text": "with reasonable latency. We want to maximize the goodput", "timestamp": "00:04:04,448", "timestamp_s": 244.0}, {"text": "that a service is able to provide. And so when a service has saturated", "timestamp": "00:04:08,068", "timestamp_s": 248.0}, {"text": "its usage of a given resource, we need to prevent oversaturation", "timestamp": "00:04:11,876", "timestamp_s": 251.0}, {"text": "and degradation of that resource. What sort of", "timestamp": "00:04:16,388", "timestamp_s": 256.0}, {"text": "resources are we talking about here? They can be physical or virtual", "timestamp": "00:04:19,778", "timestamp_s": 259.0}, {"text": "resources. Some obvious examples of physical resources are cpu", "timestamp": "00:04:23,832", "timestamp_s": 263.0}, {"text": "usage, memory usage, network bandwidth,", "timestamp": "00:04:27,832", "timestamp_s": 267.0}, {"text": "or disk I O, and all of these have hard", "timestamp": "00:04:31,452", "timestamp_s": 271.0}, {"text": "physical limits that are just not possible to push past or increase via", "timestamp": "00:04:34,806", "timestamp_s": 274.0}, {"text": "some configuration tweaks. Once these limits are hit,", "timestamp": "00:04:38,988", "timestamp_s": 278.0}, {"text": "performance starts to degrade pretty quickly.", "timestamp": "00:04:42,266", "timestamp_s": 282.0}, {"text": "Virtual resources are different altogether, but can have the same", "timestamp": "00:04:45,560", "timestamp_s": 285.0}, {"text": "impact when they are fully utilized. Some examples include threads", "timestamp": "00:04:49,322", "timestamp_s": 289.0}, {"text": "available for execution, pool DB connections,", "timestamp": "00:04:53,488", "timestamp_s": 293.0}, {"text": "or send before permits.", "timestamp": "00:04:57,044", "timestamp_s": 297.0}, {"text": "These limits can be reached in different ways. A clear case", "timestamp": "00:04:59,980", "timestamp_s": 299.0}, {"text": "is increased traffic to a service if the number of requests", "timestamp": "00:05:03,870", "timestamp_s": 303.0}, {"text": "per second goes up five x or ten x, normal things", "timestamp": "00:05:07,188", "timestamp_s": 307.0}, {"text": "aren\u0027t going to go well on that machine if it\u0027s not provisioned for that amount", "timestamp": "00:05:10,466", "timestamp_s": 310.0}, {"text": "of load. Another more subtle case is if some", "timestamp": "00:05:13,602", "timestamp_s": 313.0}, {"text": "service downstream starts to slow down. That effectively", "timestamp": "00:05:17,282", "timestamp_s": 317.0}, {"text": "applies backpressure up the call chain, and services higher up", "timestamp": "00:05:21,192", "timestamp_s": 321.0}, {"text": "are affected by that added latency in those calls. It\u0027ll slow", "timestamp": "00:05:24,870", "timestamp_s": 324.0}, {"text": "down the upstream service and causes it to have more requests in", "timestamp": "00:05:28,668", "timestamp_s": 328.0}, {"text": "flight, which could lead to memory issues or thread exhaustion.", "timestamp": "00:05:32,198", "timestamp_s": 332.0}, {"text": "One more example is if your service is running alongside others", "timestamp": "00:05:36,360", "timestamp_s": 336.0}, {"text": "on the same host without proper isolation. If a neighboring", "timestamp": "00:05:39,722", "timestamp_s": 339.0}, {"text": "process is using a lot of cpu, disk or network bandwidth,", "timestamp": "00:05:43,328", "timestamp_s": 343.0}, {"text": "your service will be negatively impacted without any change to", "timestamp": "00:05:46,996", "timestamp_s": 346.0}, {"text": "traffic or downstream latencies. So this", "timestamp": "00:05:50,222", "timestamp_s": 350.0}, {"text": "is where the holistic part comes in. We want to be able to catch", "timestamp": "00:05:53,678", "timestamp_s": 353.0}, {"text": "as many of these types of issues as possible, though the", "timestamp": "00:05:57,188", "timestamp_s": 357.0}, {"text": "services using hodor can have wildly different traffic patterns,", "timestamp": "00:06:00,498", "timestamp_s": 360.0}, {"text": "execution and threading models and workloads, and as", "timestamp": "00:06:04,680", "timestamp_s": 364.0}, {"text": "I mentioned before, it shouldn\u0027t take any configuration. We have", "timestamp": "00:06:08,418", "timestamp_s": 368.0}, {"text": "hundreds and hundreds of services running on tens of thousands of machines, and tweaking", "timestamp": "00:06:12,118", "timestamp_s": 372.0}, {"text": "things for each of those just isn\u0027t feasible to", "timestamp": "00:06:16,156", "timestamp_s": 376.0}, {"text": "addressing the problem once it\u0027s been detected. We begin dropping requests and", "timestamp": "00:06:20,038", "timestamp_s": 380.0}, {"text": "return 503, which is service unavailable responses.", "timestamp": "00:06:24,026", "timestamp_s": 384.0}, {"text": "But we want to minimize these and drop just enough traffic to", "timestamp": "00:06:29,080", "timestamp_s": 389.0}, {"text": "mitigate the problem. The tricky part here is that", "timestamp": "00:06:32,778", "timestamp_s": 392.0}, {"text": "the amount of traffic that needs to be dropped and the overall capacity of the", "timestamp": "00:06:36,282", "timestamp_s": 396.0}, {"text": "service can easily vary depending on the nature of these overload", "timestamp": "00:06:39,998", "timestamp_s": 399.0}, {"text": "itself. For example, the amount of traffic that a service", "timestamp": "00:06:43,716", "timestamp_s": 403.0}, {"text": "can handle may be much different if the cpu is saturated", "timestamp": "00:06:47,422", "timestamp_s": 407.0}, {"text": "compared to if there\u0027s back pressure from a downstream", "timestamp": "00:06:51,464", "timestamp_s": 411.0}, {"text": "and memory usage is becoming a problem.", "timestamp": "00:06:55,000", "timestamp_s": 415.0}, {"text": "So we have to be flexible and dynamic, both in detecting overloads", "timestamp": "00:06:58,320", "timestamp_s": 418.0}, {"text": "and also in knowing how much traffic to drop.", "timestamp": "00:07:02,156", "timestamp_s": 422.0}, {"text": "So what\u0027s hodor made of? There are basically three main", "timestamp": "00:07:05,860", "timestamp_s": 425.0}, {"text": "components. First, there are what we call overload", "timestamp": "00:07:09,542", "timestamp_s": 429.0}, {"text": "detectors. There could be multiple of these registered,", "timestamp": "00:07:13,312", "timestamp_s": 433.0}, {"text": "including any that might be application specific.", "timestamp": "00:07:16,336", "timestamp_s": 436.0}, {"text": "Vivek will be talking about the standard ones we provide in a bit.", "timestamp": "00:07:19,658", "timestamp_s": 439.0}, {"text": "The detectors are queried for each inbound request with some metadata", "timestamp": "00:07:23,720", "timestamp_s": 443.0}, {"text": "about the requests. This allows the detectors to operate on a", "timestamp": "00:07:27,268", "timestamp_s": 447.0}, {"text": "context specific level if needed, and potentially only detect", "timestamp": "00:07:30,606", "timestamp_s": 450.0}, {"text": "overload and pushed traffic for a targeted subset of requests.", "timestamp": "00:07:34,404", "timestamp_s": 454.0}, {"text": "Most of these detects, though, operate on a global level and don\u0027t", "timestamp": "00:07:38,408", "timestamp_s": 458.0}, {"text": "do any request specific processing. Instead, they\u0027re fetching", "timestamp": "00:07:42,008", "timestamp_s": 462.0}, {"text": "an asynchronously calculated state indicating whether the detector", "timestamp": "00:07:45,128", "timestamp_s": 465.0}, {"text": "considers things to be overloaded.", "timestamp": "00:07:48,552", "timestamp_s": 468.0}, {"text": "Second, we have the load shutter, so this decides", "timestamp": "00:07:51,700", "timestamp_s": 471.0}, {"text": "which traffic should be dropped. Once a detector is signaled that there\u0027s an", "timestamp": "00:07:55,356", "timestamp_s": 475.0}, {"text": "overload, the shutter needs to be intelligent about which requests", "timestamp": "00:07:58,518", "timestamp_s": 478.0}, {"text": "should be dropped to make sure that too much traffic isn\u0027t rejected,", "timestamp": "00:08:02,252", "timestamp_s": 482.0}, {"text": "but that enough is to exit the overloaded state.", "timestamp": "00:08:06,592", "timestamp_s": 486.0}, {"text": "The load shutter takes the signal from the detects as input,", "timestamp": "00:08:10,120", "timestamp_s": 490.0}, {"text": "as well as some contextual information about the request to make these decisions.", "timestamp": "00:08:13,392", "timestamp_s": 493.0}, {"text": "Finally, there\u0027s a platform specific component that combines the", "timestamp": "00:08:18,540", "timestamp_s": 498.0}, {"text": "detectors and load shutter and adapts request metadata into Hodor\u0027s", "timestamp": "00:08:22,478", "timestamp_s": 502.0}, {"text": "APIs. The detectors and shutter are platform", "timestamp": "00:08:26,404", "timestamp_s": 506.0}, {"text": "agnostic. At LinkedIn, we primarily use an open source project we developed", "timestamp": "00:08:30,114", "timestamp_s": 510.0}, {"text": "called restly for communication between services. So that\u0027s", "timestamp": "00:08:34,328", "timestamp_s": 514.0}, {"text": "the first platform we had Hodor running on. We\u0027ve since", "timestamp": "00:08:38,328", "timestamp_s": 518.0}, {"text": "adapted it to work with GRPC as well as HTTP", "timestamp": "00:08:41,462", "timestamp_s": 521.0}, {"text": "servers such as the play framework. I\u0027m going to hand things", "timestamp": "00:08:44,652", "timestamp_s": 524.0}, {"text": "off to Vivek now, and he will get into more details", "timestamp": "00:08:48,502", "timestamp_s": 528.0}, {"text": "of how some of our detectors work to determine when the service is overloads.", "timestamp": "00:08:52,332", "timestamp_s": 532.0}, {"text": "Thanks Brian. Hello everyone. Now let\u0027s talk about how the", "timestamp": "00:08:57,400", "timestamp_s": 537.0}, {"text": "overloads detection is done using different detectors.", "timestamp": "00:09:01,098", "timestamp_s": 541.0}, {"text": "The first detector is CPU detector. The objective of CPU detector", "timestamp": "00:09:05,980", "timestamp_s": 545.0}, {"text": "is to quickly and accurately detect CPU overloads.", "timestamp": "00:09:09,924", "timestamp_s": 549.0}, {"text": "The idea is to have a lightweight background thread running at same", "timestamp": "00:09:13,348", "timestamp_s": 553.0}, {"text": "priority as the application threads, which execute business logic.", "timestamp": "00:09:16,542", "timestamp_s": 556.0}, {"text": "This background thread, known as the heartbeat thread, is scheduled to", "timestamp": "00:09:20,664", "timestamp_s": 560.0}, {"text": "wake up every ten milliseconds. The overall amount of work here is trivial", "timestamp": "00:09:24,354", "timestamp_s": 564.0}, {"text": "and adds no major variable impact to application performance.", "timestamp": "00:09:28,376", "timestamp_s": 568.0}, {"text": "The heartbeat overload detection algorithm monitors whether the heartbeat", "timestamp": "00:09:32,820", "timestamp_s": 572.0}, {"text": "thread is getting cpu every ten milliseconds. Once the heartbeat algorithm", "timestamp": "00:09:36,748", "timestamp_s": 576.0}, {"text": "realizes that the heartbeat thread is consistently not getting cpu", "timestamp": "00:09:40,732", "timestamp_s": 580.0}, {"text": "time at the expected time intervals, we flag an overload.", "timestamp": "00:09:44,448", "timestamp_s": 584.0}, {"text": "It is important to note here that a few variations are not", "timestamp": "00:09:48,080", "timestamp_s": 588.0}, {"text": "enough to flag an overload, and that the algorithm flags an", "timestamp": "00:09:51,306", "timestamp_s": 591.0}, {"text": "overload only when we have high confidence that a", "timestamp": "00:09:54,558", "timestamp_s": 594.0}, {"text": "cpu is overloaded. In concept, this idea is straightforward,", "timestamp": "00:09:57,758", "timestamp_s": 597.0}, {"text": "but determining the appropriate variables and parameters", "timestamp": "00:10:01,972", "timestamp_s": 601.0}, {"text": "for this algorithm to maximize precision while have high", "timestamp": "00:10:06,084", "timestamp_s": 606.0}, {"text": "recall was challenging. To provide a concrete", "timestamp": "00:10:09,378", "timestamp_s": 609.0}, {"text": "example, we may have the thread slip for ten milliseconds each", "timestamp": "00:10:12,968", "timestamp_s": 612.0}, {"text": "time, and if the 99th percentile in a second\u0027s worth of", "timestamp": "00:10:16,466", "timestamp_s": 616.0}, {"text": "data is over 55 milliseconds, that window is in violation.", "timestamp": "00:10:19,730", "timestamp_s": 619.0}, {"text": "If eight consecutive windows are in violation, the service is", "timestamp": "00:10:23,596", "timestamp_s": 623.0}, {"text": "considered overloads. Values for this thresholds that we", "timestamp": "00:10:26,902", "timestamp_s": 626.0}, {"text": "use are determined by synthetic testing as well as by sourcing data", "timestamp": "00:10:30,742", "timestamp_s": 630.0}, {"text": "from production and comparing it with performance metrics when the", "timestamp": "00:10:34,666", "timestamp_s": 634.0}, {"text": "services were considered to be overloaded. The rationale", "timestamp": "00:10:38,554", "timestamp_s": 638.0}, {"text": "behind using heartbeat thread is one it directly measures", "timestamp": "00:10:42,320", "timestamp_s": 642.0}, {"text": "useful cpu time available to the application in real time.", "timestamp": "00:10:46,480", "timestamp_s": 646.0}, {"text": "What we mean by this is that just because you see 30% free cpu", "timestamp": "00:10:50,540", "timestamp_s": 650.0}, {"text": "on something like top command does not mean that it is", "timestamp": "00:10:54,740", "timestamp_s": 654.0}, {"text": "useful cpu. And number two, the concept of the heartbeat thread is", "timestamp": "00:10:58,018", "timestamp_s": 658.0}, {"text": "applicable everywhere irrespective of these environment or the application", "timestamp": "00:11:01,682", "timestamp_s": 661.0}, {"text": "type.", "timestamp": "00:11:04,994", "timestamp_s": 664.0}, {"text": "So this is an example of the cpu detector in action.", "timestamp": "00:11:08,560", "timestamp_s": 668.0}, {"text": "In the top left graph you can observe that the heartbeat detector", "timestamp": "00:11:12,500", "timestamp_s": 672.0}, {"text": "is able to capture a cpu overload. Notice that the performance", "timestamp": "00:11:16,412", "timestamp_s": 676.0}, {"text": "indicators such as average and p 90 latencies and", "timestamp": "00:11:20,332", "timestamp_s": 680.0}, {"text": "p 95 cpu all spike when the heartbeat detector", "timestamp": "00:11:23,658", "timestamp_s": 683.0}, {"text": "flags an overload. Now let\u0027s move on to", "timestamp": "00:11:27,328", "timestamp_s": 687.0}, {"text": "the next detector which focuses on memory bottlenecks.", "timestamp": "00:11:30,874", "timestamp_s": 690.0}, {"text": "The objective of GC overload detector is to quickly and", "timestamp": "00:11:36,860", "timestamp_s": 696.0}, {"text": "accurately detects increased garbage collection activity for", "timestamp": "00:11:40,366", "timestamp_s": 700.0}, {"text": "applications with auto memory management like Java applications,", "timestamp": "00:11:43,982", "timestamp_s": 703.0}, {"text": "these idea is to observe overhead of GC activity", "timestamp": "00:11:48,136", "timestamp_s": 708.0}, {"text": "in a lightweight manner to detect overload in real time.", "timestamp": "00:11:51,256", "timestamp_s": 711.0}, {"text": "On each GC event, we calculate the amortized percentage", "timestamp": "00:11:55,200", "timestamp_s": 715.0}, {"text": "of time spent in GC over a given time window.", "timestamp": "00:11:58,808", "timestamp_s": 718.0}, {"text": "We call that as GC overhead. A schedule is set", "timestamp": "00:12:02,260", "timestamp_s": 722.0}, {"text": "on top of a GC overloads. So for that schedule, the GC overhead", "timestamp": "00:12:05,910", "timestamp_s": 725.0}, {"text": "percentage range is divided into tiers called as GC overhead", "timestamp": "00:12:09,772", "timestamp_s": 729.0}, {"text": "tiers. If the duration spent in GC overloads tier", "timestamp": "00:12:13,388", "timestamp_s": 733.0}, {"text": "exceeds the volatility period for the tier, then the GC overload", "timestamp": "00:12:17,212", "timestamp_s": 737.0}, {"text": "is signaled. The volatility period is smaller for", "timestamp": "00:12:21,232", "timestamp_s": 741.0}, {"text": "higher GC over a tier as a higher GC over tier indicates more", "timestamp": "00:12:24,442", "timestamp_s": 744.0}, {"text": "severe GC activity. For example GC over it", "timestamp": "00:12:28,542", "timestamp_s": 748.0}, {"text": "of 10% or more for say 30 seconds", "timestamp": "00:12:32,686", "timestamp_s": 752.0}, {"text": "for consecutive gcs is considered overload or", "timestamp": "00:12:36,372", "timestamp_s": 756.0}, {"text": "lower tier such as Gc overhead of 8%", "timestamp": "00:12:40,178", "timestamp_s": 760.0}, {"text": "or more for say like 60 seconds is considered overload", "timestamp": "00:12:43,554", "timestamp_s": 763.0}, {"text": "and so on. So the rationale behind using percentage", "timestamp": "00:12:47,944", "timestamp_s": 767.0}, {"text": "time in GC is it causes both GC duration", "timestamp": "00:12:51,532", "timestamp_s": 771.0}, {"text": "and GC frequency that can catch different GC issues.", "timestamp": "00:12:55,036", "timestamp_s": 775.0}, {"text": "And also setting a common threshold is possible which", "timestamp": "00:12:58,580", "timestamp_s": 778.0}, {"text": "work across all the applications with different allocation rates,", "timestamp": "00:13:02,778", "timestamp_s": 782.0}, {"text": "old generation occupancy levels and so on.", "timestamp": "00:13:06,784", "timestamp_s": 786.0}, {"text": "So similar to cpu detector, this is an example of GC", "timestamp": "00:13:12,280", "timestamp_s": 792.0}, {"text": "overload detector in action when GC activity increases", "timestamp": "00:13:15,892", "timestamp_s": 795.0}, {"text": "because of increase in traffic. In the top left graph you", "timestamp": "00:13:20,300", "timestamp_s": 800.0}, {"text": "can observe that these GC detector is able to capture", "timestamp": "00:13:24,094", "timestamp_s": 804.0}, {"text": "a GC overload. Notice that the performance indicators", "timestamp": "00:13:27,352", "timestamp_s": 807.0}, {"text": "such as p 90 p 99 latencies both spike", "timestamp": "00:13:31,400", "timestamp_s": 811.0}, {"text": "when the GC detector flags an overload.", "timestamp": "00:13:34,792", "timestamp_s": 814.0}, {"text": "Now we will look at a virtual resource overload detector.", "timestamp": "00:13:40,020", "timestamp_s": 820.0}, {"text": "Study of QA time and its data", "timestamp": "00:13:44,012", "timestamp_s": 824.0}, {"text": "suggests that there is a good correlation between increased KPIs,", "timestamp": "00:13:47,370", "timestamp_s": 827.0}, {"text": "such as latencies, and increased thread queue at times", "timestamp": "00:13:51,072", "timestamp_s": 831.0}, {"text": "for synchronous services. Consider a synchronous service", "timestamp": "00:13:54,686", "timestamp_s": 834.0}, {"text": "requests will start spending more time waiting in a queue if current", "timestamp": "00:13:58,350", "timestamp_s": 838.0}, {"text": "request processing time increases, either due to", "timestamp": "00:14:02,350", "timestamp_s": 842.0}, {"text": "an issue in the service or in one of its downstreams.", "timestamp": "00:14:05,758", "timestamp_s": 845.0}, {"text": "The capacity of a service can also be reached when latencies of downstream", "timestamp": "00:14:09,928", "timestamp_s": 849.0}, {"text": "traffic increase, which can cause the number of concurrent requests", "timestamp": "00:14:13,832", "timestamp_s": 853.0}, {"text": "being handled in the local service to increase with no change", "timestamp": "00:14:18,232", "timestamp_s": 858.0}, {"text": "to the incoming request rate. But without knowing anything", "timestamp": "00:14:22,006", "timestamp_s": 862.0}, {"text": "about these downstream service, we can assert at upstream by monitoring thread", "timestamp": "00:14:25,366", "timestamp_s": 865.0}, {"text": "pull queue time that there is a thread pull starvation,", "timestamp": "00:14:29,612", "timestamp_s": 869.0}, {"text": "and by dropped traffic we can help alleviate the downstream.", "timestamp": "00:14:33,536", "timestamp_s": 873.0}, {"text": "At LinkedIn we use JT server side", "timestamp": "00:14:37,376", "timestamp_s": 877.0}, {"text": "framework extensively and hence we target that as a", "timestamp": "00:14:40,762", "timestamp_s": 880.0}, {"text": "first step. But the logic of observing thread pool q wet time", "timestamp": "00:14:44,334", "timestamp_s": 884.0}, {"text": "is applicable widely,", "timestamp": "00:14:47,886", "timestamp_s": 887.0}, {"text": "similar to the previous detectors. This is an example of the thread pool", "timestamp": "00:14:53,260", "timestamp_s": 893.0}, {"text": "overload detector in action, where there is an issue in downstream processing", "timestamp": "00:14:56,872", "timestamp_s": 896.0}, {"text": "that causes increase in the thread pool wet time. In the", "timestamp": "00:15:03,200", "timestamp_s": 903.0}, {"text": "left top graph you can observe that the thread pool detects is able to", "timestamp": "00:15:06,338", "timestamp_s": 906.0}, {"text": "capture an overload. Notice that the performance", "timestamp": "00:15:09,718", "timestamp_s": 909.0}, {"text": "indicators such as average p 99 latency, spike when", "timestamp": "00:15:12,988", "timestamp_s": 912.0}, {"text": "detector flags an overload. Now back to Brian", "timestamp": "00:15:16,518", "timestamp_s": 916.0}, {"text": "who is going to talk about remediation techniques. Thank you.", "timestamp": "00:15:20,524", "timestamp_s": 920.0}, {"text": "Thanks for that. So the question now is, once we\u0027ve", "timestamp": "00:15:25,620", "timestamp_s": 925.0}, {"text": "identified there\u0027s a problem, how can we address it with minimal impact?", "timestamp": "00:15:29,248", "timestamp_s": 929.0}, {"text": "Well, we need to reduce the amount of work that a service is doing,", "timestamp": "00:15:33,960", "timestamp_s": 933.0}, {"text": "and we do that by rejecting some requests. The trick here", "timestamp": "00:15:37,406", "timestamp_s": 937.0}, {"text": "is to identify the proper amount of requests to reject, since dropping", "timestamp": "00:15:40,942", "timestamp_s": 940.0}, {"text": "too many would have a negative impact on our users,", "timestamp": "00:15:44,868", "timestamp_s": 944.0}, {"text": "we\u0027ve tried and tested a few different load shedding approaches and found that", "timestamp": "00:15:47,940", "timestamp_s": 947.0}, {"text": "the most effective is to limit the number of concurrent requests handled by a service.", "timestamp": "00:15:51,378", "timestamp_s": 951.0}, {"text": "The load shedder adaptively determines the number of requests that need to be dropped", "timestamp": "00:15:55,920", "timestamp_s": 955.0}, {"text": "by initially being somewhat aggressive while shedding the traffic,", "timestamp": "00:16:00,092", "timestamp_s": 960.0}, {"text": "and then more conservative about allowing more traffic back", "timestamp": "00:16:03,788", "timestamp_s": 963.0}, {"text": "in. When the load shedder drops requests, they\u0027re returned", "timestamp": "00:16:06,982", "timestamp_s": 966.0}, {"text": "as five hundred and three s, and these can be retried on another healthy", "timestamp": "00:16:10,284", "timestamp_s": 970.0}, {"text": "host if one is available. We experimented", "timestamp": "00:16:14,752", "timestamp_s": 974.0}, {"text": "with other forms of adaptive load shedding, including using a percentage", "timestamp": "00:16:18,272", "timestamp_s": 978.0}, {"text": "based threshold to adaptively control the amount of traffic handled", "timestamp": "00:16:22,368", "timestamp_s": 982.0}, {"text": "or rejected. But during our tests we found that a percentage base", "timestamp": "00:16:26,212", "timestamp_s": 986.0}, {"text": "shutter didn\u0027t really do that good of a job, especially when traffic", "timestamp": "00:16:29,838", "timestamp_s": 989.0}, {"text": "patterns changed as it was continually needing to adapt", "timestamp": "00:16:33,348", "timestamp_s": 993.0}, {"text": "to the new traffic levels, whether they were increasing or decreasing over", "timestamp": "00:16:36,820", "timestamp_s": 996.0}, {"text": "previous thresholds. The graphs shown here", "timestamp": "00:16:40,498", "timestamp_s": 1000.0}, {"text": "are from one of the experiments we ran where the red host", "timestamp": "00:16:43,794", "timestamp_s": 1003.0}, {"text": "was unprotected and the blue host had load shedding enabled.", "timestamp": "00:16:47,112", "timestamp_s": 1007.0}, {"text": "They started off by receiving identical traffic levels until becoming overloaded", "timestamp": "00:16:51,484", "timestamp_s": 1011.0}, {"text": "where the behavior diverged. As you can see in the middle graph.", "timestamp": "00:16:55,772", "timestamp_s": 1015.0}, {"text": "You can see as the overall queries per second increases,", "timestamp": "00:16:59,460", "timestamp_s": 1019.0}, {"text": "the protected host is forced to increase the number of requests", "timestamp": "00:17:03,968", "timestamp_s": 1023.0}, {"text": "that are dropped. You can also see that the overall high", "timestamp": "00:17:07,792", "timestamp_s": 1027.0}, {"text": "percentile latency is lower on the protected host,", "timestamp": "00:17:11,338", "timestamp_s": 1031.0}, {"text": "but there are a few spikes where the load shutter is probing to", "timestamp": "00:17:15,492", "timestamp_s": 1035.0}, {"text": "see if the concurrency limit can be increased by slowly", "timestamp": "00:17:19,118", "timestamp_s": 1039.0}, {"text": "letting in more traffic.", "timestamp": "00:17:22,468", "timestamp_s": 1042.0}, {"text": "So I\u0027d mentioned that holder rejects requests with 503s.", "timestamp": "00:17:26,060", "timestamp_s": 1046.0}, {"text": "This is done early on in the request pipeline before any business", "timestamp": "00:17:29,442", "timestamp_s": 1049.0}, {"text": "logic is executed so they\u0027re safe to retry on another", "timestamp": "00:17:32,930", "timestamp_s": 1052.0}, {"text": "healthy host. This reduces overall member impact", "timestamp": "00:17:36,866", "timestamp_s": 1056.0}, {"text": "because the 503 response is returned quickly", "timestamp": "00:17:40,460", "timestamp_s": 1060.0}, {"text": "to the client, giving it time to retry the request someplace else.", "timestamp": "00:17:43,670", "timestamp_s": 1063.0}, {"text": "But we don\u0027t want to blindly retry all requests that are", "timestamp": "00:17:48,198", "timestamp_s": 1068.0}, {"text": "dropped by Hodor because if all hosts in these cluster are overloaded,", "timestamp": "00:17:51,754", "timestamp_s": 1071.0}, {"text": "these sending additional retry traffic can actually make these problem", "timestamp": "00:17:55,840", "timestamp_s": 1075.0}, {"text": "worse. To prevent this, we\u0027ve added functionality", "timestamp": "00:17:59,434", "timestamp_s": 1079.0}, {"text": "on the client and server side to be able to detect issues that are cluster", "timestamp": "00:18:03,232", "timestamp_s": 1083.0}, {"text": "wide and prevent retry storms. This is done by", "timestamp": "00:18:06,612", "timestamp_s": 1086.0}, {"text": "defining client and server side budgets and not", "timestamp": "00:18:11,086", "timestamp_s": 1091.0}, {"text": "retrying when any of these budgets have been exceeded.", "timestamp": "00:18:14,542", "timestamp_s": 1094.0}, {"text": "I\u0027m going to talk briefly now about how we went about rolling this out to", "timestamp": "00:18:19,200", "timestamp_s": 1099.0}, {"text": "the hundreds of separate microservices", "timestamp": "00:18:22,786", "timestamp_s": 1102.0}, {"text": "that we operate at LinkedIn. So we needed to", "timestamp": "00:18:26,760", "timestamp_s": 1106.0}, {"text": "be cautious when rolling this out to make sure that we weren\u0027t causing impact", "timestamp": "00:18:30,450", "timestamp_s": 1110.0}, {"text": "to our members from any potential false positives from the", "timestamp": "00:18:34,460", "timestamp_s": 1114.0}, {"text": "detectors. We did this by enabling the detectors in monitoring mode,", "timestamp": "00:18:37,558", "timestamp_s": 1117.0}, {"text": "where the signal from the detectors is ignored by the load", "timestamp": "00:18:41,916", "timestamp_s": 1121.0}, {"text": "shutter, but all relevant metrics are still active and collected.", "timestamp": "00:18:45,264", "timestamp_s": 1125.0}, {"text": "So this allowed us to set up a pipeline for rollout where we could", "timestamp": "00:18:49,600", "timestamp_s": 1129.0}, {"text": "monitor when detectors were firing and correlate those", "timestamp": "00:18:53,198", "timestamp_s": 1133.0}, {"text": "events with other service metrics such as latency,", "timestamp": "00:18:56,702", "timestamp_s": 1136.0}, {"text": "cpu usage, garbage collection activity, et cetera.", "timestamp": "00:19:00,620", "timestamp_s": 1140.0}, {"text": "At the same time periods before enabling load shedding.", "timestamp": "00:19:04,580", "timestamp_s": 1144.0}, {"text": "Though, we monitored a service for at least a week, which would include", "timestamp": "00:19:08,584", "timestamp_s": 1148.0}, {"text": "load tests that were running in production during that time, we found that", "timestamp": "00:19:12,712", "timestamp_s": 1152.0}, {"text": "some services were not good candidates for onboarding using our default", "timestamp": "00:19:16,562", "timestamp_s": 1156.0}, {"text": "settings. These were almost always due to issues with garbage collection", "timestamp": "00:19:20,348", "timestamp_s": 1160.0}, {"text": "and could usually be solved by tuning the GC. In some", "timestamp": "00:19:24,556", "timestamp_s": 1164.0}, {"text": "cases, this actually led to significant discoveries around inefficient memory", "timestamp": "00:19:28,582", "timestamp_s": 1168.0}, {"text": "allocation and usage patterns, which needed to be addressed in the service", "timestamp": "00:19:32,668", "timestamp_s": 1172.0}, {"text": "but hadn\u0027t been surfaced before. Making changes", "timestamp": "00:19:36,090", "timestamp_s": 1176.0}, {"text": "to address these ended up being significant wins for these services as they led", "timestamp": "00:19:39,530", "timestamp_s": 1179.0}, {"text": "to reduced cpu usage, better overall performance", "timestamp": "00:19:43,508", "timestamp_s": 1183.0}, {"text": "and scalability, and they were able to onboard the hodor\u0027s", "timestamp": "00:19:47,396", "timestamp_s": 1187.0}, {"text": "protection as a side benefit.", "timestamp": "00:19:51,028", "timestamp_s": 1191.0}, {"text": "So at the bottom here is a quote from one of the teams", "timestamp": "00:19:53,980", "timestamp_s": 1193.0}, {"text": "after adoption adding overload detectors to", "timestamp": "00:19:57,688", "timestamp_s": 1197.0}, {"text": "our service has surfaced unexpected behavior that owners were generally", "timestamp": "00:20:01,298", "timestamp_s": 1201.0}, {"text": "not familiar with, and we\u0027ve truly found some odd behavior", "timestamp": "00:20:05,192", "timestamp_s": 1205.0}, {"text": "surfaced by our detectors. For example, in one service", "timestamp": "00:20:09,660", "timestamp_s": 1209.0}, {"text": "we found that thread dumps were being automatically triggered and written", "timestamp": "00:20:13,878", "timestamp_s": 1213.0}, {"text": "to disk periodically based on a setting that the owners had enabled", "timestamp": "00:20:17,644", "timestamp_s": 1217.0}, {"text": "and forgotten about. The manifestation of this", "timestamp": "00:20:21,504", "timestamp_s": 1221.0}, {"text": "was periodic freezes of the JVM while the thread dumps were happening,", "timestamp": "00:20:24,842", "timestamp_s": 1224.0}, {"text": "which lasted over a few seconds in some cases, but this", "timestamp": "00:20:28,826", "timestamp_s": 1228.0}, {"text": "didn\u0027t register in our higher percentile metrics,", "timestamp": "00:20:32,986", "timestamp_s": 1232.0}, {"text": "so the service owners were never aware of the problem. Once onboarded", "timestamp": "00:20:35,876", "timestamp_s": 1235.0}, {"text": "to Hodor, though, it became very clear when the detectors fired", "timestamp": "00:20:39,924", "timestamp_s": 1239.0}, {"text": "and the load shutter engaged. There are other examples similar", "timestamp": "00:20:43,268", "timestamp_s": 1243.0}, {"text": "to this where fairly impactful and usually fairly interesting behavior", "timestamp": "00:20:46,866", "timestamp_s": 1246.0}, {"text": "went unnoticed until uncovered by our system.", "timestamp": "00:20:51,000", "timestamp_s": 1251.0}, {"text": "So next I\u0027m going to go through a quick example from one of our production", "timestamp": "00:20:55,440", "timestamp_s": 1255.0}, {"text": "services.", "timestamp": "00:20:58,988", "timestamp_s": 1258.0}, {"text": "So this is from our flagship application", "timestamp": "00:21:01,860", "timestamp_s": 1261.0}, {"text": "which powers these main LinkedIn.com site as well as mobile", "timestamp": "00:21:05,846", "timestamp_s": 1265.0}, {"text": "clients for iOS and Android. So we periodically do traffic", "timestamp": "00:21:09,644", "timestamp_s": 1269.0}, {"text": "shifts between our data centers for various reasons. In one of", "timestamp": "00:21:13,468", "timestamp_s": 1273.0}, {"text": "these cases, there was a new bug that was introduced in the service that only", "timestamp": "00:21:17,274", "timestamp_s": 1277.0}, {"text": "appeared when the service was extremely stressed.", "timestamp": "00:21:20,890", "timestamp_s": 1280.0}, {"text": "This traffic shift event triggered the bug,", "timestamp": "00:21:24,140", "timestamp_s": 1284.0}, {"text": "and Hodor intervened aggressively to handle the situation.", "timestamp": "00:21:27,236", "timestamp_s": 1287.0}, {"text": "You can see in these top graph that Hodor engaged for a", "timestamp": "00:21:31,100", "timestamp_s": 1291.0}, {"text": "good amount of time with a few spikes which lined up directly with when", "timestamp": "00:21:34,414", "timestamp_s": 1294.0}, {"text": "latencies were spiking. Overall,", "timestamp": "00:21:38,338", "timestamp_s": 1298.0}, {"text": "about 20% of requests were dropped", "timestamp": "00:21:41,080", "timestamp_s": 1301.0}, {"text": "during this overload period, which sounds bad, but when", "timestamp": "00:21:44,440", "timestamp_s": 1304.0}, {"text": "sres investigated further, they found that if the load hadn\u0027t been shed,", "timestamp": "00:21:47,730", "timestamp_s": 1307.0}, {"text": "this would likely have become a major site issue instead of a", "timestamp": "00:21:51,964", "timestamp_s": 1311.0}, {"text": "minor one with a service down instead of still", "timestamp": "00:21:55,238", "timestamp_s": 1315.0}, {"text": "serving partial amounts of traffic. We currently", "timestamp": "00:21:58,886", "timestamp_s": 1318.0}, {"text": "have over 100 success stories similar to these where Hodor engaged to protect", "timestamp": "00:22:02,026", "timestamp_s": 1322.0}, {"text": "a service and mitigate an issue to", "timestamp": "00:22:06,026", "timestamp_s": 1326.0}, {"text": "end with. I\u0027m going to talk about some related work that integrates", "timestamp": "00:22:10,218", "timestamp_s": 1330.0}, {"text": "well with Hodor and some things that we have planned for the future.", "timestamp": "00:22:13,968", "timestamp_s": 1333.0}, {"text": "First up is a project that has been integrated with Hodor and", "timestamp": "00:22:20,140", "timestamp_s": 1340.0}, {"text": "live for some amount of time. Our term for it is traffic tiering,", "timestamp": "00:22:23,918", "timestamp_s": 1343.0}, {"text": "but it\u0027s also known as traffic prioritization or traffic", "timestamp": "00:22:27,992", "timestamp_s": 1347.0}, {"text": "shaping. It\u0027s a pretty simple concept. Some requests", "timestamp": "00:22:31,208", "timestamp_s": 1351.0}, {"text": "can be considered more important than others. For example,", "timestamp": "00:22:34,712", "timestamp_s": 1354.0}, {"text": "our web and mobile applications will often prefetch some data", "timestamp": "00:22:38,482", "timestamp_s": 1358.0}, {"text": "that they expect might be used soon, but if it\u0027s not available, there\u0027s no", "timestamp": "00:22:42,086", "timestamp_s": 1362.0}, {"text": "actual impact to the user, it just gets fetched later", "timestamp": "00:22:46,582", "timestamp_s": 1366.0}, {"text": "on. Demand requests like this can be considered to be lower", "timestamp": "00:22:50,614", "timestamp_s": 1370.0}, {"text": "priority than directly fetching data that the user has requested.", "timestamp": "00:22:54,186", "timestamp_s": 1374.0}, {"text": "Similarly, we have offline jobs that utilize the same services", "timestamp": "00:22:58,448", "timestamp_s": 1378.0}, {"text": "that take user traffic, but nobody\u0027s sitting", "timestamp": "00:23:02,682", "timestamp_s": 1382.0}, {"text": "behind a screen waiting for that data. It\u0027s safe to retry", "timestamp": "00:23:05,988", "timestamp_s": 1385.0}, {"text": "those offline requests at a later time when the service isn\u0027t overloaded.", "timestamp": "00:23:09,508", "timestamp_s": 1389.0}, {"text": "So with traffic tiering, we\u0027re able to categorize different types", "timestamp": "00:23:13,476", "timestamp_s": 1393.0}, {"text": "of requests into different categories and start", "timestamp": "00:23:17,048", "timestamp_s": 1397.0}, {"text": "dropping traffic with the lowest importance at first, and only moving", "timestamp": "00:23:20,466", "timestamp_s": 1400.0}, {"text": "to affect higher priority traffic if necessary.", "timestamp": "00:23:24,530", "timestamp_s": 1404.0}, {"text": "Secondly, we\u0027re working on developing new types of detectors to cover blind", "timestamp": "00:23:29,200", "timestamp_s": 1409.0}, {"text": "spots in the ones we have. One of these is actually a method of", "timestamp": "00:23:33,228", "timestamp_s": 1413.0}, {"text": "confirming that the detected overload is impacting core metrics.", "timestamp": "00:23:36,902", "timestamp_s": 1416.0}, {"text": "So we\u0027ve had cases of false positives where there is an underlying", "timestamp": "00:23:41,196", "timestamp_s": 1421.0}, {"text": "issue with these service, usually GC related, which isn\u0027t", "timestamp": "00:23:44,832", "timestamp_s": 1424.0}, {"text": "affecting the user perceived performance, but is impacting the ability", "timestamp": "00:23:48,672", "timestamp_s": 1428.0}, {"text": "of the app to scale further and maximize its capacity.", "timestamp": "00:23:52,432", "timestamp_s": 1432.0}, {"text": "In these cases, we don\u0027t want to drop traffic, but we do want", "timestamp": "00:23:56,300", "timestamp_s": 1436.0}, {"text": "to signal that there is an issue. So we\u0027re working on correlating CPU", "timestamp": "00:23:59,726", "timestamp_s": 1439.0}, {"text": "or GCU overload signals with latency metrics", "timestamp": "00:24:03,668", "timestamp_s": 1443.0}, {"text": "and only dropping traffic when there\u0027s a clear degradation in performance.", "timestamp": "00:24:07,172", "timestamp_s": 1447.0}, {"text": "We\u0027re also starting to adapt Hodor to frameworks other than restly,", "timestamp": "00:24:11,608", "timestamp_s": 1451.0}, {"text": "such as the play framework, as well as Neti. These have", "timestamp": "00:24:15,432", "timestamp_s": 1455.0}, {"text": "different threading models and in some cases don\u0027t work as well with the heartbeat", "timestamp": "00:24:19,606", "timestamp_s": 1459.0}, {"text": "based cpu detection. So for example, we\u0027re working", "timestamp": "00:24:23,708", "timestamp_s": 1463.0}, {"text": "on detects specifically for Netty\u0027s event loop threading", "timestamp": "00:24:27,046", "timestamp_s": 1467.0}, {"text": "model. Finally, we\u0027re looking into leveraging the overload", "timestamp": "00:24:31,004", "timestamp_s": 1471.0}, {"text": "signals to feed them into our elastic scaling system,", "timestamp": "00:24:35,232", "timestamp_s": 1475.0}, {"text": "so this seems like an obvious match. If a service cluster has become overloaded,", "timestamp": "00:24:38,794", "timestamp_s": 1478.0}, {"text": "we can just spin up some more instances to alleviate the problem,", "timestamp": "00:24:42,816", "timestamp_s": 1482.0}, {"text": "right? Well, it turns out it\u0027s not that simple, especially when", "timestamp": "00:24:45,870", "timestamp_s": 1485.0}, {"text": "there are a mix of stateful and stateless systems within an", "timestamp": "00:24:49,198", "timestamp_s": 1489.0}, {"text": "overloaded call tree. In many cases, just scaling up one", "timestamp": "00:24:52,382", "timestamp_s": 1492.0}, {"text": "cluster that is overloaded would just propagate the issue further", "timestamp": "00:24:56,462", "timestamp_s": 1496.0}, {"text": "downstream and cause even more issues. This is an area", "timestamp": "00:24:59,732", "timestamp_s": 1499.0}, {"text": "where we\u0027re still exploring and hope to address in the future.", "timestamp": "00:25:03,790", "timestamp_s": 1503.0}, {"text": "So I hope that this presentation was enlightening for you and", "timestamp": "00:25:08,980", "timestamp_s": 1508.0}, {"text": "you learned something new. Thank you for your time. I\u0027d also", "timestamp": "00:25:12,678", "timestamp_s": 1512.0}, {"text": "like to thank the different teams at LinkedIn that came together to make this project", "timestamp": "00:25:15,862", "timestamp_s": 1515.0}, {"text": "possible and successful. That\u0027s it from", "timestamp": "00:25:19,574", "timestamp_s": 1519.0}, {"text": "us. Enjoy the rest of the conference.", "timestamp": "00:25:22,838", "timestamp_s": 1522.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: '7s-mx-IEEkc',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              Hodor: Detecting and addressing overload in LinkedIn microservices
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>When pushed hard enough any system will eventually suffer, and ultimately fail unless relief is provided in some form. At LinkedIn, we have developed a framework for our microservices to help with these issues: Hodor (Holistic Overload Detection &amp; Overload Remediation). </p>
<p>As the name suggests, it is designed to detect service overloads from multiple potential root causes, and to automatically improve the situation by dropping just enough traffic to allow the service to recover. </p>
<p>Hodor then maintains an optimal traffic level to prevent the service from reentering overload. All of this is done without manual tuning or specifying thresholds. In this talk, we will introduce Hodor, provide an overview of the framework, describe how it detects overloads, and how requests are dropped to provide relief.</p>
<!-- End Text -->
          </div>

          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
              <li>
                LinkedIn counts on Hodor to protect our microservices by detecting when our systems have become overloaded and providing relief. Hodor stands for holistic overload detection and overload remediation. What we'll be presenting here is all within the context of code running on the Java virtual machine.

              </li>
              
              <li>
                When a service has saturated its usage of a given resource, we need to prevent oversaturation and degradation of that resource. These limits can be reached in different ways. The amount of traffic that needs to be dropped and the overall capacity can easily vary depending on the nature of these overloads.

              </li>
              
              <li>
                The objective of CPU detector is to quickly and accurately detect CPU overloads. Background thread, known as the heartbeat thread, is scheduled to wake up every ten milliseconds. The algorithm flags an overload only when we have high confidence that a service is overloaded.

              </li>
              
              <li>
                GC overload detector is to quickly and accurately detects increased garbage collection activity for applications with auto memory management like Java applications. Now let's move on to the next detector which focuses on memory bottlenecks.

              </li>
              
              <li>
                The most effective way to limit the number of concurrent requests handled by a service is to reject some requests. When the load shedder drops requests, they're returned as five hundred and three s, and these can be retried on another healthy host if one is available. LinkedIn rolled out load shedding to hundreds of microservices.

              </li>
              
              <li>
                 adding overload detectors to our service has surfaced unexpected behavior that owners were generally not familiar with. We currently have over 100 success stories where Hodor engaged to protect a service and mitigate an issue to end with. I'm going to talk about some related work that integrates well with Hodor and some things that we have planned for the future.

              </li>
              
              <li>
                First up is a project that has been integrated with Hodor and live for some amount of time. It's called traffic tiering, but it's also known as traffic prioritization or traffic shaping. We're working on correlating CPU or GCU overload signals with latency metrics and only dropping traffic when there's a clear degradation in performance.
              </li>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./assemblyai/7s-mx-IEEkc.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:02:15,160'); seek(135.0)">
              Hi, my name is Brian Barkley. I'm an engineer at LinkedIn,
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:02:18,416'); seek(138.0)">
              and I'm going to be joined by my colleague Vivek Deshpande to
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:02:21,962'); seek(141.0)">
              discuss a framework that we've helped to develop called Hodor.
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:02:25,720'); seek(145.0)">
              LinkedIn counts on Hodor to protect our microservices by detecting
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:02:29,824'); seek(149.0)">
              when our systems have become overloaded and providing relief to
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:02:33,658'); seek(153.0)">
              bring them back to a stable state. So this is
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:02:37,298'); seek(157.0)">
              our goal. We want to increase our overall service resiliency,
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:02:41,208'); seek(161.0)">
              uptime, and availability, while minimizing impact to
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:02:44,978'); seek(164.0)">
              these members who are using the site. We also want to
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:02:48,194'); seek(168.0)">
              do this with an out of the box solution that doesn't require service owners
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:02:51,628'); seek(171.0)">
              to have to customize things or maintain configuration that's specific to
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:02:55,142'); seek(175.0)">
              their service. I'll also note that what we'll be presenting
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:02:58,988'); seek(178.0)">
              here is all within the context of code running on the Java virtual
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:03:02,572'); seek(182.0)">
              machine, though some of the concepts would translate well to other
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:03:05,898'); seek(185.0)">
              runtime environments. So here's our
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:03:09,098'); seek(189.0)">
              agenda for the talk. I'll provide an overview of Hodor, then Vivek
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:03:13,088'); seek(193.0)">
              will discuss the various types of overload detectors we've developed.
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:03:16,452'); seek(196.0)">
              I'll talk about how we remediate overloads situations,
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:03:20,276'); seek(200.0)">
              how we rolled this out to hundreds of existing services safely.
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:03:23,732'); seek(203.0)">
              We'll take a look at a success story from our
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:03:27,298'); seek(207.0)">
              production environment and discuss some related work and
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:03:31,042'); seek(211.0)">
              what else we have planned for the future.
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:03:34,560'); seek(214.0)">
              So, for anyone wondering about the name, as you can see,
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:03:37,746'); seek(217.0)">
              Hodor stands for holistic overload detection and
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:03:41,846'); seek(221.0)">
              overload remediation. It protects our services and
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:03:45,622'); seek(225.0)">
              so also has a similarity in that respect to a certain fictional character.
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:03:50,340'); seek(230.0)">
              So let's get into some of the details of Hodor situations
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:03:53,692'); seek(233.0)">
              that it's meant to address and how the pieces fit together.
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:03:57,240'); seek(237.0)">
              Start with let's talk about what it means for a service to be overloads.
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:04:01,248'); seek(241.0)">
              We define it as the point at which it's unable to serve traffic
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:04:04,448'); seek(244.0)">
              with reasonable latency. We want to maximize the goodput
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:04:08,068'); seek(248.0)">
              that a service is able to provide. And so when a service has saturated
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:04:11,876'); seek(251.0)">
              its usage of a given resource, we need to prevent oversaturation
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:04:16,388'); seek(256.0)">
              and degradation of that resource. What sort of
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:04:19,778'); seek(259.0)">
              resources are we talking about here? They can be physical or virtual
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:04:23,832'); seek(263.0)">
              resources. Some obvious examples of physical resources are cpu
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:04:27,832'); seek(267.0)">
              usage, memory usage, network bandwidth,
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:04:31,452'); seek(271.0)">
              or disk I O, and all of these have hard
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:04:34,806'); seek(274.0)">
              physical limits that are just not possible to push past or increase via
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:04:38,988'); seek(278.0)">
              some configuration tweaks. Once these limits are hit,
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:04:42,266'); seek(282.0)">
              performance starts to degrade pretty quickly.
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:04:45,560'); seek(285.0)">
              Virtual resources are different altogether, but can have the same
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:04:49,322'); seek(289.0)">
              impact when they are fully utilized. Some examples include threads
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:04:53,488'); seek(293.0)">
              available for execution, pool DB connections,
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:04:57,044'); seek(297.0)">
              or send before permits.
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:04:59,980'); seek(299.0)">
              These limits can be reached in different ways. A clear case
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:05:03,870'); seek(303.0)">
              is increased traffic to a service if the number of requests
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:05:07,188'); seek(307.0)">
              per second goes up five x or ten x, normal things
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:05:10,466'); seek(310.0)">
              aren't going to go well on that machine if it's not provisioned for that amount
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:05:13,602'); seek(313.0)">
              of load. Another more subtle case is if some
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:05:17,282'); seek(317.0)">
              service downstream starts to slow down. That effectively
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:05:21,192'); seek(321.0)">
              applies backpressure up the call chain, and services higher up
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:05:24,870'); seek(324.0)">
              are affected by that added latency in those calls. It'll slow
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:05:28,668'); seek(328.0)">
              down the upstream service and causes it to have more requests in
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:05:32,198'); seek(332.0)">
              flight, which could lead to memory issues or thread exhaustion.
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:05:36,360'); seek(336.0)">
              One more example is if your service is running alongside others
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:05:39,722'); seek(339.0)">
              on the same host without proper isolation. If a neighboring
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:05:43,328'); seek(343.0)">
              process is using a lot of cpu, disk or network bandwidth,
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:05:46,996'); seek(346.0)">
              your service will be negatively impacted without any change to
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:05:50,222'); seek(350.0)">
              traffic or downstream latencies. So this
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:05:53,678'); seek(353.0)">
              is where the holistic part comes in. We want to be able to catch
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:05:57,188'); seek(357.0)">
              as many of these types of issues as possible, though the
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:06:00,498'); seek(360.0)">
              services using hodor can have wildly different traffic patterns,
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:06:04,680'); seek(364.0)">
              execution and threading models and workloads, and as
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:06:08,418'); seek(368.0)">
              I mentioned before, it shouldn't take any configuration. We have
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:06:12,118'); seek(372.0)">
              hundreds and hundreds of services running on tens of thousands of machines, and tweaking
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:06:16,156'); seek(376.0)">
              things for each of those just isn't feasible to
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:06:20,038'); seek(380.0)">
              addressing the problem once it's been detected. We begin dropping requests and
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:06:24,026'); seek(384.0)">
              return 503, which is service unavailable responses.
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:06:29,080'); seek(389.0)">
              But we want to minimize these and drop just enough traffic to
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:06:32,778'); seek(392.0)">
              mitigate the problem. The tricky part here is that
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:06:36,282'); seek(396.0)">
              the amount of traffic that needs to be dropped and the overall capacity of the
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:06:39,998'); seek(399.0)">
              service can easily vary depending on the nature of these overload
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:06:43,716'); seek(403.0)">
              itself. For example, the amount of traffic that a service
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:06:47,422'); seek(407.0)">
              can handle may be much different if the cpu is saturated
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:06:51,464'); seek(411.0)">
              compared to if there's back pressure from a downstream
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:06:55,000'); seek(415.0)">
              and memory usage is becoming a problem.
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:06:58,320'); seek(418.0)">
              So we have to be flexible and dynamic, both in detecting overloads
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:07:02,156'); seek(422.0)">
              and also in knowing how much traffic to drop.
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:07:05,860'); seek(425.0)">
              So what's hodor made of? There are basically three main
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:07:09,542'); seek(429.0)">
              components. First, there are what we call overload
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:07:13,312'); seek(433.0)">
              detectors. There could be multiple of these registered,
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:07:16,336'); seek(436.0)">
              including any that might be application specific.
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:07:19,658'); seek(439.0)">
              Vivek will be talking about the standard ones we provide in a bit.
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:07:23,720'); seek(443.0)">
              The detectors are queried for each inbound request with some metadata
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:07:27,268'); seek(447.0)">
              about the requests. This allows the detectors to operate on a
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:07:30,606'); seek(450.0)">
              context specific level if needed, and potentially only detect
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:07:34,404'); seek(454.0)">
              overload and pushed traffic for a targeted subset of requests.
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:07:38,408'); seek(458.0)">
              Most of these detects, though, operate on a global level and don't
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:07:42,008'); seek(462.0)">
              do any request specific processing. Instead, they're fetching
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:07:45,128'); seek(465.0)">
              an asynchronously calculated state indicating whether the detector
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:07:48,552'); seek(468.0)">
              considers things to be overloaded.
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:07:51,700'); seek(471.0)">
              Second, we have the load shutter, so this decides
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:07:55,356'); seek(475.0)">
              which traffic should be dropped. Once a detector is signaled that there's an
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:07:58,518'); seek(478.0)">
              overload, the shutter needs to be intelligent about which requests
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:08:02,252'); seek(482.0)">
              should be dropped to make sure that too much traffic isn't rejected,
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:08:06,592'); seek(486.0)">
              but that enough is to exit the overloaded state.
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:08:10,120'); seek(490.0)">
              The load shutter takes the signal from the detects as input,
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:08:13,392'); seek(493.0)">
              as well as some contextual information about the request to make these decisions.
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:08:18,540'); seek(498.0)">
              Finally, there's a platform specific component that combines the
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:08:22,478'); seek(502.0)">
              detectors and load shutter and adapts request metadata into Hodor's
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:08:26,404'); seek(506.0)">
              APIs. The detectors and shutter are platform
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:08:30,114'); seek(510.0)">
              agnostic. At LinkedIn, we primarily use an open source project we developed
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:08:34,328'); seek(514.0)">
              called restly for communication between services. So that's
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:08:38,328'); seek(518.0)">
              the first platform we had Hodor running on. We've since
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:08:41,462'); seek(521.0)">
              adapted it to work with GRPC as well as HTTP
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:08:44,652'); seek(524.0)">
              servers such as the play framework. I'm going to hand things
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:08:48,502'); seek(528.0)">
              off to Vivek now, and he will get into more details
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:08:52,332'); seek(532.0)">
              of how some of our detectors work to determine when the service is overloads.
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:08:57,400'); seek(537.0)">
              Thanks Brian. Hello everyone. Now let's talk about how the
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:09:01,098'); seek(541.0)">
              overloads detection is done using different detectors.
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:09:05,980'); seek(545.0)">
              The first detector is CPU detector. The objective of CPU detector
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:09:09,924'); seek(549.0)">
              is to quickly and accurately detect CPU overloads.
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:09:13,348'); seek(553.0)">
              The idea is to have a lightweight background thread running at same
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:09:16,542'); seek(556.0)">
              priority as the application threads, which execute business logic.
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:09:20,664'); seek(560.0)">
              This background thread, known as the heartbeat thread, is scheduled to
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:09:24,354'); seek(564.0)">
              wake up every ten milliseconds. The overall amount of work here is trivial
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:09:28,376'); seek(568.0)">
              and adds no major variable impact to application performance.
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:09:32,820'); seek(572.0)">
              The heartbeat overload detection algorithm monitors whether the heartbeat
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:09:36,748'); seek(576.0)">
              thread is getting cpu every ten milliseconds. Once the heartbeat algorithm
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:09:40,732'); seek(580.0)">
              realizes that the heartbeat thread is consistently not getting cpu
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:09:44,448'); seek(584.0)">
              time at the expected time intervals, we flag an overload.
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:09:48,080'); seek(588.0)">
              It is important to note here that a few variations are not
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:09:51,306'); seek(591.0)">
              enough to flag an overload, and that the algorithm flags an
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:09:54,558'); seek(594.0)">
              overload only when we have high confidence that a
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:09:57,758'); seek(597.0)">
              cpu is overloaded. In concept, this idea is straightforward,
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:10:01,972'); seek(601.0)">
              but determining the appropriate variables and parameters
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:10:06,084'); seek(606.0)">
              for this algorithm to maximize precision while have high
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:10:09,378'); seek(609.0)">
              recall was challenging. To provide a concrete
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:10:12,968'); seek(612.0)">
              example, we may have the thread slip for ten milliseconds each
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:10:16,466'); seek(616.0)">
              time, and if the 99th percentile in a second's worth of
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:10:19,730'); seek(619.0)">
              data is over 55 milliseconds, that window is in violation.
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:10:23,596'); seek(623.0)">
              If eight consecutive windows are in violation, the service is
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:10:26,902'); seek(626.0)">
              considered overloads. Values for this thresholds that we
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:10:30,742'); seek(630.0)">
              use are determined by synthetic testing as well as by sourcing data
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:10:34,666'); seek(634.0)">
              from production and comparing it with performance metrics when the
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:10:38,554'); seek(638.0)">
              services were considered to be overloaded. The rationale
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:10:42,320'); seek(642.0)">
              behind using heartbeat thread is one it directly measures
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:10:46,480'); seek(646.0)">
              useful cpu time available to the application in real time.
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:10:50,540'); seek(650.0)">
              What we mean by this is that just because you see 30% free cpu
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:10:54,740'); seek(654.0)">
              on something like top command does not mean that it is
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:10:58,018'); seek(658.0)">
              useful cpu. And number two, the concept of the heartbeat thread is
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:11:01,682'); seek(661.0)">
              applicable everywhere irrespective of these environment or the application
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:11:04,994'); seek(664.0)">
              type.
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:11:08,560'); seek(668.0)">
              So this is an example of the cpu detector in action.
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:11:12,500'); seek(672.0)">
              In the top left graph you can observe that the heartbeat detector
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:11:16,412'); seek(676.0)">
              is able to capture a cpu overload. Notice that the performance
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:11:20,332'); seek(680.0)">
              indicators such as average and p 90 latencies and
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:11:23,658'); seek(683.0)">
              p 95 cpu all spike when the heartbeat detector
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:11:27,328'); seek(687.0)">
              flags an overload. Now let's move on to
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:11:30,874'); seek(690.0)">
              the next detector which focuses on memory bottlenecks.
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:11:36,860'); seek(696.0)">
              The objective of GC overload detector is to quickly and
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:11:40,366'); seek(700.0)">
              accurately detects increased garbage collection activity for
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:11:43,982'); seek(703.0)">
              applications with auto memory management like Java applications,
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:11:48,136'); seek(708.0)">
              these idea is to observe overhead of GC activity
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:11:51,256'); seek(711.0)">
              in a lightweight manner to detect overload in real time.
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:11:55,200'); seek(715.0)">
              On each GC event, we calculate the amortized percentage
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:11:58,808'); seek(718.0)">
              of time spent in GC over a given time window.
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:12:02,260'); seek(722.0)">
              We call that as GC overhead. A schedule is set
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:12:05,910'); seek(725.0)">
              on top of a GC overloads. So for that schedule, the GC overhead
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:12:09,772'); seek(729.0)">
              percentage range is divided into tiers called as GC overhead
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:12:13,388'); seek(733.0)">
              tiers. If the duration spent in GC overloads tier
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:12:17,212'); seek(737.0)">
              exceeds the volatility period for the tier, then the GC overload
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:12:21,232'); seek(741.0)">
              is signaled. The volatility period is smaller for
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:12:24,442'); seek(744.0)">
              higher GC over a tier as a higher GC over tier indicates more
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:12:28,542'); seek(748.0)">
              severe GC activity. For example GC over it
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:12:32,686'); seek(752.0)">
              of 10% or more for say 30 seconds
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:12:36,372'); seek(756.0)">
              for consecutive gcs is considered overload or
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:12:40,178'); seek(760.0)">
              lower tier such as Gc overhead of 8%
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:12:43,554'); seek(763.0)">
              or more for say like 60 seconds is considered overload
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:12:47,944'); seek(767.0)">
              and so on. So the rationale behind using percentage
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:12:51,532'); seek(771.0)">
              time in GC is it causes both GC duration
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:12:55,036'); seek(775.0)">
              and GC frequency that can catch different GC issues.
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:12:58,580'); seek(778.0)">
              And also setting a common threshold is possible which
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:13:02,778'); seek(782.0)">
              work across all the applications with different allocation rates,
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:13:06,784'); seek(786.0)">
              old generation occupancy levels and so on.
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:13:12,280'); seek(792.0)">
              So similar to cpu detector, this is an example of GC
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:13:15,892'); seek(795.0)">
              overload detector in action when GC activity increases
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:13:20,300'); seek(800.0)">
              because of increase in traffic. In the top left graph you
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:13:24,094'); seek(804.0)">
              can observe that these GC detector is able to capture
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:13:27,352'); seek(807.0)">
              a GC overload. Notice that the performance indicators
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:13:31,400'); seek(811.0)">
              such as p 90 p 99 latencies both spike
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:13:34,792'); seek(814.0)">
              when the GC detector flags an overload.
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:13:40,020'); seek(820.0)">
              Now we will look at a virtual resource overload detector.
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:13:44,012'); seek(824.0)">
              Study of QA time and its data
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:13:47,370'); seek(827.0)">
              suggests that there is a good correlation between increased KPIs,
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:13:51,072'); seek(831.0)">
              such as latencies, and increased thread queue at times
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:13:54,686'); seek(834.0)">
              for synchronous services. Consider a synchronous service
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:13:58,350'); seek(838.0)">
              requests will start spending more time waiting in a queue if current
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:14:02,350'); seek(842.0)">
              request processing time increases, either due to
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:14:05,758'); seek(845.0)">
              an issue in the service or in one of its downstreams.
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:14:09,928'); seek(849.0)">
              The capacity of a service can also be reached when latencies of downstream
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:14:13,832'); seek(853.0)">
              traffic increase, which can cause the number of concurrent requests
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:14:18,232'); seek(858.0)">
              being handled in the local service to increase with no change
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:14:22,006'); seek(862.0)">
              to the incoming request rate. But without knowing anything
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:14:25,366'); seek(865.0)">
              about these downstream service, we can assert at upstream by monitoring thread
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:14:29,612'); seek(869.0)">
              pull queue time that there is a thread pull starvation,
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:14:33,536'); seek(873.0)">
              and by dropped traffic we can help alleviate the downstream.
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:14:37,376'); seek(877.0)">
              At LinkedIn we use JT server side
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:14:40,762'); seek(880.0)">
              framework extensively and hence we target that as a
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:14:44,334'); seek(884.0)">
              first step. But the logic of observing thread pool q wet time
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:14:47,886'); seek(887.0)">
              is applicable widely,
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:14:53,260'); seek(893.0)">
              similar to the previous detectors. This is an example of the thread pool
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:14:56,872'); seek(896.0)">
              overload detector in action, where there is an issue in downstream processing
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:15:03,200'); seek(903.0)">
              that causes increase in the thread pool wet time. In the
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:15:06,338'); seek(906.0)">
              left top graph you can observe that the thread pool detects is able to
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:15:09,718'); seek(909.0)">
              capture an overload. Notice that the performance
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:15:12,988'); seek(912.0)">
              indicators such as average p 99 latency, spike when
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:15:16,518'); seek(916.0)">
              detector flags an overload. Now back to Brian
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:15:20,524'); seek(920.0)">
              who is going to talk about remediation techniques. Thank you.
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:15:25,620'); seek(925.0)">
              Thanks for that. So the question now is, once we've
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:15:29,248'); seek(929.0)">
              identified there's a problem, how can we address it with minimal impact?
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:15:33,960'); seek(933.0)">
              Well, we need to reduce the amount of work that a service is doing,
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:15:37,406'); seek(937.0)">
              and we do that by rejecting some requests. The trick here
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:15:40,942'); seek(940.0)">
              is to identify the proper amount of requests to reject, since dropping
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:15:44,868'); seek(944.0)">
              too many would have a negative impact on our users,
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:15:47,940'); seek(947.0)">
              we've tried and tested a few different load shedding approaches and found that
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:15:51,378'); seek(951.0)">
              the most effective is to limit the number of concurrent requests handled by a service.
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:15:55,920'); seek(955.0)">
              The load shedder adaptively determines the number of requests that need to be dropped
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:16:00,092'); seek(960.0)">
              by initially being somewhat aggressive while shedding the traffic,
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:16:03,788'); seek(963.0)">
              and then more conservative about allowing more traffic back
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:16:06,982'); seek(966.0)">
              in. When the load shedder drops requests, they're returned
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:16:10,284'); seek(970.0)">
              as five hundred and three s, and these can be retried on another healthy
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:16:14,752'); seek(974.0)">
              host if one is available. We experimented
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:16:18,272'); seek(978.0)">
              with other forms of adaptive load shedding, including using a percentage
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:16:22,368'); seek(982.0)">
              based threshold to adaptively control the amount of traffic handled
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:16:26,212'); seek(986.0)">
              or rejected. But during our tests we found that a percentage base
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:16:29,838'); seek(989.0)">
              shutter didn't really do that good of a job, especially when traffic
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:16:33,348'); seek(993.0)">
              patterns changed as it was continually needing to adapt
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:16:36,820'); seek(996.0)">
              to the new traffic levels, whether they were increasing or decreasing over
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:16:40,498'); seek(1000.0)">
              previous thresholds. The graphs shown here
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:16:43,794'); seek(1003.0)">
              are from one of the experiments we ran where the red host
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:16:47,112'); seek(1007.0)">
              was unprotected and the blue host had load shedding enabled.
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:16:51,484'); seek(1011.0)">
              They started off by receiving identical traffic levels until becoming overloaded
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:16:55,772'); seek(1015.0)">
              where the behavior diverged. As you can see in the middle graph.
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:16:59,460'); seek(1019.0)">
              You can see as the overall queries per second increases,
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:17:03,968'); seek(1023.0)">
              the protected host is forced to increase the number of requests
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:17:07,792'); seek(1027.0)">
              that are dropped. You can also see that the overall high
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:17:11,338'); seek(1031.0)">
              percentile latency is lower on the protected host,
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:17:15,492'); seek(1035.0)">
              but there are a few spikes where the load shutter is probing to
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:17:19,118'); seek(1039.0)">
              see if the concurrency limit can be increased by slowly
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:17:22,468'); seek(1042.0)">
              letting in more traffic.
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:17:26,060'); seek(1046.0)">
              So I'd mentioned that holder rejects requests with 503s.
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:17:29,442'); seek(1049.0)">
              This is done early on in the request pipeline before any business
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:17:32,930'); seek(1052.0)">
              logic is executed so they're safe to retry on another
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:17:36,866'); seek(1056.0)">
              healthy host. This reduces overall member impact
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:17:40,460'); seek(1060.0)">
              because the 503 response is returned quickly
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:17:43,670'); seek(1063.0)">
              to the client, giving it time to retry the request someplace else.
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:17:48,198'); seek(1068.0)">
              But we don't want to blindly retry all requests that are
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:17:51,754'); seek(1071.0)">
              dropped by Hodor because if all hosts in these cluster are overloaded,
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:17:55,840'); seek(1075.0)">
              these sending additional retry traffic can actually make these problem
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:17:59,434'); seek(1079.0)">
              worse. To prevent this, we've added functionality
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:18:03,232'); seek(1083.0)">
              on the client and server side to be able to detect issues that are cluster
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:18:06,612'); seek(1086.0)">
              wide and prevent retry storms. This is done by
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:18:11,086'); seek(1091.0)">
              defining client and server side budgets and not
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:18:14,542'); seek(1094.0)">
              retrying when any of these budgets have been exceeded.
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:18:19,200'); seek(1099.0)">
              I'm going to talk briefly now about how we went about rolling this out to
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:18:22,786'); seek(1102.0)">
              the hundreds of separate microservices
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:18:26,760'); seek(1106.0)">
              that we operate at LinkedIn. So we needed to
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:18:30,450'); seek(1110.0)">
              be cautious when rolling this out to make sure that we weren't causing impact
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:18:34,460'); seek(1114.0)">
              to our members from any potential false positives from the
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:18:37,558'); seek(1117.0)">
              detectors. We did this by enabling the detectors in monitoring mode,
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:18:41,916'); seek(1121.0)">
              where the signal from the detectors is ignored by the load
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:18:45,264'); seek(1125.0)">
              shutter, but all relevant metrics are still active and collected.
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:18:49,600'); seek(1129.0)">
              So this allowed us to set up a pipeline for rollout where we could
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:18:53,198'); seek(1133.0)">
              monitor when detectors were firing and correlate those
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:18:56,702'); seek(1136.0)">
              events with other service metrics such as latency,
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:19:00,620'); seek(1140.0)">
              cpu usage, garbage collection activity, et cetera.
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:19:04,580'); seek(1144.0)">
              At the same time periods before enabling load shedding.
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:19:08,584'); seek(1148.0)">
              Though, we monitored a service for at least a week, which would include
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:19:12,712'); seek(1152.0)">
              load tests that were running in production during that time, we found that
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:19:16,562'); seek(1156.0)">
              some services were not good candidates for onboarding using our default
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:19:20,348'); seek(1160.0)">
              settings. These were almost always due to issues with garbage collection
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:19:24,556'); seek(1164.0)">
              and could usually be solved by tuning the GC. In some
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:19:28,582'); seek(1168.0)">
              cases, this actually led to significant discoveries around inefficient memory
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:19:32,668'); seek(1172.0)">
              allocation and usage patterns, which needed to be addressed in the service
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:19:36,090'); seek(1176.0)">
              but hadn't been surfaced before. Making changes
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:19:39,530'); seek(1179.0)">
              to address these ended up being significant wins for these services as they led
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:19:43,508'); seek(1183.0)">
              to reduced cpu usage, better overall performance
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:19:47,396'); seek(1187.0)">
              and scalability, and they were able to onboard the hodor's
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:19:51,028'); seek(1191.0)">
              protection as a side benefit.
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:19:53,980'); seek(1193.0)">
              So at the bottom here is a quote from one of the teams
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:19:57,688'); seek(1197.0)">
              after adoption adding overload detectors to
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:20:01,298'); seek(1201.0)">
              our service has surfaced unexpected behavior that owners were generally
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:20:05,192'); seek(1205.0)">
              not familiar with, and we've truly found some odd behavior
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:20:09,660'); seek(1209.0)">
              surfaced by our detectors. For example, in one service
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:20:13,878'); seek(1213.0)">
              we found that thread dumps were being automatically triggered and written
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:20:17,644'); seek(1217.0)">
              to disk periodically based on a setting that the owners had enabled
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:20:21,504'); seek(1221.0)">
              and forgotten about. The manifestation of this
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:20:24,842'); seek(1224.0)">
              was periodic freezes of the JVM while the thread dumps were happening,
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:20:28,826'); seek(1228.0)">
              which lasted over a few seconds in some cases, but this
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:20:32,986'); seek(1232.0)">
              didn't register in our higher percentile metrics,
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:20:35,876'); seek(1235.0)">
              so the service owners were never aware of the problem. Once onboarded
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:20:39,924'); seek(1239.0)">
              to Hodor, though, it became very clear when the detectors fired
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:20:43,268'); seek(1243.0)">
              and the load shutter engaged. There are other examples similar
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:20:46,866'); seek(1246.0)">
              to this where fairly impactful and usually fairly interesting behavior
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:20:51,000'); seek(1251.0)">
              went unnoticed until uncovered by our system.
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:20:55,440'); seek(1255.0)">
              So next I'm going to go through a quick example from one of our production
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:20:58,988'); seek(1258.0)">
              services.
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:21:01,860'); seek(1261.0)">
              So this is from our flagship application
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:21:05,846'); seek(1265.0)">
              which powers these main LinkedIn.com site as well as mobile
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:21:09,644'); seek(1269.0)">
              clients for iOS and Android. So we periodically do traffic
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:21:13,468'); seek(1273.0)">
              shifts between our data centers for various reasons. In one of
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:21:17,274'); seek(1277.0)">
              these cases, there was a new bug that was introduced in the service that only
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:21:20,890'); seek(1280.0)">
              appeared when the service was extremely stressed.
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:21:24,140'); seek(1284.0)">
              This traffic shift event triggered the bug,
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:21:27,236'); seek(1287.0)">
              and Hodor intervened aggressively to handle the situation.
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:21:31,100'); seek(1291.0)">
              You can see in these top graph that Hodor engaged for a
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:21:34,414'); seek(1294.0)">
              good amount of time with a few spikes which lined up directly with when
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:21:38,338'); seek(1298.0)">
              latencies were spiking. Overall,
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:21:41,080'); seek(1301.0)">
              about 20% of requests were dropped
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:21:44,440'); seek(1304.0)">
              during this overload period, which sounds bad, but when
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:21:47,730'); seek(1307.0)">
              sres investigated further, they found that if the load hadn't been shed,
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:21:51,964'); seek(1311.0)">
              this would likely have become a major site issue instead of a
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:21:55,238'); seek(1315.0)">
              minor one with a service down instead of still
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:21:58,886'); seek(1318.0)">
              serving partial amounts of traffic. We currently
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:22:02,026'); seek(1322.0)">
              have over 100 success stories similar to these where Hodor engaged to protect
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:22:06,026'); seek(1326.0)">
              a service and mitigate an issue to
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:22:10,218'); seek(1330.0)">
              end with. I'm going to talk about some related work that integrates
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:22:13,968'); seek(1333.0)">
              well with Hodor and some things that we have planned for the future.
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:22:20,140'); seek(1340.0)">
              First up is a project that has been integrated with Hodor and
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:22:23,918'); seek(1343.0)">
              live for some amount of time. Our term for it is traffic tiering,
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:22:27,992'); seek(1347.0)">
              but it's also known as traffic prioritization or traffic
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:22:31,208'); seek(1351.0)">
              shaping. It's a pretty simple concept. Some requests
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:22:34,712'); seek(1354.0)">
              can be considered more important than others. For example,
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:22:38,482'); seek(1358.0)">
              our web and mobile applications will often prefetch some data
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:22:42,086'); seek(1362.0)">
              that they expect might be used soon, but if it's not available, there's no
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:22:46,582'); seek(1366.0)">
              actual impact to the user, it just gets fetched later
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:22:50,614'); seek(1370.0)">
              on. Demand requests like this can be considered to be lower
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:22:54,186'); seek(1374.0)">
              priority than directly fetching data that the user has requested.
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:22:58,448'); seek(1378.0)">
              Similarly, we have offline jobs that utilize the same services
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:23:02,682'); seek(1382.0)">
              that take user traffic, but nobody's sitting
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:23:05,988'); seek(1385.0)">
              behind a screen waiting for that data. It's safe to retry
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:23:09,508'); seek(1389.0)">
              those offline requests at a later time when the service isn't overloaded.
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:23:13,476'); seek(1393.0)">
              So with traffic tiering, we're able to categorize different types
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:23:17,048'); seek(1397.0)">
              of requests into different categories and start
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:23:20,466'); seek(1400.0)">
              dropping traffic with the lowest importance at first, and only moving
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:23:24,530'); seek(1404.0)">
              to affect higher priority traffic if necessary.
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:23:29,200'); seek(1409.0)">
              Secondly, we're working on developing new types of detectors to cover blind
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:23:33,228'); seek(1413.0)">
              spots in the ones we have. One of these is actually a method of
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:23:36,902'); seek(1416.0)">
              confirming that the detected overload is impacting core metrics.
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:23:41,196'); seek(1421.0)">
              So we've had cases of false positives where there is an underlying
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:23:44,832'); seek(1424.0)">
              issue with these service, usually GC related, which isn't
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:23:48,672'); seek(1428.0)">
              affecting the user perceived performance, but is impacting the ability
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:23:52,432'); seek(1432.0)">
              of the app to scale further and maximize its capacity.
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:23:56,300'); seek(1436.0)">
              In these cases, we don't want to drop traffic, but we do want
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:23:59,726'); seek(1439.0)">
              to signal that there is an issue. So we're working on correlating CPU
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:24:03,668'); seek(1443.0)">
              or GCU overload signals with latency metrics
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:24:07,172'); seek(1447.0)">
              and only dropping traffic when there's a clear degradation in performance.
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:24:11,608'); seek(1451.0)">
              We're also starting to adapt Hodor to frameworks other than restly,
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:24:15,432'); seek(1455.0)">
              such as the play framework, as well as Neti. These have
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:24:19,606'); seek(1459.0)">
              different threading models and in some cases don't work as well with the heartbeat
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:24:23,708'); seek(1463.0)">
              based cpu detection. So for example, we're working
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:24:27,046'); seek(1467.0)">
              on detects specifically for Netty's event loop threading
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:24:31,004'); seek(1471.0)">
              model. Finally, we're looking into leveraging the overload
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:24:35,232'); seek(1475.0)">
              signals to feed them into our elastic scaling system,
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:24:38,794'); seek(1478.0)">
              so this seems like an obvious match. If a service cluster has become overloaded,
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:24:42,816'); seek(1482.0)">
              we can just spin up some more instances to alleviate the problem,
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:24:45,870'); seek(1485.0)">
              right? Well, it turns out it's not that simple, especially when
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:24:49,198'); seek(1489.0)">
              there are a mix of stateful and stateless systems within an
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:24:52,382'); seek(1492.0)">
              overloaded call tree. In many cases, just scaling up one
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:24:56,462'); seek(1496.0)">
              cluster that is overloaded would just propagate the issue further
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:24:59,732'); seek(1499.0)">
              downstream and cause even more issues. This is an area
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:25:03,790'); seek(1503.0)">
              where we're still exploring and hope to address in the future.
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:25:08,980'); seek(1508.0)">
              So I hope that this presentation was enlightening for you and
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:25:12,678'); seek(1512.0)">
              you learned something new. Thank you for your time. I'd also
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:25:15,862'); seek(1515.0)">
              like to thank the different teams at LinkedIn that came together to make this project
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:25:19,574'); seek(1519.0)">
              possible and successful. That's it from
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:25:22,838'); seek(1522.0)">
              us. Enjoy the rest of the conference.
            </span>
            
            </div>
          </div>
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Conf42%20SRE%202022%20-%20Bryan%20Barkley%20%26%20Vivek%20Deshpande.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Conf42%20SRE%202022%20-%20Bryan%20Barkley%20%26%20Vivek%20Deshpande.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #E36414;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/sre2022" class="btn btn-sm btn-danger shadow lift" style="background-color: #E36414;">
                <i class="fe fe-grid me-2"></i>
                See all 33 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/sre_bryan_vivek.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Bryan Barkley
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Senior Staff Engineer @ LinkedIn
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/bryanbarkley/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Bryan Barkley's LinkedIn account" />
                  </a>
                  
                  
                </p>
                
                <!-- Author 2 -->
                <h2 class="me-2">
                  Vivek Deshpande
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Senior Software Engineer @ LinkedIn
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-8">
                  
                  <a href="https://www.linkedin.com/in/vivdesh/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Vivek Deshpande's LinkedIn account" />
                  </a>
                  
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by Bryan Barkley"
                  data-url="https://www.conf42.com/sre2022"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/sre2022"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>





  <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
    </script>
    <!-- SUBSCRIBE -->
    <section class="pt-8 pt-md-11 bg-gradient-light-white" id="register">
        <div class="container">
          <div class="row align-items-center justify-content-between mb-8 mb-md-11">
            <div class="col-12 col-md-6 order-md-2" data-aos="fade-left">
  
              <!-- Heading -->
              <h2>
                Awesome tech events for <br>
                <span class="text-success"><span data-typed='{"strings": ["software engineers.", "tech leaders.", "SREs.", "DevOps.", "CTOs.",  "managers.", "architects.", "QAs.", "developers.", "coders.", "founders.", "CEOs.", "students.", "geeks.", "ethical hackers.", "educators.", "enthusiasts.", "directors.", "researchers.", "PHDs.", "evangelists.", "tech authors."]}'></span></span>
              </h2>
  
              <!-- Text -->
              <p class="fs-lg text-muted mb-6">
  
              </p>
  
              <!-- List -->
              <div class="row">
                <div class="col-12 col-lg-12">
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <!-- Text -->
                    <p class="text-success">
                      Priority access to all content
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Video hallway track
                    </p>
                  </div>

                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Community chat
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Exclusive promotions and giveaways
                    </p>
                  </div>
  
                </div>
              </div> <!-- / .row -->
  
            </div>
            <div class="col-12 col-md-6 col-lg-5 order-md-1">
  
              <!-- Card -->
              <div class="card shadow-light-lg">
  
                <!-- Body -->
                <div class="card-body">
  
                  <!-- Form -->
                  <link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
                  <p class="emailoctopus-success-message text-success"></p>
                  <p class="emailoctopus-error-message text-danger"></p>
                  <form
                    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
                    method="post"
                    data-message-success="Thanks! Check your email for further directions!"
                    data-message-missing-email-address="Your email address is required."
                    data-message-invalid-email-address="Your email address looks incorrect, please try again."
                    data-message-bot-submission-error="This doesn't look like a human submission."
                    data-message-consent-required="Please check the checkbox to indicate your consent."
                    data-message-invalid-parameters-error="This form has missing or invalid fields."
                    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
                    class="emailoctopus-form"
                    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
                  >
                    <div class="form-floating emailoctopus-form-row">
                      <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
                      <label for="field_0">Email address</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
                      <label for="field_1">First Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
                      <label for="field_2">Last Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
                      <label for="field_4">Company</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
                      <label for="field_5">Job Title</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
                      <label for="field_3">Phone Number</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
                        oninput="updateCountry()"
                      >
                        <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
                      </select>
                      <label for="field_7">Country</label>
                    </div>
                    <input id="country-destination" name="field_7" type="hidden">
                    <input id="tz-country" name="field_8" type="hidden">
                    
                    <input
                      name="field_6"
                      type="hidden"
                      value="Site Reliability Engineering"
                    >
                    
                    <div class="emailoctopus-form-row-consent">
                      <input
                        type="checkbox"
                        id="consent"
                        name="consent"
                      >
                      <label for="consent">
                        I consent to the following terms:
                      </label>
                      <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
                        Terms and Conditions
                      </a>
                      &amp;
                      <a href="./code-of-conduct" target="_blank">
                        Code of Conduct
                      </a>
                    </div>
                    <div
                      aria-hidden="true"
                      class="emailoctopus-form-row-hp"
                    >
                      <input
                        type="text"
                        name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
                        tabindex="-1"
                        autocomplete="nope"
                      >
                    </div>
                    <div class="mt-6 emailoctopus-form-row-subscribe">
                      <input
                        type="hidden"
                        name="successRedirectUrl"
                      >
                      <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
                        Subscribe
                      </button>
                    </div>
                  </form>
  
                </div>
  
              </div>
  
            </div>
  
          </div> <!-- / .row -->
        </div> <!-- / .container -->
      </section>

      <!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
      <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://sreday.com/2024-amsterdam/">
                  SREday Amsterdam 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>